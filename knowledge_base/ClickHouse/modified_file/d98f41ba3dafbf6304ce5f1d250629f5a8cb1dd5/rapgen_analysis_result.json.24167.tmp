{
  "status": "completed",
  "commit_dir": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/ClickHouse/modified_file/d98f41ba3dafbf6304ce5f1d250629f5a8cb1dd5",
  "file_info": {
    "before_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/ClickHouse/modified_file/d98f41ba3dafbf6304ce5f1d250629f5a8cb1dd5/before.cpp",
    "after_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/ClickHouse/modified_file/d98f41ba3dafbf6304ce5f1d250629f5a8cb1dd5/after.cpp",
    "diff_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/ClickHouse/modified_file/d98f41ba3dafbf6304ce5f1d250629f5a8cb1dd5/diff.txt"
  },
  "semgrep_analysis": {
    "is_api_change": false,
    "api_changes": {
      "replacements": [],
      "additions": [],
      "deletions": [
        {
          "line": 515,
          "api": "rder_descr, limit);\n\n\t\t/// Ограничения на сортировку",
          "text": "rder_descr, limit);\n\n\t\t/// Ограничения на сортировку\n\t\t",
          "line_content": "\tquery_analyzer->getAggregateInfo(key_names, aggregates);"
        },
        {
          "line": 519,
          "api": "setLimits",
          "text": "overflow_mode;\n\t\tsorting_stream->setLimits(limits);\n\t\t\t\n\t\tstream = maybeAsynchronous(sorting_stream, i",
          "line_content": "\tstream = maybeAsynchronous(new FinalizingAggregatedBlockInputStream(stream, aggregates), settings.asynchronous);"
        },
        {
          "line": 526,
          "api": "stream = new U",
          "text": "stream = new U",
          "line_content": "\tif (streams.size() == 1)"
        },
        {
          "line": 531,
          "api": "ous",
          "text": "ous(new MergeSort",
          "line_content": "\tstreams.resize(1);"
        },
        {
          "line": 538,
          "api": "size",
          "text": "s && streams.size() <= settings.max_threads;\n\tfor (Bloc",
          "line_content": "\tquery_analyzer->getAggregateInfo(key_names, aggregates);"
        },
        {
          "line": 539,
          "api": "begin",
          "text": "terator it = streams.begin(); it != streams.end(); ++it)\n\t{\n\t\tBlockInputStreamPtr & stream = *it;\n\t\tstream = maybeAsynchronous(new ExpressionBlockInputStream(s",
          "line_content": "\tstreams[0] = maybeAsynchronous(new MergingAggregatedBlockInputStream(streams[0], key_names, aggregates, query.group_by_with_totals, separate_totals), settings.asynchronous);"
        },
        {
          "line": 545,
          "api": "{\n\t\tsize_t lim",
          "text": "{\n\t\tsize_t lim",
          "line_content": "\tbool is_async = settings.asynchronous && streams.size() <= settings.max_threads;"
        },
        {
          "line": 34,
          "api": "dynamic_cast<ASTSelectQuery &>(*query_ptr)",
          "text": "dynamic_cast<ASTSelectQuery &>(*query_ptr)",
          "line_content": "\t: query_ptr(query_ptr_), query(dynamic_cast<ASTSelectQuery &>(*query_ptr)),"
        },
        {
          "line": 35,
          "api": "getSettings",
          "text": "context.getSettings()",
          "line_content": "\tcontext(context_), settings(context.getSettings()), to_stage(to_stage_), subquery_depth(subquery_depth_),"
        },
        {
          "line": 36,
          "api": "Logger::get(\"InterpreterSelectQuery\")",
          "text": "Logger::get(\"InterpreterSelectQuery\")",
          "line_content": "\tlog(&Logger::get(\"InterpreterSelectQuery\"))"
        },
        {
          "line": 546,
          "api": "limit_offset",
          "text": " limit_offset",
          "line_content": "\tfor (BlockInputStreams::iterator it = streams.begin(); it != streams.end(); ++it)"
        },
        {
          "line": 549,
          "api": "стадии DISTINCT не будет выполняться ORDER BY, то можно достать не более limit_",
          "text": "стадии DISTINCT не будет выполняться ORDER BY, то можно достать не более limit_",
          "line_content": "\t\tstream = maybeAsynchronous(new ExpressionBlockInputStream(stream, expression), is_async);"
        },
        {
          "line": 39,
          "api": "toString",
          "text": "toString(settings.limits.max_subquery_depth)",
          "line_content": "\t\tthrow Exception(\"Too deep subqueries. Maximum: \" + toString(settings.limits.max_subquery_depth),"
        },
        {
          "line": 550,
          "api": "on_list || !before_order)\n\t\t\tlimit_for_d",
          "text": "on_list || !before_order)\n\t\t\tlimit_for_d",
          "line_content": "\t\tstream = maybeAsynchronous(new FilterBlockInputStream(stream, query.having_expression->getColumnName()), is_async);"
        },
        {
          "line": 42,
          "api": "dynamic_cast<ASTSelectQuery *>(&*query.table)",
          "text": "dynamic_cast<ASTSelectQuery *>(&*query.table)",
          "line_content": "\tcontext.setColumns(!query.table || !dynamic_cast<ASTSelectQuery *>(&*query.table)"
        },
        {
          "line": 43,
          "api": "getColumnsList",
          "text": "getTable()->getColumnsList()",
          "line_content": "\t\t? getTable()->getColumnsList()"
        },
        {
          "line": 44,
          "api": "getSampleBlock",
          "text": "InterpreterSelectQuery(query.table, context).getSampleBlock().getColumnsList()",
          "line_content": "\t\t: InterpreterSelectQuery(query.table, context).getSampleBlock().getColumnsList());"
        },
        {
          "line": 557,
          "api": "it != streams",
          "text": " it != streams",
          "line_content": "\tbool is_async = settings.asynchronous && streams.size() <= settings.max_threads;"
        },
        {
          "line": 46,
          "api": "getColumns",
          "text": "context.getColumns().empty()",
          "line_content": "\tif (context.getColumns().empty())"
        },
        {
          "line": 47,
          "api": "Exception",
          "text": "Exception(\"There are no available columns\", ErrorCodes::THERE_IS_NO_COLUMN)",
          "line_content": "\t\tthrow Exception(\"There are no available columns\", ErrorCodes::THERE_IS_NO_COLUMN);"
        },
        {
          "line": 558,
          "api": "ew DistinctBl",
          "text": "ew DistinctBl",
          "line_content": "\tfor (BlockInputStreams::iterator it = streams.begin(); it != streams.end(); ++it)"
        },
        {
          "line": 561,
          "api": "is_async);\n\t\t}\n\t}\n}\n\n\nvoid InterpreterSelectQuery::executeUnion(BlockInputStre",
          "text": " is_async);\n\t\t}\n\t}\n}\n\n\nvoid InterpreterSelectQuery::executeUnion(BlockInputStre",
          "line_content": "\t\tstream = maybeAsynchronous(new ExpressionBlockInputStream(stream, expression), is_async);"
        },
        {
          "line": 569,
          "api": "UnionBlockInputStream",
          "text": "UnionBlockInputStream(streams, settings.max_",
          "line_content": "\torder_descr.reserve(query.order_expression_list->children.size());"
        },
        {
          "line": 570,
          "api": ";\n\t}\n}\n\n\n/// Предварительный LIMIT - применяе",
          "text": ";\n\t}\n}\n\n\n/// Предварительный LIMIT - применяе",
          "line_content": "\tfor (ASTs::iterator it = query.order_expression_list->children.begin();"
        },
        {
          "line": 571,
          "api": "ом источнике, если источников несколько, до",
          "text": "ом источнике, если источников несколько, до",
          "line_content": "\t\tit != query.order_expression_list->children.end();"
        },
        {
          "line": 574,
          "api": "terSelectQuery::executePreLimit(BlockIn",
          "text": "terSelectQuery::executePreLimit(BlockIn",
          "line_content": "\t\tString name = (*it)->children.front()->getColumnName();"
        },
        {
          "line": 575,
          "api": "e_t limit_offset = 0;\n\tgetLimitLengthAn",
          "text": "e_t limit_offset = 0;\n\tgetLimitLengthAn",
          "line_content": "\t\torder_descr.push_back(SortColumnDescription(name, dynamic_cast<ASTOrderByElement &>(**it).direction));"
        },
        {
          "line": 64,
          "api": "dentifier &>(*query.database",
          "text": "dentifier &>(*query.database",
          "line_content": "\t\tdatabase_name = context.getCurrentDatabase();"
        },
        {
          "line": 67,
          "api": "ynamic_cast<ASTIdentifier &>(*query.table).nam",
          "text": "ynamic_cast<ASTIdentifier &>(*query.table).nam",
          "line_content": "\t\tdatabase_name = dynamic_cast<ASTIdentifier &>(*query.database).name;"
        },
        {
          "line": 69,
          "api": "::getTable()\n{\n\tString database_name;\n\tStri",
          "text": "::getTable()\n{\n\tString database_name;\n\tStri",
          "line_content": "\t\ttable_name = dynamic_cast<ASTIdentifier &>(*query.table).name;"
        },
        {
          "line": 581,
          "api": "d",
          "text": "d(); ++it)\n\t\t{\n\t\t\tBlockInputStreamPtr & stream = *it;\n\t\t\ts",
          "line_content": "\tgetLimitLengthAndOffset(query, limit_length, limit_offset);"
        },
        {
          "line": 584,
          "api": "InterpreterSe",
          "text": " InterpreterSe",
          "line_content": "\tbool is_async = settings.asynchronous && streams.size() <= settings.max_threads;"
        },
        {
          "line": 585,
          "api": "limit_offset",
          "text": " limit_offset",
          "line_content": "\tfor (BlockInputStreams::iterator it = streams.begin(); it != streams.end(); ++it)"
        },
        {
          "line": 78,
          "api": "name, table_name);\n}\n\n\nASTPtr InterpreterSelectQuer",
          "text": "name, table_name);\n}\n\n\nASTPtr InterpreterSelectQuer",
          "line_content": "\tgetDatabaseAndTableNames(database_name, table_name);"
        },
        {
          "line": 79,
          "api": "teQuery",
          "text": "teQuery()\n{\n\tString database_name;\n\tString ",
          "line_content": "\treturn context.getTable(database_name, table_name);"
        },
        {
          "line": 595,
          "api": "faultFormat",
          "text": "faultFormat();\n\n\tBlockInputStream",
          "line_content": "\t\tsorting_stream->setLimits(limits);"
        },
        {
          "line": 597,
          "api": ");\n\tBlockOutputStreamPtr out = context.getF",
          "text": ");\n\tBlockOutputStreamPtr out = context.getF",
          "line_content": "\t\tstream = maybeAsynchronous(sorting_stream, is_async);"
        },
        {
          "line": 88,
          "api": "abase_name, table_name);\n}\n\n\nDataTypes InterpreterS",
          "text": "abase_name, table_name);\n}\n\n\nDataTypes InterpreterS",
          "line_content": "\tgetDatabaseAndTableNames(database_name, table_name);"
        },
        {
          "line": 89,
          "api": "::getReturnTypes()\n{\n\tDataTypes res;\n\tNamesAndTyp",
          "text": "::getReturnTypes()\n{\n\tDataTypes res;\n\tNamesAndTyp",
          "line_content": "\treturn context.getCreateQuery(database_name, table_name);"
        },
        {
          "line": 603,
          "api": "",
          "text": "",
          "line_content": "\tif (streams.size() > 1)"
        },
        {
          "line": 606,
          "api": "",
          "text": "",
          "line_content": "\t\tstreams.resize(1);"
        },
        {
          "line": 96,
          "api": "begin",
          "text": "tor it = columns.begin(); it != columns.end(); ++it)\n\t{",
          "line_content": "\tNamesAndTypesList columns = query_analyzer->getSelectSampleBlock().getColumnsList();"
        },
        {
          "line": 97,
          "api": "terSelectQuer",
          "text": "terSelectQuer",
          "line_content": "\tfor (NamesAndTypesList::iterator it = columns.begin(); it != columns.end(); ++it)"
        },
        {
          "line": 610,
          "api": "",
          "text": "",
          "line_content": "\tstream = maybeAsynchronous(new MergeSortingBlockInputStream(stream, order_descr, limit), is_async);"
        },
        {
          "line": 99,
          "api": "lock",
          "text": "lock()\n{\n\tBlock block = q",
          "line_content": "\t\tres.push_back(it->second);"
        },
        {
          "line": 616,
          "api": "",
          "text": "",
          "line_content": "\tbool is_async = settings.asynchronous && streams.size() <= settings.max_threads;"
        },
        {
          "line": 617,
          "api": "",
          "text": "",
          "line_content": "\tfor (BlockInputStreams::iterator it = streams.begin(); it != streams.end(); ++it)"
        },
        {
          "line": 107,
          "api": "ock можно было\n\t/// писать (читать) с",
          "text": "ock можно было\n\t/// писать (читать) с ",
          "line_content": "\tBlock block = query_analyzer->getSelectSampleBlock();"
        },
        {
          "line": 620,
          "api": "",
          "text": "",
          "line_content": "\t\tstream = maybeAsynchronous(new ExpressionBlockInputStream(stream, expression), is_async);"
        },
        {
          "line": 110,
          "api": "Превращает ист",
          "text": " Превращает ист",
          "line_content": "\tfor (size_t i = 0; i < block.columns(); ++i)"
        },
        {
          "line": 112,
          "api": "tic inline BlockInputS",
          "text": "tic inline BlockInputS",
          "line_content": "\t\tColumnWithNameAndType & col = block.getByPosition(i);"
        },
        {
          "line": 113,
          "api": "nchronous",
          "text": "nchronous(BlockInputStre",
          "line_content": "\t\tcol.column = col.type->createColumn();"
        },
        {
          "line": 631,
          "api": "",
          "text": "",
          "line_content": "\t\tgetLimitLengthAndOffset(query, limit_length, limit_offset);"
        },
        {
          "line": 639,
          "api": "",
          "text": "",
          "line_content": "\t\tbool is_async = settings.asynchronous && streams.size() <= settings.max_threads;"
        },
        {
          "line": 640,
          "api": "",
          "text": "",
          "line_content": "\t\tfor (BlockInputStreams::iterator it = streams.begin(); it != streams.end(); ++it)"
        },
        {
          "line": 643,
          "api": "",
          "text": "",
          "line_content": "\t\t\tstream = maybeAsynchronous(new DistinctBlockInputStream(stream, settings.limits, limit_for_distinct), is_async);"
        },
        {
          "line": 652,
          "api": "",
          "text": "",
          "line_content": "\tif (streams.size() > 1)"
        },
        {
          "line": 142,
          "api": "r_and_select;\n\t\tExpressionAc",
          "text": "r_and_select;\n\t\tExpressionAc",
          "line_content": "\tQueryProcessingStage::Enum from_stage = executeFetchColumns(streams);"
        },
        {
          "line": 655,
          "api": "",
          "text": "",
          "line_content": "\t\tstreams.resize(1);"
        },
        {
          "line": 145,
          "api": "ставим цепочку",
          "text": "ставим цепочку ",
          "line_content": "\tif (streams.empty())"
        },
        {
          "line": 148,
          "api": "hasAggregation",
          "text": "r->hasAggregation();\n\t\t\t\n\t\tif (from_stag",
          "line_content": "\tLOG_TRACE(log, QueryProcessingStage::toString(from_stage) << \" -> \" << QueryProcessingStage::toString(to_stage));"
        },
        {
          "line": 665,
          "api": "",
          "text": "",
          "line_content": "\tgetLimitLengthAndOffset(query, limit_length, limit_offset);"
        },
        {
          "line": 670,
          "api": "",
          "text": "",
          "line_content": "\t\tfor (BlockInputStreams::iterator it = streams.begin(); it != streams.end(); ++it)"
        },
        {
          "line": 167,
          "api": "insert",
          "text": "output.insert(chain.getLastStep(",
          "line_content": "\t\tneed_aggregate = query_analyzer->hasAggregation();"
        },
        {
          "line": 683,
          "api": "",
          "text": "",
          "line_content": "\tgetLimitLengthAndOffset(query, limit_length, limit_offset);"
        },
        {
          "line": 172,
          "api": "addStep",
          "text": ".addStep();\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tif (need",
          "line_content": "\t\t\tquery_analyzer->appendArrayJoin(chain);"
        },
        {
          "line": 174,
          "api": "{\n\t\t\t\tquery_analyzer->appendGrou",
          "text": "\t\t{\n\t\t\t\tquery_analyzer->appendGrou",
          "line_content": "\t\t\tif (query_analyzer->appendWhere(chain))"
        },
        {
          "line": 177,
          "api": "unctionsArguments",
          "text": "unctionsArguments(chai",
          "line_content": "\t\t\t\tbefore_where = chain.getLastActions();"
        },
        {
          "line": 182,
          "api": "= true;\n\t\t\t\tbefore_having = chain.g",
          "text": " = true;\n\t\t\t\tbefore_having = chain.g",
          "line_content": "\t\t\t\t\tNames columns = query_analyzer->getRequiredColumns();"
        },
        {
          "line": 183,
          "api": "appendSelect",
          "text": "query_analyzer->appendSelect(chain);\n\t\t\th",
          "line_content": "\t\t\t\t\tchain.getLastStep().required_output.insert(chain.getLastStep().required_output.end(),"
        },
        {
          "line": 184,
          "api": "ndOrderBy",
          "text": "ndOrderBy(cha",
          "line_content": "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcolumns.begin(), columns.end());"
        },
        {
          "line": 696,
          "api": "",
          "text": "",
          "line_content": "\tBlock sample = getSampleBlock();"
        },
        {
          "line": 186,
          "api": "_order_and_selec",
          "text": "_order_and_selec",
          "line_content": "\t\t\t\t\tchain.finalize();"
        },
        {
          "line": 697,
          "api": "",
          "text": "",
          "line_content": "\tString format_name = query.format ? dynamic_cast<ASTIdentifier &>(*query.format).name : context.getDefaultFormat();"
        },
        {
          "line": 699,
          "api": "",
          "text": "",
          "line_content": "\tBlockInputStreamPtr in = execute();"
        },
        {
          "line": 700,
          "api": "",
          "text": "",
          "line_content": "\tBlockOutputStreamPtr out = context.getFormatFactory().getOutput(format_name, buf, sample);"
        },
        {
          "line": 190,
          "api": "chain.addSte",
          "text": "\t\t\tchain.addSte",
          "line_content": "\t\t\t\t\tchain.addStep();"
        },
        {
          "line": 702,
          "api": "",
          "text": "",
          "line_content": "\tcopyData(*in, *out);"
        },
        {
          "line": 196,
          "api": "hain);\n\t\t\tfinal_projection = chain.g",
          "text": "hain);\n\t\t\tfinal_projection = chain.g",
          "line_content": "\t\t\t\tquery_analyzer->appendGroupBy(chain);"
        },
        {
          "line": 197,
          "api": "finalize",
          "text": "Actions();\n\t\t\tchain.finalize();\n\t\t\t\n\t\t\t/// Если предыдущ",
          "line_content": "\t\t\t\tquery_analyzer->appendAggregateFunctionsArguments(chain);"
        },
        {
          "line": 198,
          "api": "сь отдельно, нам могли",
          "text": "сь отдельно, нам могли",
          "line_content": "\t\t\t\tbefore_aggregation = chain.getLastActions();"
        },
        {
          "line": 200,
          "api": "х столбцов (напр",
          "text": "х столбцов (напр",
          "line_content": "\t\t\t\tchain.finalize();"
        },
        {
          "line": 202,
          "api": "ьзуемых тольк",
          "text": "ьзуемых тольк",
          "line_content": "\t\t\t\tchain.clear();"
        },
        {
          "line": 209,
          "api": "re_order_and_select->prependProject",
          "text": "re_order_and_select->prependProject",
          "line_content": "\t\t\tif (need_aggregate && query_analyzer->appendHaving(chain))"
        },
        {
          "line": 212,
          "api": "м из блока лишние стол",
          "text": "м из блока лишние стол",
          "line_content": "\t\t\t\tbefore_having = chain.getLastActions();"
        },
        {
          "line": 213,
          "api": "основном, ключ",
          "text": " основном, ключ",
          "line_content": "\t\t\t\tchain.addStep();"
        },
        {
          "line": 216,
          "api": "if (has_having)\n\t\t\t\tbefore_havin",
          "text": "\t\t\tif (has_having)\n\t\t\t\tbefore_havin",
          "line_content": "\t\t\tquery_analyzer->appendSelect(chain);"
        },
        {
          "line": 217,
          "api": "ut",
          "text": "ut();\n\t\t}\n\t\t\n\t\t/// Теперь составим п",
          "line_content": "\t\t\thas_order_by = query_analyzer->appendOrderBy(chain);"
        },
        {
          "line": 218,
          "api": "е действия.\n\t\t\n\t\tif (f",
          "text": "е действия.\n\t\t\n\t\tif (f",
          "line_content": "\t\t\tbefore_order_and_select = chain.getLastActions();"
        },
        {
          "line": 219,
          "api": "tage < QueryPro",
          "text": "tage < QueryPro",
          "line_content": "\t\t\tchain.addStep();"
        },
        {
          "line": 221,
          "api": "age::WithMergeableState\n\t\t\t&& to_stage >=",
          "text": "age::WithMergeableState\n\t\t\t&& to_stage >= ",
          "line_content": "\t\t\tquery_analyzer->appendProjectResult(chain);"
        },
        {
          "line": 222,
          "api": "thMergeableState)\n\t\t{",
          "text": "thMergeableState)\n\t\t{\n",
          "line_content": "\t\t\tfinal_projection = chain.getLastActions();"
        },
        {
          "line": 223,
          "api": "(has_where)",
          "text": " (has_where)\n\t\t\t",
          "line_content": "\t\t\tchain.finalize();"
        },
        {
          "line": 228,
          "api": "d_aggregate && !has_having && !has_order_by",
          "text": "d_aggregate && !has_having && !has_order_by\n\t\t",
          "line_content": "\t\t\t\tbefore_order_and_select->prependProjectInput();"
        },
        {
          "line": 232,
          "api": ")\n\t\t{\n\t\t\tif (need_aggregate)\n\t\t\t{",
          "text": ")\n\t\t{\n\t\t\tif (need_aggregate)\n\t\t\t{\n\t\t",
          "line_content": "\t\t\t\tbefore_having->prependProjectInput();"
        },
        {
          "line": 241,
          "api": "s, before_having);\n\t\t\t\n\t\t\texecuteOu",
          "text": "s, before_having);\n\t\t\t\n\t\t\texecuteOu",
          "line_content": "\t\t\t\texecuteWhere(streams, before_where);"
        },
        {
          "line": 244,
          "api": "er_and_select);\n\t\t\t\n\t\t\tif (has_order_by)\n\t\t\t\tex",
          "text": "er_and_select);\n\t\t\t\n\t\t\tif (has_order_by)\n\t\t\t\tex",
          "line_content": "\t\t\t\texecuteAggregation(streams, before_aggregation);"
        },
        {
          "line": 254,
          "api": "ько и есть LIMIT, то сна",
          "text": "ько и есть LIMIT, то сна",
          "line_content": "\t\t\t\texecutePreLimit(streams);"
        },
        {
          "line": 265,
          "api": "ния.\n\t\t\tif (need_second_distinc",
          "text": "ния.\n\t\t\tif (need_second_distinc",
          "line_content": "\t\t\t\t\texecuteMergeAggregated(streams);"
        },
        {
          "line": 267,
          "api": "executeDistinct(streams, false);",
          "text": "\texecuteDistinct(streams, false);\n",
          "line_content": "\t\t\t\texecuteFinalizeAggregates(streams);"
        },
        {
          "line": 271,
          "api": "ях, DISTINCT можно было бы применять",
          "text": "ях, DISTINCT можно было бы применять ",
          "line_content": "\t\t\t\texecuteHaving(streams, before_having);"
        },
        {
          "line": 273,
          "api": "*  - до сортировки и, возможно, на удалённых серверах",
          "text": "\t  *  - до сортировки и, возможно, на удалённых серверах",
          "line_content": "\t\t\texecuteOuterExpression(streams, before_order_and_select);"
        },
        {
          "line": 276,
          "api": "ams);\n\t\t}\n\t}\n\n\texecut",
          "text": "ams);\n\t\t}\n\t}\n\n\texecut",
          "line_content": "\t\t\t\texecuteOrder(streams);"
        },
        {
          "line": 278,
          "api": "reams);\n\n\t/// Ограничения на результат, квот",
          "text": "reams);\n\n\t/// Ограничения на результат, квот",
          "line_content": "\t\t\texecuteProjection(streams, final_projection);"
        },
        {
          "line": 281,
          "api": "c_cast<IProfilingBlockInputStr",
          "text": "c_cast<IProfilingBlockInputStr",
          "line_content": "\t\t\texecuteDistinct(streams, true);"
        },
        {
          "line": 285,
          "api": "if (to_sta",
          "text": "\n\t\tif (to_sta",
          "line_content": "\t\t\t\tfor (BlockInputStreams::iterator it = streams.begin(); it != streams.end(); ++it)"
        },
        {
          "line": 286,
          "api": "BlockInputStream::LocalLimits limits;\n\t\t\tlimits.m",
          "text": "BlockInputStream::LocalLimits limits;\n\t\t\tlimits.m",
          "line_content": "\t\t\t\t\tif (IProfilingBlockInputStream * stream = dynamic_cast<IProfilingBlockInputStream *>(&**it))"
        },
        {
          "line": 287,
          "api": "to_read = settings.limit",
          "text": "to_read = settings.limit",
          "line_content": "\t\t\t\t\t\tstream->enableExtremes();"
        },
        {
          "line": 292,
          "api": "imitLengthAndO",
          "text": "imitLengthAndO",
          "line_content": "\t\t\tif (query.limit_length && streams.size() > 1)"
        },
        {
          "line": 293,
          "api": "electQuery & query, size",
          "text": "electQuery & query, size",
          "line_content": "\t\t\t\texecutePreLimit(streams);"
        },
        {
          "line": 295,
          "api": "0;\n\toffset = 0",
          "text": "0;\n\toffset = 0",
          "line_content": "\t\t\tbool need_second_distinct_pass = streams.size() > 1;"
        },
        {
          "line": 297,
          "api": "limit_length)\n\t{\n\t\tle",
          "text": "limit_length)\n\t{\n\t\tle",
          "line_content": "\t\t\texecuteUnion(streams);"
        },
        {
          "line": 301,
          "api": "cessingStage::Enum InterpreterS",
          "text": "cessingStage::Enum InterpreterS",
          "line_content": "\t\t\t\texecuteDistinct(streams, false);"
        },
        {
          "line": 307,
          "api": "ery;\n\n\tif (!query.tab",
          "text": "ery;\n\n\tif (!query.tab",
          "line_content": "\t\t\texecuteLimit(streams);"
        },
        {
          "line": 311,
          "api": "mic_cast<ASTSelectQue",
          "text": "mic_cast<ASTSelectQue",
          "line_content": "\texecuteUnion(streams);"
        },
        {
          "line": 314,
          "api": "lectQuery *>(&*query.table))\n\t\tinterpreter_subquery = ne",
          "text": "lectQuery *>(&*query.table))\n\t\tinterpreter_subquery = ne",
          "line_content": "\tif (IProfilingBlockInputStream * stream = dynamic_cast<IProfilingBlockInputStream *>(&*streams[0]))"
        },
        {
          "line": 316,
          "api": "e, context, QueryProcessingSt",
          "text": "e, context, QueryProcessingSt",
          "line_content": "\t\tstream->setProgressCallback(context.getProgressCallback());"
        },
        {
          "line": 317,
          "api": "if (query.sample_size && (!t",
          "text": "\n\n\tif (query.sample_size && (!t",
          "line_content": "\t\tstream->setProcessListElement(context.getProcessListElement());"
        },
        {
          "line": 327,
          "api": "в.\n\t  * Если у нас 20 уда",
          "text": "в.\n\t  * Если у нас 20 уда",
          "line_content": "\t\t\tstream->setLimits(limits);"
        },
        {
          "line": 328,
          "api": "_threads = 8, то б",
          "text": "_threads = 8, то б",
          "line_content": "\t\t\tstream->setQuota(context.getQuota(), IProfilingBlockInputStream::QUOTA_RESULT);"
        },
        {
          "line": 342,
          "api": "чение max_threads в settings_for_storage\n\t  *",
          "text": "чение max_threads в settings_for_storage\n\t  *  ",
          "line_content": "\t\tlength = safeGet<UInt64>(dynamic_cast<ASTLiteral &>(*query.limit_length).value);"
        },
        {
          "line": 344,
          "api": "елённой обработке запроса,\n\t  *  и там должно б",
          "text": "елённой обработке запроса,\n\t  *  и там должно б",
          "line_content": "\t\t\toffset = safeGet<UInt64>(dynamic_cast<ASTLiteral &>(*query.limit_offset).value);"
        },
        {
          "line": 356,
          "api": "f (settings.limits.max_columns_to_read && req",
          "text": "f (settings.limits.max_columns_to_read && req",
          "line_content": "\tif (!query.table || !dynamic_cast<ASTSelectQuery *>(&*query.table))"
        },
        {
          "line": 358,
          "api": "ize",
          "text": "ize() > se",
          "line_content": "\t\ttable = getTable();"
        },
        {
          "line": 359,
          "api": "imits.max_column",
          "text": "imits.max_column",
          "line_content": "\t\tif (table->getName() == \"VIEW\")"
        },
        {
          "line": 360,
          "api": "to read exc",
          "text": "to read exc",
          "line_content": "\t\t\tquery.table = dynamic_cast<StorageView *> (table.get())->getInnerQuery();"
        },
        {
          "line": 362,
          "api": "size",
          "text": "ing(required_columns.size())\n\t\t\t+ \", maximum:",
          "line_content": "\telse if (dynamic_cast<ASTSelectQuery *>(&*query.table))"
        },
        {
          "line": 365,
          "api": "y, limit_length, limit_of",
          "text": "y, limit_length, limit_of",
          "line_content": "\tif (query.sample_size && (!table || !table->supportsSampling()))"
        },
        {
          "line": 366,
          "api": "* Оптимизация - если не указаны DISTINCT, WHERE, GROUP, HAVING, ORDER, но указан LIMIT, и limit",
          "text": "* Оптимизация - если не указаны DISTINCT, WHERE, GROUP, HAVING, ORDER, но указан LIMIT, и limit",
          "line_content": "\t\tthrow Exception(\"Illegal SAMPLE: table doesn't support sampling\", ErrorCodes::SAMPLING_NOT_SUPPORTED);"
        },
        {
          "line": 368,
          "api": "в качестве размера бл",
          "text": " в качестве размера бл",
          "line_content": "\tif (query.final && (!table || !table->supportsFinal()))"
        },
        {
          "line": 369,
          "api": "спользовать limit + offset (чтобы не читать из таблиц",
          "text": "спользовать limit + offset (чтобы не читать из таблиц",
          "line_content": "\t\tthrow Exception(\"Illegal FINAL\", ErrorCodes::ILLEGAL_FINAL);"
        },
        {
          "line": 383,
          "api": "ом неэффективно.)",
          "text": "ом неэффективно.)",
          "line_content": "\tif (table && table->isRemote())"
        },
        {
          "line": 387,
          "api": "е ограничения проверяются на сервере",
          "text": "е ограничения проверяются на сервере",
          "line_content": "\tNames required_columns = query_analyzer->getRequiredColumns();"
        },
        {
          "line": 390,
          "api": "рах.\n\t  */\n\tif (table &",
          "text": "рах.\n\t  */\n\tif (table &",
          "line_content": "\tif (settings.limits.max_columns_to_read && required_columns.size() > settings.limits.max_columns_to_read)"
        },
        {
          "line": 391,
          "api": "IProfilingBlockInputStream::LocalLimits limits;\n\t\tlimits.max_rows_to_read = settings.limits.max_rows_to_read;\n\t\tlimits.max_bytes_to_read = settings.limits.max_bytes_to_read;\n\t\tlimits.read_overflow_mode = setti",
          "text": "\n\t\tIProfilingBlockInputStream::LocalLimits limits;\n\t\tlimits.max_rows_to_read = settings.limits.max_rows_to_read;\n\t\tlimits.max_bytes_to_read = settings.limits.max_bytes_to_read;\n\t\tlimits.read_overflow_mode = setti",
          "line_content": "\t\tthrow Exception(\"Limit for number of columns to read exceeded. \""
        },
        {
          "line": 392,
          "api": ".limits.max_rows_to_rea",
          "text": ".limits.max_rows_to_rea",
          "line_content": "\t\t\t\"Requested: \" + toString(required_columns.size())"
        },
        {
          "line": 393,
          "api": "o_read = settings.limits.max_bytes_to_read;",
          "text": "o_read = settings.limits.max_bytes_to_read;\n\t",
          "line_content": "\t\t\t+ \", maximum: \" + toString(settings.limits.max_columns_to_read),"
        },
        {
          "line": 398,
          "api": "me = settings.limits.max_execution_time;\n\t\tlimits.timeout_",
          "text": "me = settings.limits.max_execution_time;\n\t\tlimits.timeout_",
          "line_content": "\tgetLimitLengthAndOffset(query, limit_length, limit_offset);"
        },
        {
          "line": 405,
          "api": ")\n{\n\tbool is_async = settings.as",
          "text": ")\n{\n\tbool is_async = settings.as",
          "line_content": "\t\t&& query.limit_length && !query_analyzer->hasAggregation() && limit_length + limit_offset < settings.max_block_size)"
        },
        {
          "line": 415,
          "api": "{\n\tbool is_async = settings.asynchronous &&",
          "text": "\n{\n\tbool is_async = settings.asynchronous && ",
          "line_content": "\tif (!query.table || !dynamic_cast<ASTSelectQuery *>(&*query.table))"
        },
        {
          "line": 416,
          "api": "begin",
          "text": "<= settings.max_threads;\n\tfor (BlockInputStreams::iterator it = streams.begin(); it != streams.end(); ++it)\n\t{\n\t\tBlockInp",
          "line_content": " \t\tstreams = table->read(required_columns, query_ptr, settings_for_storage, from_stage, settings.max_block_size, settings.max_threads);"
        },
        {
          "line": 418,
          "api": "ynchronous",
          "text": "ynchronous(new ExpressionBlockI",
          "line_content": "\t\tstreams.push_back(maybeAsynchronous(interpreter_subquery->execute(), settings.asynchronous));"
        },
        {
          "line": 423,
          "api": "eableState;",
          "text": "eableState;\n\t\n",
          "line_content": "\tif (streams.size() > settings.max_threads)"
        },
        {
          "line": 424,
          "api": "size",
          "text": "полняем параллельную агрегацию\n\tif (streams.size() > 1",
          "line_content": "\t\tstreams = narrowBlockInputStreams(streams, settings.max_threads);"
        },
        {
          "line": 441,
          "api": "regateDescriptions",
          "text": "regateDescriptions",
          "line_content": "\t\tQuotaForIntervals & quota = context.getQuota();"
        },
        {
          "line": 443,
          "api": ");\n\t\n\t/// Фин",
          "text": ");\n\t\n\t/// Фин",
          "line_content": "\t\tfor (BlockInputStreams::iterator it = streams.begin(); it != streams.end(); ++it)"
        },
        {
          "line": 445,
          "api": "слений на готовые значения\n\tBlockInputStreamPtr &",
          "text": "слений на готовые значения\n\tBlockInputStreamPtr &",
          "line_content": "\t\t\tif (IProfilingBlockInputStream * stream = dynamic_cast<IProfilingBlockInputStream *>(&**it))"
        },
        {
          "line": 447,
          "api": "treams[0];\n\tstream = mayb",
          "text": "treams[0];\n\tstream = mayb",
          "line_content": "\t\t\t\tstream->setLimits(limits);"
        },
        {
          "line": 448,
          "api": "hronous",
          "text": "hronous(new FinalizingAggregatedBlockInputStream(stream, aggreg",
          "line_content": "\t\t\t\tstream->setQuota(quota, IProfilingBlockInputStream::QUOTA_READ);"
        },
        {
          "line": 459,
          "api": "Склеим нескол",
          "text": " Склеим нескол",
          "line_content": "\tbool is_async = settings.asynchronous && streams.size() <= settings.max_threads;"
        },
        {
          "line": 460,
          "api": "ads);\n\tstream",
          "text": "ads);\n\tstream",
          "line_content": "\tfor (BlockInputStreams::iterator it = streams.begin(); it != streams.end(); ++it)"
        },
        {
          "line": 463,
          "api": "singStage::WithMergeableState;\n\n\t/// Теперь объединим агрегированные блоки\n\tNam",
          "text": "singStage::WithMergeableState;\n\n\t/// Теперь объединим агрегированные блоки\n\tNam",
          "line_content": "\t\tstream = maybeAsynchronous(new ExpressionBlockInputStream(stream, expression), is_async);"
        },
        {
          "line": 464,
          "api": "getAggregateInfo",
          "text": "getAggregateInfo(key_names, aggregates)",
          "line_content": "\t\tstream = maybeAsynchronous(new FilterBlockInputStream(stream, query.where_expression->getColumnName()), is_async);"
        },
        {
          "line": 471,
          "api": ";\n}\n\n\nvoid Int",
          "text": ";\n}\n\n\nvoid Int",
          "line_content": "\tbool is_async = settings.asynchronous && streams.size() <= settings.max_threads;"
        },
        {
          "line": 472,
          "api": "ression)\n{\n\tb",
          "text": "ression)\n{\n\tb",
          "line_content": "\tfor (BlockInputStreams::iterator it = streams.begin(); it != streams.end(); ++it)"
        },
        {
          "line": 475,
          "api": "begin",
          "text": "ttings.max_threads;\n\tfor (BlockInputStreams::iterator it = streams.begin(); it ",
          "line_content": "\t\tstream = maybeAsynchronous(new ExpressionBlockInputStream(stream, expression), is_async);"
        },
        {
          "line": 482,
          "api": "ionBlockInputStream",
          "text": "ionBlockInputStream(stream, expression), is_async);\n\t\ts",
          "line_content": "\tquery_analyzer->getAggregateInfo(key_names, aggregates);"
        },
        {
          "line": 489,
          "api": "(BlockInputStr",
          "text": "(BlockInputStr",
          "line_content": "\tif (streams.size() > 1)"
        },
        {
          "line": 491,
          "api": "begin",
          "text": "streams.begin(); it != streams.end(); ++it)\n\t{\n\t\tBlockInputStreamPtr & stream = *it;\n\t\tstream = maybeAsynchronous(new ExpressionBlockInputStream(stream, expression), is_async);\n\t}\n}\n\n\nvoid InterpreterSelectQuery::executeOrder(BlockInputStreams & streams)\n{\n\tSor",
          "line_content": "\t\tstream = maybeAsynchronous(new ParallelAggregatingBlockInputStream(streams, key_names, aggregates, query.group_by_with_totals, separate_totals,"
        },
        {
          "line": 493,
          "api": "cription order_de",
          "text": "cription order_de",
          "line_content": "\t\tstreams.resize(1);"
        },
        {
          "line": 506,
          "api": "size",
          "text": "y, limit_length, limit_offset);\n\tsize_t limit = limit_length + limit_offset;\n\n\tbool is_async = settings.asynchronous && streams.size() <= settings.max_threads;\n\tfor (BlockInputStreams::iterator it = streams.begin(); it != streams.",
          "line_content": 