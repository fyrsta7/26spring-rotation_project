{
  "status": "completed",
  "commit_dir": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/ClickHouse/modified_file/4cab31a60e915b13c2f2ac717e257991fb06e2a5",
  "file_info": {
    "before_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/ClickHouse/modified_file/4cab31a60e915b13c2f2ac717e257991fb06e2a5/before.cpp",
    "after_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/ClickHouse/modified_file/4cab31a60e915b13c2f2ac717e257991fb06e2a5/after.cpp",
    "diff_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/ClickHouse/modified_file/4cab31a60e915b13c2f2ac717e257991fb06e2a5/diff.txt"
  },
  "semgrep_analysis": {
    "is_api_change": false,
    "api_changes": {
      "replacements": [
        {
          "line": 211,
          "old_api": "% sizeof(MarkInCompressedFile) != 0)\n\t\tthrow Exception(",
          "new_api": "query, because they are stored in shared cache.\n\tTempor",
          "old_text": " % sizeof(MarkInCompressedFile) != 0)\n\t\tthrow Exception(",
          "new_text": " query, because they are stored in shared cache.\n\tTempor",
          "old_line_content": null,
          "new_line_content": "\t\t\tbuffer->setProfileCallback(profile_callback, clock_type);",
          "content_same": true
        },
        {
          "line": 213,
          "old_api": "e is not divisabl",
          "new_api": "temporarily_disa",
          "old_text": "e is not divisabl",
          "new_text": " temporarily_disa",
          "old_line_content": null,
          "new_line_content": "\t\tnon_cached_buffer = std::move(buffer);",
          "content_same": true
        },
        {
          "line": 214,
          "old_api": "nCompressedFile structu",
          "new_api": ";\n\n\tsize_t file_size =",
          "old_text": "nCompressedFile structu",
          "new_text": ";\n\n\tsize_t file_size = ",
          "old_line_content": null,
          "new_line_content": "\t\tdata_buffer = non_cached_buffer.get();",
          "content_same": true
        },
        {
          "line": 226,
          "old_api": "directly to mark",
          "new_api": "File structure.\",",
          "old_text": " directly to mark",
          "new_text": "File structure.\",",
          "old_line_content": null,
          "new_line_content": "\t\tkey = cache->hash(path);",
          "content_same": true
        },
        {
          "line": 227,
          "old_api": "erFromFile buff",
          "new_api": ":CORRUPTED_DATA",
          "old_text": "erFromFile buff",
          "new_text": ":CORRUPTED_DATA",
          "old_line_content": null,
          "new_line_content": "\t\tmarks = cache->get(key);",
          "content_same": true
        },
        {
          "line": 235,
          "old_api": "set",
          "new_api": "data",
          "old_text": "ion(\"Cannot read all marks from file \" + path, ErrorCodes::CANNOT_READ_ALL_DATA);\n\n\tif (cache && save_in_cache)\n\t\tcache->set(k",
          "new_text": "arks->data()));\n\n\tif (buff",
          "old_line_content": "\t\tthrow Exception(\"Size of \" + path + \" file is not divisable by size of MarkInCompressedFile structure.\", ErrorCodes::CORRUPTED_DATA);",
          "new_line_content": "\tsize_t file_size = Poco::File(path).getSize();",
          "content_same": false
        },
        {
          "line": 242,
          "old_api": "essed_block);",
          "new_api": "arkInCompressedFile mark = (*marks)[index];\n\n\ttry",
          "old_text": "essed_block);",
          "new_text": "arkInCompressedFile mark = (*marks)[index];\n\n\ttry\n",
          "old_line_content": "\tReadBufferFromFile buffer(path, file_size, -1, reinterpret_cast<char *>(marks->data()));",
          "new_line_content": "\tmarks = std::make_shared<MarksInCompressedFile>(num_marks);",
          "content_same": false
        },
        {
          "line": 245,
          "old_api": "_compressed_file, mark.offset_in_decompressed_block);\n\t}\n\tcatch (Exception & e)\n\t{\n\t\t/",
          "new_api": "essed_block);",
          "old_text": "_compressed_file, mark.offset_in_decompressed_block);\n\t}\n\tcatch (Exception & e)\n\t{\n\t\t/",
          "new_text": "essed_block);",
          "old_line_content": "\t\tthrow Exception(\"Cannot read all marks from file \" + path, ErrorCodes::CANNOT_READ_ALL_DATA);",
          "new_line_content": "\tReadBufferFromFile buffer(path, file_size, -1, reinterpret_cast<char *>(marks->data()));",
          "content_same": false
        },
        {
          "line": 248,
          "old_api": "code",
          "new_api": "_compressed_file, mark.offset_in_decompressed_block);\n\t}\n\tcatch (Exception & e)\n\t{\n\t\t/",
          "old_text": " (e.code() == ErrorCod",
          "new_text": "_compressed_file, mark.offset_in_decompressed_block);\n\t}\n\tcatch (Exception & e)\n\t{\n\t\t/",
          "old_line_content": "\t\tcache->set(key, marks);",
          "new_line_content": "\t\tthrow Exception(\"Cannot read all marks from file \" + path, ErrorCodes::CANNOT_READ_ALL_DATA);",
          "content_same": false
        },
        {
          "line": 263,
          "old_api": "void MergeTreeReader::addStream(const String & name, const IDataType & type, const Mark",
          "new_api": "toString(mark.offset_in_compressed_file) + \" \"\n\t\t\t\t+ toString(mark.offset_in_decompre",
          "old_text": "\n\n\nvoid MergeTreeReader::addStream(const String & name, const IDataType & type, const Mark",
          "new_text": " toString(mark.offset_in_compressed_file) + \" \"\n\t\t\t\t+ toString(mark.offset_in_decompre",
          "old_line_content": "\t\t\tnon_cached_buffer->seek(mark.offset_in_compressed_file, mark.offset_in_decompressed_block);",
          "new_line_content": "\t\t\tcached_buffer->seek(mark.offset_in_compressed_file, mark.offset_in_decompressed_block);",
          "content_same": false
        },
        {
          "line": 271,
          "old_api": "о нужно, чтобы можно было добавлять новы",
          "new_api": "clockid_",
          "old_text": "о нужно, чтобы можно было добавлять новы",
          "new_text": "clockid_",
          "old_line_content": "\t\t\t\t+ toString(mark.offset_in_compressed_file) + \" \"",
          "new_line_content": "\t\tif (e.code() == ErrorCodes::ARGUMENT_OUT_OF_BOUND)",
          "content_same": false
        },
        {
          "line": 272,
          "old_api": "труктуре таблицы без создания файлов для ст",
          "new_api": ");\n\n\t/** Если ф",
          "old_text": "труктуре таблицы без создания файлов для ст",
          "new_text": ");\n\n\t/** Если ф",
          "old_line_content": "\t\t\t\t+ toString(mark.offset_in_decompressed_block) + \")\");",
          "new_line_content": "\t\t\te.addMessage(\"(while seeking to mark \" + toString(index)",
          "content_same": false
        },
        {
          "line": 295,
          "old_api": "ave_marks_in_ca",
          "new_api": "k, clock_type, level + 1);\n\t}\n\telse\n\t\tstr",
          "old_text": "ave_marks_in_ca",
          "new_text": "k, clock_type, level + 1);\n\t}\n\telse\n\t\tstr",
          "old_line_content": "\t\t\t+ ARRAY_SIZES_COLUMN_NAME_SUFFIX + toString(level);",
          "new_line_content": "\tif (const DataTypeArray * type_arr = typeid_cast<const DataTypeArray *>(&type))",
          "content_same": false
        },
        {
          "line": 297,
          "old_api": "t String & name",
          "new_api": "ke_unique<Stream>(\n\t\t\tpath + escaped_column_",
          "old_text": "t String & name",
          "new_text": "ke_unique<Stream>(\n\t\t\tpath + escaped_column_",
          "old_line_content": "\t\t\t+ ARRAY_SIZES_COLUMN_NAME_SUFFIX + toString(level);",
          "new_line_content": "\t\tString size_name = DataTypeNested::extractNestedTableName(name)",
          "content_same": false
        },
        {
          "line": 299,
          "old_api": "ataType & type, IColumn",
          "new_api": "buffer_size, profile_callback, clock_type));",
          "old_text": "ataType & type, IColumn ",
          "new_text": "buffer_size, profile_callback, clock_type));",
          "old_line_content": "\t\tif (!streams.count(size_name))",
          "new_line_content": "\t\tString escaped_size_name = escapeForFileName(DataTypeNested::extractNestedTableName(name))",
          "content_same": false
        },
        {
          "line": 300,
          "old_api": "e_t max_rows_to_read, size_t level, bool read_offsets)\n{\n\t/// Для массивов требуется сначала десериализовать размеры, а потом значения.\n\tif (const DataTypeArray * type_arr = typeid_cast<const Data",
          "new_api": "t String & name",
          "old_text": "e_t max_rows_to_read, size_t level, bool read_offsets)\n{\n\t/// Для массивов требуется сначала десериализовать размеры, а потом значения.\n\tif (const DataTypeArray * type_arr = typeid_cast<const Data",
          "new_text": "t String & name",
          "old_line_content": "\t\t\tstreams.emplace(size_name, std::make_unique<Stream>(",
          "new_line_content": "\t\t\t+ ARRAY_SIZES_COLUMN_NAME_SUFFIX + toString(level);",
          "content_same": false
        },
        {
          "line": 307,
          "old_api": "seekToMark",
          "new_api": "if (read_offsets)\n\t\t{",
          "old_text": "N_NAME_SUFFIX + toString(level)];\n\t\t\tstream.seekToMark(from_mark);\n\t\t\ttype_arr->deserializeOffsets(\n\t\t\t\tcolumn,\n\t\t\t\t*stream.data_buffer,\n\t\t\t\tmax_rows_to_read);\n\t\t}\n\n\t\tif (column.size())\n\t\t{\n\t\t\tCol",
          "new_text": "\n\t\tif (read_offsets)\n\t\t{\n",
          "old_line_content": "\t\tstreams.emplace(name, std::make_unique<Stream>(",
          "new_line_content": "\t\taddStream(name, *type_arr->getNestedType(), all_mark_ranges, profile_callback, clock_type, level + 1);",
          "content_same": false
        },
        {
          "line": 332,
          "old_api": "array.get",
          "new_api": "t",
          "old_text": "\t\t\t\tarray.get",
          "new_text": "t(\"MergeTreeR",
          "old_line_content": "\t\t\tconst size_t required_internal_size = array.getOffsets()[column.size() - 1];",
          "new_line_content": "\t\tif (column.size())",
          "content_same": false
        },
        {
          "line": 339,
          "old_api": "red_internal_si",
          "new_api": "convertToFullColumn",
          "old_text": "red_internal_si",
          "new_text": "*type_arr->getNestedType()->createConstColumn(\n\t\t\t\t\t\t\trequired_internal_size,\n\t\t\t\t\t\t\ttype_arr->getNestedType()->getDefault())).convertToFullColumn();\n\n\t\t\t\t\t/** N",
          "old_line_content": "\t\t\t\t\tarray.getData(),",
          "new_line_content": "\t\t\t\treadData(",
          "content_same": false
        },
        {
          "line": 341,
          "old_api": "())).convertToFullColu",
          "new_api": ">createConstColumn(",
          "old_text": "())).convertToFullColu",
          "new_text": ">createConstColumn(\n\t\t\t\t\t",
          "old_line_content": "\t\t\t\t\trequired_internal_size - array.getData().size(),",
          "new_line_content": "\t\t\t\t\t*type_arr->getNestedType(),",
          "content_same": false
        },
        {
          "line": 354,
          "old_api": "Эвристика, чтобы при изменениях, значение avg_value_size_hint быстро росло, но медленно уменьшалось.\n\t\t\tif (current_avg_value_size > avg_value_size_hint)\n\t\t\t\tavg_value_size_hint = cur",
          "new_api": "размере значения.\n\t\tsize_t col",
          "old_text": " Эвристика, чтобы при изменениях, значение avg_value_size_hint быстро росло, но медленно уменьшалось.\n\t\t\tif (current_avg_value_size > avg_value_size_hint)\n\t\t\t\tavg_value_size_hint = cur",
          "new_text": "размере значения.\n\t\tsize_t col",
          "old_line_content": "\t\t\t\t\tarray.getDataPtr() = dynamic_cast<IColumnConst &>(",
          "new_line_content": "\t\t\t\t\t\tLOG_ERROR((&Logger::get(\"MergeTreeReader\")),",
          "content_same": false
        },
        {
          "line": 357,
          "old_api": "value_size > avg_value_size_hint)\n\t\t\t\ta",
          "new_api": "Эвристика, чтобы при изменениях, значение avg_value_size_hint быстро росло, но медленно уменьшалось.\n\t\t\tif (current_avg_value_size > avg_value_size_hint)\n\t\t\t\tavg_value_size_hint = cur",
          "old_text": "value_size > avg_value_size_hint)\n\t\t\t\ta",
          "new_text": " Эвристика, чтобы при изменениях, значение avg_value_size_hint быстро росло, но медленно уменьшалось.\n\t\t\tif (current_avg_value_size > avg_value_size_hint)\n\t\t\t\tavg_value_size_hint = cur",
          "old_line_content": "\t\t\t\t\t\t\ttype_arr->getNestedType()->getDefault())).convertToFullColumn();",
          "new_line_content": "\t\t\t\t\tarray.getDataPtr() = dynamic_cast<IColumnConst &>(",
          "content_same": false
        },
        {
          "line": 374,
          "old_api": "для этой влож",
          "new_api": "ивов, а столбец массивов\n\t\t\t*  правильных длин.\n\t\t\t* TODO: Если для какой-то вложенной стр",
          "old_text": "для этой влож",
          "new_text": "ивов, а столбец массивов\n\t\t\t*  правильных длин.\n\t\t\t* TODO: Если для какой-то вложенной стр",
          "old_line_content": "\t\tsize_t column_size = column.size();",
          "new_line_content": "\t\ttype.deserializeBinary(column, *stream.data_buffer, max_rows_to_read, avg_value_size_hint);",
          "content_same": false
        },
        {
          "line": 377,
          "old_api": "faults, но он нем",
          "new_api": "для этой влож",
          "old_text": "faults, но он нем",
          "new_text": "для этой влож",
          "old_line_content": "\t\t\tdouble current_avg_value_size = static_cast<double>(column.byteSize()) / column_size;",
          "new_line_content": "\t\tsize_t column_size = column.size();",
          "content_same": false
        },
        {
          "line": 408,
          "old_api": "teConstColumn",
          "new_api": "Int64 &>(*off",
          "old_text": "teConstColumn(\n\t\t\t\t\t\tnested_rows, nested_type->ge",
          "new_text": "Int64 &>(*off",
          "old_line_content": "\t\t\tif (const ColumnArray * array = typeid_cast<const ColumnArray *>(&*column.column))",
          "new_line_content": "\t\tfor (size_t i = 0; i < res.columns(); ++i)",
          "content_same": false
        },
        {
          "line": 410,
          "old_api": ");\n\n\t\t\t\t\tcolumn_to_add.column = std::make_shared<Co",
          "new_api": "_column = dynamic_ca",
          "old_text": ");\n\n\t\t\t\t\tcolumn_to_add.column = std::make_shared<Co",
          "new_text": "_column = dynamic_ca",
          "old_line_content": "\t\t\t\tString offsets_name = DataTypeNested::extractNestedTableName(column.name);",
          "new_line_content": "\t\t\tconst ColumnWithTypeAndName & column = res.getByPosition(i);",
          "content_same": false
        },
        {
          "line": 428,
          "old_api": ".column_defaults, storage.context);\n\n\t\t/// sort colu",
          "new_api": "d_evaluate_defaults)\n\t\t\tevalua",
          "old_text": ".column_defaults, storage.context);\n\n\t\t/// sort colu",
          "new_text": "d_evaluate_defaults)\n\t\t\tevalua",
          "old_line_content": "\t\t\t\tif (storage.column_defaults.count(requested_column.name) != 0)",
          "new_line_content": "\t\t\tif (!res.has(requested_column.name))",
          "content_same": false
        },
        {
          "line": 442,
          "old_api": "",
          "new_api": "addMessage",
          "old_text": "",
          "new_text": "тика.\n\t\te.addMessage(\"(while readi",
          "old_line_content": "\t\t\t\t\tDataTypePtr nested_type = typeid_cast<DataTypeArray &>(*column_to_add.type).getNestedType();",
          "new_line_content": "\t\t\t\tif (offset_columns.count(offsets_name))",
          "content_same": false
        }
      ],
      "additions": [
        {
          "line": 266,
          "old_api": null,
          "new_api": "void MergeTreeReader::addStream(const String & name, const IDataType & type, const Mark",
          "old_text": null,
          "new_text": "\n\n\nvoid MergeTreeReader::addStream(const String & name, const IDataType & type, const Mark",
          "old_line_content": "\t{",
          "new_line_content": "\t\t\tnon_cached_buffer->seek(mark.offset_in_compressed_file, mark.offset_in_decompressed_block);",
          "content_same": false
        },
        {
          "line": 395,
          "old_api": null,
          "new_api": "empty",
          "old_text": null,
          "new_text": "ets_column || offsets_column->empty())\n\t\t\t\t\toffsets_column = array->getOffsetsColumn",
          "old_line_content": "\t{",
          "new_line_content": "\t\tthrow Exception(\"Empty block passed to fillMissingColumnsImpl\", ErrorCodes::LOGICAL_ERROR);",
          "content_same": false
        },
        {
          "line": 274,
          "old_api": null,
          "new_api": "о нужно, чтобы можно было добавлять новы",
          "old_text": null,
          "new_text": "о нужно, чтобы можно было добавлять новы",
          "old_line_content": "\t\tthrow;",
          "new_line_content": "\t\t\t\t+ toString(mark.offset_in_compressed_file) + \" \"",
          "content_same": false
        },
        {
          "line": 275,
          "old_api": null,
          "new_api": "труктуре таблицы без создания файлов для ст",
          "old_text": null,
          "new_text": "труктуре таблицы без создания файлов для ст",
          "old_line_content": "\t}",
          "new_line_content": "\t\t\t\t+ toString(mark.offset_in_decompressed_block) + \")\");",
          "content_same": false
        },
        {
          "line": 411,
          "old_api": null,
          "new_api": "teConstColumn",
          "old_text": null,
          "new_text": "teConstColumn(\n\t\t\t\t\t\tnested_rows, nested_type->ge",
          "old_line_content": "\t\t\t\tauto & offsets_column = offset_columns[offsets_name];",
          "new_line_content": "\t\t\tif (const ColumnArray * array = typeid_cast<const ColumnArray *>(&*column.column))",
          "content_same": false
        },
        {
          "line": 413,
          "old_api": null,
          "new_api": ");\n\n\t\t\t\t\tcolumn_to_add.column = std::make_shared<Co",
          "old_text": null,
          "new_text": ");\n\n\t\t\t\t\tcolumn_to_add.column = std::make_shared<Co",
          "old_line_content": "\t\t\t\t/// Если почему-то есть разные столбцы смещений для одной вложенной структуры, то берём непустой.",
          "new_line_content": "\t\t\t\tString offsets_name = DataTypeNested::extractNestedTableName(column.name);",
          "content_same": false
        },
        {
          "line": 286,
          "old_api": null,
          "new_api": ":extractNestedTableName",
          "old_text": null,
          "new_text": ":extractNestedTableName",
          "old_line_content": "\t\t* Это нужно, чтобы можно было добавлять новые столбцы к структуре таблицы без создания файлов для старых кусков.",
          "new_line_content": "\tString escaped_column_name = escapeForFileName(name);",
          "content_same": false
        },
        {
          "line": 417,
          "old_api": null,
          "new_api": "*/\n\t\t\t\t\tcolumn_to_",
          "old_text": null,
          "new_text": "\t\t\t\t\t*/\n\t\t\t\t\tcolumn_to_",
          "old_line_content": "\t\t}",
          "new_line_content": "\t\t\t\tif (!offsets_column || offsets_column->empty())",
          "content_same": false
        },
        {
          "line": 418,
          "old_api": null,
          "new_api": "t<IColumnConst &>(*column",
          "old_text": null,
          "new_text": "t<IColumnConst &>(*column",
          "old_line_content": "",
          "new_line_content": "\t\t\t\t\toffsets_column = array->getOffsetsColumn();",
          "content_same": false
        },
        {
          "line": 291,
          "old_api": null,
          "new_api": "mpressed_cache, mark_cache, save_marks_in_cache,\n\t\t\t\tall",
          "old_text": null,
          "new_text": "mpressed_cache, mark_cache, save_marks_in_cache,\n\t\t\t\tall",
          "old_line_content": "\t/// Для массивов используются отдельные потоки для размеров.",
          "new_line_content": "\tif (!Poco::File(path + escaped_column_name + \".bin\").exists())",
          "content_same": false
        },
        {
          "line": 298,
          "old_api": null,
          "new_api": "ave_marks_in_ca",
          "old_text": null,
          "new_text": "ave_marks_in_ca",
          "old_line_content": "",
          "new_line_content": "\t\t\t+ ARRAY_SIZES_COLUMN_NAME_SUFFIX + toString(level);",
          "content_same": false
        },
        {
          "line": 302,
          "old_api": null,
          "new_api": "ataType & type, IColumn",
          "old_text": null,
          "new_text": "ataType & type, IColumn ",
          "old_line_content": "\t\t\t\tall_mark_ranges, aio_threshold, max_read_buffer_size, profile_callback, clock_type));",
          "new_line_content": "\t\tif (!streams.count(size_name))",
          "content_same": false
        },
        {
          "line": 303,
          "old_api": null,
          "new_api": "e_t max_rows_to_read, size_t level, bool read_offsets)\n{\n\t/// Для массивов требуется сначала десериализовать размеры, а потом значения.\n\tif (const DataTypeArray * type_arr = typeid_cast<const Data",
          "old_text": null,
          "new_text": "e_t max_rows_to_read, size_t level, bool read_offsets)\n{\n\t/// Для массивов требуется сначала десериализовать размеры, а потом значения.\n\tif (const DataTypeArray * type_arr = typeid_cast<const Data",
          "old_line_content": "",
          "new_line_content": "\t\t\tstreams.emplace(size_name, std::make_unique<Stream>(",
          "content_same": false
        },
        {
          "line": 431,
          "old_api": null,
          "new_api": ".column_defaults, storage.context);\n\n\t\t/// sort colu",
          "old_text": null,
          "new_text": ".column_defaults, storage.context);\n\n\t\t/// sort colu",
          "old_line_content": "\t\t\t\t\tcontinue;",
          "new_line_content": "\t\t\t\tif (storage.column_defaults.count(requested_column.name) != 0)",
          "content_same": false
        },
        {
          "line": 310,
          "old_api": null,
          "new_api": "seekToMark",
          "old_text": null,
          "new_text": "N_NAME_SUFFIX + toString(level)];\n\t\t\tstream.seekToMark(from_mark);\n\t\t\ttype_arr->deserializeOffsets(\n\t\t\t\tcolumn,\n\t\t\t\t*stream.data_buffer,\n\t\t\t\tmax_rows_to_read);\n\t\t}\n\n\t\tif (column.size())\n\t\t{\n\t\t\tCol",
          "old_line_content": "}",
          "new_line_content": "\t\tstreams.emplace(name, std::make_unique<Stream>(",
          "content_same": false
        },
        {
          "line": 441,
          "old_api": null,
          "new_api": "block);\n\t\t}\n\t}\n\tcatch (Exception & e)\n\t{\n\t\t/// Более хорош",
          "old_text": null,
          "new_text": "block);\n\t\t}\n\t}\n\tcatch (Exception & e)\n\t{\n\t\t/// Более хорош",
          "old_line_content": "\t\t\t\t\tColumnPtr offsets_column = offset_columns[offsets_name];",
          "new_line_content": "\t\t\t\tString offsets_name = DataTypeNested::extractNestedTableName(column_to_add.name);",
          "content_same": false
        },
        {
          "line": 445,
          "old_api": null,
          "new_api": "",
          "old_text": null,
          "new_text": "",
          "old_line_content": "",
          "new_line_content": "\t\t\t\t\tDataTypePtr nested_type = typeid_cast<DataTypeArray &>(*column_to_add.type).getNestedType();",
          "content_same": false
        },
        {
          "line": 320,
          "old_api": null,
          "new_api": "для ошибочно записанных пустых файлов с д",
          "old_text": null,
          "new_text": "для ошибочно записанных пустых файлов с д",
          "old_line_content": "\t\t{",
          "new_line_content": "\tif (const DataTypeArray * type_arr = typeid_cast<const DataTypeArray *>(&type))",
          "content_same": false
        },
        {
          "line": 450,
          "old_api": null,
          "new_api": "",
          "old_text": null,
          "new_text": "",
          "old_line_content": "\t\t\t\t}",
          "new_line_content": "\t\t\t\t\t\tnested_rows, nested_type->getDefault())).convertToFullColumn();",
          "content_same": false
        },
        {
          "line": 324,
          "old_api": null,
          "new_api": "l_size = array.",
          "old_text": null,
          "new_text": "l_size = array.",
          "old_line_content": "\t\t\t\tcolumn,",
          "new_line_content": "\t\t\tStream & stream = *streams[DataTypeNested::extractNestedTableName(name) + ARRAY_SIZES_COLUMN_NAME_SUFFIX + toString(level)];",
          "content_same": false
        },
        {
          "line": 325,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "a().size();\n\t\t\t\tif (required",
          "old_line_content": "\t\t\t\t*stream.data_buffer,",
          "new_line_content": "\t\t\tstream.seekToMark(from_mark);",
          "content_same": false
        },
        {
          "line": 326,
          "old_api": null,
          "new_api": "rnal_size != read_internal_size)\n\t\t\t\t{\n\t\t\t\t\tif (read_internal_size != 0)\n\t\t\t\t\t\tLOG_ERROR",
          "old_text": null,
          "new_text": "rnal_size != read_internal_size)\n\t\t\t\t{\n\t\t\t\t\tif (read_internal_size != 0)\n\t\t\t\t\t\tLOG_ERROR",
          "old_line_content": "\t\t\t\tmax_rows_to_read);",
          "new_line_content": "\t\t\ttype_arr->deserializeOffsets(",
          "content_same": false
        },
        {
          "line": 452,
          "old_api": null,
          "new_api": "",
          "old_text": null,
          "new_text": "",
          "old_line_content": "\t\t\t\t{",
          "new_line_content": "\t\t\t\t\tcolumn_to_add.column = std::make_shared<ColumnArray>(nested_column, offsets_column);",
          "content_same": false
        },
        {
          "line": 459,
          "old_api": null,
          "new_api": "",
          "old_text": null,
          "new_text": "",
          "old_line_content": "",
          "new_line_content": "\t\t\t\t\tcolumn_to_add.column = dynamic_cast<IColumnConst &>(*column_to_add.type->createConstColumn(",
          "content_same": false
        },
        {
          "line": 334,
          "old_api": null,
          "new_api": "of array \" + name + \" doesn't mat",
          "old_text": null,
          "new_text": " of array \" + name + \" doesn't mat",
          "old_line_content": "\t\t\tif (required_internal_size)",
          "new_line_content": "\t\t\tColumnArray & array = typeid_cast<ColumnArray &>(column);",
          "content_same": false
        },
        {
          "line": 335,
          "old_api": null,
          "new_api": "array.get",
          "old_text": null,
          "new_text": "\t\t\t\tarray.get",
          "old_line_content": "\t\t\t{",
          "new_line_content": "\t\t\tconst size_t required_internal_size = array.getOffsets()[column.size() - 1];",
          "content_same": false
        },
        {
          "line": 463,
          "old_api": null,
          "new_api": "",
          "old_text": null,
          "new_text": "",
          "old_line_content": "",
          "new_line_content": "\t\t\t\tres.insert(std::move(column_to_add));",
          "content_same": false
        },
        {
          "line": 469,
          "old_api": null,
          "new_api": "",
          "old_text": null,
          "new_text": "",
          "old_line_content": "\t\tif (should_sort)",
          "new_line_content": "\t\t\tevaluateMissingDefaults(res, columns, storage.column_defaults, storage.context);",
          "content_same": false
        },
        {
          "line": 342,
          "old_api": null,
          "new_api": "red_internal_si",
          "old_text": null,
          "new_text": "red_internal_si",
          "old_line_content": "\t\t\t\t\tlevel + 1);",
          "new_line_content": "\t\t\t\t\tarray.getData(),",
          "content_same": false
        },
        {
          "line": 344,
          "old_api": null,
          "new_api": "())).convertToFullColu",
          "old_text": null,
          "new_text": "())).convertToFullColu",
          "old_line_content": "\t\t\t\t/** Исправление для ошибочно записанных пустых файлов с данными массива.",
          "new_line_content": "\t\t\t\t\trequired_internal_size - array.getData().size(),",
          "content_same": false
        },
        {
          "line": 350,
          "old_api": null,
          "new_api": "k);\n\t\ttype.deserialize",
          "old_text": null,
          "new_text": "k);\n\t\ttype.deserialize",
          "old_line_content": "\t\t\t\t\tif (read_internal_size != 0)",
          "new_line_content": "\t\t\t\tsize_t read_internal_size = array.getData().size();",
          "content_same": false
        },
        {
          "line": 478,
          "old_api": null,
          "new_api": "",
          "old_text": null,
          "new_text": "",
          "old_line_content": "\t\t}",
          "new_line_content": "\t\t\t\t\tordered_block.insert(res.getByName(name));",
          "content_same": false
        },
        {
          "line": 480,
          "old_api": null,
          "new_api": "",
          "old_text": null,
          "new_text": "",
          "old_line_content": "\tcatch (Exception & e)",
          "new_line_content": "\t\t\tstd::swap(res, ordered_block);",
          "content_same": false
        },
        {
          "line": 358,
          "old_api": null,
          "new_api": "чение avg_value_size_hint быстро росло, но медленно уменьшалось.\n\t\t\tif (current_avg_value_size > avg_value_size_hint)\n\t\t\t\tav",
          "old_text": null,
          "new_text": "чение avg_value_size_hint быстро росло, но медленно уменьшалось.\n\t\t\tif (current_avg_value_size > avg_value_size_hint)\n\t\t\t\tav",
          "old_line_content": "",
          "new_line_content": "\t\t\t\t\t\t*type_arr->getNestedType()->createConstColumn(",
          "content_same": false
        },
        {
          "line": 486,
          "old_api": null,
          "new_api": "",
          "old_text": null,
          "new_text": "",
          "old_line_content": "}",
          "new_line_content": "\t\te.addMessage(\"(while reading from part \" + path + \")\");",
          "content_same": false
        },
        {
          "line": 360,
          "old_api": null,
          "new_api": "value_size > avg_value_size_hint)\n\t\t\t\ta",
          "old_text": null,
          "new_text": "value_size > avg_value_size_hint)\n\t\t\t\ta",
          "old_line_content": "\t\t\t\t\t\t*  а впоследствии создавался с более правильными (из определения таблицы) значениями по-умолчанию.",
          "new_line_content": "\t\t\t\t\t\t\ttype_arr->getNestedType()->getDefault())).convertToFullColumn();",
          "content_same": false
        },
        {
          "line": 238,
          "old_api": null,
          "new_api": "set",
          "old_text": null,
          "new_text": "ion(\"Cannot read all marks from file \" + path, ErrorCodes::CANNOT_READ_ALL_DATA);\n\n\tif (cache && save_in_cache)\n\t\tcache->set(k",
          "old_line_content": "",
          "new_line_content": "\t\tthrow Exception(\"Size of \" + path + \" file is not divisable by size of MarkInCompressedFile structure.\", ErrorCodes::CORRUPTED_DATA);",
          "content_same": false
        },
        {
          "line": 373,
          "old_api": null,
          "new_api": "создавать не столбец пустых",
          "old_text": null,
          "new_text": "создавать не столбец пустых ",
          "old_line_content": "\t\t/// Вычисление подсказки о среднем размере значения.",
          "new_line_content": "\t\tstream.seekToMark(from_mark);",
          "content_same": false
        },
        {
          "line": 247,
          "old_api": null,
          "new_api": "er)\n\t\t\tnon_cached_buff",
          "old_text": null,
          "new_text": "er)\n\t\t\tnon_cached_buff",
          "old_line_content": "\tif (cache && save_in_cache)",
          "new_line_content": "\tif (buffer.eof() || buffer.buffer().size() != file_size)",
          "content_same": false
        },
        {
          "line": 251,
          "old_api": null,
          "new_api": "code",
          "old_text": null,
          "new_text": " (e.code() == ErrorCod",
          "old_line_content": "",
          "new_line_content": "\t\tcache->set(key, marks);",
          "content_same": false
        },
        {
          "line": 380,
          "old_api": null,
          "new_api": "faults, но он нем",
          "old_text": null,
          "new_text": "faults, но он нем",
          "old_line_content": "\t\t\tif (current_avg_value_size > avg_value_size_hint)",
          "new_line_content": "\t\t\tdouble current_avg_value_size = static_cast<double>(column.byteSize()) / column_size;",
          "content_same": false
        }
      ],
      "deletions": [
        {
          "line": 260,
          "old_api": "toString(mark.offset_in_compressed_file) + \" \"\n\t\t\t\t+ toString(mark.offset_in_decompre",
          "new_api": null,
          "old_text": " toString(mark.offset_in_compressed_file) + \" \"\n\t\t\t\t+ toString(mark.offset_in_decompre",
          "new_text": null,
          "old_line_content": "\t\t\tcached_buffer->seek(mark.offset_in_compressed_file, mark.offset_in_decompressed_block);",
          "new_line_content": "\t{",
          "content_same": false
        },
        {
          "line": 392,
          "old_api": "empty",
          "new_api": null,
          "old_text": "ets_column || offsets_column->empty())\n\t\t\t\t\toffsets_column = array->getOffsetsColumn",
          "new_text": null,
          "old_line_content": "\t\tthrow Exception(\"Empty block passed to fillMissingColumnsImpl\", ErrorCodes::LOGICAL_ERROR);",
          "new_line_content": "void MergeTreeReader::fillMissingColumnsImpl(Block & res, const Names & ordered_names, bool always_reorder)",
          "content_same": false
        },
        {
          "line": 268,
          "old_api": "clockid_",
          "new_api": null,
          "old_text": "clockid_",
          "new_text": null,
          "old_line_content": "\t\tif (e.code() == ErrorCodes::ARGUMENT_OUT_OF_BOUND)",
          "new_line_content": "\tcatch (Exception & e)",
          "content_same": false
        },
        {
          "line": 269,
          "old_api": ");\n\n\t/** Если ф",
          "new_api": null,
          "old_text": ");\n\n\t/** Если ф",
          "new_text": null,
          "old_line_content": "\t\t\te.addMessage(\"(while seeking to mark \" + toString(index)",
          "new_line_content": "\t{",
          "content_same": false
        },
        {
          "line": 405,
          "old_api": "Int64 &>(*off",
          "new_api": null,
          "old_text": "Int64 &>(*off",
          "new_text": null,
          "old_line_content": "\t\tfor (size_t i = 0; i < res.columns(); ++i)",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 407,
          "old_api": "_column = dynamic_ca",
          "new_api": null,
          "old_text": "_column = dynamic_ca",
          "new_text": null,
          "old_line_content": "\t\t\tconst ColumnWithTypeAndName & column = res.getByPosition(i);",
          "new_line_content": "\t\tOffsetColumns offset_columns;",
          "content_same": false
        },
        {
          "line": 283,
          "old_api": ":extractNestedTableName",
          "new_api": null,
          "old_text": ":extractNestedTableName",
          "new_text": null,
          "old_line_content": "\tString escaped_column_name = escapeForFileName(name);",
          "new_line_content": "\tconst ReadBufferFromFileBase::ProfileCallback & profile_callback, clockid_t clock_type,",
          "content_same": false
        },
        {
          "line": 414,
          "old_api": "*/\n\t\t\t\t\tcolumn_to_",
          "new_api": null,
          "old_text": "\t\t\t\t\t*/\n\t\t\t\t\tcolumn_to_",
          "new_text": null,
          "old_line_content": "\t\t\t\tif (!offsets_column || offsets_column->empty())",
          "new_line_content": "\t\t\t\tauto & offsets_column = offset_columns[offsets_name];",
          "content_same": false
        },
        {
          "line": 415,
          "old_api": "t<IColumnConst &>(*column",
          "new_api": null,
          "old_text": "t<IColumnConst &>(*column",
          "new_text": null,
          "old_line_content": "\t\t\t\t\toffsets_column = array->getOffsetsColumn();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 288,
          "old_api": "mpressed_cache, mark_cache, save_marks_in_cache,\n\t\t\t\tall",
          "new_api": null,
          "old_text": "mpressed_cache, mark_cache, save_marks_in_cache,\n\t\t\t\tall",
          "new_text": null,
          "old_line_content": "\tif (!Poco::File(path + escaped_column_name + \".bin\").exists())",
          "new_line_content": "\t/** Если файла с данными нет - то не будем пытаться открыть его.",
          "content_same": false
        },
        {
          "line": 292,
          "old_api": "k, clock_type, level + 1);\n\t}\n\telse\n\t\tstr",
          "new_api": null,
          "old_text": "k, clock_type, level + 1);\n\t}\n\telse\n\t\tstr",
          "new_text": null,
          "old_line_content": "\tif (const DataTypeArray * type_arr = typeid_cast<const DataTypeArray *>(&type))",
          "new_line_content": "\t\treturn;",
          "content_same": false
        },
        {
          "line": 294,
          "old_api": "ke_unique<Stream>(\n\t\t\tpath + escaped_column_",
          "new_api": null,
          "old_text": "ke_unique<Stream>(\n\t\t\tpath + escaped_column_",
          "new_text": null,
          "old_line_content": "\t\tString size_name = DataTypeNested::extractNestedTableName(name)",
          "new_line_content": "\t/// Для массивов используются отдельные потоки для размеров.",
          "content_same": false
        },
        {
          "line": 296,
          "old_api": "buffer_size, profile_callback, clock_type));",
          "new_api": null,
          "old_text": "buffer_size, profile_callback, clock_type));",
          "new_text": null,
          "old_line_content": "\t\tString escaped_size_name = escapeForFileName(DataTypeNested::extractNestedTableName(name))",
          "new_line_content": "\t{",
          "content_same": false
        },
        {
          "line": 425,
          "old_api": "d_evaluate_defaults)\n\t\t\tevalua",
          "new_api": null,
          "old_text": "d_evaluate_defaults)\n\t\t\tevalua",
          "new_text": null,
          "old_line_content": "\t\t\tif (!res.has(requested_column.name))",
          "new_line_content": "\t\tfor (const auto & requested_column : columns)",
          "content_same": false
        },
        {
          "line": 304,
          "old_api": "if (read_offsets)\n\t\t{",
          "new_api": null,
          "old_text": "\n\t\tif (read_offsets)\n\t\t{\n",
          "new_text": null,
          "old_line_content": "\t\taddStream(name, *type_arr->getNestedType(), all_mark_ranges, profile_callback, clock_type, level + 1);",
          "new_line_content": "\t\t\t\tpath + escaped_size_name, uncompressed_cache, mark_cache, save_marks_in_cache,",
          "content_same": false
        },
        {
          "line": 438,
          "old_api": "block);\n\t\t}\n\t}\n\tcatch (Exception & e)\n\t{\n\t\t/// Более хорош",
          "new_api": null,
          "old_text": "block);\n\t\t}\n\t}\n\tcatch (Exception & e)\n\t{\n\t\t/// Более хорош",
          "new_text": null,
          "old_line_content": "\t\t\t\tString offsets_name = DataTypeNested::extractNestedTableName(column_to_add.name);",
          "new_line_content": "\t\t\t\tcolumn_to_add.name = requested_column.name;",
          "content_same": false
        },
        {
          "line": 439,
          "old_api": "addMessage",
          "new_api": null,
          "old_text": "тика.\n\t\te.addMessage(\"(while readi",
          "new_text": null,
          "old_line_content": "\t\t\t\tif (offset_columns.count(offsets_name))",
          "new_line_content": "\t\t\t\tcolumn_to_add.type = requested_column.type;",
          "content_same": false
        },
        {
          "line": 443,
          "old_api": "",
          "new_api": null,
          "old_text": "",
          "new_text": null,
          "old_line_content": "\t\t\t\t\tsize_t nested_rows = offsets_column->empty() ? 0",
          "new_line_content": "\t\t\t\t{",
          "content_same": false
        },
        {
          "line": 444,
          "old_api": "",
          "new_api": null,
          "old_text": "",
          "new_text": null,
          "old_line_content": "\t\t\t\t\t\t: typeid_cast<ColumnUInt64 &>(*offsets_column).getData().back();",
          "new_line_content": "\t\t\t\t\tColumnPtr offsets_column = offset_columns[offsets_name];",
          "content_same": false
        },
        {
          "line": 317,
          "old_api": "для ошибочно записанных пустых файлов с д",
          "new_api": null,
          "old_text": "для ошибочно записанных пустых файлов с д",
          "new_text": null,
          "old_line_content": "\tif (const DataTypeArray * type_arr = typeid_cast<const DataTypeArray *>(&type))",
          "new_line_content": "\tsize_t from_mark, size_t max_rows_to_read, size_t level, bool read_offsets)",
          "content_same": false
        },
        {
          "line": 321,
          "old_api": "l_size = array.",
          "new_api": null,
          "old_text": "l_size = array.",
          "new_text": null,
          "old_line_content": "\t\t\tStream & stream = *streams[DataTypeNested::extractNestedTableName(name) + ARRAY_SIZES_COLUMN_NAME_SUFFIX + toString(level)];",
          "new_line_content": "\t{",
          "content_same": false
        },
        {
          "line": 322,
          "old_api": "size",
          "new_api": null,
          "old_text": "a().size();\n\t\t\t\tif (required",
          "new_text": null,
          "old_line_content": "\t\t\tstream.seekToMark(from_mark);",
          "new_line_content": "\t\tif (read_offsets)",
          "content_same": false
        },
        {
          "line": 323,
          "old_api": "rnal_size != read_internal_size)\n\t\t\t\t{\n\t\t\t\t\tif (read_internal_size != 0)\n\t\t\t\t\t\tLOG_ERROR",
          "new_api": null,
          "old_text": "rnal_size != read_internal_size)\n\t\t\t\t{\n\t\t\t\t\tif (read_internal_size != 0)\n\t\t\t\t\t\tLOG_ERROR",
          "new_text": null,
          "old_line_content": "\t\t\ttype_arr->deserializeOffsets(",
          "new_line_content": "\t\t{",
          "content_same": false
        },
        {
          "line": 456,
          "old_api": "",
          "new_api": null,
          "old_text": "",
          "new_text": null,
          "old_line_content": "\t\t\t\t\tcolumn_to_add.column = dynamic_cast<IColumnConst &>(*column_to_add.type->createConstColumn(",
          "new_line_content": "\t\t\t\t\t/** Нужно превратить константный столбец в полноценный, так как в части блоков (из других кусков),",
          "content_same": false
        },
        {
          "line": 329,
          "old_api": "t",
          "new_api": null,
          "old_text": "t(\"MergeTreeR",
          "new_text": null,
          "old_line_content": "\t\tif (column.size())",
          "new_line_content": "\t\t\t\tmax_rows_to_read);",
          "content_same": false
        },
        {
          "line": 457,
          "old_api": "",
          "new_api": null,
          "old_text": "",
          "new_text": null,
          "old_line_content": "\t\t\t\t\t\tres.rows(), column_to_add.type->getDefault())).convertToFullColumn();",
          "new_line_content": "\t\t\t\t\t\t*  он может быть полноценным (а то интерпретатор может посчитать, что он константный везде).",
          "content_same": false
        },
        {
          "line": 331,
          "old_api": "of array \" + name + \" doesn't mat",
          "new_api": null,
          "old_text": " of array \" + name + \" doesn't mat",
          "new_text": null,
          "old_line_content": "\t\t\tColumnArray & array = typeid_cast<ColumnArray &>(column);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 336,
          "old_api": "convertToFullColumn",
          "new_api": null,
          "old_text": "*type_arr->getNestedType()->createConstColumn(\n\t\t\t\t\t\t\trequired_internal_size,\n\t\t\t\t\t\t\ttype_arr->getNestedType()->getDefault())).convertToFullColumn();\n\n\t\t\t\t\t/** N",
          "new_text": null,
          "old_line_content": "\t\t\t\treadData(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 338,
          "old_api": ">createConstColumn(",
          "new_api": null,
          "old_text": ">createConstColumn(\n\t\t\t\t\t",
          "new_text": null,
          "old_line_content": "\t\t\t\t\t*type_arr->getNestedType(),",
          "new_line_content": "\t\t\t{",
          "content_same": false
        },
        {
          "line": 466,
          "old_api": "",
          "new_api": null,
          "old_text": "",
          "new_text": null,
          "old_line_content": "\t\t\tevaluateMissingDefaults(res, columns, storage.column_defaults, storage.context);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 474,
          "old_api": "",
          "new_api": null,
          "old_text": "",
          "new_text": null,
          "old_line_content": "\t\t\t\tif (res.has(name))",
          "new_line_content": "\t\t\tBlock ordered_block;",
          "content_same": false
        },
        {
          "line": 347,
          "old_api": "k);\n\t\ttype.deserialize",
          "new_api": null,
          "old_text": "k);\n\t\ttype.deserialize",
          "new_text": null,
          "old_line_content": "\t\t\t\tsize_t read_internal_size = array.getData().size();",
          "new_line_content": "\t\t\t\t/** Исправление для ошибочно записанных пустых файлов с данными массива.",
          "content_same": false
        },
        {
          "line": 475,
          "old_api": "",
          "new_api": null,
          "old_text": "",
          "new_text": null,
          "old_line_content": "\t\t\t\t\tordered_block.insert(res.getByName(name));",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 351,
          "old_api": "размере значения.\n\t\tsize_t col",
          "new_api": null,
          "old_text": "размере значения.\n\t\tsize_t col",
          "new_text": null,
          "old_line_content": "\t\t\t\t\t\tLOG_ERROR((&Logger::get(\"MergeTreeReader\")),",
          "new_line_content": "\t\t\t\tif (required_internal_size != read_internal_size)",
          "content_same": false
        },
        {
          "line": 355,
          "old_api": "чение avg_value_size_hint быстро росло, но медленно уменьшалось.\n\t\t\tif (current_avg_value_size > avg_value_size_hint)\n\t\t\t\tav",
          "new_api": null,
          "old_text": "чение avg_value_size_hint быстро росло, но медленно уменьшалось.\n\t\t\tif (current_avg_value_size > avg_value_size_hint)\n\t\t\t\tav",
          "new_text": null,
          "old_line_content": "\t\t\t\t\t\t*type_arr->getNestedType()->createConstColumn(",
          "new_line_content": "\t\t\t\t\t\t\t\"Internal size of array \" + name + \" doesn't match offsets: corrupted data, filling with default values.\");",
          "content_same": false
        },
        {
          "line": 483,
          "old_api": "",
          "new_api": null,
          "old_text": "",
          "new_text": null,
          "old_line_content": "\t\te.addMessage(\"(while reading from part \" + path + \")\");",
          "new_line_content": "\tcatch (Exception & e)",
          "content_same": false
        },
        {
          "line": 232,
          "old_api": "data",
          "new_api": null,
          "old_text": "arks->data()));\n\n\tif (buff",
          "new_text": null,
          "old_line_content": "\tsize_t file_size = Poco::File(path).getSize();",
          "new_line_content": "\t/// Memory for marks must not be accounted as memory usage for query, because they are stored in shared cache.",
          "content_same": false
        },
        {
          "line": 239,
          "old_api": "arkInCompressedFile mark = (*marks)[index];\n\n\ttry",
          "new_api": null,
          "old_text": "arkInCompressedFile mark = (*marks)[index];\n\n\ttry\n",
          "new_text": null,
          "old_line_content": "\tmarks = std::make_shared<MarksInCompressedFile>(num_marks);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 370,
          "old_api": "создавать не столбец пустых",
          "new_api": null,
          "old_text": "создавать не столбец пустых ",
          "new_text": null,
          "old_line_content": "\t\tstream.seekToMark(from_mark);",
          "new_line_content": "\t{",
          "content_same": false
        },
        {
          "line": 371,
          "old_api": "ивов, а столбец массивов\n\t\t\t*  правильных длин.\n\t\t\t* TODO: Если для какой-то вложенной стр",
          "new_api": null,
          "old_text": "ивов, а столбец массивов\n\t\t\t*  правильных длин.\n\t\t\t* TODO: Если для какой-то вложенной стр",
          "new_text": null,
          "old_line_content": "\t\ttype.deserializeBinary(column, *stream.data_buffer, max_rows_to_read, avg_value_size_hint);",
          "new_line_content": "\t\tStream & stream = *streams[name];",
          "content_same": false
        },
        {
          "line": 244,
          "old_api": "er)\n\t\t\tnon_cached_buff",
          "new_api": null,
          "old_text": "er)\n\t\t\tnon_cached_buff",
          "new_text": null,
          "old_line_content": "\tif (buffer.eof() || buffer.buffer().size() != file_size)",
          "new_line_content": "\t/// Read directly to marks.",
          "content_same": false
        }
      ]
    },
    "api_summary": {
      "total_replacements": 28,
      "total_additions": 41,
      "total_deletions": 41,
      "total_api_changes": 110
    },
    "non_api_changes": {
      "has_non_api_changes": true,
      "evidence": {
        "total_diff_lines": 3,
        "api_related_lines": 110,
        "non_api_lines": 2,
        "non_api_line_numbers": [
          233,
          234
        ]
      }
    },
    "api_calls_before": 150,
    "api_calls_after": 150,
    "diff_info": {
      "added_lines": 3,
      "removed_lines": 0,
      "total_diff_lines": 15
    }
  }
}