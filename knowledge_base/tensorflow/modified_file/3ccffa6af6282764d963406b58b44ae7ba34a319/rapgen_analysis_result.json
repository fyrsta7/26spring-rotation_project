{
  "status": "completed",
  "commit_dir": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/3ccffa6af6282764d963406b58b44ae7ba34a319",
  "file_info": {
    "before_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/3ccffa6af6282764d963406b58b44ae7ba34a319/before.cc",
    "after_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/3ccffa6af6282764d963406b58b44ae7ba34a319/after.cc",
    "diff_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/3ccffa6af6282764d963406b58b44ae7ba34a319/diff.txt"
  },
  "semgrep_analysis": {
    "is_api_change": false,
    "api_changes": {
      "replacements": [
        {
          "line": 594,
          "old_api": "get",
          "new_api": "std::make_unique<mlir::MLIRContext>(\n      registry, mlir::MLIRContext::Threading::DISABLED)",
          "old_text": "module.get()",
          "new_text": "std::make_unique<mlir::MLIRContext>(\n      registry, mlir::MLIRContext::Threading::DISABLED)",
          "old_line_content": "  symbol_uids.tf_symbol_uid = MaybeUploadMlirToXsymbol(module.get());",
          "new_line_content": "  auto context = std::make_unique<mlir::MLIRContext>(",
          "content_same": false
        },
        {
          "line": 611,
          "old_api": "get",
          "new_api": "absl::Now()",
          "old_text": "resource_context_.get()",
          "new_text": "absl::Now()",
          "old_line_content": "                                    resource_context_.get());",
          "new_line_content": "  auto compile_start_time = absl::Now();",
          "content_same": false
        },
        {
          "line": 623,
          "old_api": "tensorflow::errors::Internal(\"Missing kernel registry in MLRT.\")",
          "new_api": "get",
          "old_text": "tensorflow::errors::Internal(\"Missing kernel registry in MLRT.\")",
          "new_text": "ASSIGN_OR_RETURN_IN_COMPILE(\n        executable_context,\n        tfrt::BuildExecutableContext(module.get(), *kernel_registry_))",
          "old_line_content": "      return tensorflow::errors::Internal(\"Missing kernel registry in MLRT.\");",
          "new_line_content": "    ASSIGN_OR_RETURN_IN_COMPILE(",
          "content_same": false
        },
        {
          "line": 639,
          "old_api": "get",
          "new_api": "std::make_unique<mlrt::LoadedExecutable>(executable, *kernel_registry_)",
          "old_text": "module.get()",
          "new_text": "std::make_unique<mlrt::LoadedExecutable>(executable, *kernel_registry_)",
          "old_line_content": "        options_.compile_options, module.get(), &bef, model_context));",
          "new_line_content": "        std::make_unique<mlrt::LoadedExecutable>(executable, *kernel_registry_);",
          "content_same": false
        },
        {
          "line": 648,
          "old_api": "LOG",
          "new_api": "std::make_shared<ExecutableContext>(\n        std::move(bef), std::move(bef_file))",
          "old_text": "LOG(INFO)",
          "new_text": "std::make_shared<ExecutableContext>(\n        std::move(bef), std::move(bef_file))",
          "old_line_content": "  LOG(INFO) << \"TFRT finished compiling client graph (\" << &client_graph",
          "new_line_content": "    executable_context = std::make_shared<ExecutableContext>(",
          "content_same": false
        },
        {
          "line": 649,
          "old_api": "absl::ToInt64Milliseconds(compile_duration)",
          "new_api": "std::move(bef_file)",
          "old_text": "absl::ToInt64Milliseconds(compile_duration)",
          "new_text": "std::move(bef_file)",
          "old_line_content": "            << \"). Took \" << absl::ToInt64Milliseconds(compile_duration)",
          "new_line_content": "        std::move(bef), std::move(bef_file));",
          "content_same": false
        },
        {
          "line": 653,
          "old_api": "std::move(context)",
          "new_api": "absl::Now()",
          "old_text": "std::move(context)",
          "new_text": "absl::Now()",
          "old_line_content": "      client_graph.name, std::move(symbol_uids), this, std::move(context),",
          "new_line_content": "  auto compile_duration = absl::Now() - compile_start_time;",
          "content_same": false
        },
        {
          "line": 654,
          "old_api": "std::move(module)",
          "new_api": "LOG",
          "old_text": "std::move(module)",
          "new_text": "LOG(INFO)",
          "old_line_content": "      std::move(module_with_op_keys), std::move(module),",
          "new_line_content": "  LOG(INFO) << \"TFRT finished compiling client graph (\" << &client_graph",
          "content_same": false
        },
        {
          "line": 655,
          "old_api": "std::move(executable_context)",
          "new_api": "absl::ToInt64Milliseconds(compile_duration)",
          "old_text": "std::move(executable_context)",
          "new_text": "absl::ToInt64Milliseconds(compile_duration)",
          "old_line_content": "      std::move(executable_context), options_.enable_online_cost_analysis);",
          "new_line_content": "            << \"). Took \" << absl::ToInt64Milliseconds(compile_duration)",
          "content_same": false
        },
        {
          "line": 668,
          "old_api": "absl::Now()",
          "new_api": "LOG",
          "old_text": "absl::Now()",
          "new_text": "LOG(INFO)",
          "old_line_content": "  auto init_start_time = absl::Now();",
          "new_line_content": "  LOG(INFO) << \"TFRT loading client graph (\" << &client_graph << \") \"",
          "content_same": false
        },
        {
          "line": 675,
          "old_api": "LOG",
          "new_api": "executable_context",
          "old_text": "LOG(INFO)",
          "new_text": "loaded_client_graph->executable_context()->IsForMlrt()",
          "old_line_content": "  LOG(INFO) << \"TFRT finished initializing client graph (\" << &client_graph",
          "new_line_content": "  if (loaded_client_graph->executable_context()->IsForMlrt()) {",
          "content_same": false
        },
        {
          "line": 676,
          "old_api": "absl::ToInt64Milliseconds(init_duration)",
          "new_api": "get",
          "old_text": "absl::ToInt64Milliseconds(init_duration)",
          "new_text": "loaded_client_graph.get()",
          "old_line_content": "            << \"). Took \" << absl::ToInt64Milliseconds(init_duration)",
          "new_line_content": "    RETURN_IF_ERROR_IN_INIT(InitBytecode(loaded_client_graph.get()));",
          "content_same": false
        },
        {
          "line": 710,
          "old_api": "flib_def",
          "new_api": "LOG",
          "old_text": "tensorflow::ConvertGraphToMlir(\n      *optimized_graph.graph, /*debug_info=*/{},\n      optimized_graph.graph->flib_def(), graph_import_config, context)",
          "new_text": "LOG(INFO)",
          "old_line_content": "  return tensorflow::ConvertGraphToMlir(",
          "new_line_content": "  LOG(INFO) << \"TFRT import client graph (\" << &client_graph",
          "content_same": false
        },
        {
          "line": 712,
          "old_api": "flib_def",
          "new_api": "absl::ToInt64Milliseconds(optimized_graph.grappler_duration)",
          "old_text": "optimized_graph.graph->flib_def()",
          "new_text": "absl::ToInt64Milliseconds(optimized_graph.grappler_duration)",
          "old_line_content": "      optimized_graph.graph->flib_def(), graph_import_config, context);",
          "new_line_content": "            << absl::ToInt64Milliseconds(optimized_graph.grappler_duration)",
          "content_same": false
        },
        {
          "line": 718,
          "old_api": "get",
          "new_api": "flib_def",
          "old_text": "loaded_client_graph->executable_context()->bef_file.get()",
          "new_text": "optimized_graph.graph->flib_def()",
          "old_line_content": "  auto* bef_file = loaded_client_graph->executable_context()->bef_file.get();",
          "new_line_content": "      optimized_graph.graph->flib_def(), graph_import_config, context);",
          "content_same": false
        },
        {
          "line": 766,
          "old_api": "GetFunction",
          "new_api": "sync_resource_state",
          "old_text": "loaded_executable->GetFunction(kResourceInitFunction)",
          "new_text": "RunMlrtFunction(\n        function, *loaded_executable, request_info->tfrt_request_context,\n        *request_info->request_queue, {}, &outputs,\n        &loaded_graph->sync_resource_state())",
          "old_line_content": "  if (auto function = loaded_executable->GetFunction(kResourceInitFunction)) {",
          "new_line_content": "    TF_RETURN_IF_ERROR(RunMlrtFunction(",
          "content_same": false
        },
        {
          "line": 773,
          "old_api": "OkStatus",
          "new_api": "sync_resource_state",
          "old_text": "OkStatus()",
          "new_text": "RunMlrtFunction(\n        function, *loaded_executable, request_info->tfrt_request_context,\n        *request_info->request_queue, {}, &outputs,\n        &loaded_graph->sync_resource_state())",
          "old_line_content": "  return OkStatus();",
          "new_line_content": "    TF_RETURN_IF_ERROR(RunMlrtFunction(",
          "content_same": false
        },
        {
          "line": 801,
          "old_api": "find",
          "new_api": "absl::StrJoin(target_tensor_names,\n                              kTensorNameJoiningDelimiter)",
          "old_text": "loaded_client_graphs_.find(joined_name)",
          "new_text": "absl::StrJoin(target_tensor_names,\n                              kTensorNameJoiningDelimiter)",
          "old_line_content": "  const auto iter = loaded_client_graphs_.find(joined_name);",
          "new_line_content": "                absl::StrJoin(target_tensor_names,",
          "content_same": false
        },
        {
          "line": 820,
          "old_api": "set_unknown_rank",
          "new_api": "size",
          "old_text": "array_info.shape.set_unknown_rank(true)",
          "new_text": "input_tensor_names.size()",
          "old_line_content": "    array_info.shape.set_unknown_rank(true);",
          "new_line_content": "  for (int i = 0; i < input_tensor_names.size(); ++i) {",
          "content_same": false
        },
        {
          "line": 826,
          "old_api": "end",
          "new_api": "set_unknown_rank",
          "old_text": "output_tensor_names.end()",
          "new_text": "array_info.shape.set_unknown_rank(true)",
          "old_line_content": "      {output_tensor_names.begin(), output_tensor_names.end()},",
          "new_line_content": "    array_info.shape.set_unknown_rank(true);",
          "content_same": false
        },
        {
          "line": 832,
          "old_api": "get",
          "new_api": "end",
          "old_text": "loaded_client_graph.get()",
          "new_text": "output_tensor_names.end()",
          "old_line_content": "  auto* loaded_client_graph_ptr = loaded_client_graph.get();",
          "new_line_content": "      {output_tensor_names.begin(), output_tensor_names.end()},",
          "content_same": false
        },
        {
          "line": 833,
          "old_api": "std::move(loaded_client_graph)",
          "new_api": "end",
          "old_text": "std::move(loaded_client_graph)",
          "new_text": "target_tensor_names.end()",
          "old_line_content": "  loaded_client_graphs_[joined_name] = std::move(loaded_client_graph);",
          "new_line_content": "      {target_tensor_names.begin(), target_tensor_names.end()}};",
          "content_same": false
        },
        {
          "line": 856,
          "old_api": "get",
          "new_api": "empty",
          "old_text": "executable_context->bytecode_executable.get()",
          "new_text": "graph_name.empty()",
          "old_line_content": "      executable_context->bytecode_executable.get());",
          "new_line_content": "          graph_name.empty() ? output_tensor_names[0] : graph_name));",
          "content_same": false
        },
        {
          "line": 860,
          "old_api": "sync_resource_state",
          "new_api": "executable_context",
          "old_text": "loaded_client_graph.sync_resource_state()",
          "new_text": "loaded_client_graph.executable_context()",
          "old_line_content": "                 &loaded_client_graph.sync_resource_state());",
          "new_line_content": "  auto executable_context = loaded_client_graph.executable_context();",
          "content_same": false
        },
        {
          "line": 864,
          "old_api": "runner_table",
          "new_api": "sync_resource_state",
          "old_text": "loaded_client_graph.runner_table()",
          "new_text": "AddSyncContext(execution_context,\n                 *options_.runtime->core_runtime()->GetHostContext(),\n                 &loaded_client_graph.sync_resource_state())",
          "old_line_content": "      /*step_id=*/0, &loaded_client_graph.runner_table(),",
          "new_line_content": "  AddSyncContext(execution_context,",
          "content_same": false
        },
        {
          "line": 865,
          "old_api": "resource_array",
          "new_api": "core_runtime",
          "old_text": "loaded_client_graph.resource_array()",
          "new_text": "options_.runtime->core_runtime()->GetHostContext()",
          "old_line_content": "      &loaded_client_graph.resource_array(),",
          "new_line_content": "                 *options_.runtime->core_runtime()->GetHostContext(),",
          "content_same": false
        },
        {
          "line": 870,
          "old_api": "std::move(tf_context)",
          "new_api": "runner_table",
          "old_text": "std::move(tf_context)",
          "new_text": "loaded_client_graph.runner_table()",
          "old_line_content": "  execution_context.AddUserContext(std::move(tf_context));",
          "new_line_content": "      /*step_id=*/0, &loaded_client_graph.runner_table(),",
          "content_same": false
        },
        {
          "line": 873,
          "old_api": "name",
          "new_api": "get",
          "old_text": "loaded_client_graph.name()",
          "new_text": "fallback_state_.get().process_function_library_runtime()",
          "old_line_content": "      loaded_client_graph.name());",
          "new_line_content": "      &fallback_state_.get().process_function_library_runtime());",
          "content_same": false
        },
        {
          "line": 874,
          "old_api": "DCHECK",
          "new_api": "get",
          "old_text": "DCHECK(serving_function)",
          "new_text": "std::make_unique<tensorflow::tf_mlrt::Context>(\n      &kernel_fallback_state, resource_context_.get())",
          "old_line_content": "  DCHECK(serving_function);",
          "new_line_content": "  auto tf_context = std::make_unique<tensorflow::tf_mlrt::Context>(",
          "content_same": false
        },
        {
          "line": 876,
          "old_api": "CallByMove",
          "new_api": "std::move(tf_context)",
          "old_text": "execution_context.CallByMove(serving_function, input_values, outputs)",
          "new_text": "std::move(tf_context)",
          "old_line_content": "  execution_context.CallByMove(serving_function, input_values, outputs);",
          "new_line_content": "  execution_context.AddUserContext(std::move(tf_context));",
          "content_same": false
        },
        {
          "line": 878,
          "old_api": "status",
          "new_api": "name",
          "old_text": "execution_context.status()",
          "new_text": "executable_context->bytecode_executable->GetFunction(\n      loaded_client_graph.name())",
          "old_line_content": "  return execution_context.status();",
          "new_line_content": "  auto serving_function = executable_context->bytecode_executable->GetFunction(",
          "content_same": false
        },
        {
          "line": 899,
          "old_api": "get",
          "new_api": "LOG",
          "old_text": "tfrt_mlir.get().getContext()",
          "new_text": "LOG(INFO)",
          "old_line_content": "      tfrt_mlir.get().getContext());",
          "new_line_content": "  LOG(INFO) << \"TFRT updating op costs of loaded client graph (\" << this << \") \"",
          "content_same": false
        },
        {
          "line": 917,
          "old_api": "get",
          "new_api": "std::make_unique<mlrt::LoadedExecutable>(\n        executable, *graph_executor_->kernel_registry_)",
          "old_text": "tfrt_mlir.get()",
          "new_text": "std::make_unique<mlrt::LoadedExecutable>(\n        executable, *graph_executor_->kernel_registry_)",
          "old_line_content": "    tfrt_compiler::UpdateOpCostInTfrtMlir(tfrt_mlir.get(), cost_recorder);",
          "new_line_content": "    auto bytecode_executable = std::make_unique<mlrt::LoadedExecutable>(",
          "content_same": false
        },
        {
          "line": 920,
          "old_api": "get",
          "new_api": "std::move(bytecode_executable)",
          "old_text": "tfrt_mlir.get()",
          "new_text": "std::move(bytecode_executable)",
          "old_line_content": "    auto bef = tfrt::ConvertMLIRToBEF(tfrt_mlir.get(),",
          "new_line_content": "        std::move(bytecode_buffer), std::move(bytecode_executable));",
          "content_same": false
        },
        {
          "line": 923,
          "old_api": "empty",
          "new_api": "get",
          "old_text": "bef.empty()",
          "new_text": "tfrt_mlir.get()",
          "old_line_content": "    if (bef.empty()) {",
          "new_line_content": "    tfrt_compiler::UpdateOpCostInTfrtMlir(tfrt_mlir.get(), cost_recorder);",
          "content_same": false
        },
        {
          "line": 930,
          "old_api": "std::make_shared<ExecutableContext>(\n        std::move(bef), std::move(bef_file))",
          "new_api": "Combine",
          "old_text": "std::make_shared<ExecutableContext>(\n        std::move(bef), std::move(bef_file))",
          "new_text": "diag_handler.Combine(\n          tensorflow::errors::Internal(\"failed to convert MLIR to BEF.\"))",
          "old_line_content": "    new_executable_context = std::make_shared<ExecutableContext>(",
          "new_line_content": "      return diag_handler.Combine(",
          "content_same": false
        },
        {
          "line": 931,
          "old_api": "std::move(bef_file)",
          "new_api": "tensorflow::errors::Internal(\"failed to convert MLIR to BEF.\")",
          "old_text": "std::move(bef_file)",
          "new_text": "tensorflow::errors::Internal(\"failed to convert MLIR to BEF.\")",
          "old_line_content": "        std::move(bef), std::move(bef_file));",
          "new_line_content": "          tensorflow::errors::Internal(\"failed to convert MLIR to BEF.\"));",
          "content_same": false
        },
        {
          "line": 937,
          "old_api": "std::move(new_executable_context)",
          "new_api": "std::move(bef_file)",
          "old_text": "std::move(new_executable_context)",
          "new_text": "std::move(bef_file)",
          "old_line_content": "  executable_context_ = std::move(new_executable_context);",
          "new_line_content": "        std::move(bef), std::move(bef_file));",
          "content_same": false
        }
      ],
      "additions": [
        {
          "line": 640,
          "old_api": null,
          "new_api": "std::make_shared<ExecutableContext>(\n        std::move(bytecode_buffer), std::move(bytecode_executable))",
          "old_text": null,
          "new_text": "std::make_shared<ExecutableContext>(\n        std::move(bytecode_buffer), std::move(bytecode_executable))",
          "old_line_content": "    ASSIGN_OR_RETURN_IN_COMPILE(",
          "new_line_content": "    executable_context = std::make_shared<ExecutableContext>(",
          "content_same": false
        },
        {
          "line": 641,
          "old_api": null,
          "new_api": "std::move(bytecode_executable)",
          "old_text": null,
          "new_text": "std::move(bytecode_executable)",
          "old_line_content": "        auto bef_file, tfrt::CreateBefFileFromBefBuffer(runtime(), bef));",
          "new_line_content": "        std::move(bytecode_buffer), std::move(bytecode_executable));",
          "content_same": false
        },
        {
          "line": 769,
          "old_api": null,
          "new_api": "sync_resource_state",
          "old_text": null,
          "new_text": "loaded_graph->sync_resource_state()",
          "old_line_content": "        *request_info->request_queue, {}, &outputs,",
          "new_line_content": "        &loaded_graph->sync_resource_state()));",
          "content_same": false
        },
        {
          "line": 644,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "tensorflow::ConvertTfMlirToBef(\n        options_.compile_options, module.get(), &bef, model_context)",
          "old_line_content": "  }",
          "new_line_content": "    TF_RETURN_IF_ERROR(tensorflow::ConvertTfMlirToBef(",
          "content_same": false
        },
        {
          "line": 772,
          "old_api": null,
          "new_api": "GetFunction",
          "old_text": null,
          "new_text": "loaded_executable->GetFunction(kResourceInitFunction)",
          "old_line_content": "",
          "new_line_content": "  if (auto function = loaded_executable->GetFunction(kResourceInitFunction)) {",
          "content_same": false
        },
        {
          "line": 902,
          "old_api": null,
          "new_api": "std::move(tfrt_mlir_)",
          "old_text": null,
          "new_text": "std::move(tfrt_mlir_)",
          "old_line_content": "    // Recompile from the TF MLIR with recorded costs (skipping",
          "new_line_content": "  auto tfrt_mlir = std::move(tfrt_mlir_);",
          "content_same": false
        },
        {
          "line": 903,
          "old_api": null,
          "new_api": "std::move(tf_mlir_with_op_keys_)",
          "old_text": null,
          "new_text": "std::move(tf_mlir_with_op_keys_)",
          "old_line_content": "    // AssignOpKeyPass), during which Stream Analysis is redone.",
          "new_line_content": "  auto tf_mlir_with_op_keys = std::move(tf_mlir_with_op_keys_);",
          "content_same": false
        },
        {
          "line": 776,
          "old_api": null,
          "new_api": "sync_resource_state",
          "old_text": null,
          "new_text": "loaded_graph->sync_resource_state()",
          "old_line_content": "StatusOr<std::reference_wrapper<GraphExecutor::LoadedClientGraph>>",
          "new_line_content": "        &loaded_graph->sync_resource_state()));",
          "content_same": false
        },
        {
          "line": 765,
          "old_api": null,
          "new_api": "GetFunction",
          "old_text": null,
          "new_text": "loaded_executable->GetFunction(kFallbackInitFunction)",
          "old_line_content": "",
          "new_line_content": "  if (auto function = loaded_executable->GetFunction(kFallbackInitFunction)) {",
          "content_same": false
        },
        {
          "line": 905,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "tfrt_mlir.get().getContext()",
          "old_line_content": "        auto bytecode_buffer,",
          "new_line_content": "      tfrt_mlir.get().getContext());",
          "content_same": false
        },
        {
          "line": 651,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "module.get()",
          "old_line_content": "",
          "new_line_content": "  symbol_uids.tfrt_symbol_uid = MaybeUploadMlirToXsymbol(module.get());",
          "content_same": false
        },
        {
          "line": 779,
          "old_api": null,
          "new_api": "OkStatus",
          "old_text": null,
          "new_text": "OkStatus()",
          "old_line_content": "    absl::Span<const std::string> input_tensor_names,",
          "new_line_content": "  return OkStatus();",
          "content_same": false
        },
        {
          "line": 907,
          "old_api": null,
          "new_api": "IsForMlrt",
          "old_text": null,
          "new_text": "executable_context()->IsForMlrt()",
          "old_line_content": "            graph_executor_->options().compile_options,",
          "new_line_content": "  if (executable_context()->IsForMlrt()) {",
          "content_same": false
        },
        {
          "line": 658,
          "old_api": null,
          "new_api": "std::make_unique<LoadedClientGraph>(\n      client_graph.name, std::move(symbol_uids), this, std::move(context),\n      std::move(module_with_op_keys), std::move(module),\n      std::move(executable_context), options_.enable_online_cost_analysis)",
          "old_text": null,
          "new_text": "std::make_unique<LoadedClientGraph>(\n      client_graph.name, std::move(symbol_uids), this, std::move(context),\n      std::move(module_with_op_keys), std::move(module),\n      std::move(executable_context), options_.enable_online_cost_analysis)",
          "old_line_content": "StatusOr<std::unique_ptr<GraphExecutor::LoadedClientGraph>>",
          "new_line_content": "  return std::make_unique<LoadedClientGraph>(",
          "content_same": false
        },
        {
          "line": 659,
          "old_api": null,
          "new_api": "std::move(context)",
          "old_text": null,
          "new_text": "std::move(context)",
          "old_line_content": "GraphExecutor::LoadClientGraph(",
          "new_line_content": "      client_graph.name, std::move(symbol_uids), this, std::move(context),",
          "content_same": false
        },
        {
          "line": 660,
          "old_api": null,
          "new_api": "std::move(module)",
          "old_text": null,
          "new_text": "std::move(module)",
          "old_line_content": "    const GraphExecutor::ClientGraph& client_graph,",
          "new_line_content": "      std::move(module_with_op_keys), std::move(module),",
          "content_same": false
        },
        {
          "line": 661,
          "old_api": null,
          "new_api": "std::move(executable_context)",
          "old_text": null,
          "new_text": "std::move(executable_context)",
          "old_line_content": "    tensorflow::tfrt_stub::WorkQueueInterface* work_queue) {",
          "new_line_content": "      std::move(executable_context), options_.enable_online_cost_analysis);",
          "content_same": false
        },
        {
          "line": 916,
          "old_api": null,
          "new_api": "data",
          "old_text": null,
          "new_text": "bytecode_buffer.data()",
          "old_line_content": "    // Update costs in TFRT MLIR.",
          "new_line_content": "    mlrt::bc::Executable executable(bytecode_buffer.data());",
          "content_same": false
        },
        {
          "line": 919,
          "old_api": null,
          "new_api": "std::make_shared<ExecutableContext>(\n        std::move(bytecode_buffer), std::move(bytecode_executable))",
          "old_text": null,
          "new_text": "std::make_shared<ExecutableContext>(\n        std::move(bytecode_buffer), std::move(bytecode_executable))",
          "old_line_content": "    // redone.",
          "new_line_content": "    new_executable_context = std::make_shared<ExecutableContext>(",
          "content_same": false
        },
        {
          "line": 796,
          "old_api": null,
          "new_api": "absl::StrCat(\n                absl::StrJoin(input_tensor_names, kTensorNameJoiningDelimiter),\n                kArgumentTypeJoiningDelimiter,\n                absl::StrJoin(output_tensor_names, kTensorNameJoiningDelimiter),\n                kArgumentTypeJoiningDelimiter,\n                absl::StrJoin(target_tensor_names,\n                              kTensorNameJoiningDelimiter))",
          "old_text": null,
          "new_text": "absl::StrCat(\n                absl::StrJoin(input_tensor_names, kTensorNameJoiningDelimiter),\n                kArgumentTypeJoiningDelimiter,\n                absl::StrJoin(output_tensor_names, kTensorNameJoiningDelimiter),\n                kArgumentTypeJoiningDelimiter,\n                absl::StrJoin(target_tensor_names,\n                              kTensorNameJoiningDelimiter))",
          "old_line_content": "                              kTensorNameJoiningDelimiter));",
          "new_line_content": "          : absl::StrCat(",
          "content_same": false
        },
        {
          "line": 797,
          "old_api": null,
          "new_api": "absl::StrJoin(input_tensor_names, kTensorNameJoiningDelimiter)",
          "old_text": null,
          "new_text": "absl::StrJoin(input_tensor_names, kTensorNameJoiningDelimiter)",
          "old_line_content": "",
          "new_line_content": "                absl::StrJoin(input_tensor_names, kTensorNameJoiningDelimiter),",
          "content_same": false
        },
        {
          "line": 926,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "tfrt_mlir.get()",
          "old_line_content": "    }",
          "new_line_content": "    auto bef = tfrt::ConvertMLIRToBEF(tfrt_mlir.get(),",
          "content_same": false
        },
        {
          "line": 799,
          "old_api": null,
          "new_api": "absl::StrJoin(output_tensor_names, kTensorNameJoiningDelimiter)",
          "old_text": null,
          "new_text": "absl::StrJoin(output_tensor_names, kTensorNameJoiningDelimiter)",
          "old_line_content": "",
          "new_line_content": "                absl::StrJoin(output_tensor_names, kTensorNameJoiningDelimiter),",
          "content_same": false
        },
        {
          "line": 929,
          "old_api": null,
          "new_api": "empty",
          "old_text": null,
          "new_text": "bef.empty()",
          "old_line_content": "                        tfrt::CreateBefFileFromBefBuffer(runtime, bef));",
          "new_line_content": "    if (bef.empty()) {",
          "content_same": false
        },
        {
          "line": 933,
          "old_api": null,
          "new_api": "shrink_to_fit",
          "old_text": null,
          "new_text": "bef.shrink_to_fit()",
          "old_line_content": "  // Swap in the new `ExecutableContext`.",
          "new_line_content": "    bef.shrink_to_fit();",
          "content_same": false
        },
        {
          "line": 678,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "loaded_client_graph.get()",
          "old_line_content": "",
          "new_line_content": "    RETURN_IF_ERROR_IN_INIT(InitBef(loaded_client_graph.get(), work_queue));",
          "content_same": false
        },
        {
          "line": 807,
          "old_api": null,
          "new_api": "find",
          "old_text": null,
          "new_text": "loaded_client_graphs_.find(joined_name)",
          "old_line_content": "                     \"the compiled graph is not found for \",",
          "new_line_content": "  const auto iter = loaded_client_graphs_.find(joined_name);",
          "content_same": false
        },
        {
          "line": 680,
          "old_api": null,
          "new_api": "absl::Now()",
          "old_text": null,
          "new_text": "absl::Now()",
          "old_line_content": "}",
          "new_line_content": "  auto init_duration = absl::Now() - init_start_time;",
          "content_same": false
        },
        {
          "line": 681,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(INFO)",
          "old_line_content": "",
          "new_line_content": "  LOG(INFO) << \"TFRT finished initializing client graph (\" << &client_graph",
          "content_same": false
        },
        {
          "line": 682,
          "old_api": null,
          "new_api": "absl::ToInt64Milliseconds(init_duration)",
          "old_text": null,
          "new_text": "absl::ToInt64Milliseconds(init_duration)",
          "old_line_content": "tensorflow::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>>",
          "new_line_content": "            << \"). Took \" << absl::ToInt64Milliseconds(init_duration)",
          "content_same": false
        },
        {
          "line": 808,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "loaded_client_graphs_.end()",
          "old_line_content": "                     joined_name));",
          "new_line_content": "  if (iter != loaded_client_graphs_.end()) return {*iter->second};",
          "content_same": false
        },
        {
          "line": 811,
          "old_api": null,
          "new_api": "tensorflow::errors::InvalidArgument(\n        absl::StrCat(\"GraphExecutor: compilation is disabled in execution but \"\n                     \"the compiled graph is not found for \",\n                     joined_name))",
          "old_text": null,
          "new_text": "tensorflow::errors::InvalidArgument(\n        absl::StrCat(\"GraphExecutor: compilation is disabled in execution but \"\n                     \"the compiled graph is not found for \",\n                     joined_name))",
          "old_line_content": "  // Cache miss; populate a `ClientGraph` and load it.",
          "new_line_content": "    return tensorflow::errors::InvalidArgument(",
          "content_same": false
        },
        {
          "line": 812,
          "old_api": null,
          "new_api": "absl::StrCat(\"GraphExecutor: compilation is disabled in execution but \"\n                     \"the compiled graph is not found for \",\n                     joined_name)",
          "old_text": null,
          "new_text": "absl::StrCat(\"GraphExecutor: compilation is disabled in execution but \"\n                     \"the compiled graph is not found for \",\n                     joined_name)",
          "old_line_content": "  tensorflow::GraphImportConfig::InputArrays input_nodes;",
          "new_line_content": "        absl::StrCat(\"GraphExecutor: compilation is disabled in execution but \"",
          "content_same": false
        },
        {
          "line": 936,
          "old_api": null,
          "new_api": "std::make_shared<ExecutableContext>(\n        std::move(bef), std::move(bef_file))",
          "old_text": null,
          "new_text": "std::make_shared<ExecutableContext>(\n        std::move(bef), std::move(bef_file))",
          "old_line_content": "  // add a test kernel that examines the cost.",
          "new_line_content": "    new_executable_context = std::make_shared<ExecutableContext>(",
          "content_same": false
        },
        {
          "line": 943,
          "old_api": null,
          "new_api": "std::move(new_executable_context)",
          "old_text": null,
          "new_text": "std::move(new_executable_context)",
          "old_line_content": "    absl::Span<const std::string> input_tensor_names,",
          "new_line_content": "  executable_context_ = std::move(new_executable_context);",
          "content_same": false
        },
        {
          "line": 944,
          "old_api": null,
          "new_api": "OkStatus",
          "old_text": null,
          "new_text": "OkStatus()",
          "old_line_content": "    absl::Span<const tensorflow::DataType> input_tensor_dtypes,",
          "new_line_content": "  return OkStatus();",
          "content_same": false
        },
        {
          "line": 819,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "input_tensor_dtypes.size()",
          "old_line_content": "    array_info.imported_dtype = input_dtype;",
          "new_line_content": "  DCHECK_EQ(input_tensor_names.size(), input_tensor_dtypes.size());",
          "content_same": false
        },
        {
          "line": 953,
          "old_api": null,
          "new_api": "status",
          "old_text": null,
          "new_text": "GetOrCreateLoadedClientGraph(\n             /*run_options=*/{}, input_tensor_names, input_tensor_dtypes,\n             output_tensor_names, target_tensor_names,\n             /*work_queue=*/nullptr, graph_name)\n      .status()",
          "old_line_content": "",
          "new_line_content": "  return GetOrCreateLoadedClientGraph(",
          "content_same": false
        },
        {
          "line": 831,
          "old_api": null,
          "new_api": "std::move(input_nodes)",
          "old_text": null,
          "new_text": "std::move(input_nodes)",
          "old_line_content": "  // Store the new loaded client graph in cache and return.",
          "new_line_content": "      std::move(input_nodes),",
          "content_same": false
        },
        {
          "line": 705,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(INFO)",
          "old_line_content": "            << \"): Grappler took \"",
          "new_line_content": "  LOG(INFO) << \"TFRT import client graph (\" << &client_graph",
          "content_same": false
        },
        {
          "line": 961,
          "old_api": null,
          "new_api": "registry.insert<mlir::BuiltinDialect, mlir::func::FuncDialect>()",
          "old_text": null,
          "new_text": "registry.insert<mlir::BuiltinDialect, mlir::func::FuncDialect>()",
          "old_line_content": "",
          "new_line_content": "  registry.insert<mlir::BuiltinDialect, mlir::func::FuncDialect>();",
          "content_same": false
        },
        {
          "line": 707,
          "old_api": null,
          "new_api": "absl::ToInt64Milliseconds(\n                   optimized_graph.functionalization_duration)",
          "old_text": null,
          "new_text": "absl::ToInt64Milliseconds(\n                   optimized_graph.functionalization_duration)",
          "old_line_content": "            << \" ms. Client graph name: \" << client_graph.name;",
          "new_line_content": "            << absl::ToInt64Milliseconds(",
          "content_same": false
        },
        {
          "line": 962,
          "old_api": null,
          "new_api": "mlir::RegisterAllTensorFlowDialects(registry)",
          "old_text": null,
          "new_text": "mlir::RegisterAllTensorFlowDialects(registry)",
          "old_line_content": "",
          "new_line_content": "  mlir::RegisterAllTensorFlowDialects(registry);",
          "content_same": false
        },
        {
          "line": 838,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "loaded_client_graph.get()",
          "old_line_content": "    const std::string& graph_name, absl::Span<mlrt::Value> input_values,",
          "new_line_content": "  auto* loaded_client_graph_ptr = loaded_client_graph.get();",
          "content_same": false
        },
        {
          "line": 839,
          "old_api": null,
          "new_api": "std::move(loaded_client_graph)",
          "old_text": null,
          "new_text": "std::move(loaded_client_graph)",
          "old_line_content": "    absl::Span<const std::string> input_names,",
          "new_line_content": "  loaded_client_graphs_[joined_name] = std::move(loaded_client_graph);",
          "content_same": false
        },
        {
          "line": 716,
          "old_api": null,
          "new_api": "flib_def",
          "old_text": null,
          "new_text": "tensorflow::ConvertGraphToMlir(\n      *optimized_graph.graph, /*debug_info=*/{},\n      optimized_graph.graph->flib_def(), graph_import_config, context)",
          "old_line_content": "    LoadedClientGraph* loaded_client_graph,",
          "new_line_content": "  return tensorflow::ConvertGraphToMlir(",
          "content_same": false
        },
        {
          "line": 724,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "loaded_client_graph->executable_context()->bef_file.get()",
          "old_line_content": "          &loaded_client_graph->runner_table(),",
          "new_line_content": "  auto* bef_file = loaded_client_graph->executable_context()->bef_file.get();",
          "content_same": false
        },
        {
          "line": 852,
          "old_api": null,
          "new_api": "empty",
          "old_text": null,
          "new_text": "GetOrCreateLoadedClientGraph(\n          /*run_options=*/{}, input_names, input_dtypes, output_tensor_names,\n          target_tensor_names,\n          /*work_queue=*/nullptr,\n          graph_name.empty() ? output_tensor_names[0] : graph_name)",
          "old_line_content": "  // Get a shared_ptr of the executable so that during the current request the",
          "new_line_content": "      GetOrCreateLoadedClientGraph(",
          "content_same": false
        },
        {
          "line": 600,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "module.get()",
          "old_line_content": "",
          "new_line_content": "  symbol_uids.tf_symbol_uid = MaybeUploadMlirToXsymbol(module.get());",
          "content_same": false
        },
        {
          "line": 602,
          "old_api": null,
          "new_api": "absl::Now()",
          "old_text": null,
          "new_text": "absl::Now()",
          "old_line_content": "  // (in BEF).",
          "new_line_content": "  auto import_duration = absl::Now() - import_start_time;",
          "content_same": false
        },
        {
          "line": 603,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(INFO)",
          "old_line_content": "  // TODO(b/229261464): Unify the sync and async lowering passes so we do not",
          "new_line_content": "  LOG(INFO) << \"TFRT finished importing client graph (\" << &client_graph",
          "content_same": false
        },
        {
          "line": 604,
          "old_api": null,
          "new_api": "absl::ToInt64Milliseconds(import_duration)",
          "old_text": null,
          "new_text": "absl::ToInt64Milliseconds(import_duration)",
          "old_line_content": "  // need this branch.",
          "new_line_content": "            << \"). Took \" << absl::ToInt64Milliseconds(import_duration)",
          "content_same": false
        },
        {
          "line": 862,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "executable_context->bytecode_executable.get()",
          "old_line_content": "  tensorflow::tfd::KernelFallbackCompatRequestState kernel_fallback_state(",
          "new_line_content": "      executable_context->bytecode_executable.get());",
          "content_same": false
        },
        {
          "line": 866,
          "old_api": null,
          "new_api": "sync_resource_state",
          "old_text": null,
          "new_text": "loaded_client_graph.sync_resource_state()",
          "old_line_content": "      /*user_intra_op_threadpool=*/nullptr, /*model_metadata=*/std::nullopt,",
          "new_line_content": "                 &loaded_client_graph.sync_resource_state());",
          "content_same": false
        },
        {
          "line": 871,
          "old_api": null,
          "new_api": "resource_array",
          "old_text": null,
          "new_text": "loaded_client_graph.resource_array()",
          "old_line_content": "",
          "new_line_content": "      &loaded_client_graph.resource_array(),",
          "content_same": false
        },
        {
          "line": 744,
          "old_api": null,
          "new_api": "TF_RETURN_IF_ERROR",
          "old_text": null,
          "new_text": "TF_RETURN_IF_ERROR(\n      RunRuntimeInitializer(exec_ctx, bef_file, kResourceInitFunction))",
          "old_line_content": "tensorflow::Status GraphExecutor::InitBytecode(",
          "new_line_content": "  TF_RETURN_IF_ERROR(",
          "content_same": false
        },
        {
          "line": 745,
          "old_api": null,
          "new_api": "RunRuntimeInitializer",
          "old_text": null,
          "new_text": "RunRuntimeInitializer(exec_ctx, bef_file, kResourceInitFunction)",
          "old_line_content": "    LoadedClientGraph* loaded_graph) {",
          "new_line_content": "      RunRuntimeInitializer(exec_ctx, bef_file, kResourceInitFunction));",
          "content_same": false
        },
        {
          "line": 747,
          "old_api": null,
          "new_api": "OkStatus",
          "old_text": null,
          "new_text": "OkStatus()",
          "old_line_content": "      auto request_info,",
          "new_line_content": "  return OkStatus();",
          "content_same": false
        },
        {
          "line": 875,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "resource_context_.get()",
          "old_line_content": "",
          "new_line_content": "      &kernel_fallback_state, resource_context_.get());",
          "content_same": false
        },
        {
          "line": 621,
          "old_api": null,
          "new_api": "tensorflow::errors::Internal(\"Missing kernel registry in MLRT.\")",
          "old_text": null,
          "new_text": "tensorflow::errors::Internal(\"Missing kernel registry in MLRT.\")",
          "old_line_content": "  } else if (options_.enable_mlrt) {",
          "new_line_content": "      return tensorflow::errors::Internal(\"Missing kernel registry in MLRT.\");",
          "content_same": false
        },
        {
          "line": 879,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "loaded_client_graph.name()",
          "old_line_content": "}",
          "new_line_content": "      loaded_client_graph.name());",
          "content_same": false
        },
        {
          "line": 880,
          "old_api": null,
          "new_api": "DCHECK",
          "old_text": null,
          "new_text": "DCHECK(serving_function)",
          "old_line_content": "",
          "new_line_content": "  DCHECK(serving_function);",
          "content_same": false
        },
        {
          "line": 625,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "module.get()",
          "old_line_content": "",
          "new_line_content": "        tfrt::BuildExecutableContext(module.get(), *kernel_registry_));",
          "content_same": false
        },
        {
          "line": 882,
          "old_api": null,
          "new_api": "CallByMove",
          "old_text": null,
          "new_text": "execution_context.CallByMove(serving_function, input_values, outputs)",
          "old_line_content": "GraphExecutor::LoadedClientGraph::MaybeCreateCostRecorder(",
          "new_line_content": "  execution_context.CallByMove(serving_function, input_values, outputs);",
          "content_same": false
        },
        {
          "line": 883,
          "old_api": null,
          "new_api": "mlrt::Execute(execution_context)",
          "old_text": null,
          "new_text": "mlrt::Execute(execution_context)",
          "old_line_content": "    uint64_t normalize_ratio) const {",
          "new_line_content": "  mlrt::Execute(execution_context);",
          "content_same": false
        },
        {
          "line": 884,
          "old_api": null,
          "new_api": "status",
          "old_text": null,
          "new_text": "execution_context.status()",
          "old_line_content": "  std::unique_ptr<CostRecorder> cost_recorder;",
          "new_line_content": "  return execution_context.status();",
          "content_same": false
        },
        {
          "line": 629,
          "old_api": null,
          "new_api": "tensorflow::errors::Internal(\"Missing kernel registry in MLRT.\")",
          "old_text": null,
          "new_text": "tensorflow::errors::Internal(\"Missing kernel registry in MLRT.\")",
          "old_line_content": "            options_.compile_options, fallback_state_, module.get(),",
          "new_line_content": "      return tensorflow::errors::Internal(\"Missing kernel registry in MLRT.\");",
          "content_same": false
        },
        {
          "line": 758,
          "old_api": null,
          "new_api": "resource_array",
          "old_text": null,
          "new_text": "loaded_graph->resource_array()",
          "old_line_content": "  std::vector<tensorflow::Tensor> outputs;",
          "new_line_content": "                        &loaded_graph->resource_array(), fallback_state_));",
          "content_same": false
        },
        {
          "line": 761,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "loaded_graph->executable_context()->bytecode_executable.get()",
          "old_line_content": "        function, *loaded_executable, request_info->tfrt_request_context,",
          "new_line_content": "      loaded_graph->executable_context()->bytecode_executable.get();",
          "content_same": false
        },
        {
          "line": 762,
          "old_api": null,
          "new_api": "DCHECK",
          "old_text": null,
          "new_text": "DCHECK(loaded_executable)",
          "old_line_content": "        *request_info->request_queue, {}, &outputs,",
          "new_line_content": "  DCHECK(loaded_executable);",
          "content_same": false
        },
        {
          "line": 891,
          "old_api": null,
          "new_api": "absl::call_once(create_cost_recorder_once_, [&]() {\n    cost_recorder = std::make_unique<CostRecorder>(normalize_ratio);\n  })",
          "old_text": null,
          "new_text": "absl::call_once(create_cost_recorder_once_, [&]() {\n    cost_recorder = std::make_unique<CostRecorder>(normalize_ratio);\n  })",
          "old_line_content": "Status GraphExecutor::LoadedClientGraph::UpdateCost(",
          "new_line_content": "  absl::call_once(create_cost_recorder_once_, [&]() {",
          "content_same": false
        },
        {
          "line": 892,
          "old_api": null,
          "new_api": "std::make_unique<CostRecorder>(normalize_ratio)",
          "old_text": null,
          "new_text": "std::make_unique<CostRecorder>(normalize_ratio)",
          "old_line_content": "    const CostRecorder& cost_recorder, const Runtime& runtime) {",
          "new_line_content": "    cost_recorder = std::make_unique<CostRecorder>(normalize_ratio);",
          "content_same": false
        },
        {
          "line": 637,
          "old_api": null,
          "new_api": "data",
          "old_text": null,
          "new_text": "bytecode_buffer.data()",
          "old_line_content": "    tfrt::BefBuffer bef;",
          "new_line_content": "    mlrt::bc::Executable executable(bytecode_buffer.data());",
          "content_same": false
        }
      ],
      "deletions": [
        {
          "line": 896,
          "old_api": "std::move(tfrt_mlir_)",
          "new_api": null,
          "old_text": "std::move(tfrt_mlir_)",
          "new_text": null,
          "old_line_content": "  auto tfrt_mlir = std::move(tfrt_mlir_);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 897,
          "old_api": "std::move(tf_mlir_with_op_keys_)",
          "new_api": null,
          "old_text": "std::move(tf_mlir_with_op_keys_)",
          "new_text": null,
          "old_line_content": "  auto tf_mlir_with_op_keys = std::move(tf_mlir_with_op_keys_);",
          "new_line_content": "Status GraphExecutor::LoadedClientGraph::UpdateCost(",
          "content_same": false
        },
        {
          "line": 642,
          "old_api": "std::make_shared<ExecutableContext>(\n        std::move(bef), std::move(bef_file))",
          "new_api": null,
          "old_text": "std::make_shared<ExecutableContext>(\n        std::move(bef), std::move(bef_file))",
          "new_text": null,
          "old_line_content": "    executable_context = std::make_shared<ExecutableContext>(",
          "new_line_content": "  } else {",
          "content_same": false
        },
        {
          "line": 643,
          "old_api": "std::move(bef_file)",
          "new_api": null,
          "old_text": "std::move(bef_file)",
          "new_text": null,
          "old_line_content": "        std::move(bef), std::move(bef_file));",
          "new_line_content": "    tfrt::BefBuffer bef;",
          "content_same": false
        },
        {
          "line": 770,
          "old_api": "sync_resource_state",
          "new_api": null,
          "old_text": "loaded_graph->sync_resource_state()",
          "new_text": null,
          "old_line_content": "        &loaded_graph->sync_resource_state()));",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 901,
          "old_api": "IsForMlrt",
          "new_api": null,
          "old_text": "executable_context()->IsForMlrt()",
          "new_text": null,
          "old_line_content": "  if (executable_context()->IsForMlrt()) {",
          "new_line_content": "  // Move to function scope to reduce memory footprint.",
          "content_same": false
        },
        {
          "line": 647,
          "old_api": "absl::Now()",
          "new_api": null,
          "old_text": "absl::Now()",
          "new_text": null,
          "old_line_content": "  auto compile_duration = absl::Now() - compile_start_time;",
          "new_line_content": "        auto bef_file, tfrt::CreateBefFileFromBefBuffer(runtime(), bef));",
          "content_same": false
        },
        {
          "line": 652,
          "old_api": "std::make_unique<LoadedClientGraph>(\n      client_graph.name, std::move(symbol_uids), this, std::move(context),\n      std::move(module_with_op_keys), std::move(module),\n      std::move(executable_context), options_.enable_online_cost_analysis)",
          "new_api": null,
          "old_text": "std::make_unique<LoadedClientGraph>(\n      client_graph.name, std::move(symbol_uids), this, std::move(context),\n      std::move(module_with_op_keys), std::move(module),\n      std::move(executable_context), options_.enable_online_cost_analysis)",
          "new_text": null,
          "old_line_content": "  return std::make_unique<LoadedClientGraph>(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 910,
          "old_api": "data",
          "new_api": null,
          "old_text": "bytecode_buffer.data()",
          "new_text": null,
          "old_line_content": "    mlrt::bc::Executable executable(bytecode_buffer.data());",
          "new_line_content": "    TF_ASSIGN_OR_RETURN(",
          "content_same": false
        },
        {
          "line": 911,
          "old_api": "std::make_unique<mlrt::LoadedExecutable>(\n        executable, *graph_executor_->kernel_registry_)",
          "new_api": null,
          "old_text": "std::make_unique<mlrt::LoadedExecutable>(\n        executable, *graph_executor_->kernel_registry_)",
          "new_text": null,
          "old_line_content": "    auto bytecode_executable = std::make_unique<mlrt::LoadedExecutable>(",
          "new_line_content": "        auto bytecode_buffer,",
          "content_same": false
        },
        {
          "line": 913,
          "old_api": "std::make_shared<ExecutableContext>(\n        std::move(bytecode_buffer), std::move(bytecode_executable))",
          "new_api": null,
          "old_text": "std::make_shared<ExecutableContext>(\n        std::move(bytecode_buffer), std::move(bytecode_executable))",
          "new_text": null,
          "old_line_content": "    new_executable_context = std::make_shared<ExecutableContext>(",
          "new_line_content": "            graph_executor_->options().compile_options,",
          "content_same": false
        },
        {
          "line": 914,
          "old_api": "std::move(bytecode_executable)",
          "new_api": null,
          "old_text": "std::move(bytecode_executable)",
          "new_text": null,
          "old_line_content": "        std::move(bytecode_buffer), std::move(bytecode_executable));",
          "new_line_content": "            graph_executor_->fallback_state_.get(), tf_mlir_with_op_keys.get(),",
          "content_same": false
        },
        {
          "line": 767,
          "old_api": "sync_resource_state",
          "new_api": null,
          "old_text": "RunMlrtFunction(\n        function, *loaded_executable, request_info->tfrt_request_context,\n        *request_info->request_queue, {}, &outputs,\n        &loaded_graph->sync_resource_state())",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(RunMlrtFunction(",
          "new_line_content": "        function, *loaded_executable, request_info->tfrt_request_context,",
          "content_same": false
        },
        {
          "line": 662,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(INFO)",
          "new_text": null,
          "old_line_content": "  LOG(INFO) << \"TFRT loading client graph (\" << &client_graph << \") \"",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 790,
          "old_api": "absl::StrCat(\n                absl::StrJoin(input_tensor_names, kTensorNameJoiningDelimiter),\n                kArgumentTypeJoiningDelimiter,\n                absl::StrJoin(output_tensor_names, kTensorNameJoiningDelimiter),\n                kArgumentTypeJoiningDelimiter,\n                absl::StrJoin(target_tensor_names,\n                              kTensorNameJoiningDelimiter))",
          "new_api": null,
          "old_text": "absl::StrCat(\n                absl::StrJoin(input_tensor_names, kTensorNameJoiningDelimiter),\n                kArgumentTypeJoiningDelimiter,\n                absl::StrJoin(output_tensor_names, kTensorNameJoiningDelimiter),\n                kArgumentTypeJoiningDelimiter,\n                absl::StrJoin(target_tensor_names,\n                              kTensorNameJoiningDelimiter))",
          "new_text": null,
          "old_line_content": "          : absl::StrCat(",
          "new_line_content": "    std::optional<const std::string> graph_name) {",
          "content_same": false
        },
        {
          "line": 791,
          "old_api": "absl::StrJoin(input_tensor_names, kTensorNameJoiningDelimiter)",
          "new_api": null,
          "old_text": "absl::StrJoin(input_tensor_names, kTensorNameJoiningDelimiter)",
          "new_text": null,
          "old_line_content": "                absl::StrJoin(input_tensor_names, kTensorNameJoiningDelimiter),",
          "new_line_content": "  // The format of the joined name is illustrated as in the following example:",
          "content_same": false
        },
        {
          "line": 793,
          "old_api": "absl::StrJoin(output_tensor_names, kTensorNameJoiningDelimiter)",
          "new_api": null,
          "old_text": "absl::StrJoin(output_tensor_names, kTensorNameJoiningDelimiter)",
          "new_text": null,
          "old_line_content": "                absl::StrJoin(output_tensor_names, kTensorNameJoiningDelimiter),",
          "new_line_content": "  const auto joined_name =",
          "content_same": false
        },
        {
          "line": 795,
          "old_api": "absl::StrJoin(target_tensor_names,\n                              kTensorNameJoiningDelimiter)",
          "new_api": null,
          "old_text": "absl::StrJoin(target_tensor_names,\n                              kTensorNameJoiningDelimiter)",
          "new_text": null,
          "old_line_content": "                absl::StrJoin(target_tensor_names,",
          "new_line_content": "          ? *graph_name",
          "content_same": false
        },
        {
          "line": 924,
          "old_api": "Combine",
          "new_api": null,
          "old_text": "diag_handler.Combine(\n          tensorflow::errors::Internal(\"failed to convert MLIR to BEF.\"))",
          "new_text": null,
          "old_line_content": "      return diag_handler.Combine(",
          "new_line_content": "    // Recompile from the updated TFRT MLIR, during which Stream Analysis is",
          "content_same": false
        },
        {
          "line": 669,
          "old_api": "executable_context",
          "new_api": null,
          "old_text": "loaded_client_graph->executable_context()->IsForMlrt()",
          "new_text": null,
          "old_line_content": "  if (loaded_client_graph->executable_context()->IsForMlrt()) {",
          "new_line_content": "            << client_graph.name;",
          "content_same": false
        },
        {
          "line": 670,
          "old_api": "get",
          "new_api": null,
          "old_text": "loaded_client_graph.get()",
          "new_text": null,
          "old_line_content": "    RETURN_IF_ERROR_IN_INIT(InitBytecode(loaded_client_graph.get()));",
          "new_line_content": "  TF_ASSIGN_OR_RETURN(auto loaded_client_graph,",
          "content_same": false
        },
        {
          "line": 925,
          "old_api": "tensorflow::errors::Internal(\"failed to convert MLIR to BEF.\")",
          "new_api": null,
          "old_text": "tensorflow::errors::Internal(\"failed to convert MLIR to BEF.\")",
          "new_text": null,
          "old_line_content": "          tensorflow::errors::Internal(\"failed to convert MLIR to BEF.\"));",
          "new_line_content": "    // redone.",
          "content_same": false
        },
        {
          "line": 672,
          "old_api": "get",
          "new_api": null,
          "old_text": "loaded_client_graph.get()",
          "new_text": null,
          "old_line_content": "    RETURN_IF_ERROR_IN_INIT(InitBef(loaded_client_graph.get(), work_queue));",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 927,
          "old_api": "shrink_to_fit",
          "new_api": null,
          "old_text": "bef.shrink_to_fit()",
          "new_text": null,
          "old_line_content": "    bef.shrink_to_fit();",
          "new_line_content": "                                      /*disable_optional_sections=*/true);",
          "content_same": false
        },
        {
          "line": 802,
          "old_api": "end",
          "new_api": null,
          "old_text": "loaded_client_graphs_.end()",
          "new_text": null,
          "old_line_content": "  if (iter != loaded_client_graphs_.end()) return {*iter->second};",
          "new_line_content": "                              kTensorNameJoiningDelimiter));",
          "content_same": false
        },
        {
          "line": 805,
          "old_api": "tensorflow::errors::InvalidArgument(\n        absl::StrCat(\"GraphExecutor: compilation is disabled in execution but \"\n                     \"the compiled graph is not found for \",\n                     joined_name))",
          "new_api": null,
          "old_text": "tensorflow::errors::InvalidArgument(\n        absl::StrCat(\"GraphExecutor: compilation is disabled in execution but \"\n                     \"the compiled graph is not found for \",\n                     joined_name))",
          "new_text": null,
          "old_line_content": "    return tensorflow::errors::InvalidArgument(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 806,
          "old_api": "absl::StrCat(\"GraphExecutor: compilation is disabled in execution but \"\n                     \"the compiled graph is not found for \",\n                     joined_name)",
          "new_api": null,
          "old_text": "absl::StrCat(\"GraphExecutor: compilation is disabled in execution but \"\n                     \"the compiled graph is not found for \",\n                     joined_name)",
          "new_text": null,
          "old_line_content": "        absl::StrCat(\"GraphExecutor: compilation is disabled in execution but \"",
          "new_line_content": "  // Cache hit; return immediately.",
          "content_same": false
        },
        {
          "line": 938,
          "old_api": "OkStatus",
          "new_api": null,
          "old_text": "OkStatus()",
          "new_text": null,
          "old_line_content": "  return OkStatus();",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 813,
          "old_api": "size",
          "new_api": null,
          "old_text": "input_tensor_dtypes.size()",
          "new_text": null,
          "old_line_content": "  DCHECK_EQ(input_tensor_names.size(), input_tensor_dtypes.size());",
          "new_line_content": "                     \"the compiled graph is not found for \",",
          "content_same": false
        },
        {
          "line": 814,
          "old_api": "size",
          "new_api": null,
          "old_text": "input_tensor_names.size()",
          "new_text": null,
          "old_line_content": "  for (int i = 0; i < input_tensor_names.size(); ++i) {",
          "new_line_content": "                     joined_name));",
          "content_same": false
        },
        {
          "line": 947,
          "old_api": "status",
          "new_api": null,
          "old_text": "GetOrCreateLoadedClientGraph(\n             /*run_options=*/{}, input_tensor_names, input_tensor_dtypes,\n             output_tensor_names, target_tensor_names,\n             /*work_queue=*/nullptr, graph_name)\n      .status()",
          "new_text": null,
          "old_line_content": "  return GetOrCreateLoadedClientGraph(",
          "new_line_content": "tensorflow::Status GraphExecutor::CompileGraph(",
          "content_same": false
        },
        {
          "line": 825,
          "old_api": "std::move(input_nodes)",
          "new_api": null,
          "old_text": "std::move(input_nodes)",
          "new_text": null,
          "old_line_content": "      std::move(input_nodes),",
          "new_line_content": "    array_info.imported_dtype = input_dtype;",
          "content_same": false
        },
        {
          "line": 699,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(INFO)",
          "new_text": null,
          "old_line_content": "  LOG(INFO) << \"TFRT import client graph (\" << &client_graph",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 827,
          "old_api": "end",
          "new_api": null,
          "old_text": "target_tensor_names.end()",
          "new_text": null,
          "old_line_content": "      {target_tensor_names.begin(), target_tensor_names.end()}};",
          "new_line_content": "    input_nodes[input_name] = array_info;",
          "content_same": false
        },
        {
          "line": 701,
          "old_api": "absl::ToInt64Milliseconds(\n                   optimized_graph.functionalization_duration)",
          "new_api": null,
          "old_text": "absl::ToInt64Milliseconds(\n                   optimized_graph.functionalization_duration)",
          "new_text": null,
          "old_line_content": "            << absl::ToInt64Milliseconds(",
          "new_line_content": "  TF_ASSIGN_OR_RETURN(",
          "content_same": false
        },
        {
          "line": 955,
          "old_api": "registry.insert<mlir::BuiltinDialect, mlir::func::FuncDialect>()",
          "new_api": null,
          "old_text": "registry.insert<mlir::BuiltinDialect, mlir::func::FuncDialect>()",
          "new_text": null,
          "old_line_content": "  registry.insert<mlir::BuiltinDialect, mlir::func::FuncDialect>();",
          "new_line_content": "             output_tensor_names, target_tensor_names,",
          "content_same": false
        },
        {
          "line": 956,
          "old_api": "mlir::RegisterAllTensorFlowDialects(registry)",
          "new_api": null,
          "old_text": "mlir::RegisterAllTensorFlowDialects(registry)",
          "new_text": null,
          "old_line_content": "  mlir::RegisterAllTensorFlowDialects(registry);",
          "new_line_content": "             /*work_queue=*/nullptr, graph_name)",
          "content_same": false
        },
        {
          "line": 704,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(INFO)",
          "new_text": null,
          "old_line_content": "  LOG(INFO) << \"TFRT import client graph (\" << &client_graph",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 706,
          "old_api": "absl::ToInt64Milliseconds(optimized_graph.grappler_duration)",
          "new_api": null,
          "old_text": "absl::ToInt64Milliseconds(optimized_graph.grappler_duration)",
          "new_text": null,
          "old_line_content": "            << absl::ToInt64Milliseconds(optimized_graph.grappler_duration)",
          "new_line_content": "            << \"): Functionalization took \"",
          "content_same": false
        },
        {
          "line": 844,
          "old_api": "empty",
          "new_api": null,
          "old_text": "TF_ASSIGN_OR_RETURN(\n      LoadedClientGraph & loaded_client_graph,\n      GetOrCreateLoadedClientGraph(\n          /*run_options=*/{}, input_names, input_dtypes, output_tensor_names,\n          target_tensor_names,\n          /*work_queue=*/nullptr,\n          graph_name.empty() ? output_tensor_names[0] : graph_name))",
          "new_text": null,
          "old_line_content": "  TF_ASSIGN_OR_RETURN(",
          "new_line_content": "    const std::string& graph_name, absl::Span<mlrt::Value> input_values,",
          "content_same": false
        },
        {
          "line": 589,
          "old_api": "std::make_unique<mlir::MLIRContext>(registry)",
          "new_api": null,
          "old_text": "std::make_unique<mlir::MLIRContext>(registry)",
          "new_text": null,
          "old_line_content": "  auto context = std::make_unique<mlir::MLIRContext>(registry);",
          "new_line_content": "  // Disable multi-threading in lazy loading as the thread pool it uses is out",
          "content_same": false
        },
        {
          "line": 846,
          "old_api": "empty",
          "new_api": null,
          "old_text": "GetOrCreateLoadedClientGraph(\n          /*run_options=*/{}, input_names, input_dtypes, output_tensor_names,\n          target_tensor_names,\n          /*work_queue=*/nullptr,\n          graph_name.empty() ? output_tensor_names[0] : graph_name)",
          "new_text": null,
          "old_line_content": "      GetOrCreateLoadedClientGraph(",
          "new_line_content": "    absl::Span<const tensorflow::DataType> input_dtypes,",
          "content_same": false
        },
        {
          "line": 596,
          "old_api": "absl::Now()",
          "new_api": null,
          "old_text": "absl::Now()",
          "new_text": null,
          "old_line_content": "  auto import_duration = absl::Now() - import_start_time;",
          "new_line_content": "  ASSIGN_OR_RETURN_IN_IMPORT(",
          "content_same": false
        },
        {
          "line": 597,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(INFO)",
          "new_text": null,
          "old_line_content": "  LOG(INFO) << \"TFRT finished importing client graph (\" << &client_graph",
          "new_line_content": "      auto module, ImportClientGraphToMlirModule(client_graph, context.get()));",
          "content_same": false
        },
        {
          "line": 598,
          "old_api": "absl::ToInt64Milliseconds(import_duration)",
          "new_api": null,
          "old_text": "absl::ToInt64Milliseconds(import_duration)",
          "new_text": null,
          "old_line_content": "            << \"). Took \" << absl::ToInt64Milliseconds(import_duration)",
          "new_line_content": "  // TODO(b/278143179): Upload module w/o control flow.",
          "content_same": false
        },
        {
          "line": 854,
          "old_api": "executable_context",
          "new_api": null,
          "old_text": "loaded_client_graph.executable_context()",
          "new_text": null,
          "old_line_content": "  auto executable_context = loaded_client_graph.executable_context();",
          "new_line_content": "          target_tensor_names,",
          "content_same": false
        },
        {
          "line": 858,
          "old_api": "sync_resource_state",
          "new_api": null,
          "old_text": "AddSyncContext(execution_context,\n                 *options_.runtime->core_runtime()->GetHostContext(),\n                 &loaded_client_graph.sync_resource_state())",
          "new_text": null,
          "old_line_content": "  AddSyncContext(execution_context,",
          "new_line_content": "  // Get a shared_ptr of the executable so that during the current request the",
          "content_same": false
        },
        {
          "line": 859,
          "old_api": "core_runtime",
          "new_api": null,
          "old_text": "options_.runtime->core_runtime()->GetHostContext()",
          "new_text": null,
          "old_line_content": "                 *options_.runtime->core_runtime()->GetHostContext(),",
          "new_line_content": "  // executable to use is guaranteed to be alive.",
          "content_same": false
        },
        {
          "line": 732,
          "old_api": "TF_RETURN_IF_ERROR",
          "new_api": null,
          "old_text": "TF_RETURN_IF_ERROR(\n      RunRuntimeInitializer(exec_ctx, bef_file, kFallbackInitFunction))",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 605,
          "old_api": "absl::Now()",
          "new_api": null,
          "old_text": "absl::Now()",
          "new_text": null,
          "old_line_content": "  auto compile_start_time = absl::Now();",
          "new_line_content": "            << \" ms. Client graph name: \" << client_graph.name;",
          "content_same": false
        },
        {
          "line": 733,
          "old_api": "RunRuntimeInitializer",
          "new_api": null,
          "old_text": "RunRuntimeInitializer(exec_ctx, bef_file, kFallbackInitFunction)",
          "new_text": null,
          "old_line_content": "      RunRuntimeInitializer(exec_ctx, bef_file, kFallbackInitFunction));",
          "new_line_content": "  tfrt::ExecutionContext exec_ctx(request_info->tfrt_request_context);",
          "content_same": false
        },
        {
          "line": 863,
          "old_api": "get",
          "new_api": null,
          "old_text": "fallback_state_.get().device_manager()",
          "new_text": null,
          "old_line_content": "      tfd::GetDefaultRunner(), &fallback_state_.get().device_manager(),",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 867,
          "old_api": "get",
          "new_api": null,
          "old_text": "fallback_state_.get().process_function_library_runtime()",
          "new_text": null,
          "old_line_content": "      &fallback_state_.get().process_function_library_runtime());",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 868,
          "old_api": "get",
          "new_api": null,
          "old_text": "std::make_unique<tensorflow::tf_mlrt::Context>(\n      &kernel_fallback_state, resource_context_.get())",
          "new_text": null,
          "old_line_content": "  auto tf_context = std::make_unique<tensorflow::tf_mlrt::Context>(",
          "new_line_content": "  tensorflow::tfd::KernelFallbackCompatRequestState kernel_fallback_state(",
          "content_same": false
        },
        {
          "line": 741,
          "old_api": "OkStatus",
          "new_api": null,
          "old_text": "OkStatus()",
          "new_text": null,
          "old_line_content": "  return OkStatus();",
          "new_line_content": "  // After we initialized all the resources in the original graph, we can run",
          "content_same": false
        },
        {
          "line": 615,
          "old_api": "tensorflow::errors::Internal(\"Missing kernel registry in MLRT.\")",
          "new_api": null,
          "old_text": "tensorflow::errors::Internal(\"Missing kernel registry in MLRT.\")",
          "new_text": null,
          "old_line_content": "      return tensorflow::errors::Internal(\"Missing kernel registry in MLRT.\");",
          "new_line_content": "  ModelRuntimeContext model_context(&options_,",
          "content_same": false
        },
        {
          "line": 872,
          "old_api": "name",
          "new_api": null,
          "old_text": "executable_context->bytecode_executable->GetFunction(\n      loaded_client_graph.name())",
          "new_text": null,
          "old_line_content": "  auto serving_function = executable_context->bytecode_executable->GetFunction(",
          "new_line_content": "      /*user_intra_op_threadpool=*/nullptr, /*model_metadata=*/std::nullopt,",
          "content_same": false
        },
        {
          "line": 619,
          "old_api": "get",
          "new_api": null,
          "old_text": "module.get()",
          "new_text": null,
          "old_line_content": "        tfrt::BuildExecutableContext(module.get(), *kernel_registry_));",
          "new_line_content": "  if (options_.compile_options.compile_to_sync_tfrt_dialect) {",
          "content_same": false
        },
        {
          "line": 759,
          "old_api": "GetFunction",
          "new_api": null,
          "old_text": "loaded_executable->GetFunction(kFallbackInitFunction)",
          "new_text": null,
          "old_line_content": "  if (auto function = loaded_executable->GetFunction(kFallbackInitFunction)) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 877,
          "old_api": "mlrt::Execute(execution_context)",
          "new_api": null,
          "old_text": "mlrt::Execute(execution_context)",
          "new_text": null,
          "old_line_content": "  mlrt::Execute(execution_context);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 752,
          "old_api": "resource_array",
          "new_api": null,
          "old_text": "loaded_graph->resource_array()",
          "new_text": null,
          "old_line_content": "                        &loaded_graph->resource_array(), fallback_state_));",
          "new_line_content": "  TF_ASSIGN_OR_RETURN(",
          "content_same": false
        },
        {
          "line": 755,
          "old_api": "get",
          "new_api": null,
          "old_text": "loaded_graph->executable_context()->bytecode_executable.get()",
          "new_text": null,
          "old_line_content": "      loaded_graph->executable_context()->bytecode_executable.get();",
          "new_line_content": "                        options_.runtime->work_queue(), resource_context_.get(),",
          "content_same": false
        },
        {
          "line": 756,
          "old_api": "DCHECK",
          "new_api": null,
          "old_text": "DCHECK(loaded_executable)",
          "new_text": null,
          "old_line_content": "  DCHECK(loaded_executable);",
          "new_line_content": "                        /*client_graph_resource_context=*/nullptr,",
          "content_same": false
        },
        {
          "line": 885,
          "old_api": "absl::call_once(create_cost_recorder_once_, [&]() {\n    cost_recorder = std::make_unique<CostRecorder>(normalize_ratio);\n  })",
          "new_api": null,
          "old_text": "absl::call_once(create_cost_recorder_once_, [&]() {\n    cost_recorder = std::make_unique<CostRecorder>(normalize_ratio);\n  })",
          "new_text": null,
          "old_line_content": "  absl::call_once(create_cost_recorder_once_, [&]() {",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 886,
          "old_api": "std::make_unique<CostRecorder>(normalize_ratio)",
          "new_api": null,
          "old_text": "std::make_unique<CostRecorder>(normalize_ratio)",
          "new_text": null,
          "old_line_content": "    cost_recorder = std::make_unique<CostRecorder>(normalize_ratio);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 631,
          "old_api": "data",
          "new_api": null,
          "old_text": "bytecode_buffer.data()",
          "new_text": null,
          "old_line_content": "    mlrt::bc::Executable executable(bytecode_buffer.data());",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 760,
          "old_api": "sync_resource_state",
          "new_api": null,
          "old_text": "RunMlrtFunction(\n        function, *loaded_executable, request_info->tfrt_request_context,\n        *request_info->request_queue, {}, &outputs,\n        &loaded_graph->sync_resource_state())",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(RunMlrtFunction(",
          "new_line_content": "  const auto* loaded_executable =",
          "content_same": false
        },
        {
          "line": 633,
          "old_api": "std::make_unique<mlrt::LoadedExecutable>(executable, *kernel_registry_)",
          "new_api": null,
          "old_text": "std::make_unique<mlrt::LoadedExecutable>(executable, *kernel_registry_)",
          "new_text": null,
          "old_line_content": "        std::make_unique<mlrt::LoadedExecutable>(executable, *kernel_registry_);",
          "new_line_content": "        auto bytecode_buffer,",
          "content_same": false
        },
        {
          "line": 634,
          "old_api": "std::make_shared<ExecutableContext>(\n        std::move(bytecode_buffer), std::move(bytecode_executable))",
          "new_api": null,
          "old_text": "std::make_shared<ExecutableContext>(\n        std::move(bytecode_buffer), std::move(bytecode_executable))",
          "new_text": null,
          "old_line_content": "    executable_context = std::make_shared<ExecutableContext>(",
          "new_line_content": "        tensorflow::mlrt_compiler::ConvertTfMlirToBytecode(",
          "content_same": false
        },
        {
          "line": 635,
          "old_api": "std::move(bytecode_executable)",
          "new_api": null,
          "old_text": "std::move(bytecode_executable)",
          "new_text": null,
          "old_line_content": "        std::move(bytecode_buffer), std::move(bytecode_executable));",
          "new_line_content": "            options_.compile_options, fallback_state_, module.get(),",
          "content_same": false
        },
        {
          "line": 893,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(INFO)",
          "new_text": null,
          "old_line_content": "  LOG(INFO) << \"TFRT updating op costs of loaded client graph (\" << this << \") \"",
          "new_line_content": "  });",
          "content_same": false
        },
        {
          "line": 638,
          "old_api": "get",
          "new_api": null,
          "old_text": "tensorflow::ConvertTfMlirToBef(\n        options_.compile_options, module.get(), &bef, model_context)",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(tensorflow::ConvertTfMlirToBef(",
          "new_line_content": "    auto bytecode_executable =",
          "content_same": false
        },
        {
          "line": 763,
          "old_api": "sync_resource_state",
          "new_api": null,
          "old_text": "loaded_graph->sync_resource_state()",
          "new_text": null,
          "old_line_content": "        &loaded_graph->sync_resource_state()));",
          "new_line_content": "",
          "content_same": false
        }
      ]
    },
    "api_summary": {
      "total_replacements": 38,
      "total_additions": 73,
      "total_deletions": 73,
      "total_api_changes": 184
    },
    "non_api_changes": {
      "has_non_api_changes": true,
      "evidence": {
        "total_diff_lines": 7,
        "api_related_lines": 184,
        "non_api_lines": 5,
        "non_api_line_numbers": [
          590,
          591,
          592,
          593,
          595
        ]
      }
    },
    "api_calls_before": 370,
    "api_calls_after": 370,
    "diff_info": {
      "added_lines": 7,
      "removed_lines": 1,
      "total_diff_lines": 20
    }
  }
}