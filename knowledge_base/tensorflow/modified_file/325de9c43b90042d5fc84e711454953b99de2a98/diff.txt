diff --git a/tensorflow/lite/delegates/gpu/common/tasks/reduce.cc b/tensorflow/lite/delegates/gpu/common/tasks/reduce.cc
index f1e09568625..33f4f7f48ba 100644
--- a/tensorflow/lite/delegates/gpu/common/tasks/reduce.cc
+++ b/tensorflow/lite/delegates/gpu/common/tasks/reduce.cc
@@ -75,12 +75,26 @@ int3 GetMaximumPossibleWGSize(const std::vector<int>& ordered_sizes,
                               int max_total_wg_size) {
   int3 wg_size = int3(1, 1, 1);
   int wg_size_total = 1;
+  // Make sure that a minimum number of reductions happens inside the loop over
+  // reduction dims. Otherwise, the reduction size could equal the number of
+  // workgroups and the inner loop would just copy the values to the reducer,
+  // which is inefficient.
+  const int minimum_loop_reductions = 2;
+  int total_loop_reductions = 4;
   for (int i = ordered_sizes.size() - 1; i >= 0; i--) {
     const int wg_index = ordered_sizes.size() - 1 - i;
     if (wg_index >= 3) {
       return wg_size;
     }
-    while (ordered_sizes[i] >= wg_size[wg_index] * 2) {
+    int loop_reductions_dim = 1;
+    while (ordered_sizes[i] >= wg_size[wg_index] * 2 * loop_reductions_dim) {
+      // Don't increase the work group size of this dim until we have at least
+      // 'minimum_loop_reductions' reductions.
+      if (total_loop_reductions < minimum_loop_reductions) {
+        total_loop_reductions *= 2;
+        loop_reductions_dim *= 2;
+        continue;
+      }
       wg_size_total *= 2;
       if (wg_size_total > max_total_wg_size) {
         return wg_size;
