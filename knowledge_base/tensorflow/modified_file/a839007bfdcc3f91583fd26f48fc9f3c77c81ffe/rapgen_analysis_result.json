{
  "status": "completed",
  "commit_dir": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/a839007bfdcc3f91583fd26f48fc9f3c77c81ffe",
  "file_info": {
    "before_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/a839007bfdcc3f91583fd26f48fc9f3c77c81ffe/before.cc",
    "after_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/a839007bfdcc3f91583fd26f48fc9f3c77c81ffe/after.cc",
    "diff_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/a839007bfdcc3f91583fd26f48fc9f3c77c81ffe/diff.txt"
  },
  "semgrep_analysis": {
    "is_api_change": false,
    "api_changes": {
      "replacements": [
        {
          "line": 158,
          "old_api": "mlir::createParallelLoopToGpuPass()",
          "new_api": "mlir::kernel_gen::transforms::CreateBufferReusePass()",
          "old_text": "mlir::createParallelLoopToGpuPass()",
          "new_text": "mlir::kernel_gen::transforms::CreateBufferReusePass()",
          "old_line_content": "  pm.addNestedPass<::mlir::FuncOp>(mlir::createParallelLoopToGpuPass());",
          "new_line_content": "        mlir::kernel_gen::transforms::CreateBufferReusePass());",
          "content_same": false
        },
        {
          "line": 161,
          "old_api": "::mlir::createCanonicalizerPass()",
          "new_api": "xla::mlir_gpu::createMapParallelLoopsPass()",
          "old_text": "::mlir::createCanonicalizerPass()",
          "new_text": "xla::mlir_gpu::createMapParallelLoopsPass()",
          "old_line_content": "  pm.addNestedPass<::mlir::FuncOp>(::mlir::createCanonicalizerPass());",
          "new_line_content": "  pm.addNestedPass<::mlir::FuncOp>(xla::mlir_gpu::createMapParallelLoopsPass());",
          "content_same": false
        },
        {
          "line": 166,
          "old_api": "mlir::createForLoopSpecializationPass()",
          "new_api": "::mlir::createCanonicalizerPass()",
          "old_text": "mlir::createForLoopSpecializationPass()",
          "new_text": "::mlir::createCanonicalizerPass()",
          "old_line_content": "    pm.addNestedPass<::mlir::FuncOp>(mlir::createForLoopSpecializationPass());",
          "new_line_content": "  pm.addNestedPass<::mlir::FuncOp>(::mlir::createCanonicalizerPass());",
          "content_same": false
        },
        {
          "line": 170,
          "old_api": "::mlir::mhlo::createLegalizeTrigonometricToApproximationPass()",
          "new_api": "empty",
          "old_text": "::mlir::mhlo::createLegalizeTrigonometricToApproximationPass()",
          "new_text": "unroll_factors.empty()",
          "old_line_content": "      ::mlir::mhlo::createLegalizeTrigonometricToApproximationPass());",
          "new_line_content": "  if (!unroll_factors.empty()) {",
          "content_same": false
        },
        {
          "line": 177,
          "old_api": "xla::mlir_gpu::createRewriteKernelSignaturePass()",
          "new_api": "::mlir::createGpuKernelOutliningPass()",
          "old_text": "xla::mlir_gpu::createRewriteKernelSignaturePass()",
          "new_text": "::mlir::createGpuKernelOutliningPass()",
          "old_line_content": "        xla::mlir_gpu::createRewriteKernelSignaturePass());",
          "new_line_content": "  pm.addPass(::mlir::createGpuKernelOutliningPass());",
          "content_same": false
        },
        {
          "line": 181,
          "old_api": "mlir::kernel_gen::tf_framework::CreateEmbedTFFrameworkPass()",
          "new_api": "pm.addNestedPass<::mlir::FuncOp>(\n        xla::mlir_gpu::createRewriteKernelSignaturePass())",
          "old_text": "mlir::kernel_gen::tf_framework::CreateEmbedTFFrameworkPass()",
          "new_text": "pm.addNestedPass<::mlir::FuncOp>(\n        xla::mlir_gpu::createRewriteKernelSignaturePass())",
          "old_line_content": "  pm.addPass(mlir::kernel_gen::tf_framework::CreateEmbedTFFrameworkPass());",
          "new_line_content": "    pm.addNestedPass<::mlir::FuncOp>(",
          "content_same": false
        },
        {
          "line": 186,
          "old_api": "mlir::kernel_gen::transforms::CreateEmbedMemRefPrintsPass()",
          "new_api": "mlir::kernel_gen::tf_framework::CreateEmbedTFFrameworkPass()",
          "old_text": "mlir::kernel_gen::transforms::CreateEmbedMemRefPrintsPass()",
          "new_text": "mlir::kernel_gen::tf_framework::CreateEmbedTFFrameworkPass()",
          "old_line_content": "        mlir::kernel_gen::transforms::CreateEmbedMemRefPrintsPass());",
          "new_line_content": "  pm.addPass(mlir::kernel_gen::tf_framework::CreateEmbedTFFrameworkPass());",
          "content_same": false
        },
        {
          "line": 188,
          "old_api": "::mlir::createCanonicalizerPass()",
          "new_api": "::mlir::createConvertShapeConstraintsPass()",
          "old_text": "::mlir::createCanonicalizerPass()",
          "new_text": "::mlir::createConvertShapeConstraintsPass()",
          "old_line_content": "  pm.addNestedPass<::mlir::FuncOp>(::mlir::createCanonicalizerPass());",
          "new_line_content": "  pm.addNestedPass<::mlir::FuncOp>(::mlir::createConvertShapeConstraintsPass());",
          "content_same": false
        },
        {
          "line": 190,
          "old_api": "::mlir::createLowerToCFGPass()",
          "new_api": "pm.addNestedPass<::mlir::FuncOp>(\n        mlir::kernel_gen::transforms::CreateEmbedMemRefPrintsPass())",
          "old_text": "::mlir::createLowerToCFGPass()",
          "new_text": "pm.addNestedPass<::mlir::FuncOp>(\n        mlir::kernel_gen::transforms::CreateEmbedMemRefPrintsPass())",
          "old_line_content": "  pm.addPass(::mlir::createLowerToCFGPass());",
          "new_line_content": "    pm.addNestedPass<::mlir::FuncOp>(",
          "content_same": false
        },
        {
          "line": 191,
          "old_api": "run",
          "new_api": "mlir::kernel_gen::transforms::CreateEmbedMemRefPrintsPass()",
          "old_text": "pm.run(module)",
          "new_text": "mlir::kernel_gen::transforms::CreateEmbedMemRefPrintsPass()",
          "old_line_content": "  if (failed(pm.run(module))) {",
          "new_line_content": "        mlir::kernel_gen::transforms::CreateEmbedMemRefPrintsPass());",
          "content_same": false
        },
        {
          "line": 199,
          "old_api": "applyTensorflowAndCLOptions",
          "new_api": "Status::OK()",
          "old_text": "applyTensorflowAndCLOptions(pm)",
          "new_text": "Status::OK()",
          "old_line_content": "  applyTensorflowAndCLOptions(pm);",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 203,
          "old_api": "pm.addNestedPass<mlir::FuncOp>(\n      mlir::kernel_gen::transforms::CreatePropagateTfAbiKnowledgeToKernels())",
          "new_api": "getContext",
          "old_text": "pm.addNestedPass<mlir::FuncOp>(\n      mlir::kernel_gen::transforms::CreatePropagateTfAbiKnowledgeToKernels())",
          "new_text": "module.getContext()",
          "old_line_content": "  pm.addNestedPass<mlir::FuncOp>(",
          "new_line_content": "  mlir::PassManager pm(module.getContext());",
          "content_same": false
        },
        {
          "line": 204,
          "old_api": "mlir::kernel_gen::transforms::CreatePropagateTfAbiKnowledgeToKernels()",
          "new_api": "applyTensorflowAndCLOptions",
          "old_text": "mlir::kernel_gen::transforms::CreatePropagateTfAbiKnowledgeToKernels()",
          "new_text": "applyTensorflowAndCLOptions(pm)",
          "old_line_content": "      mlir::kernel_gen::transforms::CreatePropagateTfAbiKnowledgeToKernels());",
          "new_line_content": "  applyTensorflowAndCLOptions(pm);",
          "content_same": false
        },
        {
          "line": 206,
          "old_api": "run",
          "new_api": "pm.addNestedPass<mlir::FuncOp>(\n      mlir::kernel_gen::transforms::CreatePropagateShapeKnowledgeToKernels())",
          "old_text": "pm.run(module)",
          "new_text": "pm.addNestedPass<mlir::FuncOp>(\n      mlir::kernel_gen::transforms::CreatePropagateShapeKnowledgeToKernels())",
          "old_line_content": "  return failed(pm.run(module))",
          "new_line_content": "  pm.addNestedPass<mlir::FuncOp>(",
          "content_same": false
        },
        {
          "line": 207,
          "old_api": "InternalError",
          "new_api": "mlir::kernel_gen::transforms::CreatePropagateShapeKnowledgeToKernels()",
          "old_text": "InternalError(\"Amending LLVMIR with static knowledge failed.\")",
          "new_text": "mlir::kernel_gen::transforms::CreatePropagateShapeKnowledgeToKernels()",
          "old_line_content": "             ? InternalError(\"Amending LLVMIR with static knowledge failed.\")",
          "new_line_content": "      mlir::kernel_gen::transforms::CreatePropagateShapeKnowledgeToKernels());",
          "content_same": false
        },
        {
          "line": 208,
          "old_api": "Status::OK()",
          "new_api": "pm.addNestedPass<mlir::FuncOp>(\n      mlir::kernel_gen::transforms::CreatePropagateTfAbiKnowledgeToKernels())",
          "old_text": "Status::OK()",
          "new_text": "pm.addNestedPass<mlir::FuncOp>(\n      mlir::kernel_gen::transforms::CreatePropagateTfAbiKnowledgeToKernels())",
          "old_line_content": "             : Status::OK();",
          "new_line_content": "  pm.addNestedPass<mlir::FuncOp>(",
          "content_same": false
        },
        {
          "line": 220,
          "old_api": "mlir::createStripDebugInfoPass()",
          "new_api": "getContext",
          "old_text": "mlir::createStripDebugInfoPass()",
          "new_text": "module.getContext()",
          "old_line_content": "  kernel_pm.addPass(mlir::createStripDebugInfoPass());",
          "new_line_content": "  mlir::PassManager pm(module.getContext());",
          "content_same": false
        },
        {
          "line": 221,
          "old_api": "mlir::kernel_gen::transforms::CreateGpuKernelToBlobPass(\n      gpu_binary_attr_name, architectures, generate_fatbin)",
          "new_api": "applyTensorflowAndCLOptions",
          "old_text": "mlir::kernel_gen::transforms::CreateGpuKernelToBlobPass(\n      gpu_binary_attr_name, architectures, generate_fatbin)",
          "new_text": "applyTensorflowAndCLOptions(pm)",
          "old_line_content": "  kernel_pm.addPass(mlir::kernel_gen::transforms::CreateGpuKernelToBlobPass(",
          "new_line_content": "  applyTensorflowAndCLOptions(pm);",
          "content_same": false
        },
        {
          "line": 225,
          "old_api": "InternalError",
          "new_api": "mlir::createStripDebugInfoPass()",
          "old_text": "InternalError(\"Generating device code failed.\")",
          "new_text": "mlir::createStripDebugInfoPass()",
          "old_line_content": "             ? InternalError(\"Generating device code failed.\")",
          "new_line_content": "  kernel_pm.addPass(mlir::createStripDebugInfoPass());",
          "content_same": false
        },
        {
          "line": 226,
          "old_api": "Status::OK()",
          "new_api": "mlir::kernel_gen::transforms::CreateGpuKernelToBlobPass(\n      gpu_binary_attr_name, architectures, generate_fatbin)",
          "old_text": "Status::OK()",
          "new_text": "mlir::kernel_gen::transforms::CreateGpuKernelToBlobPass(\n      gpu_binary_attr_name, architectures, generate_fatbin)",
          "old_line_content": "             : Status::OK();",
          "new_line_content": "  kernel_pm.addPass(mlir::kernel_gen::transforms::CreateGpuKernelToBlobPass(",
          "content_same": false
        },
        {
          "line": 230,
          "old_api": "getContext",
          "new_api": "InternalError",
          "old_text": "module.getContext()",
          "new_text": "InternalError(\"Generating device code failed.\")",
          "old_line_content": "  mlir::PassManager pm(module.getContext());",
          "new_line_content": "             ? InternalError(\"Generating device code failed.\")",
          "content_same": false
        },
        {
          "line": 231,
          "old_api": "applyTensorflowAndCLOptions",
          "new_api": "Status::OK()",
          "old_text": "applyTensorflowAndCLOptions(pm)",
          "new_text": "Status::OK()",
          "old_line_content": "  applyTensorflowAndCLOptions(pm);",
          "new_line_content": "             : Status::OK();",
          "content_same": false
        },
        {
          "line": 235,
          "old_api": "mlir::createCSEPass()",
          "new_api": "getContext",
          "old_text": "mlir::createCSEPass()",
          "new_text": "module.getContext()",
          "old_line_content": "  pm.addPass(mlir::createCSEPass());",
          "new_line_content": "  mlir::PassManager pm(module.getContext());",
          "content_same": false
        },
        {
          "line": 238,
          "old_api": "InternalError",
          "new_api": "mlir::kernel_gen::transforms::CreateTFKernelToLLVMPass()",
          "old_text": "InternalError(\"Final lowering of host side failed.\")",
          "new_text": "mlir::kernel_gen::transforms::CreateTFKernelToLLVMPass()",
          "old_line_content": "             ? InternalError(\"Final lowering of host side failed.\")",
          "new_line_content": "  pm.addPass(mlir::kernel_gen::transforms::CreateTFKernelToLLVMPass());",
          "content_same": false
        },
        {
          "line": 239,
          "old_api": "Status::OK()",
          "new_api": "mlir::createCanonicalizerPass()",
          "old_text": "Status::OK()",
          "new_text": "mlir::createCanonicalizerPass()",
          "old_line_content": "             : Status::OK();",
          "new_line_content": "  pm.addPass(mlir::createCanonicalizerPass());",
          "content_same": false
        },
        {
          "line": 255,
          "old_api": "InternalError",
          "new_api": "getDialectRegistry",
          "old_text": "InternalError(\n      \"Neither TENSORFLOW_USE_ROCM nor GOOGLE_CUDA are defined.\"\n      \" Did you specify either --config=rocm or --config=cuda ?\")",
          "new_text": "context.getDialectRegistry()",
          "old_line_content": "  return InternalError(",
          "new_line_content": "  mlir::RegisterAllTensorFlowDialects(context.getDialectRegistry());",
          "content_same": false
        },
        {
          "line": 280,
          "old_api": "gpu_mod.getAttrOfType<mlir::StringAttr>(kGpuBinaryAttrName)",
          "new_api": "module.getOps<mlir::gpu::GPUModuleOp>()",
          "old_text": "gpu_mod.getAttrOfType<mlir::StringAttr>(kGpuBinaryAttrName)",
          "new_text": "module.getOps<mlir::gpu::GPUModuleOp>()",
          "old_line_content": "  auto blob = gpu_mod.getAttrOfType<mlir::StringAttr>(kGpuBinaryAttrName);",
          "new_line_content": "  auto gpu_modules = module.getOps<mlir::gpu::GPUModuleOp>();",
          "content_same": false
        },
        {
          "line": 284,
          "old_api": "getValue",
          "new_api": "begin",
          "old_text": "blob.getValue().str()",
          "new_text": "gpu_modules.begin()",
          "old_line_content": "  return blob.getValue().str();",
          "new_line_content": "  mlir::gpu::GPUModuleOp gpu_mod = *gpu_modules.begin();",
          "content_same": false
        }
      ],
      "additions": [
        {
          "line": 256,
          "old_api": null,
          "new_api": "mlir::parseSourceString(tf_code, &context)",
          "old_text": null,
          "new_text": "mlir::parseSourceString(tf_code, &context)",
          "old_line_content": "      \"Neither TENSORFLOW_USE_ROCM nor GOOGLE_CUDA are defined.\"",
          "new_line_content": "  mlir::OwningModuleRef module = mlir::parseSourceString(tf_code, &context);",
          "content_same": false
        },
        {
          "line": 257,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "module.get()",
          "old_line_content": "      \" Did you specify either --config=rocm or --config=cuda ?\");",
          "new_line_content": "  TF_RETURN_IF_ERROR(LowerTFtoGPU(module.get(), gpu_binary_only, tile_sizes,",
          "content_same": false
        },
        {
          "line": 260,
          "old_api": null,
          "new_api": "InternalError",
          "old_text": null,
          "new_text": "InternalError(\n      \"Neither TENSORFLOW_USE_ROCM nor GOOGLE_CUDA are defined.\"\n      \" Did you specify either --config=rocm or --config=cuda ?\")",
          "old_line_content": "#if TENSORFLOW_USE_ROCM",
          "new_line_content": "  return InternalError(",
          "content_same": false
        },
        {
          "line": 268,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "module.get()",
          "old_line_content": "  if (!gpu_binary_only) {",
          "new_line_content": "  TF_RETURN_IF_ERROR(xla::mlir_gpu::LowerKernelBodiesToNVVM(module.get()));",
          "content_same": false
        },
        {
          "line": 270,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "module.get()",
          "old_line_content": "  }",
          "new_line_content": "  TF_RETURN_IF_ERROR(AmendKernelLLVMIRWithStaticKnowledge(module.get()));",
          "content_same": false
        },
        {
          "line": 271,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "module.get()",
          "old_line_content": "  return module;",
          "new_line_content": "  TF_RETURN_IF_ERROR(GenerateDeviceCode(module.get(), kGpuBinaryAttrName,",
          "content_same": false
        },
        {
          "line": 274,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "module.get()",
          "old_line_content": "StatusOr<std::string> ExtractGpuBinary(mlir::ModuleOp module) {",
          "new_line_content": "    TF_RETURN_IF_ERROR(LowerHostSideToFinalForm(module.get()));",
          "content_same": false
        },
        {
          "line": 281,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "gpu_modules.end()",
          "old_line_content": "  if (blob == nullptr) {",
          "new_line_content": "  if (std::distance(gpu_modules.begin(), gpu_modules.end()) != 1) {",
          "content_same": false
        },
        {
          "line": 157,
          "old_api": null,
          "new_api": "pm.addNestedPass<mlir::FuncOp>(\n        mlir::kernel_gen::transforms::CreateBufferReusePass())",
          "old_text": null,
          "new_text": "pm.addNestedPass<mlir::FuncOp>(\n        mlir::kernel_gen::transforms::CreateBufferReusePass())",
          "old_line_content": "  // Apply the mapping.",
          "new_line_content": "    pm.addNestedPass<mlir::FuncOp>(",
          "content_same": false
        },
        {
          "line": 285,
          "old_api": null,
          "new_api": "gpu_mod.getAttrOfType<mlir::StringAttr>(kGpuBinaryAttrName)",
          "old_text": null,
          "new_text": "gpu_mod.getAttrOfType<mlir::StringAttr>(kGpuBinaryAttrName)",
          "old_line_content": "}",
          "new_line_content": "  auto blob = gpu_mod.getAttrOfType<mlir::StringAttr>(kGpuBinaryAttrName);",
          "content_same": false
        },
        {
          "line": 287,
          "old_api": null,
          "new_api": "InternalError",
          "old_text": null,
          "new_text": "InternalError(\"No binary blob found in the module\")",
          "old_line_content": "}  // namespace kernel_gen",
          "new_line_content": "    return InternalError(\"No binary blob found in the module\");",
          "content_same": false
        },
        {
          "line": 289,
          "old_api": null,
          "new_api": "getValue",
          "old_text": null,
          "new_text": "blob.getValue().str()",
          "old_line_content": "",
          "new_line_content": "  return blob.getValue().str();",
          "content_same": false
        },
        {
          "line": 163,
          "old_api": null,
          "new_api": "mlir::createParallelLoopToGpuPass()",
          "old_text": null,
          "new_text": "mlir::createParallelLoopToGpuPass()",
          "old_line_content": "  // Make loops with min bounds into a conditional plus static bounds.",
          "new_line_content": "  pm.addNestedPass<::mlir::FuncOp>(mlir::createParallelLoopToGpuPass());",
          "content_same": false
        },
        {
          "line": 167,
          "old_api": null,
          "new_api": "::mlir::createCSEPass()",
          "old_text": null,
          "new_text": "::mlir::createCSEPass()",
          "old_line_content": "  }",
          "new_line_content": "  pm.addNestedPass<::mlir::FuncOp>(::mlir::createCSEPass());",
          "content_same": false
        },
        {
          "line": 171,
          "old_api": null,
          "new_api": "mlir::createForLoopSpecializationPass()",
          "old_text": null,
          "new_text": "mlir::createForLoopSpecializationPass()",
          "old_line_content": "  // Take launches to launches with kernels.",
          "new_line_content": "    pm.addNestedPass<::mlir::FuncOp>(mlir::createForLoopSpecializationPass());",
          "content_same": false
        },
        {
          "line": 174,
          "old_api": null,
          "new_api": "pm.addNestedPass<::mlir::FuncOp>(\n      ::mlir::mhlo::createLegalizeTrigonometricToApproximationPass())",
          "old_text": null,
          "new_text": "pm.addNestedPass<::mlir::FuncOp>(\n      ::mlir::mhlo::createLegalizeTrigonometricToApproximationPass())",
          "old_line_content": "  if (gpu_binary_only) {",
          "new_line_content": "  pm.addNestedPass<::mlir::FuncOp>(",
          "content_same": false
        },
        {
          "line": 175,
          "old_api": null,
          "new_api": "::mlir::mhlo::createLegalizeTrigonometricToApproximationPass()",
          "old_text": null,
          "new_text": "::mlir::mhlo::createLegalizeTrigonometricToApproximationPass()",
          "old_line_content": "    // Make kernel signature deterministic so that we can call it externally.",
          "new_line_content": "      ::mlir::mhlo::createLegalizeTrigonometricToApproximationPass());",
          "content_same": false
        },
        {
          "line": 182,
          "old_api": null,
          "new_api": "xla::mlir_gpu::createRewriteKernelSignaturePass()",
          "old_text": null,
          "new_text": "xla::mlir_gpu::createRewriteKernelSignaturePass()",
          "old_line_content": "  // Constraints are removed as late as possible and before lowering to CFG.",
          "new_line_content": "        xla::mlir_gpu::createRewriteKernelSignaturePass());",
          "content_same": false
        },
        {
          "line": 184,
          "old_api": null,
          "new_api": "::mlir::createLowerAffinePass()",
          "old_text": null,
          "new_text": "::mlir::createLowerAffinePass()",
          "old_line_content": "  if (embed_memref_prints) {",
          "new_line_content": "  pm.addPass(::mlir::createLowerAffinePass());",
          "content_same": false
        },
        {
          "line": 193,
          "old_api": null,
          "new_api": "::mlir::createCanonicalizerPass()",
          "old_text": null,
          "new_text": "::mlir::createCanonicalizerPass()",
          "old_line_content": "  }",
          "new_line_content": "  pm.addNestedPass<::mlir::FuncOp>(::mlir::createCanonicalizerPass());",
          "content_same": false
        },
        {
          "line": 195,
          "old_api": null,
          "new_api": "::mlir::createLowerToCFGPass()",
          "old_text": null,
          "new_text": "::mlir::createLowerToCFGPass()",
          "old_line_content": "}",
          "new_line_content": "  pm.addPass(::mlir::createLowerToCFGPass());",
          "content_same": false
        },
        {
          "line": 196,
          "old_api": null,
          "new_api": "run",
          "old_text": null,
          "new_text": "pm.run(module)",
          "old_line_content": "",
          "new_line_content": "  if (failed(pm.run(module))) {",
          "content_same": false
        },
        {
          "line": 197,
          "old_api": null,
          "new_api": "InternalError",
          "old_text": null,
          "new_text": "InternalError(\"Lowering to GPU kernels failed.\")",
          "old_line_content": "Status AmendKernelLLVMIRWithStaticKnowledge(mlir::ModuleOp module) {",
          "new_line_content": "    return InternalError(\"Lowering to GPU kernels failed.\");",
          "content_same": false
        },
        {
          "line": 209,
          "old_api": null,
          "new_api": "mlir::kernel_gen::transforms::CreatePropagateTfAbiKnowledgeToKernels()",
          "old_text": null,
          "new_text": "mlir::kernel_gen::transforms::CreatePropagateTfAbiKnowledgeToKernels()",
          "old_line_content": "}",
          "new_line_content": "      mlir::kernel_gen::transforms::CreatePropagateTfAbiKnowledgeToKernels());",
          "content_same": false
        },
        {
          "line": 211,
          "old_api": null,
          "new_api": "run",
          "old_text": null,
          "new_text": "pm.run(module)",
          "old_line_content": "Status GenerateDeviceCode(mlir::ModuleOp module,",
          "new_line_content": "  return failed(pm.run(module))",
          "content_same": false
        },
        {
          "line": 212,
          "old_api": null,
          "new_api": "InternalError",
          "old_text": null,
          "new_text": "InternalError(\"Amending LLVMIR with static knowledge failed.\")",
          "old_line_content": "                          llvm::StringRef gpu_binary_attr_name,",
          "new_line_content": "             ? InternalError(\"Amending LLVMIR with static knowledge failed.\")",
          "content_same": false
        },
        {
          "line": 213,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "                          llvm::ArrayRef<std::string> architectures,",
          "new_line_content": "             : Status::OK();",
          "content_same": false
        },
        {
          "line": 223,
          "old_api": null,
          "new_api": "pm.nest<mlir::gpu::GPUModuleOp>()",
          "old_text": null,
          "new_text": "pm.nest<mlir::gpu::GPUModuleOp>()",
          "old_line_content": "",
          "new_line_content": "  auto& kernel_pm = pm.nest<mlir::gpu::GPUModuleOp>();",
          "content_same": false
        },
        {
          "line": 229,
          "old_api": null,
          "new_api": "run",
          "old_text": null,
          "new_text": "pm.run(module)",
          "old_line_content": "Status LowerHostSideToFinalForm(mlir::ModuleOp module) {",
          "new_line_content": "  return failed(pm.run(module))",
          "content_same": false
        },
        {
          "line": 236,
          "old_api": null,
          "new_api": "applyTensorflowAndCLOptions",
          "old_text": null,
          "new_text": "applyTensorflowAndCLOptions(pm)",
          "old_line_content": "",
          "new_line_content": "  applyTensorflowAndCLOptions(pm);",
          "content_same": false
        },
        {
          "line": 240,
          "old_api": null,
          "new_api": "mlir::createCSEPass()",
          "old_text": null,
          "new_text": "mlir::createCSEPass()",
          "old_line_content": "}",
          "new_line_content": "  pm.addPass(mlir::createCSEPass());",
          "content_same": false
        },
        {
          "line": 242,
          "old_api": null,
          "new_api": "run",
          "old_text": null,
          "new_text": "pm.run(module)",
          "old_line_content": "}  // namespace",
          "new_line_content": "  return failed(pm.run(module))",
          "content_same": false
        },
        {
          "line": 243,
          "old_api": null,
          "new_api": "InternalError",
          "old_text": null,
          "new_text": "InternalError(\"Final lowering of host side failed.\")",
          "old_line_content": "",
          "new_line_content": "             ? InternalError(\"Final lowering of host side failed.\")",
          "content_same": false
        },
        {
          "line": 244,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "StatusOr<mlir::OwningModuleRef> GenerateKernelForTfCode(",
          "new_line_content": "             : Status::OK();",
          "content_same": false
        }
      ],
      "deletions": [
        {
          "line": 261,
          "old_api": "get",
          "new_api": null,
          "old_text": "module.get()",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(xla::mlir_gpu::LowerKernelBodiesToROCDL(module.get()));",
          "new_line_content": "      \"Neither TENSORFLOW_USE_ROCM nor GOOGLE_CUDA are defined.\"",
          "content_same": false
        },
        {
          "line": 263,
          "old_api": "get",
          "new_api": null,
          "old_text": "module.get()",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(xla::mlir_gpu::LowerKernelBodiesToNVVM(module.get()));",
          "new_line_content": "#endif",
          "content_same": false
        },
        {
          "line": 265,
          "old_api": "get",
          "new_api": null,
          "old_text": "module.get()",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(AmendKernelLLVMIRWithStaticKnowledge(module.get()));",
          "new_line_content": "#if TENSORFLOW_USE_ROCM",
          "content_same": false
        },
        {
          "line": 269,
          "old_api": "get",
          "new_api": null,
          "old_text": "module.get()",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(LowerHostSideToFinalForm(module.get()));",
          "new_line_content": "#endif",
          "content_same": false
        },
        {
          "line": 275,
          "old_api": "module.getOps<mlir::gpu::GPUModuleOp>()",
          "new_api": null,
          "old_text": "module.getOps<mlir::gpu::GPUModuleOp>()",
          "new_text": null,
          "old_line_content": "  auto gpu_modules = module.getOps<mlir::gpu::GPUModuleOp>();",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 276,
          "old_api": "end",
          "new_api": null,
          "old_text": "gpu_modules.end()",
          "new_text": null,
          "old_line_content": "  if (std::distance(gpu_modules.begin(), gpu_modules.end()) != 1) {",
          "new_line_content": "  return module;",
          "content_same": false
        },
        {
          "line": 277,
          "old_api": "InternalError",
          "new_api": null,
          "old_text": "InternalError(\"There should be exactly one GPU Module\")",
          "new_text": null,
          "old_line_content": "    return InternalError(\"There should be exactly one GPU Module\");",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 279,
          "old_api": "begin",
          "new_api": null,
          "old_text": "gpu_modules.begin()",
          "new_text": null,
          "old_line_content": "  mlir::gpu::GPUModuleOp gpu_mod = *gpu_modules.begin();",
          "new_line_content": "StatusOr<std::string> ExtractGpuBinary(mlir::ModuleOp module) {",
          "content_same": false
        },
        {
          "line": 156,
          "old_api": "xla::mlir_gpu::createMapParallelLoopsPass()",
          "new_api": null,
          "old_text": "xla::mlir_gpu::createMapParallelLoopsPass()",
          "new_text": null,
          "old_line_content": "  pm.addNestedPass<::mlir::FuncOp>(xla::mlir_gpu::createMapParallelLoopsPass());",
          "new_line_content": "    // Find candidates for buffer reuse.",
          "content_same": false
        },
        {
          "line": 162,
          "old_api": "::mlir::createCSEPass()",
          "new_api": null,
          "old_text": "::mlir::createCSEPass()",
          "new_text": null,
          "old_line_content": "  pm.addNestedPass<::mlir::FuncOp>(::mlir::createCSEPass());",
          "new_line_content": "  // Apply the mapping.",
          "content_same": false
        },
        {
          "line": 165,
          "old_api": "empty",
          "new_api": null,
          "old_text": "unroll_factors.empty()",
          "new_text": null,
          "old_line_content": "  if (!unroll_factors.empty()) {",
          "new_line_content": "  // Some basic cleanup.",
          "content_same": false
        },
        {
          "line": 169,
          "old_api": "pm.addNestedPass<::mlir::FuncOp>(\n      ::mlir::mhlo::createLegalizeTrigonometricToApproximationPass())",
          "new_api": null,
          "old_text": "pm.addNestedPass<::mlir::FuncOp>(\n      ::mlir::mhlo::createLegalizeTrigonometricToApproximationPass())",
          "new_text": null,
          "old_line_content": "  pm.addNestedPass<::mlir::FuncOp>(",
          "new_line_content": "  // Only do this if we unrolled in the first place.",
          "content_same": false
        },
        {
          "line": 172,
          "old_api": "::mlir::createGpuKernelOutliningPass()",
          "new_api": null,
          "old_text": "::mlir::createGpuKernelOutliningPass()",
          "new_text": null,
          "old_line_content": "  pm.addPass(::mlir::createGpuKernelOutliningPass());",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 176,
          "old_api": "pm.addNestedPass<::mlir::FuncOp>(\n        xla::mlir_gpu::createRewriteKernelSignaturePass())",
          "new_api": null,
          "old_text": "pm.addNestedPass<::mlir::FuncOp>(\n        xla::mlir_gpu::createRewriteKernelSignaturePass())",
          "new_text": null,
          "old_line_content": "    pm.addNestedPass<::mlir::FuncOp>(",
          "new_line_content": "  // Take launches to launches with kernels.",
          "content_same": false
        },
        {
          "line": 179,
          "old_api": "::mlir::createLowerAffinePass()",
          "new_api": null,
          "old_text": "::mlir::createLowerAffinePass()",
          "new_text": null,
          "old_line_content": "  pm.addPass(::mlir::createLowerAffinePass());",
          "new_line_content": "  if (gpu_binary_only) {",
          "content_same": false
        },
        {
          "line": 183,
          "old_api": "::mlir::createConvertShapeConstraintsPass()",
          "new_api": null,
          "old_text": "::mlir::createConvertShapeConstraintsPass()",
          "new_text": null,
          "old_line_content": "  pm.addNestedPass<::mlir::FuncOp>(::mlir::createConvertShapeConstraintsPass());",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 185,
          "old_api": "pm.addNestedPass<::mlir::FuncOp>(\n        mlir::kernel_gen::transforms::CreateEmbedMemRefPrintsPass())",
          "new_api": null,
          "old_text": "pm.addNestedPass<::mlir::FuncOp>(\n        mlir::kernel_gen::transforms::CreateEmbedMemRefPrintsPass())",
          "new_text": null,
          "old_line_content": "    pm.addNestedPass<::mlir::FuncOp>(",
          "new_line_content": "  // Map allocs, asserts, etc. to the tensorflow framework.",
          "content_same": false
        },
        {
          "line": 192,
          "old_api": "InternalError",
          "new_api": null,
          "old_text": "InternalError(\"Lowering to GPU kernels failed.\")",
          "new_text": null,
          "old_line_content": "    return InternalError(\"Lowering to GPU kernels failed.\");",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 194,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "  return Status::OK();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 198,
          "old_api": "getContext",
          "new_api": null,
          "old_text": "module.getContext()",
          "new_text": null,
          "old_line_content": "  mlir::PassManager pm(module.getContext());",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 201,
          "old_api": "pm.addNestedPass<mlir::FuncOp>(\n      mlir::kernel_gen::transforms::CreatePropagateShapeKnowledgeToKernels())",
          "new_api": null,
          "old_text": "pm.addNestedPass<mlir::FuncOp>(\n      mlir::kernel_gen::transforms::CreatePropagateShapeKnowledgeToKernels())",
          "new_text": null,
          "old_line_content": "  pm.addNestedPass<mlir::FuncOp>(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 202,
          "old_api": "mlir::kernel_gen::transforms::CreatePropagateShapeKnowledgeToKernels()",
          "new_api": null,
          "old_text": "mlir::kernel_gen::transforms::CreatePropagateShapeKnowledgeToKernels()",
          "new_text": null,
          "old_line_content": "      mlir::kernel_gen::transforms::CreatePropagateShapeKnowledgeToKernels());",
          "new_line_content": "Status AmendKernelLLVMIRWithStaticKnowledge(mlir::ModuleOp module) {",
          "content_same": false
        },
        {
          "line": 215,
          "old_api": "getContext",
          "new_api": null,
          "old_text": "module.getContext()",
          "new_text": null,
          "old_line_content": "  mlir::PassManager pm(module.getContext());",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 216,
          "old_api": "applyTensorflowAndCLOptions",
          "new_api": null,
          "old_text": "applyTensorflowAndCLOptions(pm)",
          "new_text": null,
          "old_line_content": "  applyTensorflowAndCLOptions(pm);",
          "new_line_content": "Status GenerateDeviceCode(mlir::ModuleOp module,",
          "content_same": false
        },
        {
          "line": 218,
          "old_api": "pm.nest<mlir::gpu::GPUModuleOp>()",
          "new_api": null,
          "old_text": "pm.nest<mlir::gpu::GPUModuleOp>()",
          "new_text": null,
          "old_line_content": "  auto& kernel_pm = pm.nest<mlir::gpu::GPUModuleOp>();",
          "new_line_content": "                          llvm::ArrayRef<std::string> architectures,",
          "content_same": false
        },
        {
          "line": 224,
          "old_api": "run",
          "new_api": null,
          "old_text": "pm.run(module)",
          "new_text": null,
          "old_line_content": "  return failed(pm.run(module))",
          "new_line_content": "  // Remove debug information to ensure we do not create debug PTX.",
          "content_same": false
        },
        {
          "line": 233,
          "old_api": "mlir::kernel_gen::transforms::CreateTFKernelToLLVMPass()",
          "new_api": null,
          "old_text": "mlir::kernel_gen::transforms::CreateTFKernelToLLVMPass()",
          "new_text": null,
          "old_line_content": "  pm.addPass(mlir::kernel_gen::transforms::CreateTFKernelToLLVMPass());",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 234,
          "old_api": "mlir::createCanonicalizerPass()",
          "new_api": null,
          "old_text": "mlir::createCanonicalizerPass()",
          "new_text": null,
          "old_line_content": "  pm.addPass(mlir::createCanonicalizerPass());",
          "new_line_content": "Status LowerHostSideToFinalForm(mlir::ModuleOp module) {",
          "content_same": false
        },
        {
          "line": 237,
          "old_api": "run",
          "new_api": null,
          "old_text": "pm.run(module)",
          "new_text": null,
          "old_line_content": "  return failed(pm.run(module))",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 250,
          "old_api": "getDialectRegistry",
          "new_api": null,
          "old_text": "context.getDialectRegistry()",
          "new_text": null,
          "old_line_content": "  mlir::RegisterAllTensorFlowDialects(context.getDialectRegistry());",
          "new_line_content": "    mlir::MLIRContext& context, llvm::StringRef tf_code, bool gpu_binary_only,",
          "content_same": false
        },
        {
          "line": 251,
          "old_api": "mlir::parseSourceString(tf_code, &context)",
          "new_api": null,
          "old_text": "mlir::parseSourceString(tf_code, &context)",
          "new_text": null,
          "old_line_content": "  mlir::OwningModuleRef module = mlir::parseSourceString(tf_code, &context);",
          "new_line_content": "    llvm::ArrayRef<std::string> architectures,",
          "content_same": false
        },
        {
          "line": 252,
          "old_api": "get",
          "new_api": null,
          "old_text": "module.get()",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(LowerTFtoGPU(module.get(), gpu_binary_only, tile_sizes,",
          "new_line_content": "    llvm::ArrayRef<uint32_t> tile_sizes,",
          "content_same": false
        }
      ]
    },
    "api_summary": {
      "total_replacements": 28,
      "total_additions": 34,
      "total_deletions": 32,
      "total_api_changes": 94
    },
    "non_api_changes": {
      "has_non_api_changes": true,
      "evidence": {
        "total_diff_lines": 5,
        "api_related_lines": 94,
        "non_api_lines": 2,
        "non_api_line_numbers": [
          155,
          159
        ]
      }
    },
    "api_calls_before": 174,
    "api_calls_after": 176,
    "diff_info": {
      "added_lines": 5,
      "removed_lines": 0,
      "total_diff_lines": 17
    }
  }
}