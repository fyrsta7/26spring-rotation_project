{
  "status": "completed",
  "commit_dir": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/da4a62b9e2eb2447b31ffb26d1ae2892344eaa71",
  "file_info": {
    "before_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/da4a62b9e2eb2447b31ffb26d1ae2892344eaa71/before.cc",
    "after_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/da4a62b9e2eb2447b31ffb26d1ae2892344eaa71/after.cc",
    "diff_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/da4a62b9e2eb2447b31ffb26d1ae2892344eaa71/diff.txt"
  },
  "semgrep_analysis": {
    "is_api_change": false,
    "api_changes": {
      "replacements": [
        {
          "line": 2402,
          "old_api": "size",
          "new_api": "MPSolver::infinity()",
          "old_text": "s[i].size()",
          "new_text": "MPSolver::infinity()",
          "old_line_content": "        for (size_t j = 0; j < s[i].size(); ++j) {",
          "new_line_content": "          -MPSolver::infinity(), M - total_fixed_memory_cost,",
          "content_same": false
        },
        {
          "line": 2403,
          "old_api": "GetCoefficient",
          "new_api": "absl::StrCat(\"mem[\", t, \"] = \", str)",
          "old_text": "constraint->GetCoefficient(s[i][j])",
          "new_text": "absl::StrCat(\"mem[\", t, \"] = \", str)",
          "old_line_content": "          double accumulated_coefficient = constraint->GetCoefficient(s[i][j]);",
          "new_line_content": "          absl::StrCat(\"mem[\", t, \"] = \", str));",
          "content_same": false
        },
        {
          "line": 2419,
          "old_api": "SetCoefficient",
          "new_api": "MakeRowConstraint",
          "old_text": "constraint->SetCoefficient(e[i][j], 1.0)",
          "new_text": "solver->MakeRowConstraint(\n        1.0, 1.0,\n        absl::StrCat(\"sum(e[\", edge.first, \"][\", edge.second, \"][*]) = 1\"))",
          "old_line_content": "      constraint->SetCoefficient(e[i][j], 1.0);",
          "new_line_content": "    MPConstraint* constraint = solver->MakeRowConstraint(",
          "content_same": false
        },
        {
          "line": 2430,
          "old_api": "size",
          "new_api": "MakeRowConstraint",
          "old_text": "s[edge.second].size()",
          "new_text": "solver->MakeRowConstraint(\n          -MPSolver::infinity(), 0, absl::StrCat(\"f for i = \", i, \", p = \", p))",
          "old_line_content": "        constraint->SetCoefficient(e[i][p * s[edge.second].size() + q], 1.0);",
          "new_line_content": "      MPConstraint* constraint = solver->MakeRowConstraint(",
          "content_same": false
        },
        {
          "line": 2442,
          "old_api": "size",
          "new_api": "MakeRowConstraint",
          "old_text": "s[edge.second].size()",
          "new_text": "solver->MakeRowConstraint(\n          -MPSolver::infinity(), 0, absl::StrCat(\"g for i = \", i, \", q = \", q))",
          "old_line_content": "        constraint->SetCoefficient(e[i][p * s[edge.second].size() + q], 1.0);",
          "new_line_content": "      MPConstraint* constraint = solver->MakeRowConstraint(",
          "content_same": false
        },
        {
          "line": 2453,
          "old_api": "MakeRowConstraint",
          "new_api": "size",
          "old_text": "solver->MakeRowConstraint(\n              -MPSolver::infinity(), 1,\n              absl::StrCat(\"s[\", alias.first, \"][\", p, \"] + s[\", alias.second,\n                           \"][\", q, \"] <= 1\"))",
          "new_text": "s[alias.first].size()",
          "old_line_content": "          MPConstraint* constraint = solver->MakeRowConstraint(",
          "new_line_content": "    for (size_t p = 0; p < s[alias.first].size(); ++p) {",
          "content_same": false
        },
        {
          "line": 2454,
          "old_api": "MPSolver::infinity()",
          "new_api": "size",
          "old_text": "MPSolver::infinity()",
          "new_text": "s[alias.second].size()",
          "old_line_content": "              -MPSolver::infinity(), 1,",
          "new_line_content": "      for (size_t q = 0; q < s[alias.second].size(); ++q) {",
          "content_same": false
        },
        {
          "line": 2457,
          "old_api": "SetCoefficient",
          "new_api": "MakeRowConstraint",
          "old_text": "constraint->SetCoefficient(s[alias.first][p], 1.0)",
          "new_text": "solver->MakeRowConstraint(\n              -MPSolver::infinity(), 1,\n              absl::StrCat(\"s[\", alias.first, \"][\", p, \"] + s[\", alias.second,\n                           \"][\", q, \"] <= 1\"))",
          "old_line_content": "          constraint->SetCoefficient(s[alias.first][p], 1.0);",
          "new_line_content": "          MPConstraint* constraint = solver->MakeRowConstraint(",
          "content_same": false
        },
        {
          "line": 2458,
          "old_api": "SetCoefficient",
          "new_api": "MPSolver::infinity()",
          "old_text": "constraint->SetCoefficient(s[alias.second][q], 1.0)",
          "new_text": "MPSolver::infinity()",
          "old_line_content": "          constraint->SetCoefficient(s[alias.second][q], 1.0);",
          "new_line_content": "              -MPSolver::infinity(), 1,",
          "content_same": false
        },
        {
          "line": 2473,
          "old_api": "file::Defaults()",
          "new_api": "ExportModelToProto",
          "old_text": "file::Defaults()",
          "new_text": "solver->ExportModelToProto(&model_proto)",
          "old_line_content": "        model_proto, file::Defaults());",
          "new_line_content": "    solver->ExportModelToProto(&model_proto);",
          "content_same": false
        },
        {
          "line": 2474,
          "old_api": "ok",
          "new_api": "NumVariables",
          "old_text": "write_status.ok()",
          "new_text": "file::SetTextProto(\n        // Modify this file path if needed.\n        absl::StrCat(\"/tmp/model_\", solver->NumVariables(), \".proto\"),\n        model_proto, file::Defaults())",
          "old_line_content": "    if (!write_status.ok()) {",
          "new_line_content": "    auto write_status = file::SetTextProto(",
          "content_same": false
        },
        {
          "line": 2479,
          "old_api": "absl::Seconds(solver_timeout_in_seconds)",
          "new_api": "message",
          "old_text": "absl::Seconds(solver_timeout_in_seconds)",
          "new_text": "write_status.message()",
          "old_line_content": "  solver->SetTimeLimit(absl::Seconds(solver_timeout_in_seconds));",
          "new_line_content": "      LOG(ERROR) << write_status.message();",
          "content_same": false
        },
        {
          "line": 2483,
          "old_api": "GetNumThreads",
          "new_api": "absl::Seconds(solver_timeout_in_seconds)",
          "old_text": "solver->GetNumThreads()",
          "new_text": "absl::Seconds(solver_timeout_in_seconds)",
          "old_line_content": "          << \"Number of threads: \" << solver->GetNumThreads() << \"\\n\"",
          "new_line_content": "  solver->SetTimeLimit(absl::Seconds(solver_timeout_in_seconds));",
          "content_same": false
        },
        {
          "line": 2484,
          "old_api": "time_limit",
          "new_api": "ProblemType",
          "old_text": "solver->time_limit()",
          "new_text": "solver->ProblemType()",
          "old_line_content": "          << \"Time limit: \" << solver->time_limit() << \"\\n\"",
          "new_line_content": "  VLOG(0) << \"Starting solver \" << solver->ProblemType() << \"\\n\"",
          "content_same": false
        },
        {
          "line": 2489,
          "old_api": "NumConstraints",
          "new_api": "NumVariables",
          "old_text": "solver->NumConstraints()",
          "new_text": "solver->NumVariables()",
          "old_line_content": "          << \"Number of ILP constraints: \" << solver->NumConstraints();",
          "new_line_content": "          << \"Number variables for ILP: \" << solver->NumVariables() << \"\\n\"",
          "content_same": false
        },
        {
          "line": 2493,
          "old_api": "LOG",
          "new_api": "NumConstraints",
          "old_text": "LOG(ERROR)",
          "new_text": "solver->NumConstraints()",
          "old_line_content": "    LOG(ERROR) << \"MPSolver could not find any feasible solution.\";",
          "new_line_content": "          << \"Number of ILP constraints: \" << solver->NumConstraints();",
          "content_same": false
        },
        {
          "line": 2497,
          "old_api": "ProblemType",
          "new_api": "LOG",
          "old_text": "solver->ProblemType()",
          "new_text": "LOG(ERROR)",
          "old_line_content": "    if (solver->ProblemType() ==",
          "new_line_content": "    LOG(ERROR) << \"MPSolver could not find any feasible solution.\";",
          "content_same": false
        },
        {
          "line": 2507,
          "old_api": "MPSolver::ComputeIrreducibleInfeasibleSubset(model_request)",
          "new_api": "set_solver_type",
          "old_text": "MPSolver::ComputeIrreducibleInfeasibleSubset(model_request)",
          "new_text": "model_request.set_solver_type(\n          operations_research::MPModelRequest::SCIP_MIXED_INTEGER_PROGRAMMING)",
          "old_line_content": "    auto iis = MPSolver::ComputeIrreducibleInfeasibleSubset(model_request);",
          "new_line_content": "      model_request.set_solver_type(",
          "content_same": false
        },
        {
          "line": 2510,
          "old_api": "constraint_index",
          "new_api": "set_solver_time_limit_seconds",
          "old_text": "iis.constraint_index()",
          "new_text": "model_request.set_solver_time_limit_seconds(100)",
          "old_line_content": "    for (int index : iis.constraint_index()) {",
          "new_line_content": "    model_request.set_solver_time_limit_seconds(100);",
          "content_same": false
        },
        {
          "line": 2511,
          "old_api": "model",
          "new_api": "MPSolver::ComputeIrreducibleInfeasibleSubset(model_request)",
          "old_text": "model_request.model().constraint(index).name()",
          "new_text": "MPSolver::ComputeIrreducibleInfeasibleSubset(model_request)",
          "old_line_content": "      LOG(INFO) << \" - \" << model_request.model().constraint(index).name();",
          "new_line_content": "    auto iis = MPSolver::ComputeIrreducibleInfeasibleSubset(model_request);",
          "content_same": false
        },
        {
          "line": 2513,
          "old_api": "general_constraint_index",
          "new_api": "LOG",
          "old_text": "iis.general_constraint_index()",
          "new_text": "LOG(INFO)",
          "old_line_content": "    for (int index : iis.general_constraint_index()) {",
          "new_line_content": "    LOG(INFO) << \"Infeasible constraints: \";",
          "content_same": false
        },
        {
          "line": 2514,
          "old_api": "LOG",
          "new_api": "constraint_index",
          "old_text": "LOG(INFO)",
          "new_text": "iis.constraint_index()",
          "old_line_content": "      LOG(INFO)",
          "new_line_content": "    for (int index : iis.constraint_index()) {",
          "content_same": false
        },
        {
          "line": 2520,
          "old_api": "ORToolsSolverResult",
          "new_api": "model",
          "old_text": "ORToolsSolverResult(\n        absl::InternalError(\"MPSolver could not find any feasible solution.\"),\n        false)",
          "new_text": "model_request.model().general_constraint(index).DebugString()",
          "old_line_content": "    return ORToolsSolverResult(",
          "new_line_content": "          << model_request.model().general_constraint(index).DebugString();",
          "content_same": false
        },
        {
          "line": 2525,
          "old_api": "LOG",
          "new_api": "absl::InternalError(\"MPSolver could not find any feasible solution.\")",
          "old_text": "LOG(WARNING)",
          "new_text": "absl::InternalError(\"MPSolver could not find any feasible solution.\")",
          "old_line_content": "    LOG(WARNING) << err_msg;",
          "new_line_content": "        absl::InternalError(\"MPSolver could not find any feasible solution.\"),",
          "content_same": false
        },
        {
          "line": 2529,
          "old_api": "absl::InternalError(err_msg)",
          "new_api": "LOG",
          "old_text": "absl::InternalError(err_msg)",
          "new_text": "LOG(WARNING)",
          "old_line_content": "    return ORToolsSolverResult(absl::InternalError(err_msg), true);",
          "new_line_content": "    LOG(WARNING) << err_msg;",
          "content_same": false
        },
        {
          "line": 2533,
          "old_api": "Value",
          "new_api": "absl::InternalError(err_msg)",
          "old_text": "solver->Objective().Value()",
          "new_text": "absl::InternalError(err_msg)",
          "old_line_content": "            << \" Objective value: \" << solver->Objective().Value();",
          "new_line_content": "    return ORToolsSolverResult(absl::InternalError(err_msg), true);",
          "content_same": false
        },
        {
          "line": 2544,
          "old_api": "ExportModelToProto",
          "new_api": "VLOG_IS_ON",
          "old_text": "solver->ExportModelToProto(&model_proto)",
          "new_text": "VLOG_IS_ON(10)",
          "old_line_content": "    solver->ExportModelToProto(&model_proto);",
          "new_line_content": "  if (VLOG_IS_ON(10)) {",
          "content_same": false
        },
        {
          "line": 2549,
          "old_api": "FillSolutionResponseProto",
          "new_api": "VLOG",
          "old_text": "solver->FillSolutionResponseProto(&response)",
          "new_text": "VLOG(10)",
          "old_line_content": "    solver->FillSolutionResponseProto(&response);",
          "new_line_content": "    VLOG(10) << \"MODEL:\";",
          "content_same": false
        },
        {
          "line": 2580,
          "old_api": "PrintLargestInstructions",
          "new_api": "LOG",
          "old_text": "PrintLargestInstructions(chosen_strategy, m, L, instruction_names)",
          "new_text": "LOG(INFO)",
          "old_line_content": "  PrintLargestInstructions(chosen_strategy, m, L, instruction_names);",
          "new_line_content": "    LOG(INFO) << \"memory budget: -1\";",
          "content_same": false
        },
        {
          "line": 2582,
          "old_api": "std::move(e_val)",
          "new_api": "LOG",
          "old_text": "std::move(e_val)",
          "new_text": "LOG(INFO)",
          "old_line_content": "      std::make_tuple(std::move(chosen_strategy), std::move(e_val),",
          "new_line_content": "    LOG(INFO) << \"memory budget: \" << M / (1024 * 1024 * 1024) << \" GB\";",
          "content_same": false
        },
        {
          "line": 2623,
          "old_api": "push_back",
          "new_api": "at",
          "old_text": "ci.push_back(strategies->leaf_vector[j].compute_cost)",
          "new_text": "absl::StrCat(\n        instructions.at(strategies->instruction_id)->name(), \" (id: \", i, \")\")",
          "old_line_content": "      ci.push_back(strategies->leaf_vector[j].compute_cost);",
          "new_line_content": "    instruction_names.push_back(absl::StrCat(",
          "content_same": false
        },
        {
          "line": 2624,
          "old_api": "push_back",
          "new_api": "at",
          "old_text": "di.push_back(strategies->leaf_vector[j].communication_cost +\n                   cost_graph.extra_node_costs_[i][j])",
          "new_text": "instructions.at(strategies->instruction_id)->name()",
          "old_line_content": "      di.push_back(strategies->leaf_vector[j].communication_cost +",
          "new_line_content": "        instructions.at(strategies->instruction_id)->name(), \" (id: \", i, \")\"));",
          "content_same": false
        },
        {
          "line": 2626,
          "old_api": "push_back",
          "new_api": "size",
          "old_text": "mi.push_back(strategies->leaf_vector[j].memory_cost)",
          "new_text": "strategies->leaf_vector.size()",
          "old_line_content": "      mi.push_back(strategies->leaf_vector[j].memory_cost);",
          "new_line_content": "    for (size_t j = 0; j < strategies->leaf_vector.size(); ++j) {",
          "content_same": false
        },
        {
          "line": 2646,
          "old_api": "raw_cost",
          "new_api": "size",
          "old_text": "raw_cost(i, j)",
          "new_text": "src_strategies->leaf_vector.size()",
          "old_line_content": "          raw_cost(i, j) = 0.0;",
          "new_line_content": "    for (size_t i = 0; i < src_strategies->leaf_vector.size(); ++i) {",
          "content_same": false
        },
        {
          "line": 2662,
          "old_api": "end",
          "new_api": "at",
          "old_text": "row_indices.end()",
          "new_text": "cost_graph.reindexing_vector_.at(idx_a)",
          "old_line_content": "      std::iota(row_indices.begin(), row_indices.end(), 0);",
          "new_line_content": "      row_indices = cost_graph.reindexing_vector_.at(idx_a);",
          "content_same": false
        },
        {
          "line": 2666,
          "old_api": "at",
          "new_api": "end",
          "old_text": "cost_graph.reindexing_vector_.at(idx_b)",
          "new_text": "row_indices.end()",
          "old_line_content": "      col_indices = cost_graph.reindexing_vector_.at(idx_b);",
          "new_line_content": "      std::iota(row_indices.begin(), row_indices.end(), 0);",
          "content_same": false
        },
        {
          "line": 2670,
          "old_api": "end",
          "new_api": "at",
          "old_text": "col_indices.end()",
          "new_text": "cost_graph.reindexing_vector_.at(idx_b)",
          "old_line_content": "      std::iota(col_indices.begin(), col_indices.end(), 0);",
          "new_line_content": "      col_indices = cost_graph.reindexing_vector_.at(idx_b);",
          "content_same": false
        },
        {
          "line": 2673,
          "old_api": "size",
          "new_api": "assign",
          "old_text": "row_indices.size()",
          "new_text": "col_indices.assign(s_len[idx_b], 0)",
          "old_line_content": "    CHECK_EQ(s_len[idx_a], row_indices.size());",
          "new_line_content": "      col_indices.assign(s_len[idx_b], 0);",
          "content_same": false
        },
        {
          "line": 2674,
          "old_api": "size",
          "new_api": "end",
          "old_text": "col_indices.size()",
          "new_text": "col_indices.end()",
          "old_line_content": "    CHECK_EQ(s_len[idx_b], col_indices.size());",
          "new_line_content": "      std::iota(col_indices.begin(), col_indices.end(), 0);",
          "content_same": false
        },
        {
          "line": 2680,
          "old_api": "raw_cost",
          "new_api": "std::make_pair(idx_a, idx_b)",
          "old_text": "raw_cost(i, j)",
          "new_text": "std::make_pair(idx_a, idx_b)",
          "old_line_content": "        vij.push_back(raw_cost(i, j));",
          "new_line_content": "    A.push_back(std::make_pair(idx_a, idx_b));",
          "content_same": false
        },
        {
          "line": 2687,
          "old_api": "size",
          "new_api": "push_back",
          "old_text": "liveness_set.size()",
          "new_text": "v.push_back(vij)",
          "old_line_content": "  std::vector<std::vector<int>> L(liveness_set.size());",
          "new_line_content": "    v.push_back(vij);",
          "content_same": false
        },
        {
          "line": 2698,
          "old_api": "push_back",
          "new_api": "empty",
          "old_text": "current_liveness_set_indices.push_back(strategies->id)",
          "new_text": "index.empty()",
          "old_line_content": "        current_liveness_set_indices.push_back(strategies->id);",
          "new_line_content": "      if (!index.empty()) {",
          "content_same": false
        },
        {
          "line": 2702,
          "old_api": "empty",
          "new_api": "push_back",
          "old_text": "value->index().empty()",
          "new_text": "current_liveness_set_indices.push_back(strategies->id)",
          "old_line_content": "      if (value->instruction()->shape().IsTuple() && value->index().empty()) {",
          "new_line_content": "        current_liveness_set_indices.push_back(strategies->id);",
          "content_same": false
        },
        {
          "line": 2706,
          "old_api": "index",
          "new_api": "empty",
          "old_text": "value->index()",
          "new_text": "value->index().empty()",
          "old_line_content": "                                 value->index());",
          "new_line_content": "      if (value->instruction()->shape().IsTuple() && value->index().empty()) {",
          "content_same": false
        },
        {
          "line": 2709,
          "old_api": "CallORToolsSolver",
          "new_api": "instruction",
          "old_text": "CallORToolsSolver(N, M, s_len, s_follow, E, L, c, d, m, r, A, v,\n                           instruction_names, solver_timeout_in_seconds,\n                           crash_at_infinity_costs_check)",
          "new_text": "value->instruction()",
          "old_line_content": "  return CallORToolsSolver(N, M, s_len, s_follow, E, L, c, d, m, r, A, v,",
          "new_line_content": "      traverse_live_instructions(strategy_map.at(value->instruction()).get(),",
          "content_same": false
        },
        {
          "line": 2723,
          "old_api": "opcode",
          "new_api": "has_sharding",
          "old_text": "ins->opcode()",
          "new_text": "ins->has_sharding()",
          "old_line_content": "        ins->opcode() != HloOpcode::kGetTupleElement) {",
          "new_line_content": "    if (!ins->has_sharding()) {",
          "content_same": false
        },
        {
          "line": 2726,
          "old_api": "shape",
          "new_api": "IsTuple",
          "old_text": "ins->shape()",
          "new_text": "ins->shape().IsTuple()",
          "old_line_content": "      double size = GetInstructionSize(ins->shape()) / 1024 / 1024 / 1024;",
          "new_line_content": "    if (!ins->shape().IsTuple() &&",
          "content_same": false
        },
        {
          "line": 2727,
          "old_api": "sharding",
          "new_api": "opcode",
          "old_text": "ins->sharding()",
          "new_text": "ins->opcode()",
          "old_line_content": "      if ((!ShardingIsComplete(ins->sharding(), total_num_devices) ||",
          "new_line_content": "        ins->opcode() != HloOpcode::kGetTupleElement) {",
          "content_same": false
        },
        {
          "line": 2730,
          "old_api": "LOG",
          "new_api": "shape",
          "old_text": "LOG(INFO)",
          "new_text": "ins->shape()",
          "old_line_content": "        LOG(INFO) << \"Instruction is not fully sharded: (\" << size << \" GB) \"",
          "new_line_content": "      double size = GetInstructionSize(ins->shape()) / 1024 / 1024 / 1024;",
          "content_same": false
        },
        {
          "line": 2731,
          "old_api": "ToString",
          "new_api": "sharding",
          "old_text": "ins->ToString()",
          "new_text": "ins->sharding()",
          "old_line_content": "                  << ins->ToString();",
          "new_line_content": "      if ((!ShardingIsComplete(ins->sharding(), total_num_devices) ||",
          "content_same": false
        },
        {
          "line": 2732,
          "old_api": "has_sharding",
          "new_api": "IsReplicated",
          "old_text": "ins->has_sharding()",
          "new_text": "ins->sharding().IsReplicated()",
          "old_line_content": "      } else if (!ins->has_sharding()) {",
          "new_line_content": "           ins->sharding().IsReplicated()) &&",
          "content_same": false
        },
        {
          "line": 2735,
          "old_api": "operands",
          "new_api": "ToString",
          "old_text": "ins->operands()",
          "new_text": "ins->ToString()",
          "old_line_content": "      for (const auto& op : ins->operands()) {",
          "new_line_content": "                  << ins->ToString();",
          "content_same": false
        },
        {
          "line": 2737,
          "old_api": "IsReplicated",
          "new_api": "name",
          "old_text": "ins->sharding().IsReplicated()",
          "new_text": "ins->name()",
          "old_line_content": "          if (op->sharding().IsReplicated() || ins->sharding().IsReplicated()) {",
          "new_line_content": "        LOG(INFO) << \"Instruction does not have sharding: \" << ins->name();",
          "content_same": false
        },
        {
          "line": 2741,
          "old_api": "tile_assignment",
          "new_api": "IsReplicated",
          "old_text": "VectorGreaterThanOneElementIndices(\n                  ins->sharding().tile_assignment().dimensions(),\n                  ins->sharding().ReplicateOnLastTileDim())",
          "new_text": "ins->sharding().IsReplicated()",
          "old_line_content": "              VectorGreaterThanOneElementIndices(",
          "new_line_content": "          if (op->sharding().IsReplicated() || ins->sharding().IsReplicated()) {",
          "content_same": false
        },
        {
          "line": 2749,
          "old_api": "size",
          "new_api": "tile_assignment",
          "old_text": "op_sharded_dims.size()",
          "new_text": "VectorGreaterThanOneElementIndices(\n                  op->sharding().tile_assignment().dimensions(),\n                  op->sharding().ReplicateOnLastTileDim())",
          "old_line_content": "          if (ins_sharded_dims.size() != op_sharded_dims.size()) {",
          "new_line_content": "              VectorGreaterThanOneElementIndices(",
          "content_same": false
        },
        {
          "line": 2753,
          "old_api": "at",
          "new_api": "size",
          "old_text": "op_sharded_dims.at(i)",
          "new_text": "op_sharded_dims.size()",
          "old_line_content": "              if (op->shape().dimensions().at(op_sharded_dims.at(i)) !=",
          "new_line_content": "          if (ins_sharded_dims.size() != op_sharded_dims.size()) {",
          "content_same": false
        },
        {
          "line": 2768,
          "old_api": "std::move(str)",
          "new_api": "shape",
          "old_text": "std::move(str)",
          "new_text": "op->shape()",
          "old_line_content": "            size_string.push_back(std::make_pair(op_size, std::move(str)));",
          "new_line_content": "                GetInstructionSize(op->shape()) / (1024.0 * 1024 * 1024);",
          "content_same": false
        },
        {
          "line": 2771,
          "old_api": "name",
          "new_api": "ToString",
          "old_text": "op->name()",
          "new_text": "op->ToString()",
          "old_line_content": "          LOG(INFO) << \"Instruction \" << op->name()",
          "new_line_content": "                                           \"\\n Operand: \", op->ToString());",
          "content_same": false
        },
        {
          "line": 2787,
          "old_api": "at",
          "new_api": "end",
          "old_text": "size_string.at(t)",
          "new_text": "size_string.end()",
          "old_line_content": "    LOG(INFO) << size_string.at(t).second;",
          "new_line_content": "  std::sort(size_string.begin(), size_string.end(), MemLarger);",
          "content_same": false
        },
        {
          "line": 2801,
          "old_api": "end",
          "new_api": "instructions",
          "old_text": "strategy_map.end()",
          "new_text": "sequence.instructions()",
          "old_line_content": "    if (iter == strategy_map.end()) {",
          "new_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "content_same": false
        },
        {
          "line": 2805,
          "old_api": "get",
          "new_api": "end",
          "old_text": "iter->second.get()",
          "new_text": "strategy_map.end()",
          "old_line_content": "    const StrategyVector* strategies = iter->second.get();",
          "new_line_content": "    if (iter == strategy_map.end()) {",
          "content_same": false
        },
        {
          "line": 2820,
          "old_api": "push_back",
          "new_api": "IsReplicated",
          "old_text": "output_flattened_shardings.push_back(\n            t->leaf_vector[stra_idx].output_sharding)",
          "new_text": "t->leaf_vector[stra_idx].output_sharding.IsReplicated()",
          "old_line_content": "        output_flattened_shardings.push_back(",
          "new_line_content": "        if (t->leaf_vector[stra_idx].output_sharding.IsReplicated() &&",
          "content_same": false
        },
        {
          "line": 2829,
          "old_api": "HloSharding::Tuple(output_tuple_sharding)",
          "new_api": "leaves",
          "old_text": "HloSharding::Tuple(output_tuple_sharding)",
          "new_text": "output_tuple_sharding.leaves()",
          "old_line_content": "        inst->set_sharding(HloSharding::Tuple(output_tuple_sharding));",
          "new_line_content": "      for (auto& leaf : output_tuple_sharding.leaves()) {",
          "content_same": false
        },
        {
          "line": 2833,
          "old_api": "GetShardingStrategy",
          "new_api": "HloSharding::Tuple(output_tuple_sharding)",
          "old_text": "GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "new_text": "HloSharding::Tuple(output_tuple_sharding)",
          "old_line_content": "          GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "new_line_content": "        inst->set_sharding(HloSharding::Tuple(output_tuple_sharding));",
          "content_same": false
        },
        {
          "line": 2839,
          "old_api": "IsReplicated",
          "new_api": "IsUndefined",
          "old_text": "sharding_spec.IsReplicated()",
          "new_text": "IsUndefined(sharding_spec)",
          "old_line_content": "      if (sharding_spec.IsReplicated() && !last_iteration) {",
          "new_line_content": "      if (IsUndefined(sharding_spec)) {",
          "content_same": false
        },
        {
          "line": 2872,
          "old_api": "operand",
          "new_api": "opcode",
          "old_text": "inst->operand(1)",
          "new_text": "inst->opcode()",
          "old_line_content": "      const HloInstruction* rhs = inst->operand(1);",
          "new_line_content": "    if (inst->opcode() == HloOpcode::kDot) {",
          "content_same": false
        },
        {
          "line": 2874,
          "old_api": "sharding",
          "new_api": "GetShardingStrategy",
          "old_text": "rhs->sharding()",
          "new_text": "GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "old_line_content": "      const HloSharding& rhs_sharding = rhs->sharding();",
          "new_line_content": "          GetShardingStrategy(inst, strategy_map, cost_graph, s_val);",
          "content_same": false
        },
        {
          "line": 2875,
          "old_api": "dot_dimension_numbers",
          "new_api": "operand",
          "old_text": "inst->dot_dimension_numbers()",
          "new_text": "inst->operand(0)",
          "old_line_content": "      const DotDimensionNumbers& dot_dnums = inst->dot_dimension_numbers();",
          "new_line_content": "      const HloInstruction* lhs = inst->operand(0);",
          "content_same": false
        },
        {
          "line": 2876,
          "old_api": "lhs_contracting_dimensions",
          "new_api": "operand",
          "old_text": "dot_dnums.lhs_contracting_dimensions()",
          "new_text": "inst->operand(1)",
          "old_line_content": "      const auto& lhs_con_dims = dot_dnums.lhs_contracting_dimensions();",
          "new_line_content": "      const HloInstruction* rhs = inst->operand(1);",
          "content_same": false
        },
        {
          "line": 2877,
          "old_api": "rhs_contracting_dimensions",
          "new_api": "sharding",
          "old_text": "dot_dnums.rhs_contracting_dimensions()",
          "new_text": "lhs->sharding()",
          "old_line_content": "      const auto& rhs_con_dims = dot_dnums.rhs_contracting_dimensions();",
          "new_line_content": "      const HloSharding& lhs_sharding = lhs->sharding();",
          "content_same": false
        },
        {
          "line": 2880,
          "old_api": "shape",
          "new_api": "lhs_contracting_dimensions",
          "old_text": "lhs->shape()",
          "new_text": "dot_dnums.lhs_contracting_dimensions()",
          "old_line_content": "          cluster_env.GetTensorDimToMeshDimWrapper(lhs->shape(), lhs_sharding);",
          "new_line_content": "      const auto& lhs_con_dims = dot_dnums.lhs_contracting_dimensions();",
          "content_same": false
        },
        {
          "line": 2884,
          "old_api": "absl::StrContains(stra.name, \"allreduce\")",
          "new_api": "shape",
          "old_text": "absl::StrContains(stra.name, \"allreduce\")",
          "new_text": "lhs->shape()",
          "old_line_content": "      if (absl::StrContains(stra.name, \"allreduce\") &&",
          "new_line_content": "          cluster_env.GetTensorDimToMeshDimWrapper(lhs->shape(), lhs_sharding);",
          "content_same": false
        },
        {
          "line": 2894,
          "old_api": "FixMixedMeshShapeResharding",
          "new_api": "size",
          "old_text": "FixMixedMeshShapeResharding(inst, 0, stra.input_shardings[0],\n                                    device_mesh, resharding_cache)",
          "new_text": "stra.input_shardings.size()",
          "old_line_content": "        FixMixedMeshShapeResharding(inst, 0, stra.input_shardings[0],",
          "new_line_content": "        CHECK(stra.input_shardings.size() == 2)",
          "content_same": false
        },
        {
          "line": 2903,
          "old_api": "operand",
          "new_api": "opcode",
          "old_text": "inst->operand(1)",
          "new_text": "inst->opcode()",
          "old_line_content": "      const HloInstruction* rhs = inst->operand(1);",
          "new_line_content": "    } else if (inst->opcode() == HloOpcode::kConvolution) {",
          "content_same": false
        },
        {
          "line": 2905,
          "old_api": "sharding",
          "new_api": "GetShardingStrategy",
          "old_text": "rhs->sharding()",
          "new_text": "GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "old_line_content": "      const HloSharding& rhs_sharding = rhs->sharding();",
          "new_line_content": "          GetShardingStrategy(inst, strategy_map, cost_graph, s_val);",
          "content_same": false
        },
        {
          "line": 2907,
          "old_api": "convolution_dimension_numbers",
          "new_api": "operand",
          "old_text": "inst->convolution_dimension_numbers()",
          "new_text": "inst->operand(1)",
          "old_line_content": "          inst->convolution_dimension_numbers();",
          "new_line_content": "      const HloInstruction* rhs = inst->operand(1);",
          "content_same": false
        },
        {
          "line": 2908,
          "old_api": "input_feature_dimension",
          "new_api": "sharding",
          "old_text": "conv_dnums.input_feature_dimension()",
          "new_text": "lhs->sharding()",
          "old_line_content": "      const int lhs_in_channel_dim = conv_dnums.input_feature_dimension();",
          "new_line_content": "      const HloSharding& lhs_sharding = lhs->sharding();",
          "content_same": false
        },
        {
          "line": 2917,
          "old_api": "absl::StrContains(stra.name, \"allreduce\")",
          "new_api": "shape",
          "old_text": "absl::StrContains(stra.name, \"allreduce\")",
          "new_text": "lhs->shape()",
          "old_line_content": "      if (absl::StrContains(stra.name, \"allreduce\") &&",
          "new_line_content": "          cluster_env.GetTensorDimToMeshDimWrapper(lhs->shape(), lhs_sharding);",
          "content_same": false
        },
        {
          "line": 2932,
          "old_api": "FixMixedMeshShapeResharding",
          "new_api": "opcode",
          "old_text": "FixMixedMeshShapeResharding(inst, 0, stra.input_shardings[0],\n                                    device_mesh, resharding_cache)",
          "new_text": "inst->opcode()",
          "old_line_content": "        FixMixedMeshShapeResharding(inst, 0, stra.input_shardings[0],",
          "new_line_content": "    } else if (inst->opcode() == HloOpcode::kReshape) {",
          "content_same": false
        },
        {
          "line": 2944,
          "old_api": "tuple_shapes_size",
          "new_api": "opcode",
          "old_text": "inst->shape().tuple_shapes_size()",
          "new_text": "inst->opcode()",
          "old_line_content": "            for (size_t i = 0; i < inst->shape().tuple_shapes_size(); ++i) {",
          "new_line_content": "        switch (inst->opcode()) {",
          "content_same": false
        },
        {
          "line": 2948,
          "old_api": "FixMixedMeshShapeResharding",
          "new_api": "tuple_shapes_size",
          "old_text": "FixMixedMeshShapeResharding(inst, i, stra.input_shardings[i],\n                                            device_mesh, resharding_cache)",
          "new_text": "inst->shape().tuple_shapes_size()",
          "old_line_content": "                FixMixedMeshShapeResharding(inst, i, stra.input_shardings[i],",
          "new_line_content": "            for (size_t i = 0; i < inst->shape().tuple_shapes_size(); ++i) {",
          "content_same": false
        },
        {
          "line": 2959,
          "old_api": "FixMixedMeshShapeResharding",
          "new_api": "tuple_shapes_size",
          "old_text": "FixMixedMeshShapeResharding(inst, i, stra.input_shardings[0],\n                                          device_mesh, resharding_cache)",
          "new_text": "inst->shape().tuple_shapes_size()",
          "old_line_content": "              FixMixedMeshShapeResharding(inst, i, stra.input_shardings[0],",
          "new_line_content": "            for (size_t i = 0; i < inst->shape().tuple_shapes_size(); ++i) {",
          "content_same": false
        },
        {
          "line": 2976,
          "old_api": "GetShardingStrategy",
          "new_api": "ToString",
          "old_text": "GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "new_text": "inst->ToString()",
          "old_line_content": "            GetShardingStrategy(inst, strategy_map, cost_graph, s_val);",
          "new_line_content": "            LOG(FATAL) << \"Unhandled instruction: \" + inst->ToString();",
          "content_same": false
        },
        {
          "line": 2980,
          "old_api": "opcode",
          "new_api": "GetShardingStrategy",
          "old_text": "inst->opcode()",
          "new_text": "GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "old_line_content": "        if (inst->opcode() == HloOpcode::kGetTupleElement) {",
          "new_line_content": "            GetShardingStrategy(inst, strategy_map, cost_graph, s_val);",
          "content_same": false
        },
        {
          "line": 2981,
          "old_api": "sharding",
          "new_api": "empty",
          "old_text": "FixMixedMeshShapeReshardingGetTupleElement(\n              inst, inst->sharding(), device_mesh, preserve_shardings)",
          "new_text": "stra.input_shardings.empty()",
          "old_line_content": "          FixMixedMeshShapeReshardingGetTupleElement(",
          "new_line_content": "        if (stra.input_shardings.empty()) {",
          "content_same": false
        },
        {
          "line": 2984,
          "old_api": "operand_count",
          "new_api": "opcode",
          "old_text": "inst->operand_count()",
          "new_text": "inst->opcode()",
          "old_line_content": "          for (size_t i = 0; i < inst->operand_count(); ++i) {",
          "new_line_content": "        if (inst->opcode() == HloOpcode::kGetTupleElement) {",
          "content_same": false
        },
        {
          "line": 2985,
          "old_api": "size",
          "new_api": "sharding",
          "old_text": "stra.input_shardings.size()",
          "new_text": "FixMixedMeshShapeReshardingGetTupleElement(\n              inst, inst->sharding(), device_mesh, preserve_shardings)",
          "old_line_content": "            if (stra.input_shardings.size() > i) {",
          "new_line_content": "          FixMixedMeshShapeReshardingGetTupleElement(",
          "content_same": false
        },
        {
          "line": 2986,
          "old_api": "FixMixedMeshShapeResharding",
          "new_api": "sharding",
          "old_text": "FixMixedMeshShapeResharding(inst, i, stra.input_shardings[i],\n                                          device_mesh, resharding_cache)",
          "new_text": "inst->sharding()",
          "old_line_content": "              FixMixedMeshShapeResharding(inst, i, stra.input_shardings[i],",
          "new_line_content": "              inst, inst->sharding(), device_mesh, preserve_shardings);",
          "content_same": false
        },
        {
          "line": 3003,
          "old_api": "instruction",
          "new_api": "size",
          "old_text": "value->instruction()->name()",
          "new_text": "liveness_set.size()",
          "old_line_content": "      names.push_back(absl::StrCat(value->instruction()->name(),",
          "new_line_content": "  for (size_t i = 0; i < liveness_set.size(); ++i) {",
          "content_same": false
        },
        {
          "line": 3007,
          "old_api": "absl::StrJoin(names, \", \")",
          "new_api": "instruction",
          "old_text": "absl::StrJoin(names, \", \")",
          "new_text": "value->instruction()->name()",
          "old_line_content": "    absl::StrAppend(&str, \"Time \", i, \": \", absl::StrJoin(names, \", \"), \"\\n\");",
          "new_line_content": "      names.push_back(absl::StrCat(value->instruction()->name(),",
          "content_same": false
        },
        {
          "line": 3050,
          "old_api": "ToString",
          "new_api": "size",
          "old_text": "absl::StrAppend(&str, i, \" \",\n                    instructions[leaf_strategies[i]->instruction_id]->ToString(\n                        HloPrintOptions::ShortParsable()),\n                    \" \")",
          "new_text": "leaf_strategies.size()",
          "old_line_content": "    absl::StrAppend(&str, i, \" \",",
          "new_line_content": "  size_t N = leaf_strategies.size();",
          "content_same": false
        },
        {
          "line": 3054,
          "old_api": "RemapIndex",
          "new_api": "ToString",
          "old_text": "cost_graph.RemapIndex(i, s_val[i])",
          "new_text": "absl::StrAppend(&str, i, \" \",\n                    instructions[leaf_strategies[i]->instruction_id]->ToString(\n                        HloPrintOptions::ShortParsable()),\n                    \" \")",
          "old_line_content": "    int stra_idx = cost_graph.RemapIndex(i, s_val[i]);",
          "new_line_content": "    absl::StrAppend(&str, i, \" \",",
          "content_same": false
        },
        {
          "line": 3056,
          "old_api": "ToString",
          "new_api": "HloPrintOptions::ShortParsable()",
          "old_text": "absl::StrAppend(\n          &str, leaf_strategies[i]->leaf_vector[stra_idx].ToString(), \"\\n\")",
          "new_text": "HloPrintOptions::ShortParsable()",
          "old_line_content": "      absl::StrAppend(",
          "new_line_content": "                        HloPrintOptions::ShortParsable()),",
          "content_same": false
        },
        {
          "line": 3091,
          "old_api": "size",
          "new_api": "RemapIndex",
          "old_text": "liveness_set.size()",
          "new_text": "cost_graph.RemapIndex(ins_idx, s_val[ins_idx])",
          "old_line_content": "  for (size_t t = 0; t < liveness_set.size(); ++t) {",
          "new_line_content": "    int stra_idx = cost_graph.RemapIndex(ins_idx, s_val[ins_idx]);",
          "content_same": false
        },
        {
          "line": 3095,
          "old_api": "at",
          "new_api": "size",
          "old_text": "strategy_map.at(ins).get()",
          "new_text": "liveness_set.size()",
          "old_line_content": "      auto tmp = calculate_memory_usage(strategy_map.at(ins).get());",
          "new_line_content": "  for (size_t t = 0; t < liveness_set.size(); ++t) {",
          "content_same": false
        },
        {
          "line": 3098,
          "old_api": "VLOG_IS_ON",
          "new_api": "instruction",
          "old_text": "VLOG_IS_ON(6)",
          "new_text": "val->instruction()",
          "old_line_content": "      if (VLOG_IS_ON(6) && tmp / (1024 * 1024) > 1) {",
          "new_line_content": "      const HloInstruction* ins = val->instruction();",
          "content_same": false
        },
        {
          "line": 3127,
          "old_api": "size",
          "new_api": "front",
          "old_text": "time_memory_usage.size()",
          "new_text": "time_memory_usage.front()",
          "old_line_content": "  k = std::min(k, time_memory_usage.size());",
          "new_line_content": "                  \" GB at time \", time_memory_usage.front().first, \"\\n\");",
          "content_same": false
        },
        {
          "line": 3131,
          "old_api": "instruction",
          "new_api": "size",
          "old_text": "val->instruction()",
          "new_text": "time_memory_usage.size()",
          "old_line_content": "      const HloInstruction* ins = val->instruction();",
          "new_line_content": "  k = std::min(k, time_memory_usage.size());",
          "content_same": false
        },
        {
          "line": 3134,
          "old_api": "ToString",
          "new_api": "at",
          "old_text": "std::make_pair(\n            absl::StrCat(ins->name(), val->index().ToString()), mem)",
          "new_text": "time_memory_usage.at(t)",
          "old_line_content": "        instruction_mem.push_back(std::make_pair(",
          "new_line_content": "    for (const auto& val : liveness_set[time_memory_usage.at(t).first]) {",
          "content_same": false
        },
        {
          "line": 3135,
          "old_api": "ToString",
          "new_api": "instruction",
          "old_text": "val->index().ToString()",
          "new_text": "val->instruction()",
          "old_line_content": "            absl::StrCat(ins->name(), val->index().ToString()), mem));",
          "new_line_content": "      const HloInstruction* ins = val->instruction();",
          "content_same": false
        },
        {
          "line": 3150,
          "old_api": "absl::StrAppend(&str, \"Top \", top_tensors, \" largest tensors:\\n\")",
          "new_api": "end",
          "old_text": "absl::StrAppend(&str, \"Top \", top_tensors, \" largest tensors:\\n\")",
          "new_text": "instruction_mem.end()",
          "old_line_content": "  absl::StrAppend(&str, \"Top \", top_tensors, \" largest tensors:\\n\");",
          "new_line_content": "  std::sort(instruction_mem.begin(), instruction_mem.end(), NameMemLarger);",
          "content_same": false
        },
        {
          "line": 3153,
          "old_api": "at",
          "new_api": "size",
          "old_text": "instruction_mem.at(i)",
          "new_text": "instruction_mem.size()",
          "old_line_content": "        &str, \"instruction name: \", instruction_mem.at(i).first,",
          "new_line_content": "  top_tensors = std::min(top_tensors, instruction_mem.size());",
          "content_same": false
        },
        {
          "line": 3154,
          "old_api": "at",
          "new_api": "absl::StrAppend(&str, \"Top \", top_tensors, \" largest tensors:\\n\")",
          "old_text": "instruction_mem.at(i)",
          "new_text": "absl::StrAppend(&str, \"Top \", top_tensors, \" largest tensors:\\n\")",
          "old_line_content": "        \" memory usage: \", instruction_mem.at(i).second / (1024 * 1024 * 1024),",
          "new_line_content": "  absl::StrAppend(&str, \"Top \", top_tensors, \" largest tensors:\\n\");",
          "content_same": false
        },
        {
          "line": 3169,
          "old_api": "sharding",
          "new_api": "has_sharding",
          "old_text": "inst->sharding()",
          "new_text": "inst->has_sharding()",
          "old_line_content": "    preserve_shardings[inst->name()] = {inst->sharding()};",
          "new_line_content": "  if (!inst->has_sharding()) {",
          "content_same": false
        },
        {
          "line": 3187,
          "old_api": "opcode",
          "new_api": "SaveShardingForInstruction",
          "old_text": "user->opcode()",
          "new_text": "SaveShardingForInstruction(preserve_shardings, inst)",
          "old_line_content": "          if (user->opcode() == HloOpcode::kCopy) {",
          "new_line_content": "        SaveShardingForInstruction(preserve_shardings, inst);",
          "content_same": false
        },
        {
          "line": 3188,
          "old_api": "SaveShardingForInstruction",
          "new_api": "users",
          "old_text": "SaveShardingForInstruction(preserve_shardings, user)",
          "new_text": "inst->users()",
          "old_line_content": "            SaveShardingForInstruction(preserve_shardings, user);",
          "new_line_content": "        for (const auto user : inst->users()) {",
          "content_same": false
        },
        {
          "line": 3202,
          "old_api": "opcode",
          "new_api": "SaveShardingForInstruction",
          "old_text": "user->opcode()",
          "new_text": "SaveShardingForInstruction(preserve_shardings, inst)",
          "old_line_content": "        if (user->opcode() == HloOpcode::kCopy) {",
          "new_line_content": "      SaveShardingForInstruction(preserve_shardings, inst);",
          "content_same": false
        },
        {
          "line": 3203,
          "old_api": "SaveShardingForInstruction",
          "new_api": "users",
          "old_text": "SaveShardingForInstruction(preserve_shardings, user)",
          "new_text": "inst->users()",
          "old_line_content": "          SaveShardingForInstruction(preserve_shardings, user);",
          "new_line_content": "      for (const auto user : inst->users()) {",
          "content_same": false
        },
        {
          "line": 3212,
          "old_api": "LOG",
          "new_api": "entry_computation",
          "old_text": "LOG(INFO)",
          "new_text": "module->entry_computation()->root_instruction()",
          "old_line_content": "    LOG(INFO) << \"User shardings that need to be kept (printing only the 1st \"",
          "new_line_content": "    auto inst = module->entry_computation()->root_instruction();",
          "content_same": false
        },
        {
          "line": 3235,
          "old_api": "has_sharding",
          "new_api": "instructions",
          "old_text": "inst->has_sharding()",
          "new_text": "computation->instructions()",
          "old_line_content": "      if (!inst->has_sharding()) {",
          "new_line_content": "    for (const auto inst : computation->instructions()) {",
          "content_same": false
        },
        {
          "line": 3236,
          "old_api": "LOG",
          "new_api": "end",
          "old_text": "LOG(FATAL)",
          "new_text": "preserve_shardings.end()",
          "old_line_content": "        LOG(FATAL) << \"User sharding is not preserved! Instruction with name \"",
          "new_line_content": "      if (preserve_shardings.find(inst->name()) == preserve_shardings.end()) {",
          "content_same": false
        },
        {
          "line": 3240,
          "old_api": "IsTuple",
          "new_api": "LOG",
          "old_text": "inst->sharding().IsTuple()",
          "new_text": "LOG(FATAL)",
          "old_line_content": "      } else if (!inst->sharding().IsTuple() &&",
          "new_line_content": "        LOG(FATAL) << \"User sharding is not preserved! Instruction with name \"",
          "content_same": false
        },
        {
          "line": 3242,
          "old_api": "ToString",
          "new_api": "name",
          "old_text": "inst->sharding().ToString()",
          "new_text": "inst->name()",
          "old_line_content": "                     inst->sharding().ToString()) {",
          "new_line_content": "                   << preserve_shardings.at(inst->name())[0].ToString()",
          "content_same": false
        },
        {
          "line": 3244,
          "old_api": "name",
          "new_api": "IsTuple",
          "old_text": "inst->name()",
          "new_text": "inst->sharding().IsTuple()",
          "old_line_content": "                   << inst->name() << \" should be: \"",
          "new_line_content": "      } else if (!inst->sharding().IsTuple() &&",
          "content_same": false
        },
        {
          "line": 3247,
          "old_api": "IsTuple",
          "new_api": "LOG",
          "old_text": "inst->sharding().IsTuple()",
          "new_text": "LOG(FATAL)",
          "old_line_content": "      } else if (inst->sharding().IsTuple()) {",
          "new_line_content": "        LOG(FATAL) << \"User sharding is not preserved! Instruction with name \"",
          "content_same": false
        },
        {
          "line": 3250,
          "old_api": "tuple_shapes_size",
          "new_api": "ToString",
          "old_text": "inst->shape().tuple_shapes_size()",
          "new_text": "inst->sharding().ToString()",
          "old_line_content": "        for (size_t i = 0; i < inst->shape().tuple_shapes_size(); i++) {",
          "new_line_content": "                   << \"\\nbut it's: \" << inst->sharding().ToString();",
          "content_same": false
        },
        {
          "line": 3251,
          "old_api": "ToString",
          "new_api": "IsTuple",
          "old_text": "preserve_shardings_tuple->at(i).ToString()",
          "new_text": "inst->sharding().IsTuple()",
          "old_line_content": "          if (preserve_shardings_tuple->at(i).ToString() !=",
          "new_line_content": "      } else if (inst->sharding().IsTuple()) {",
          "content_same": false
        },
        {
          "line": 3253,
          "old_api": "LOG",
          "new_api": "name",
          "old_text": "LOG(FATAL)",
          "new_text": "inst->name()",
          "old_line_content": "            LOG(FATAL) << \"Tuple sharding is not preserved! Instruction \"",
          "new_line_content": "            &preserve_shardings.at(inst->name());",
          "content_same": false
        },
        {
          "line": 3255,
          "old_api": "name",
          "new_api": "ToString",
          "old_text": "inst->name()",
          "new_text": "preserve_shardings_tuple->at(i).ToString()",
          "old_line_content": "                       << inst->name() << \" \" << i << \"th tuple element \"",
          "new_line_content": "          if (preserve_shardings_tuple->at(i).ToString() !=",
          "content_same": false
        },
        {
          "line": 3257,
          "old_api": "ToString",
          "new_api": "LOG",
          "old_text": "preserve_shardings_tuple->at(i).ToString()",
          "new_text": "LOG(FATAL)",
          "old_line_content": "                       << preserve_shardings_tuple->at(i).ToString()",
          "new_line_content": "            LOG(FATAL) << \"Tuple sharding is not preserved! Instruction \"",
          "content_same": false
        },
        {
          "line": 3259,
          "old_api": "tuple_elements",
          "new_api": "name",
          "old_text": "inst->sharding().tuple_elements().at(i).ToString()",
          "new_text": "inst->name()",
          "old_line_content": "                       << inst->sharding().tuple_elements().at(i).ToString();",
          "new_line_content": "                       << inst->name() << \" \" << i << \"th tuple element \"",
          "content_same": false
        },
        {
          "line": 3288,
          "old_api": "get_value_sharding",
          "new_api": "size",
          "old_text": "get_value_sharding(value)",
          "new_text": "liveness_set.size()",
          "old_line_content": "        auto this_value_sharding = get_value_sharding(value);",
          "new_line_content": "  for (size_t t = 0; t < liveness_set.size(); ++t) {",
          "content_same": false
        },
        {
          "line": 3290,
          "old_api": "end",
          "new_api": "GetBufferContainingValue",
          "old_text": "buffer_to_sharded_value_mapping.end()",
          "new_text": "alias_analysis->GetBufferContainingValue(*value)",
          "old_line_content": "        if (iter != buffer_to_sharded_value_mapping.end()) {",
          "new_line_content": "      auto buffer = alias_analysis->GetBufferContainingValue(*value);",
          "content_same": false
        },
        {
          "line": 3291,
          "old_api": "get_value_sharding",
          "new_api": "instruction",
          "old_text": "get_value_sharding(iter->second)",
          "new_text": "value->instruction()->has_sharding()",
          "old_line_content": "          auto buffer_value_sharding = get_value_sharding(iter->second);",
          "new_line_content": "      if (value->instruction()->has_sharding()) {",
          "content_same": false
        },
        {
          "line": 3295,
          "old_api": "VLOG",
          "new_api": "get_value_sharding",
          "old_text": "VLOG(1)",
          "new_text": "get_value_sharding(iter->second)",
          "old_line_content": "            VLOG(1) << \"We have a situation where two HloValues alias, but \"",
          "new_line_content": "          auto buffer_value_sharding = get_value_sharding(iter->second);",
          "content_same": false
        },
        {
          "line": 3304,
          "old_api": "id",
          "new_api": "ToShortString",
          "old_text": "buffer.id()",
          "new_text": "value->ToShortString()",
          "old_line_content": "        buffer_to_sharded_value_mapping[buffer.id()] = value;",
          "new_line_content": "                    << value->ToShortString() << \" and \"",
          "content_same": false
        },
        {
          "line": 3317,
          "old_api": "index",
          "new_api": "empty",
          "old_text": "value->index()",
          "new_text": "value->index().empty()",
          "old_line_content": "          ShapeUtil::GetSubshape(value->instruction()->shape(), value->index());",
          "new_line_content": "      if (value->instruction()->shape().IsTuple() && value->index().empty()) {",
          "content_same": false
        },
        {
          "line": 3321,
          "old_api": "end",
          "new_api": "index",
          "old_text": "buffer_to_sharded_value_mapping.end()",
          "new_text": "value->index()",
          "old_line_content": "      if (iter != buffer_to_sharded_value_mapping.end()) {",
          "new_line_content": "          ShapeUtil::GetSubshape(value->instruction()->shape(), value->index());",
          "content_same": false
        },
        {
          "line": 3322,
          "old_api": "get_value_sharding",
          "new_api": "GetBufferContainingValue",
          "old_text": "get_value_sharding(iter->second)",
          "new_text": "alias_analysis->GetBufferContainingValue(*value)",
          "old_line_content": "        optional_sharding = get_value_sharding(iter->second);",
          "new_line_content": "      auto buffer = alias_analysis->GetBufferContainingValue(*value);",
          "content_same": false
        },
        {
          "line": 3325,
          "old_api": "GetShardedInstructionSize",
          "new_api": "end",
          "old_text": "GetShardedInstructionSize(shape, num_devices, optional_sharding)",
          "new_text": "buffer_to_sharded_value_mapping.end()",
          "old_line_content": "          GetShardedInstructionSize(shape, num_devices, optional_sharding);",
          "new_line_content": "      if (iter != buffer_to_sharded_value_mapping.end()) {",
          "content_same": false
        },
        {
          "line": 3340,
          "old_api": "IsTuple",
          "new_api": "instructions",
          "old_text": "ins->shape().IsTuple()",
          "new_text": "sequence.instructions()",
          "old_line_content": "      if (ins->shape().IsTuple()) {",
          "new_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "content_same": false
        },
        {
          "line": 3343,
          "old_api": "leaves",
          "new_api": "end",
          "old_text": "output_tuple_sharding.leaves()",
          "new_text": "preserve_shardings.end()",
          "old_line_content": "        for (auto& leaf : output_tuple_sharding.leaves()) {",
          "new_line_content": "    if (preserve_shardings.find(ins->name()) != preserve_shardings.end()) {",
          "content_same": false
        },
        {
          "line": 3344,
          "old_api": "name",
          "new_api": "IsTuple",
          "old_text": "ins->name()",
          "new_text": "ins->shape().IsTuple()",
          "old_line_content": "          leaf.second = preserve_shardings.at(ins->name()).at(i++);",
          "new_line_content": "      if (ins->shape().IsTuple()) {",
          "content_same": false
        },
        {
          "line": 3383,
          "old_api": "shape",
          "new_api": "opcode",
          "old_text": "shape_inst->shape()",
          "new_text": "consumer->opcode()",
          "old_line_content": "        !DimensionsEqual(consumer->shape(), shape_inst->shape())) {",
          "new_line_content": "    if (consumer->opcode() == HloOpcode::kTuple ||",
          "content_same": false
        },
        {
          "line": 3384,
          "old_api": "insert",
          "new_api": "IsParameterConvert",
          "old_text": "boundary_set.insert(cur)",
          "new_text": "IsParameterConvert(consumer)",
          "old_line_content": "      boundary_set.insert(cur);",
          "new_line_content": "        (do_all_gather_after_backward && IsParameterConvert(consumer)) ||",
          "content_same": false
        },
        {
          "line": 3394,
          "old_api": "FindReplicateSet",
          "new_api": "insert",
          "old_text": "FindReplicateSet(consumer, alias_map, cost_graph, s_val, strategy_map,\n                       strategy, output, do_all_gather_after_backward,\n                       transpose_inst, replicated_set, boundary_set,\n                       consumer_set, visited)",
          "new_text": "replicated_set.insert(cur)",
          "old_line_content": "      FindReplicateSet(consumer, alias_map, cost_graph, s_val, strategy_map,",
          "new_line_content": "  replicated_set.insert(cur);",
          "content_same": false
        },
        {
          "line": 3405,
          "old_api": "IsAlwaysReplicated",
          "new_api": "operand_count",
          "old_text": "IsAlwaysReplicated(operand)",
          "new_text": "cur->operand_count()",
          "old_line_content": "    if (!visited.contains(operand) && !IsAlwaysReplicated(operand) &&",
          "new_line_content": "  for (size_t i = 0; i < cur->operand_count(); ++i) {",
          "content_same": false
        },
        {
          "line": 3406,
          "old_api": "GetShardingStrategy",
          "new_api": "mutable_operand",
          "old_text": "GetShardingStrategy(operand, strategy_map, cost_graph, s_val)",
          "new_text": "cur->mutable_operand(i)",
          "old_line_content": "        GetShardingStrategy(operand, strategy_map, cost_graph, s_val)",
          "new_line_content": "    HloInstruction* operand = cur->mutable_operand(i);",
          "content_same": false
        },
        {
          "line": 3409,
          "old_api": "FindReplicateSet",
          "new_api": "IsAlwaysReplicated",
          "old_text": "FindReplicateSet(operand, alias_map, cost_graph, s_val, strategy_map,\n                       strategy, output, do_all_gather_after_backward,\n                       transpose_inst, replicated_set, boundary_set,\n                       consumer_set, visited)",
          "new_text": "IsAlwaysReplicated(operand)",
          "old_line_content": "      FindReplicateSet(operand, alias_map, cost_graph, s_val, strategy_map,",
          "new_line_content": "    if (!visited.contains(operand) && !IsAlwaysReplicated(operand) &&",
          "content_same": false
        },
        {
          "line": 3430,
          "old_api": "IsCustomCallMarker",
          "new_api": "instructions",
          "old_text": "IsCustomCallMarker(output)",
          "new_text": "sequence.instructions()",
          "old_line_content": "  if (IsCustomCallMarker(output)) {",
          "new_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "content_same": false
        },
        {
          "line": 3493,
          "old_api": "insert",
          "new_api": "AllUsersAreReduce",
          "old_text": "replicated_set.insert(node)",
          "new_text": "AllUsersAreReduce(node)",
          "old_line_content": "          replicated_set.insert(node);",
          "new_line_content": "        if (AllUsersAreReduce(node)) {",
          "content_same": false
        },
        {
          "line": 3507,
          "old_api": "push_back",
          "new_api": "front",
          "old_text": "path.push_back(root)",
          "new_text": "need_all_gather.front()",
          "old_line_content": "        path.push_back(root);",
          "new_line_content": "      HloInstruction* point = need_all_gather.front();",
          "content_same": false
        },
        {
          "line": 3523,
          "old_api": "find",
          "new_api": "erase",
          "old_text": "alias_map.find(x)",
          "new_text": "boundary_set.erase(x)",
          "old_line_content": "          auto iter = alias_map.find(x);",
          "new_line_content": "          boundary_set.erase(x);",
          "content_same": false
        },
        {
          "line": 3525,
          "old_api": "insert",
          "new_api": "clear",
          "old_text": "boundary_set.insert(x)",
          "new_text": "need_all_gather.clear()",
          "old_line_content": "            boundary_set.insert(x);",
          "new_line_content": "        need_all_gather.clear();",
          "content_same": false
        },
        {
          "line": 3560,
          "old_api": "absl::c_linear_search(need_all_gather, x)",
          "new_api": "size",
          "old_text": "absl::c_linear_search(need_all_gather, x)",
          "new_text": "need_all_gather.size()",
          "old_line_content": "               << absl::c_linear_search(need_all_gather, x) << \"\\n\";",
          "new_line_content": "    VLOG(10) << \"boundary set (#incompatible: \" << need_all_gather.size()",
          "content_same": false
        },
        {
          "line": 3569,
          "old_api": "IsUndefined",
          "new_api": "size",
          "old_text": "IsUndefined(output_spec)",
          "new_text": "need_all_gather.size()",
          "old_line_content": "      if (IsUndefined(output_spec)) {",
          "new_line_content": "    if (num_replicated_parameters >= 1 && need_all_gather.size() <= 1 &&",
          "content_same": false
        },
        {
          "line": 3573,
          "old_api": "ToString",
          "new_api": "IsUndefined",
          "old_text": "output_spec.ToString()",
          "new_text": "IsUndefined(output_spec)",
          "old_line_content": "      VLOG(10) << \"SET: \" << output_spec.ToString();",
          "new_line_content": "      if (IsUndefined(output_spec)) {",
          "content_same": false
        },
        {
          "line": 3582,
          "old_api": "UseAllReduceForGradAcc",
          "new_api": "erase",
          "old_text": "UseAllReduceForGradAcc(replicated_set, inst)",
          "new_text": "replicated_set.erase(inst)",
          "old_line_content": "        UseAllReduceForGradAcc(replicated_set, inst);",
          "new_line_content": "        replicated_set.erase(inst);",
          "content_same": false
        },
        {
          "line": 3586,
          "old_api": "SetSharding",
          "new_api": "UseAllReduceForGradAcc",
          "old_text": "SetSharding(to_split, output_spec, inst, transpose_inst, modified)",
          "new_text": "UseAllReduceForGradAcc(replicated_set, inst)",
          "old_line_content": "        SetSharding(to_split, output_spec, inst, transpose_inst, modified);",
          "new_line_content": "        UseAllReduceForGradAcc(replicated_set, inst);",
          "content_same": false
        },
        {
          "line": 3596,
          "old_api": "contains",
          "new_api": "SetSharding",
          "old_text": "alias_map.contains(to_split)",
          "new_text": "SetSharding(to_split, output_spec, inst, transpose_inst, modified)",
          "old_line_content": "              alias_map.contains(to_split)) {",
          "new_line_content": "          SetSharding(to_split, output_spec, inst, transpose_inst, modified);",
          "content_same": false
        },
        {
          "line": 3605,
          "old_api": "push_back",
          "new_api": "at",
          "old_text": "insert_all_gather.push_back(to_split)",
          "new_text": "alias_map.at(to_split)",
          "old_line_content": "            insert_all_gather.push_back(to_split);",
          "new_line_content": "            SetSharding(alias_map.at(to_split), output_spec, inst,",
          "content_same": false
        },
        {
          "line": 3607,
          "old_api": "opcode",
          "new_api": "at",
          "old_text": "to_split->opcode()",
          "new_text": "alias_map.at(to_split)",
          "old_line_content": "            if (to_split->opcode() == HloOpcode::kGetTupleElement &&",
          "new_line_content": "            insert_all_gather.push_back(alias_map.at(to_split));",
          "content_same": false
        },
        {
          "line": 3609,
          "old_api": "size",
          "new_api": "push_back",
          "old_text": "to_split->users().size()",
          "new_text": "insert_all_gather.push_back(to_split)",
          "old_line_content": "                to_split->users().size() == 1 &&",
          "new_line_content": "            insert_all_gather.push_back(to_split);",
          "content_same": false
        },
        {
          "line": 3611,
          "old_api": "mutable_operand",
          "new_api": "opcode",
          "old_text": "PassThroughCustomCallMarkerOperand(\n                  to_split->mutable_operand(0), to_split)",
          "new_text": "to_split->opcode()",
          "old_line_content": "              insert_all_gather.push_back(PassThroughCustomCallMarkerOperand(",
          "new_line_content": "            if (to_split->opcode() == HloOpcode::kGetTupleElement &&",
          "content_same": false
        },
        {
          "line": 3612,
          "old_api": "mutable_operand",
          "new_api": "operand",
          "old_text": "to_split->mutable_operand(0)",
          "new_text": "to_split->operand(0)",
          "old_line_content": "                  to_split->mutable_operand(0), to_split));",
          "new_line_content": "                IsCustomCallMarker(to_split->operand(0)) &&",
          "content_same": false
        },
        {
          "line": 3626,
          "old_api": "contains",
          "new_api": "SetSharding",
          "old_text": "alias_map.contains(to_split)",
          "new_text": "SetSharding(to_split, output_spec, inst, transpose_inst, modified)",
          "old_line_content": "              alias_map.contains(to_split)) {",
          "new_line_content": "          SetSharding(to_split, output_spec, inst, transpose_inst, modified);",
          "content_same": false
        },
        {
          "line": 3628,
          "old_api": "at",
          "new_api": "size",
          "old_text": "alias_map.at(to_split)",
          "new_text": "to_split->users().size()",
          "old_line_content": "            HloInstruction* param = alias_map.at(to_split);",
          "new_line_content": "          if (to_split->users().size() == 1 &&",
          "content_same": false
        },
        {
          "line": 3637,
          "old_api": "front",
          "new_api": "size",
          "old_text": "cur->users().front()",
          "new_text": "cur->users().size()",
          "old_line_content": "              cur = cur->users().front();",
          "new_line_content": "            while (cur->users().size() == 1) {",
          "content_same": false
        },
        {
          "line": 3639,
          "old_api": "SetSharding",
          "new_api": "IsArray",
          "old_text": "SetSharding(cur, output_spec, inst, transpose_inst, modified)",
          "new_text": "cur->shape().IsArray()",
          "old_line_content": "            SetSharding(cur, output_spec, inst, transpose_inst, modified);",
          "new_line_content": "              CHECK(cur->shape().IsArray());",
          "content_same": false
        },
        {
          "line": 3641,
          "old_api": "empty",
          "new_api": "front",
          "old_text": "cur->users().empty()",
          "new_text": "cur->users().front()",
          "old_line_content": "            CHECK(!cur->users().empty());",
          "new_line_content": "              cur = cur->users().front();",
          "content_same": false
        },
        {
          "line": 3651,
          "old_api": "opcode",
          "new_api": "find",
          "old_text": "x->opcode()",
          "new_text": "depth_map.find(x)",
          "old_line_content": "              if (x->opcode() != HloOpcode::kConvolution &&",
          "new_line_content": "              auto iter = depth_map.find(x);",
          "content_same": false
        },
        {
          "line": 3652,
          "old_api": "opcode",
          "new_api": "end",
          "old_text": "x->opcode()",
          "new_text": "depth_map.end()",
          "old_line_content": "                  x->opcode() != HloOpcode::kDot) {",
          "new_line_content": "              if (iter == depth_map.end()) {",
          "content_same": false
        },
        {
          "line": 3669,
          "old_api": "ReplaceOperand",
          "new_api": "shape",
          "old_text": "ReplaceOperand(first_user, cur, identity)",
          "new_text": "cur->shape()",
          "old_line_content": "              ReplaceOperand(first_user, cur, identity);",
          "new_line_content": "                  HloInstruction::CreateCustomCall(cur->shape(), {cur},",
          "content_same": false
        },
        {
          "line": 3687,
          "old_api": "ReplaceAllUsesWith",
          "new_api": "shape",
          "old_text": "inst->ReplaceAllUsesWith(replace_with)",
          "new_text": "inst->shape()",
          "old_line_content": "    TF_CHECK_OK(inst->ReplaceAllUsesWith(replace_with));",
          "new_line_content": "        HloInstruction::CreateReshape(inst->shape(), inst));",
          "content_same": false
        },
        {
          "line": 3700,
          "old_api": "dimensions",
          "new_api": "num_elements",
          "old_text": "device_mesh.dimensions()",
          "new_text": "device_mesh.num_elements()",
          "old_line_content": "  for (int dim : device_mesh.dimensions()) {",
          "new_line_content": "  int64_t num_devices = device_mesh.num_elements();",
          "content_same": false
        },
        {
          "line": 3711,
          "old_api": "set_sharding",
          "new_api": "entry_computation",
          "old_text": "inst->set_sharding(output_spec)",
          "new_text": "module->entry_computation()",
          "old_line_content": "      inst->set_sharding(output_spec);",
          "new_line_content": "  HloComputation* entry_computation = module->entry_computation();",
          "content_same": false
        },
        {
          "line": 3715,
          "old_api": "rank",
          "new_api": "set_sharding",
          "old_text": "inst->shape().rank()",
          "new_text": "inst->set_sharding(output_spec)",
          "old_line_content": "        for (int64_t i = 0; i < inst->shape().rank(); ++i) {",
          "new_line_content": "      inst->set_sharding(output_spec);",
          "content_same": false
        },
        {
          "line": 3719,
          "old_api": "Argsort",
          "new_api": "rank",
          "old_text": "Argsort(lengths)",
          "new_text": "inst->shape().rank()",
          "old_line_content": "        std::vector<int> indices = Argsort(lengths);",
          "new_line_content": "        for (int64_t i = 0; i < inst->shape().rank(); ++i) {",
          "content_same": false
        },
        {
          "line": 3720,
          "old_api": "size",
          "new_api": "dimensions",
          "old_text": "indices.size()",
          "new_text": "inst->shape().dimensions(i)",
          "old_line_content": "        int common_dims = std::min(mesh_nn_dims, indices.size());",
          "new_line_content": "          lengths.push_back(inst->shape().dimensions(i));",
          "content_same": false
        },
        {
          "line": 3745,
          "old_api": "rank",
          "new_api": "shape",
          "old_text": "inst->shape().rank()",
          "new_text": "inst->shape()",
          "old_line_content": "        if (inst->shape().rank() > 0 &&",
          "new_line_content": "                Tile(inst->shape(), {dim0, dim1}, {0, 1}, device_mesh);",
          "content_same": false
        },
        {
          "line": 3750,
          "old_api": "rank",
          "new_api": "dimensions",
          "old_text": "inst->shape().rank()",
          "new_text": "inst->shape().dimensions(0)",
          "old_line_content": "        int64_t last_dim = inst->shape().rank() - 1;",
          "new_line_content": "            inst->shape().dimensions(0) % num_devices == 0) {",
          "content_same": false
        },
        {
          "line": 3751,
          "old_api": "rank",
          "new_api": "shape",
          "old_text": "inst->shape().rank()",
          "new_text": "inst->shape()",
          "old_line_content": "        if (inst->shape().rank() > 0 &&",
          "new_line_content": "          output_spec = Tile(inst->shape(), {0}, {0}, device_mesh_1d);",
          "content_same": false
        },
        {
          "line": 3756,
          "old_api": "LOG",
          "new_api": "dimensions",
          "old_text": "LOG(FATAL)",
          "new_text": "inst->shape().dimensions(last_dim)",
          "old_line_content": "        LOG(FATAL) << \"Invalid heuristic: \" << heuristic;",
          "new_line_content": "            inst->shape().dimensions(last_dim) % num_devices == 0) {",
          "content_same": false
        },
        {
          "line": 3763,
          "old_api": "operand",
          "new_api": "set_sharding",
          "old_text": "inst->operand(0)",
          "new_text": "inst->set_sharding(output_spec)",
          "old_line_content": "      const HloInstruction* lhs = inst->operand(0);",
          "new_line_content": "      inst->set_sharding(output_spec);",
          "content_same": false
        },
        {
          "line": 3769,
          "old_api": "std::tie(lhs_space_dims, rhs_space_dims)",
          "new_api": "dot_dimension_numbers",
          "old_text": "std::tie(lhs_space_dims, rhs_space_dims)",
          "new_text": "inst->dot_dimension_numbers()",
          "old_line_content": "      std::tie(lhs_space_dims, rhs_space_dims) =",
          "new_line_content": "      const DotDimensionNumbers& dot_dnums = inst->dot_dimension_numbers();",
          "content_same": false
        },
        {
          "line": 3786,
          "old_api": "get_flattened_shardings",
          "new_api": "operand_count",
          "old_text": "get_flattened_shardings(operand)",
          "new_text": "cur->operand_count()",
          "old_line_content": "        get_flattened_shardings(operand);",
          "new_line_content": "    for (int64_t i = 0; i < cur->operand_count(); ++i) {",
          "content_same": false
        },
        {
          "line": 3789,
          "old_api": "at",
          "new_api": "IsTuple",
          "old_text": "alias_map.at(operand)",
          "new_text": "operand->shape().IsTuple()",
          "old_line_content": "          operand = alias_map.at(operand);",
          "new_line_content": "      if (operand->shape().IsTuple()) {",
          "content_same": false
        },
        {
          "line": 3792,
          "old_api": "HloSharding::Replicate()",
          "new_api": "contains",
          "old_text": "HloSharding::Replicate()",
          "new_text": "alias_map.contains(operand)",
          "old_line_content": "          operand->set_sharding(HloSharding::Replicate());",
          "new_line_content": "        if (alias_map.contains(operand)) {",
          "content_same": false
        },
        {
          "line": 3795,
          "old_api": "sharding",
          "new_api": "has_sharding",
          "old_text": "operand->sharding()",
          "new_text": "operand->has_sharding()",
          "old_line_content": "        flattened_shardings.push_back(operand->sharding());",
          "new_line_content": "        if (!operand->has_sharding()) {",
          "content_same": false
        },
        {
          "line": 3799,
          "old_api": "get_flattened_shardings",
          "new_api": "sharding",
          "old_text": "get_flattened_shardings(output)",
          "new_text": "operand->sharding()",
          "old_line_content": "  get_flattened_shardings(output);",
          "new_line_content": "        flattened_shardings.push_back(operand->sharding());",
          "content_same": false
        },
        {
          "line": 3805,
          "old_api": "HloSharding::Tuple(tuple_sharding)",
          "new_api": "leaves",
          "old_text": "HloSharding::Tuple(tuple_sharding)",
          "new_text": "tuple_sharding.leaves()",
          "old_line_content": "  output->set_sharding(HloSharding::Tuple(tuple_sharding));",
          "new_line_content": "  for (auto& leaf : tuple_sharding.leaves()) {",
          "content_same": false
        },
        {
          "line": 3820,
          "old_api": "absl::InvalidArgumentError(\n        \"The length of batch dimension is \"\n        \"not divisible by the number of devices\")",
          "new_api": "GetBatchDimMapKey",
          "old_text": "absl::InvalidArgumentError(\n        \"The length of batch dimension is \"\n        \"not divisible by the number of devices\")",
          "new_text": "GetBatchDimMapKey(ins)",
          "old_line_content": "    return absl::InvalidArgumentError(",
          "new_line_content": "  int batch_dim = batch_map.at(GetBatchDimMapKey(ins));",
          "content_same": false
        },
        {
          "line": 3834,
          "old_api": "std::move(stra)",
          "new_api": "dim",
          "old_text": "std::move(stra)",
          "new_text": "device_mesh.dim(mesh_dim)",
          "old_line_content": "        new_leaf_vector.push_back(std::move(stra));",
          "new_line_content": "    if (device_mesh.dim(mesh_dim) > 1) {",
          "content_same": false
        },
        {
          "line": 3844,
          "old_api": "empty",
          "new_api": "std::move(stra)",
          "old_text": "new_leaf_vector.empty()",
          "new_text": "std::move(stra)",
          "old_line_content": "  CHECK(!new_leaf_vector.empty())",
          "new_line_content": "        new_leaf_vector.push_back(std::move(stra));",
          "content_same": false
        },
        {
          "line": 3848,
          "old_api": "OkStatus",
          "new_api": "empty",
          "old_text": "OkStatus()",
          "new_text": "new_leaf_vector.empty()",
          "old_line_content": "  return OkStatus();",
          "new_line_content": "  CHECK(!new_leaf_vector.empty())",
          "content_same": false
        },
        {
          "line": 3862,
          "old_api": "absl::StartsWith(strategy.name, \"SR = SS x SR\")",
          "new_api": "opcode",
          "old_text": "absl::StartsWith(strategy.name, \"SR = SS x SR\")",
          "new_text": "ins->opcode()",
          "old_line_content": "    if (absl::StartsWith(strategy.name, \"SR = SS x SR\") ||",
          "new_line_content": "  if (ins->opcode() == HloOpcode::kDot) {",
          "content_same": false
        },
        {
          "line": 3863,
          "old_api": "absl::StartsWith(strategy.name, \"RS = RS x SS\")",
          "new_api": "dot_dimension_numbers",
          "old_text": "absl::StartsWith(strategy.name, \"RS = RS x SS\")",
          "new_text": "ins->dot_dimension_numbers()",
          "old_line_content": "        absl::StartsWith(strategy.name, \"RS = RS x SS\")) {",
          "new_line_content": "    const DotDimensionNumbers& dot_dnums = ins->dot_dimension_numbers();",
          "content_same": false
        },
        {
          "line": 3867,
          "old_api": "IsDivisible",
          "new_api": "absl::StartsWith(strategy.name, \"RS = RS x SS\")",
          "old_text": "IsDivisible(ins, device_mesh, {space_base_dim, space_base_dim + 1},\n                       {mesh_dim0, mesh_dim1})",
          "new_text": "absl::StartsWith(strategy.name, \"RS = RS x SS\")",
          "old_line_content": "      if (!IsDivisible(ins, device_mesh, {space_base_dim, space_base_dim + 1},",
          "new_line_content": "        absl::StartsWith(strategy.name, \"RS = RS x SS\")) {",
          "content_same": false
        },
        {
          "line": 3882,
          "old_api": "IsDivisible",
          "new_api": "absl::StartsWith(strategy.name, \"SbR = SbSk x SbSk\")",
          "old_text": "IsDivisible(ins, device_mesh, {0, space_base_dim},\n                       {mesh_dim0, mesh_dim1})",
          "new_text": "absl::StartsWith(strategy.name, \"SbR = SbSk x SbSk\")",
          "old_line_content": "      if (!IsDivisible(ins, device_mesh, {0, space_base_dim},",
          "new_line_content": "    if (absl::StartsWith(strategy.name, \"SbR = SbSk x SbSk\")) {",
          "content_same": false
        },
        {
          "line": 3894,
          "old_api": "absl::StrContains(strategy.name, \"{0}\")",
          "new_api": "shape",
          "old_text": "absl::StrContains(strategy.name, \"{0}\")",
          "new_text": "ins->shape()",
          "old_line_content": "      int mesh_dim = absl::StrContains(strategy.name, \"{0}\") ? 0 : 1;",
          "new_line_content": "      return Tile(ins->shape(), {0, space_base_dim}, {mesh_dim0, mesh_dim1},",
          "content_same": false
        },
        {
          "line": 3897,
          "old_api": "Undefined",
          "new_api": "absl::StartsWith(strategy.name, \"RR = RS x SR\")",
          "old_text": "Undefined()",
          "new_text": "absl::StartsWith(strategy.name, \"RR = RS x SR\")",
          "old_line_content": "        return Undefined();",
          "new_line_content": "    if (absl::StartsWith(strategy.name, \"RR = RS x SR\")) {",
          "content_same": false
        },
        {
          "line": 3900,
          "old_api": "shape",
          "new_api": "IsDivisible",
          "old_text": "ins->shape()",
          "new_text": "IsDivisible(ins, device_mesh, {space_base_dim}, {mesh_dim})",
          "old_line_content": "      return Tile(ins->shape(), {space_base_dim}, {mesh_dim}, device_mesh);",
          "new_line_content": "      if (!IsDivisible(ins, device_mesh, {space_base_dim}, {mesh_dim})) {",
          "content_same": false
        },
        {
          "line": 3906,
          "old_api": "Undefined",
          "new_api": "absl::StartsWith(strategy.name, \"R = Sk x Sk\")",
          "old_text": "Undefined()",
          "new_text": "absl::StartsWith(strategy.name, \"R = Sk x Sk\")",
          "old_line_content": "        return Undefined();",
          "new_line_content": "    if (absl::StartsWith(strategy.name, \"R = Sk x Sk\")) {",
          "content_same": false
        },
        {
          "line": 3909,
          "old_api": "shape",
          "new_api": "IsDivisible",
          "old_text": "ins->shape()",
          "new_text": "IsDivisible(ins, device_mesh_1d, {space_base_dim}, {mesh_dim})",
          "old_line_content": "      return Tile(ins->shape(), {space_base_dim}, {mesh_dim}, device_mesh_1d);",
          "new_line_content": "      if (!IsDivisible(ins, device_mesh_1d, {space_base_dim}, {mesh_dim})) {",
          "content_same": false
        },
        {
          "line": 3913,
          "old_api": "convolution_dimension_numbers",
          "new_api": "shape",
          "old_text": "ins->convolution_dimension_numbers()",
          "new_text": "ins->shape()",
          "old_line_content": "        ins->convolution_dimension_numbers();",
          "new_line_content": "      return Tile(ins->shape(), {space_base_dim}, {mesh_dim}, device_mesh_1d);",
          "content_same": false
        },
        {
          "line": 3915,
          "old_api": "output_feature_dimension",
          "new_api": "opcode",
          "old_text": "conv_dnums.output_feature_dimension()",
          "new_text": "ins->opcode()",
          "old_line_content": "    int out_out_channel_dim = conv_dnums.output_feature_dimension();",
          "new_line_content": "  } else if (ins->opcode() == HloOpcode::kConvolution) {",
          "content_same": false
        },
        {
          "line": 3917,
          "old_api": "absl::StartsWith(strategy.name, \"SR = SS x SR\")",
          "new_api": "convolution_dimension_numbers",
          "old_text": "absl::StartsWith(strategy.name, \"SR = SS x SR\")",
          "new_text": "ins->convolution_dimension_numbers()",
          "old_line_content": "    if (absl::StartsWith(strategy.name, \"SR = SS x SR\") ||",
          "new_line_content": "        ins->convolution_dimension_numbers();",
          "content_same": false
        },
        {
          "line": 3918,
          "old_api": "absl::StartsWith(strategy.name, \"RS = RS x SS\")",
          "new_api": "output_batch_dimension",
          "old_text": "absl::StartsWith(strategy.name, \"RS = RS x SS\")",
          "new_text": "conv_dnums.output_batch_dimension()",
          "old_line_content": "        absl::StartsWith(strategy.name, \"RS = RS x SS\")) {",
          "new_line_content": "    int out_batch_dim = conv_dnums.output_batch_dimension();",
          "content_same": false
        },
        {
          "line": 3922,
          "old_api": "IsDivisible",
          "new_api": "absl::StartsWith(strategy.name, \"RS = RS x SS\")",
          "old_text": "IsDivisible(ins, device_mesh, {out_batch_dim, out_out_channel_dim},\n                       {mesh_dim0, mesh_dim1})",
          "new_text": "absl::StartsWith(strategy.name, \"RS = RS x SS\")",
          "old_line_content": "      if (!IsDivisible(ins, device_mesh, {out_batch_dim, out_out_channel_dim},",
          "new_line_content": "        absl::StartsWith(strategy.name, \"RS = RS x SS\")) {",
          "content_same": false
        },
        {
          "line": 3924,
          "old_api": "Undefined",
          "new_api": "ParseMeshDims",
          "old_text": "Undefined()",
          "new_text": "ParseMeshDims(strategy.name)",
          "old_line_content": "        return Undefined();",
          "new_line_content": "      std::tie(mesh_dim0, mesh_dim1) = ParseMeshDims(strategy.name);",
          "content_same": false
        },
        {
          "line": 3934,
          "old_api": "Undefined",
          "new_api": "absl::StartsWith(strategy.name, \"R = Sk x Sk\")",
          "old_text": "Undefined()",
          "new_text": "absl::StartsWith(strategy.name, \"R = Sk x Sk\")",
          "old_line_content": "        return Undefined();",
          "new_line_content": "    if (absl::StartsWith(strategy.name, \"R = Sk x Sk\")) {",
          "content_same": false
        },
        {
          "line": 3937,
          "old_api": "shape",
          "new_api": "IsDivisible",
          "old_text": "ins->shape()",
          "new_text": "IsDivisible(ins, device_mesh_1d, {out_batch_dim}, {mesh_dim})",
          "old_line_content": "      return Tile(ins->shape(), {out_batch_dim}, {mesh_dim}, device_mesh_1d);",
          "new_line_content": "      if (!IsDivisible(ins, device_mesh_1d, {out_batch_dim}, {mesh_dim})) {",
          "content_same": false
        },
        {
          "line": 3941,
          "old_api": "rank",
          "new_api": "shape",
          "old_text": "ins->shape().rank()",
          "new_text": "ins->shape()",
          "old_line_content": "    CHECK_EQ(ins->shape().rank(), 1);",
          "new_line_content": "      return Tile(ins->shape(), {out_batch_dim}, {mesh_dim}, device_mesh_1d);",
          "content_same": false
        },
        {
          "line": 3956,
          "old_api": "shape",
          "new_api": "IsDivisible",
          "old_text": "ins->shape()",
          "new_text": "IsDivisible(ins, device_mesh_1d, {0}, {mesh_dim})",
          "old_line_content": "        return Tile(ins->shape(), {0}, {mesh_dim}, device_mesh_1d);",
          "new_line_content": "        if (!IsDivisible(ins, device_mesh_1d, {0}, {mesh_dim})) {",
          "content_same": false
        },
        {
          "line": 3962,
          "old_api": "shape",
          "new_api": "IsDivisible",
          "old_text": "ins->shape()",
          "new_text": "IsDivisible(ins, device_mesh, {0}, {mesh_dim})",
          "old_line_content": "      return Tile(ins->shape(), {0}, {mesh_dim}, device_mesh);",
          "new_line_content": "      if (!IsDivisible(ins, device_mesh, {0}, {mesh_dim})) {",
          "content_same": false
        },
        {
          "line": 3968,
          "old_api": "tile_assignment",
          "new_api": "IsDivisible",
          "old_text": "strategy.output_sharding.tile_assignment()",
          "new_text": "IsDivisible(ins, device_mesh_1d, {0}, {0})",
          "old_line_content": "    Array<int64_t> tile_assignment = strategy.output_sharding.tile_assignment();",
          "new_line_content": "    if (!IsDivisible(ins, device_mesh_1d, {0}, {0})) {",
          "content_same": false
        },
        {
          "line": 3969,
          "old_api": "Reshape",
          "new_api": "Undefined",
          "old_text": "tile_assignment.Reshape({cluster_env.total_devices_})",
          "new_text": "Undefined()",
          "old_line_content": "    tile_assignment.Reshape({cluster_env.total_devices_});",
          "new_line_content": "      return Undefined();",
          "content_same": false
        },
        {
          "line": 3973,
          "old_api": "ToString",
          "new_api": "Reshape",
          "old_text": "ins->ToString()",
          "new_text": "tile_assignment.Reshape({cluster_env.total_devices_})",
          "old_line_content": "    LOG(FATAL) << \"Invalid instruction: \" << ins->ToString();",
          "new_line_content": "    tile_assignment.Reshape({cluster_env.total_devices_});",
          "content_same": false
        },
        {
          "line": 3995,
          "old_api": "rank",
          "new_api": "contains",
          "old_text": "inst->shape().rank()",
          "new_text": "modified.contains(inst)",
          "old_line_content": "  if (inst->opcode() == HloOpcode::kReduce && inst->shape().rank() == 1) {",
          "new_line_content": "  if (modified.contains(inst)) {",
          "content_same": false
        },
        {
          "line": 3999,
          "old_api": "operand",
          "new_api": "rank",
          "old_text": "inst->operand(0)",
          "new_text": "inst->shape().rank()",
          "old_line_content": "    if (GetShardingStrategy(inst->operand(0), strategy_map, cost_graph, s_val)",
          "new_line_content": "  if (inst->opcode() == HloOpcode::kReduce && inst->shape().rank() == 1) {",
          "content_same": false
        },
        {
          "line": 4030,
          "old_api": "IsEntryComputation",
          "new_api": "VLOG",
          "old_text": "computation->IsEntryComputation()",
          "new_text": "VLOG(0)",
          "old_line_content": "    bool is_entry_computation = computation->IsEntryComputation();",
          "new_line_content": "  VLOG(0) << \"Removing user sharding annotations.\";",
          "content_same": false
        },
        {
          "line": 4043,
          "old_api": "opcode",
          "new_api": "IsRoot",
          "old_text": "ins->opcode()",
          "new_text": "ins->IsRoot()",
          "old_line_content": "      if (ins->opcode() == HloOpcode::kCopy &&",
          "new_line_content": "           (ins->opcode() == HloOpcode::kParameter || ins->IsRoot()))) {",
          "content_same": false
        },
        {
          "line": 4044,
          "old_api": "end",
          "new_api": "insert",
          "old_text": "keep_inst.end()",
          "new_text": "keep_inst.insert(ins)",
          "old_line_content": "          keep_inst.find(ins->operand(0)) != keep_inst.end()) {",
          "new_line_content": "        keep_inst.insert(ins);",
          "content_same": false
        },
        {
          "line": 4047,
          "old_api": "has_sharding",
          "new_api": "opcode",
          "old_text": "ins->has_sharding()",
          "new_text": "ins->opcode()",
          "old_line_content": "      if (ins->has_sharding()) {",
          "new_line_content": "      if (ins->opcode() == HloOpcode::kCopy &&",
          "content_same": false
        },
        {
          "line": 4070,
          "old_api": "parameter_count",
          "new_api": "entry_computation_layout",
          "old_text": "entry_computation_layout.parameter_count()",
          "new_text": "module->config().entry_computation_layout()",
          "old_line_content": "  CHECK_NE(entry_computation_layout.parameter_count(), 0);",
          "new_line_content": "      module->config().entry_computation_layout();",
          "content_same": false
        },
        {
          "line": 4071,
          "old_api": "parameter_count",
          "new_api": "mutable_result_layout",
          "old_text": "entry_computation_layout.parameter_count()",
          "new_text": "TF_RETURN_IF_ERROR(\n      entry_computation_layout.mutable_result_layout()->CopyLayoutFromShape(\n          result_shape))",
          "old_line_content": "  CHECK_EQ(argument_shapes.size(), entry_computation_layout.parameter_count());",
          "new_line_content": "  TF_RETURN_IF_ERROR(",
          "content_same": false
        },
        {
          "line": 4072,
          "old_api": "parameter_count",
          "new_api": "mutable_result_layout",
          "old_text": "entry_computation_layout.parameter_count()",
          "new_text": "entry_computation_layout.mutable_result_layout()->CopyLayoutFromShape(\n          result_shape)",
          "old_line_content": "  for (int32_t i = 0; i < entry_computation_layout.parameter_count(); i++) {",
          "new_line_content": "      entry_computation_layout.mutable_result_layout()->CopyLayoutFromShape(",
          "content_same": false
        },
        {
          "line": 4074,
          "old_api": "at",
          "new_api": "parameter_count",
          "old_text": "argument_shapes.at(i)",
          "new_text": "entry_computation_layout.parameter_count()",
          "old_line_content": "                           ->CopyLayoutFromShape(argument_shapes.at(i)));",
          "new_line_content": "  CHECK_NE(entry_computation_layout.parameter_count(), 0);",
          "content_same": false
        },
        {
          "line": 4076,
          "old_api": "mutable_entry_computation_layout",
          "new_api": "parameter_count",
          "old_text": "module->config().mutable_entry_computation_layout()",
          "new_text": "entry_computation_layout.parameter_count()",
          "old_line_content": "  *module->config().mutable_entry_computation_layout() =",
          "new_line_content": "  for (int32_t i = 0; i < entry_computation_layout.parameter_count(); i++) {",
          "content_same": false
        },
        {
          "line": 4078,
          "old_api": "OkStatus",
          "new_api": "at",
          "old_text": "OkStatus()",
          "new_text": "argument_shapes.at(i)",
          "old_line_content": "  return OkStatus();",
          "new_line_content": "                           ->CopyLayoutFromShape(argument_shapes.at(i)));",
          "content_same": false
        },
        {
          "line": 4150,
          "old_api": "ok",
          "new_api": "ProcessShardingInstruction",
          "old_text": "status_or_changed.ok()",
          "new_text": "ProcessShardingInstruction(\n      module, execution_threads, /*replace_sharding_with_copy=*/true,\n      &unspecified_dims, /*saved_root_shardings=*/nullptr,\n      /*saved_parameter_shardings=*/nullptr)",
          "old_line_content": "  if (!status_or_changed.ok()) {",
          "new_line_content": "  auto status_or_changed = ProcessShardingInstruction(",
          "content_same": false
        },
        {
          "line": 4155,
          "old_api": "VLOG",
          "new_api": "status",
          "old_text": "VLOG(3)",
          "new_text": "status_or_changed.status()",
          "old_line_content": "    VLOG(3) << \"CustomCalls with custom_call_target=Sharding are removed and \"",
          "new_line_content": "    return status_or_changed.status();",
          "content_same": false
        },
        {
          "line": 4174,
          "old_api": "value",
          "new_api": "RemoveShardingAnnotation",
          "old_text": "status_or_changed.value()",
          "new_text": "RemoveShardingAnnotation(module, execution_threads)",
          "old_line_content": "    if (status_or_changed.value()) {",
          "new_line_content": "        RemoveShardingAnnotation(module, execution_threads);",
          "content_same": false
        },
        {
          "line": 4176,
          "old_api": "VLOG",
          "new_api": "status",
          "old_text": "VLOG(3)",
          "new_text": "status_or_changed.status()",
          "old_line_content": "      VLOG(3) << \"XLA sharding annotations are removed.\";",
          "new_line_content": "      return status_or_changed.status();",
          "content_same": false
        },
        {
          "line": 4178,
          "old_api": "VLOG",
          "new_api": "value",
          "old_text": "VLOG(3)",
          "new_text": "status_or_changed.value()",
          "old_line_content": "      VLOG(3) << \"This workload does not have XLA sharding annotations.\";",
          "new_line_content": "    if (status_or_changed.value()) {",
          "content_same": false
        },
        {
          "line": 4198,
          "old_api": "HloLiveRange::Run(schedule, *alias_analysis, entry_computation)",
          "new_api": "spmd::BuildAliasMap(module)",
          "old_text": "HloLiveRange::Run(schedule, *alias_analysis, entry_computation)",
          "new_text": "spmd::BuildAliasMap(module)",
          "old_line_content": "      HloLiveRange::Run(schedule, *alias_analysis, entry_computation));",
          "new_line_content": "  spmd::AliasMap alias_map = spmd::BuildAliasMap(module);",
          "content_same": false
        },
        {
          "line": 4200,
          "old_api": "buffer_live_ranges",
          "new_api": "TF_ASSIGN_OR_RETURN",
          "old_text": "hlo_live_range->buffer_live_ranges()",
          "new_text": "TF_ASSIGN_OR_RETURN(\n      std::unique_ptr<HloLiveRange> hlo_live_range,\n      HloLiveRange::Run(schedule, *alias_analysis, entry_computation))",
          "old_line_content": "      buffer_live_ranges = hlo_live_range->buffer_live_ranges();",
          "new_line_content": "  TF_ASSIGN_OR_RETURN(",
          "content_same": false
        },
        {
          "line": 4204,
          "old_api": "push_back",
          "new_api": "buffer_live_ranges",
          "old_text": "liveness_set[i].push_back(iter.first)",
          "new_text": "hlo_live_range->buffer_live_ranges()",
          "old_line_content": "      liveness_set[i].push_back(iter.first);",
          "new_line_content": "      buffer_live_ranges = hlo_live_range->buffer_live_ranges();",
          "content_same": false
        },
        {
          "line": 4208,
          "old_api": "spmd::PrintLivenessSet(liveness_set)",
          "new_api": "push_back",
          "old_text": "spmd::PrintLivenessSet(liveness_set)",
          "new_text": "liveness_set[i].push_back(iter.first)",
          "old_line_content": "  VLOG(10) << spmd::PrintLivenessSet(liveness_set);",
          "new_line_content": "      liveness_set[i].push_back(iter.first);",
          "content_same": false
        },
        {
          "line": 4211,
          "old_api": "flattened_instruction_sequence",
          "new_api": "ToString",
          "old_text": "hlo_live_range->flattened_instruction_sequence()",
          "new_text": "hlo_live_range->ToString()",
          "old_line_content": "      hlo_live_range->flattened_instruction_sequence();",
          "new_line_content": "  VLOG(10) << hlo_live_range->ToString();",
          "content_same": false
        },
        {
          "line": 4238,
          "old_api": "spmd::ToString(mesh_shape)",
          "new_api": "size",
          "old_text": "spmd::ToString(mesh_shape)",
          "new_text": "partial_mesh_shapes.size()",
          "old_line_content": "              << spmd::ToString(mesh_shape);",
          "new_line_content": "  for (size_t mesh_idx = 0; mesh_idx < partial_mesh_shapes.size(); ++mesh_idx) {",
          "content_same": false
        },
        {
          "line": 4249,
          "old_api": "ok",
          "new_api": "size",
          "old_text": "changed_or.ok()",
          "new_text": "partial_mesh_shapes.size()",
          "old_line_content": "      if (changed_or.ok()) {",
          "new_line_content": "    if (mesh_idx != partial_mesh_shapes.size() - 1) {",
          "content_same": false
        },
        {
          "line": 4250,
          "old_api": "LOG",
          "new_api": "instructions",
          "old_text": "LOG(INFO)",
          "new_text": "spmd::AdjustShardingsWithPartialMeshShape(\n          sequence.instructions(), mesh_shape, total_devices,\n          /* crash_on_error */ !option_.try_multiple_mesh_shapes)",
          "old_line_content": "        LOG(INFO)",
          "new_line_content": "      auto changed_or = spmd::AdjustShardingsWithPartialMeshShape(",
          "content_same": false
        },
        {
          "line": 4254,
          "old_api": "status",
          "new_api": "LOG",
          "old_text": "changed_or.status()",
          "new_text": "LOG(INFO)",
          "old_line_content": "        return changed_or.status();",
          "new_line_content": "        LOG(INFO)",
          "content_same": false
        },
        {
          "line": 4258,
          "old_api": "end",
          "new_api": "status",
          "old_text": "device_mesh_ids.end()",
          "new_text": "changed_or.status()",
          "old_line_content": "    std::iota(device_mesh_ids.begin(), device_mesh_ids.end(), 0);",
          "new_line_content": "        return changed_or.status();",
          "content_same": false
        },
        {
          "line": 4274,
          "old_api": "LOG",
          "new_api": "num_elements",
          "old_text": "LOG(INFO)",
          "new_text": "device_mesh.num_elements()",
          "old_line_content": "    LOG(INFO) << \"Memory consumption lower bound is \" << memory_lower_bound_gb",
          "new_line_content": "        device_mesh.num_elements());",
          "content_same": false
        },
        {
          "line": 4297,
          "old_api": "empty",
          "new_api": "LOG",
          "old_text": "solver_option.force_simple_heuristic.empty()",
          "new_text": "LOG(INFO)",
          "old_line_content": "    if (!solver_option.force_simple_heuristic.empty()) {",
          "new_line_content": "      LOG(INFO) << \"Setting option.memory_budget_per_device to \"",
          "content_same": false
        },
        {
          "line": 4323,
          "old_api": "spmd::BuildAliasSet(module, strategy_map)",
          "new_api": "BuildStrategyAndCost",
          "old_text": "spmd::BuildAliasSet(module, strategy_map)",
          "new_text": "BuildStrategyAndCost(sequence, module, instruction_execution_counts,\n                             ins_depth_map, batch_dim_map, alias_map,\n                             cluster_env, solver_option, *call_graph,\n                             option_.try_multiple_mesh_shapes)",
          "old_line_content": "    spmd::AliasSet alias_set = spmd::BuildAliasSet(module, strategy_map);",
          "new_line_content": "        BuildStrategyAndCost(sequence, module, instruction_execution_counts,",
          "content_same": false
        },
        {
          "line": 4329,
          "old_api": "Simplify",
          "new_api": "PrintStrategyMap",
          "old_text": "cost_graph.Simplify(option_.simplify_graph)",
          "new_text": "PrintStrategyMap(strategy_map, sequence)",
          "old_line_content": "    cost_graph.Simplify(option_.simplify_graph);",
          "new_line_content": "    XLA_VLOG_LINES(8, PrintStrategyMap(strategy_map, sequence));",
          "content_same": false
        },
        {
          "line": 4346,
          "old_api": "std::tie(s_val, e_val, objective)",
          "new_api": "ok",
          "old_text": "std::tie(s_val, e_val, objective)",
          "new_text": "solver_result.status.ok()",
          "old_line_content": "        std::tie(s_val, e_val, objective) = solution;",
          "new_line_content": "      } else if (!solver_result.status.ok()) {",
          "content_same": false
        },
        {
          "line": 4367,
          "old_api": "size",
          "new_api": "GenerateReduceScatter",
          "old_text": "SetHloSharding(sequence, strategy_map, cost_graph, s_val,\n                   (mesh_idx == partial_mesh_shapes.size() - 1))",
          "new_text": "GenerateReduceScatter(sequence, alias_map, ins_depth_map, strategy_map,\n                            cost_graph, s_val, cluster_env, solver_option)",
          "old_line_content": "    SetHloSharding(sequence, strategy_map, cost_graph, s_val,",
          "new_line_content": "      GenerateReduceScatter(sequence, alias_map, ins_depth_map, strategy_map,",
          "content_same": false
        },
        {
          "line": 4373,
          "old_api": "spmd::RecoverShardingsFromPartialMesh(sequence, preserve_shardings)",
          "new_api": "size",
          "old_text": "spmd::RecoverShardingsFromPartialMesh(sequence, preserve_shardings)",
          "new_text": "partial_mesh_shapes.size()",
          "old_line_content": "      spmd::RecoverShardingsFromPartialMesh(sequence, preserve_shardings);",
          "new_line_content": "    if (mesh_idx == partial_mesh_shapes.size() - 1) {",
          "content_same": false
        },
        {
          "line": 4377,
          "old_api": "VLOG_IS_ON",
          "new_api": "spmd::RecoverShardingsFromPartialMesh(sequence, preserve_shardings)",
          "old_text": "VLOG_IS_ON(1)",
          "new_text": "spmd::RecoverShardingsFromPartialMesh(sequence, preserve_shardings)",
          "old_line_content": "  if (VLOG_IS_ON(1)) {",
          "new_line_content": "      spmd::RecoverShardingsFromPartialMesh(sequence, preserve_shardings);",
          "content_same": false
        },
        {
          "line": 4382,
          "old_api": "VLOG_IS_ON",
          "new_api": "num_elements",
          "old_text": "VLOG_IS_ON(1)",
          "new_text": "original_device_mesh.num_elements()",
          "old_line_content": "  if (VLOG_IS_ON(1)) {",
          "new_line_content": "    spmd::CheckHloSharding(sequence, original_device_mesh.num_elements());",
          "content_same": false
        },
        {
          "line": 4387,
          "old_api": "CanonicalizeLayouts",
          "new_api": "spmd::CheckUserShardingPreservation(module, preserve_shardings)",
          "old_text": "CanonicalizeLayouts(module)",
          "new_text": "spmd::CheckUserShardingPreservation(module, preserve_shardings)",
          "old_line_content": "  TF_RETURN_IF_ERROR(CanonicalizeLayouts(module));",
          "new_line_content": "    spmd::CheckUserShardingPreservation(module, preserve_shardings);",
          "content_same": false
        },
        {
          "line": 4391,
          "old_api": "DumpHloModuleIfEnabled",
          "new_api": "CanonicalizeLayouts",
          "old_text": "DumpHloModuleIfEnabled(*module, \"after_auto_spmd_sharding\")",
          "new_text": "CanonicalizeLayouts(module)",
          "old_line_content": "  DumpHloModuleIfEnabled(*module, \"after_auto_spmd_sharding\");",
          "new_line_content": "  TF_RETURN_IF_ERROR(CanonicalizeLayouts(module));",
          "content_same": false
        },
        {
          "line": 4426,
          "old_api": "DumpHloModuleIfEnabled",
          "new_api": "VLOG",
          "old_text": "DumpHloModuleIfEnabled(*module, \"before_auto_spmd_sharding\")",
          "new_text": "VLOG(1)",
          "old_line_content": "  DumpHloModuleIfEnabled(*module, \"before_auto_spmd_sharding\");",
          "new_line_content": "  VLOG(1) << \"Start auto sharding pass\";",
          "content_same": false
        },
        {
          "line": 4430,
          "old_api": "absl::Now()",
          "new_api": "DumpHloModuleIfEnabled",
          "old_text": "absl::Now()",
          "new_text": "DumpHloModuleIfEnabled(*module, \"before_auto_spmd_sharding\")",
          "old_line_content": "  absl::Time start_time = absl::Now();",
          "new_line_content": "  DumpHloModuleIfEnabled(*module, \"before_auto_spmd_sharding\");",
          "content_same": false
        },
        {
          "line": 4434,
          "old_api": "CheckAndSetup",
          "new_api": "absl::Now()",
          "old_text": "option_.CheckAndSetup()",
          "new_text": "absl::Now()",
          "old_line_content": "  TF_RETURN_IF_ERROR(option_.CheckAndSetup());",
          "new_line_content": "  absl::Time start_time = absl::Now();",
          "content_same": false
        },
        {
          "line": 4435,
          "old_api": "ToString",
          "new_api": "metrics::RecordAutoShardingInvocations()",
          "old_text": "option_.ToString()",
          "new_text": "metrics::RecordAutoShardingInvocations()",
          "old_line_content": "  VLOG(1) << \"AutoShardingOptions:\\n\" << option_.ToString();",
          "new_line_content": "  metrics::RecordAutoShardingInvocations();",
          "content_same": false
        },
        {
          "line": 4438,
          "old_api": "size",
          "new_api": "CheckAndSetup",
          "old_text": "option_.device_mesh_shape.size()",
          "new_text": "option_.CheckAndSetup()",
          "old_line_content": "  for (size_t i = 0; i < option_.device_mesh_shape.size(); ++i) {",
          "new_line_content": "  TF_RETURN_IF_ERROR(option_.CheckAndSetup());",
          "content_same": false
        },
        {
          "line": 4468,
          "old_api": "size",
          "new_api": "spmd::ToString(option_.device_mesh_shape)",
          "old_text": "mesh_shapes.size()",
          "new_text": "spmd::ToString(option_.device_mesh_shape)",
          "old_line_content": "  for (size_t i = 0; i < mesh_shapes.size(); ++i) {",
          "new_line_content": "          << spmd::ToString(option_.device_mesh_shape);",
          "content_same": false
        },
        {
          "line": 4469,
          "old_api": "spmd::ToString(mesh_shapes[i])",
          "new_api": "std::numeric_limits<double>::max()",
          "old_text": "spmd::ToString(mesh_shapes[i])",
          "new_text": "std::numeric_limits<double>::max()",
          "old_line_content": "    VLOG(1) << \"Trying mesh shape \" << spmd::ToString(mesh_shapes[i]);",
          "new_line_content": "  double min_objective_value = std::numeric_limits<double>::max();",
          "content_same": false
        },
        {
          "line": 4473,
          "old_api": "Clone",
          "new_api": "spmd::ToString(mesh_shapes[i])",
          "old_text": "module->Clone(\"\")",
          "new_text": "spmd::ToString(mesh_shapes[i])",
          "old_line_content": "    auto module_clone = module->Clone(\"\");",
          "new_line_content": "    VLOG(1) << \"Trying mesh shape \" << spmd::ToString(mesh_shapes[i]);",
          "content_same": false
        },
        {
          "line": 4477,
          "old_api": "get",
          "new_api": "Clone",
          "old_text": "module_clone.get()",
          "new_text": "module->Clone(\"\")",
          "old_line_content": "        pass->RunAutoSharding(module_clone.get(), execution_threads);",
          "new_line_content": "    auto module_clone = module->Clone(\"\");",
          "content_same": false
        },
        {
          "line": 4481,
          "old_api": "std::move(module_clone)",
          "new_api": "get",
          "old_text": "std::move(module_clone)",
          "new_text": "module_clone.get()",
          "old_line_content": "    modules[i] = std::move(module_clone);",
          "new_line_content": "        pass->RunAutoSharding(module_clone.get(), execution_threads);",
          "content_same": false
        },
        {
          "line": 4523,
          "old_api": "value",
          "new_api": "ok",
          "old_text": "changed[min_mesh_shape_index].value()",
          "new_text": "changed[min_mesh_shape_index].ok()",
          "old_line_content": "      if (changed[min_mesh_shape_index].value() ==",
          "new_line_content": "    if (!changed[min_mesh_shape_index].ok()) {",
          "content_same": false
        },
        {
          "line": 4539,
          "old_api": "ReplaceComputations",
          "new_api": "mutable_computation",
          "old_text": "module->ReplaceComputations(computation_replacements)",
          "new_text": "modules[min_mesh_shape_index]->mutable_computation(i)",
          "old_line_content": "        module->ReplaceComputations(computation_replacements);",
          "new_line_content": "              modules[min_mesh_shape_index]->mutable_computation(i);",
          "content_same": false
        },
        {
          "line": 4543,
          "old_api": "entry_computation_layout",
          "new_api": "ReplaceComputations",
          "old_text": "modules[min_mesh_shape_index]->entry_computation_layout()",
          "new_text": "module->ReplaceComputations(computation_replacements)",
          "old_line_content": "            modules[min_mesh_shape_index]->entry_computation_layout();",
          "new_line_content": "        module->ReplaceComputations(computation_replacements);",
          "content_same": false
        },
        {
          "line": 4546,
          "old_api": "value",
          "new_api": "mutable_entry_computation_layout",
          "old_text": "changed[min_mesh_shape_index].value()",
          "new_text": "module->config().mutable_entry_computation_layout()",
          "old_line_content": "      } else if (changed[min_mesh_shape_index].value() ==",
          "new_line_content": "        *module->config().mutable_entry_computation_layout() =",
          "content_same": false
        },
        {
          "line": 4562,
          "old_api": "ToString",
          "new_api": "metrics::RecordAutoShardingCompilationTime(\n      absl::ToInt64Microseconds(duration))",
          "old_text": "module->ToString()",
          "new_text": "metrics::RecordAutoShardingCompilationTime(\n      absl::ToInt64Microseconds(duration))",
          "old_line_content": "  XLA_VLOG_LINES(6, absl::StrCat(\"After auto sharding:\\n\", module->ToString()));",
          "new_line_content": "  metrics::RecordAutoShardingCompilationTime(",
          "content_same": false
        },
        {
          "line": 4563,
          "old_api": "DumpHloModuleIfEnabled",
          "new_api": "absl::ToInt64Microseconds(duration)",
          "old_text": "DumpHloModuleIfEnabled(*module, \"after_auto_spmd_sharding\")",
          "new_text": "absl::ToInt64Microseconds(duration)",
          "old_line_content": "  DumpHloModuleIfEnabled(*module, \"after_auto_spmd_sharding\");",
          "new_line_content": "      absl::ToInt64Microseconds(duration));",
          "content_same": false
        },
        {
          "line": 4576,
          "old_api": "IsTuple",
          "new_api": "entry_computation",
          "old_text": "out_shape.IsTuple()",
          "new_text": "module->entry_computation()",
          "old_line_content": "    if (out_shape.IsTuple()) {",
          "new_line_content": "  HloComputation* entry = module->entry_computation();",
          "content_same": false
        },
        {
          "line": 4579,
          "old_api": "HloSharding::Tuple(tuple_sharding)",
          "new_api": "shape",
          "old_text": "HloSharding::Tuple(tuple_sharding)",
          "new_text": "inst->shape()",
          "old_line_content": "      inst->set_sharding(HloSharding::Tuple(tuple_sharding));",
          "new_line_content": "    const Shape& out_shape = inst->shape();",
          "content_same": false
        }
      ],
      "additions": [
        {
          "line": 4138,
          "old_api": null,
          "new_api": "spmd::ComputeInstructionExecutionCounts(\n          module, option_.loop_iteration_count_estimate)",
          "old_text": null,
          "new_text": "spmd::ComputeInstructionExecutionCounts(\n          module, option_.loop_iteration_count_estimate)",
          "old_line_content": "  // shardings to their input ops.",
          "new_line_content": "      instruction_execution_counts = spmd::ComputeInstructionExecutionCounts(",
          "content_same": false
        },
        {
          "line": 4154,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "status_or_changed.ok()",
          "old_line_content": "    module_is_changed = true;",
          "new_line_content": "  if (!status_or_changed.ok()) {",
          "content_same": false
        },
        {
          "line": 4157,
          "old_api": null,
          "new_api": "value",
          "old_text": null,
          "new_text": "status_or_changed.value()",
          "old_line_content": "  } else {",
          "new_line_content": "  if (status_or_changed.value()) {",
          "content_same": false
        },
        {
          "line": 4159,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(3)",
          "old_line_content": "               \"custom_call_target=Sharding.\";",
          "new_line_content": "    VLOG(3) << \"CustomCalls with custom_call_target=Sharding are removed and \"",
          "content_same": false
        },
        {
          "line": 4162,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(3)",
          "old_line_content": "  absl::flat_hash_map<std::string, std::vector<HloSharding>>",
          "new_line_content": "    VLOG(3) << \"This workload does not have CustomCalls with \"",
          "content_same": false
        },
        {
          "line": 4168,
          "old_api": null,
          "new_api": "spmd::SaveUserShardings(module, option_.preserve_shardings)",
          "old_text": null,
          "new_text": "spmd::SaveUserShardings(module, option_.preserve_shardings)",
          "old_line_content": "      AutoShardingOption::PreserveShardingsType::kKeepAllShardings) {",
          "new_line_content": "          spmd::SaveUserShardings(module, option_.preserve_shardings);",
          "content_same": false
        },
        {
          "line": 4175,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "status_or_changed.ok()",
          "old_line_content": "      module_is_changed = true;",
          "new_line_content": "    if (!status_or_changed.ok()) {",
          "content_same": false
        },
        {
          "line": 4180,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(3)",
          "old_line_content": "  }",
          "new_line_content": "      VLOG(3) << \"XLA sharding annotations are removed.\";",
          "content_same": false
        },
        {
          "line": 4182,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(3)",
          "old_line_content": "  // ----- Get a sequential schedule and do liveness analysis -----",
          "new_line_content": "      VLOG(3) << \"This workload does not have XLA sharding annotations.\";",
          "content_same": false
        },
        {
          "line": 4188,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "buffer.shape()",
          "old_line_content": "      ScheduleModule(module, size_fn,",
          "new_line_content": "    return spmd::GetBytes(buffer.shape());",
          "content_same": false
        },
        {
          "line": 4195,
          "old_api": null,
          "new_api": "entry_computation",
          "old_text": null,
          "new_text": "module->entry_computation()",
          "old_line_content": "",
          "new_line_content": "  const HloComputation* entry_computation = module->entry_computation();",
          "content_same": false
        },
        {
          "line": 4197,
          "old_api": null,
          "new_api": "value",
          "old_text": null,
          "new_text": "HloAliasAnalysis::Run(module).value()",
          "old_line_content": "      std::unique_ptr<HloLiveRange> hlo_live_range,",
          "new_line_content": "      HloAliasAnalysis::Run(module).value();",
          "content_same": false
        },
        {
          "line": 4202,
          "old_api": null,
          "new_api": "HloLiveRange::Run(schedule, *alias_analysis, entry_computation)",
          "old_text": null,
          "new_text": "HloLiveRange::Run(schedule, *alias_analysis, entry_computation)",
          "old_line_content": "  for (const auto& iter : buffer_live_ranges) {",
          "new_line_content": "      HloLiveRange::Run(schedule, *alias_analysis, entry_computation));",
          "content_same": false
        },
        {
          "line": 4205,
          "old_api": null,
          "new_api": "schedule_end_time",
          "old_text": null,
          "new_text": "hlo_live_range->schedule_end_time()",
          "old_line_content": "    }",
          "new_line_content": "  spmd::LivenessSet liveness_set(hlo_live_range->schedule_end_time() + 1);",
          "content_same": false
        },
        {
          "line": 4212,
          "old_api": null,
          "new_api": "spmd::PrintLivenessSet(liveness_set)",
          "old_text": null,
          "new_text": "spmd::PrintLivenessSet(liveness_set)",
          "old_line_content": "",
          "new_line_content": "  VLOG(10) << spmd::PrintLivenessSet(liveness_set);",
          "content_same": false
        },
        {
          "line": 4213,
          "old_api": null,
          "new_api": "spmd::PrintLivenessSet(liveness_set)",
          "old_text": null,
          "new_text": "spmd::PrintLivenessSet(liveness_set)",
          "old_line_content": "  // ----- Analyze the batch dim -----",
          "new_line_content": "  XLA_VLOG_LINES(10, spmd::PrintLivenessSet(liveness_set));",
          "content_same": false
        },
        {
          "line": 4215,
          "old_api": null,
          "new_api": "flattened_instruction_sequence",
          "old_text": null,
          "new_text": "hlo_live_range->flattened_instruction_sequence()",
          "old_line_content": "  // TODO(yuemmawang) Enable the batch_dim_map if it becomes helpful. This is",
          "new_line_content": "      hlo_live_range->flattened_instruction_sequence();",
          "content_same": false
        },
        {
          "line": 4225,
          "old_api": null,
          "new_api": "SetValues",
          "old_text": null,
          "new_text": "original_device_mesh.SetValues(option_.device_mesh_ids)",
          "old_line_content": "  if (option_.solve_nd_sharding_iteratively) {",
          "new_line_content": "  original_device_mesh.SetValues(option_.device_mesh_ids);",
          "content_same": false
        },
        {
          "line": 4231,
          "old_api": null,
          "new_api": "spmd::DecomposeMeshShapes(option_.device_mesh_shape)",
          "old_text": null,
          "new_text": "spmd::DecomposeMeshShapes(option_.device_mesh_shape)",
          "old_line_content": "",
          "new_line_content": "    partial_mesh_shapes = spmd::DecomposeMeshShapes(option_.device_mesh_shape);",
          "content_same": false
        },
        {
          "line": 4236,
          "old_api": null,
          "new_api": "CallGraph::Build(module)",
          "old_text": null,
          "new_text": "CallGraph::Build(module)",
          "old_line_content": "    std::vector<int64_t> mesh_shape = partial_mesh_shapes[mesh_idx];",
          "new_line_content": "  std::unique_ptr<CallGraph> call_graph = CallGraph::Build(module);",
          "content_same": false
        },
        {
          "line": 4241,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(INFO)",
          "old_line_content": "    int64_t total_devices = 1;",
          "new_line_content": "    LOG(INFO) << \"Processing partial mesh shape: \"",
          "content_same": false
        },
        {
          "line": 4242,
          "old_api": null,
          "new_api": "spmd::ToString(mesh_shape)",
          "old_text": null,
          "new_text": "spmd::ToString(mesh_shape)",
          "old_line_content": "    for (auto i : mesh_shape) {",
          "new_line_content": "              << spmd::ToString(mesh_shape);",
          "content_same": false
        },
        {
          "line": 4251,
          "old_api": null,
          "new_api": "instructions",
          "old_text": null,
          "new_text": "sequence.instructions()",
          "old_line_content": "            << \"Shardings are adjusted based on current partial mesh shape: \"",
          "new_line_content": "          sequence.instructions(), mesh_shape, total_devices,",
          "content_same": false
        },
        {
          "line": 4253,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "changed_or.ok()",
          "old_line_content": "      } else {",
          "new_line_content": "      if (changed_or.ok()) {",
          "content_same": false
        },
        {
          "line": 4261,
          "old_api": null,
          "new_api": "std::vector<int64_t>(total_devices)",
          "old_text": null,
          "new_text": "std::vector<int64_t>(total_devices)",
          "old_line_content": "    // TODO (zhuohan): include the prof result as an option.",
          "new_line_content": "    std::vector<int64_t> device_mesh_ids = std::vector<int64_t>(total_devices);",
          "content_same": false
        },
        {
          "line": 4262,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "device_mesh_ids.end()",
          "old_line_content": "    spmd::ProfilingResult prof_result;",
          "new_line_content": "    std::iota(device_mesh_ids.begin(), device_mesh_ids.end(), 0);",
          "content_same": false
        },
        {
          "line": 4263,
          "old_api": null,
          "new_api": "SetValues",
          "old_text": null,
          "new_text": "device_mesh.SetValues(device_mesh_ids)",
          "old_line_content": "    spmd::ClusterEnvironment cluster_env(",
          "new_line_content": "    device_mesh.SetValues(device_mesh_ids);",
          "content_same": false
        },
        {
          "line": 4271,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "module->ToString()",
          "old_line_content": "    // Rounds up to the next GB.",
          "new_line_content": "    XLA_VLOG_LINES(1, module->ToString());",
          "content_same": false
        },
        {
          "line": 4272,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "spmd::MemoryBudgetLowerBound(\n        *module, liveness_set, alias_analysis.get(),\n        device_mesh.num_elements())",
          "old_line_content": "    int64_t memory_lower_bound_gb =",
          "new_line_content": "    int64_t memory_lower_bound = spmd::MemoryBudgetLowerBound(",
          "content_same": false
        },
        {
          "line": 4273,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "alias_analysis.get()",
          "old_line_content": "        1 + memory_lower_bound / (1024 * 1024 * 1024);",
          "new_line_content": "        *module, liveness_set, alias_analysis.get(),",
          "content_same": false
        },
        {
          "line": 4278,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(INFO)",
          "old_line_content": "          << \"--xla_tpu_auto_spmd_partitioning_memory_budget_gb is 0, and \"",
          "new_line_content": "    LOG(INFO) << \"Memory consumption lower bound is \" << memory_lower_bound_gb",
          "content_same": false
        },
        {
          "line": 4281,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(INFO)",
          "old_line_content": "          << \", so setting \"",
          "new_line_content": "      LOG(INFO)",
          "content_same": false
        },
        {
          "line": 4295,
          "old_api": null,
          "new_api": "num_elements",
          "old_text": null,
          "new_text": "original_device_mesh.num_elements()",
          "old_line_content": "    }",
          "new_line_content": "                                         original_device_mesh.num_elements() /",
          "content_same": false
        },
        {
          "line": 4296,
          "old_api": null,
          "new_api": "num_elements",
          "old_text": null,
          "new_text": "device_mesh.num_elements()",
          "old_line_content": "",
          "new_line_content": "                                         device_mesh.num_elements();",
          "content_same": false
        },
        {
          "line": 4301,
          "old_api": null,
          "new_api": "empty",
          "old_text": null,
          "new_text": "solver_option.force_simple_heuristic.empty()",
          "old_line_content": "    }",
          "new_line_content": "    if (!solver_option.force_simple_heuristic.empty()) {",
          "content_same": false
        },
        {
          "line": 4302,
          "old_api": null,
          "new_api": "AnnotateShardingWithSimpleHeuristic",
          "old_text": null,
          "new_text": "AnnotateShardingWithSimpleHeuristic(\n          module, solver_option.force_simple_heuristic, alias_map, cluster_env)",
          "old_line_content": "",
          "new_line_content": "      AnnotateShardingWithSimpleHeuristic(",
          "content_same": false
        },
        {
          "line": 4308,
          "old_api": null,
          "new_api": "instructions",
          "old_text": null,
          "new_text": "DisableIncompatibleMixedMeshShapeAndForceBatchDim(\n          batch_dim_map, sequence.instructions(), device_mesh.num_elements(),\n          solver_option)",
          "old_line_content": "",
          "new_line_content": "      DisableIncompatibleMixedMeshShapeAndForceBatchDim(",
          "content_same": false
        },
        {
          "line": 4309,
          "old_api": null,
          "new_api": "num_elements",
          "old_text": null,
          "new_text": "device_mesh.num_elements()",
          "old_line_content": "    // ----- Analyze depth -----",
          "new_line_content": "          batch_dim_map, sequence.instructions(), device_mesh.num_elements(),",
          "content_same": false
        },
        {
          "line": 4315,
          "old_api": null,
          "new_api": "spmd::BuildInstructionDepthMap(sequence, batch_dim_map)",
          "old_text": null,
          "new_text": "spmd::BuildInstructionDepthMap(sequence, batch_dim_map)",
          "old_line_content": "    spmd::AssociativeDotPairs associative_dot_pairs;",
          "new_line_content": "    ins_depth_map = spmd::BuildInstructionDepthMap(sequence, batch_dim_map);",
          "content_same": false
        },
        {
          "line": 4321,
          "old_api": null,
          "new_api": "TF_ASSIGN_OR_RETURN",
          "old_text": null,
          "new_text": "TF_ASSIGN_OR_RETURN(\n        std::tie(strategy_map, leaf_strategies, associative_dot_pairs),\n        BuildStrategyAndCost(sequence, module, instruction_execution_counts,\n                             ins_depth_map, batch_dim_map, alias_map,\n                             cluster_env, solver_option, *call_graph,\n                             option_.try_multiple_mesh_shapes))",
          "old_line_content": "                             cluster_env, solver_option, *call_graph,",
          "new_line_content": "    TF_ASSIGN_OR_RETURN(",
          "content_same": false
        },
        {
          "line": 4322,
          "old_api": null,
          "new_api": "std::tie(strategy_map, leaf_strategies, associative_dot_pairs)",
          "old_text": null,
          "new_text": "std::tie(strategy_map, leaf_strategies, associative_dot_pairs)",
          "old_line_content": "                             option_.try_multiple_mesh_shapes));",
          "new_line_content": "        std::tie(strategy_map, leaf_strategies, associative_dot_pairs),",
          "content_same": false
        },
        {
          "line": 4327,
          "old_api": null,
          "new_api": "spmd::BuildAliasSet(module, strategy_map)",
          "old_text": null,
          "new_text": "spmd::BuildAliasSet(module, strategy_map)",
          "old_line_content": "    // ----- Build cost graph and merge unimporant nodes -----",
          "new_line_content": "    spmd::AliasSet alias_set = spmd::BuildAliasSet(module, strategy_map);",
          "content_same": false
        },
        {
          "line": 4328,
          "old_api": null,
          "new_api": "CheckAliasSetCompatibility",
          "old_text": null,
          "new_text": "CheckAliasSetCompatibility(alias_set, leaf_strategies, sequence)",
          "old_line_content": "    spmd::CostGraph cost_graph(leaf_strategies, associative_dot_pairs);",
          "new_line_content": "    CheckAliasSetCompatibility(alias_set, leaf_strategies, sequence);",
          "content_same": false
        },
        {
          "line": 4333,
          "old_api": null,
          "new_api": "Simplify",
          "old_text": null,
          "new_text": "cost_graph.Simplify(option_.simplify_graph)",
          "old_line_content": "    double objective = -1.0;",
          "new_line_content": "    cost_graph.Simplify(option_.simplify_graph);",
          "content_same": false
        },
        {
          "line": 4339,
          "old_api": null,
          "new_api": "CallSolver",
          "old_text": null,
          "new_text": "CallSolver(\n          sequence, liveness_set, strategy_map, leaf_strategies, cost_graph,\n          alias_set, option_.memory_budget_per_device,\n          /*crash_at_infinity_costs_check*/\n          !option_.try_multiple_mesh_shapes, option_.solver_timeout_in_seconds)",
          "old_line_content": "          !option_.try_multiple_mesh_shapes, option_.solver_timeout_in_seconds);",
          "new_line_content": "      auto solver_result = CallSolver(",
          "content_same": false
        },
        {
          "line": 4350,
          "old_api": null,
          "new_api": "std::tie(s_val, e_val, objective)",
          "old_text": null,
          "new_text": "std::tie(s_val, e_val, objective)",
          "old_line_content": "      }",
          "new_line_content": "        std::tie(s_val, e_val, objective) = solution;",
          "content_same": false
        },
        {
          "line": 4351,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "partial_mesh_shapes.size()",
          "old_line_content": "    } else {",
          "new_line_content": "        if (mesh_idx == partial_mesh_shapes.size() - 1) {",
          "content_same": false
        },
        {
          "line": 4359,
          "old_api": null,
          "new_api": "PrintAutoShardingSolution",
          "old_text": null,
          "new_text": "PrintAutoShardingSolution(sequence, liveness_set,\n                                                strategy_map, leaf_strategies,\n                                                cost_graph, s_val, objective)",
          "old_line_content": "                                               cost_graph, s_val));",
          "new_line_content": "    XLA_VLOG_LINES(5, PrintAutoShardingSolution(sequence, liveness_set,",
          "content_same": false
        },
        {
          "line": 4362,
          "old_api": null,
          "new_api": "PrintSolutionMemoryUsage",
          "old_text": null,
          "new_text": "PrintSolutionMemoryUsage(liveness_set, strategy_map,\n                                               cost_graph, s_val)",
          "old_line_content": "    if (solver_option.prefer_reduce_scatter) {",
          "new_line_content": "    XLA_VLOG_LINES(1, PrintSolutionMemoryUsage(liveness_set, strategy_map,",
          "content_same": false
        },
        {
          "line": 4371,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "SetHloSharding(sequence, strategy_map, cost_graph, s_val,\n                   (mesh_idx == partial_mesh_shapes.size() - 1))",
          "old_line_content": "                                   cluster_env, &preserve_shardings);",
          "new_line_content": "    SetHloSharding(sequence, strategy_map, cost_graph, s_val,",
          "content_same": false
        },
        {
          "line": 4372,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "partial_mesh_shapes.size()",
          "old_line_content": "    } else {",
          "new_line_content": "                   (mesh_idx == partial_mesh_shapes.size() - 1));",
          "content_same": false
        },
        {
          "line": 4374,
          "old_api": null,
          "new_api": "SetHloShardingPostProcessing",
          "old_text": null,
          "new_text": "SetHloShardingPostProcessing(sequence, strategy_map, cost_graph, s_val,\n                                   cluster_env, &preserve_shardings)",
          "old_line_content": "    }",
          "new_line_content": "      SetHloShardingPostProcessing(sequence, strategy_map, cost_graph, s_val,",
          "content_same": false
        },
        {
          "line": 4381,
          "old_api": null,
          "new_api": "VLOG_IS_ON",
          "old_text": null,
          "new_text": "VLOG_IS_ON(1)",
          "old_line_content": "",
          "new_line_content": "  if (VLOG_IS_ON(1)) {",
          "content_same": false
        },
        {
          "line": 4386,
          "old_api": null,
          "new_api": "VLOG_IS_ON",
          "old_text": null,
          "new_text": "VLOG_IS_ON(1)",
          "old_line_content": "  // ----- Canonicalize layouts based on LayoutCanonicalizationCallback. -----",
          "new_line_content": "  if (VLOG_IS_ON(1)) {",
          "content_same": false
        },
        {
          "line": 4392,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "absl::StrCat(\"After auto sharding for mesh \",\n                                 spmd::ToString(option_.device_mesh_shape),\n                                 \":\\n\", module->ToString())",
          "old_line_content": "",
          "new_line_content": "  XLA_VLOG_LINES(7, absl::StrCat(\"After auto sharding for mesh \",",
          "content_same": false
        },
        {
          "line": 4393,
          "old_api": null,
          "new_api": "spmd::ToString(option_.device_mesh_shape)",
          "old_text": null,
          "new_text": "spmd::ToString(option_.device_mesh_shape)",
          "old_line_content": "  return module_is_changed ? AutoShardingResult::kModuleChangedShardingPerformed",
          "new_line_content": "                                 spmd::ToString(option_.device_mesh_shape),",
          "content_same": false
        },
        {
          "line": 4394,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "module->ToString()",
          "old_line_content": "                           : AutoShardingResult::kModuleUnchanged;",
          "new_line_content": "                                 \":\\n\", module->ToString()));",
          "content_same": false
        },
        {
          "line": 4395,
          "old_api": null,
          "new_api": "DumpHloModuleIfEnabled",
          "old_text": null,
          "new_text": "DumpHloModuleIfEnabled(*module, \"after_auto_spmd_sharding\")",
          "old_line_content": "}",
          "new_line_content": "  DumpHloModuleIfEnabled(*module, \"after_auto_spmd_sharding\");",
          "content_same": false
        },
        {
          "line": 4403,
          "old_api": null,
          "new_api": "computations",
          "old_text": null,
          "new_text": "module->computations()",
          "old_line_content": "        break;",
          "new_line_content": "  for (auto computation : module->computations()) {",
          "content_same": false
        },
        {
          "line": 4404,
          "old_api": null,
          "new_api": "instructions",
          "old_text": null,
          "new_text": "computation->instructions()",
          "old_line_content": "      }",
          "new_line_content": "    for (auto instruction : computation->instructions()) {",
          "content_same": false
        },
        {
          "line": 4405,
          "old_api": null,
          "new_api": "has_sharding",
          "old_text": null,
          "new_text": "instruction->has_sharding()",
          "old_line_content": "    }",
          "new_line_content": "      if (instruction->has_sharding()) {",
          "content_same": false
        },
        {
          "line": 4428,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "XLA_VLOG_LINES(6,\n                 absl::StrCat(\"Before auto sharding:\\n\", module->ToString()))",
          "old_line_content": "#if !defined(__APPLE__)",
          "new_line_content": "  XLA_VLOG_LINES(6,",
          "content_same": false
        },
        {
          "line": 4429,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "module->ToString()",
          "old_line_content": "  // Streamz metrics.",
          "new_line_content": "                 absl::StrCat(\"Before auto sharding:\\n\", module->ToString()));",
          "content_same": false
        },
        {
          "line": 4439,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "option_.ToString()",
          "old_line_content": "    if (option_.device_mesh_beta[0] != option_.device_mesh_beta[i] ||",
          "new_line_content": "  VLOG(1) << \"AutoShardingOptions:\\n\" << option_.ToString();",
          "content_same": false
        },
        {
          "line": 4442,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "option_.device_mesh_shape.size()",
          "old_line_content": "      break;",
          "new_line_content": "  for (size_t i = 0; i < option_.device_mesh_shape.size(); ++i) {",
          "content_same": false
        },
        {
          "line": 2397,
          "old_api": null,
          "new_api": "absl::StrAppend(&str, i, \", \")",
          "old_text": null,
          "new_text": "absl::StrAppend(&str, i, \", \")",
          "old_line_content": "      }",
          "new_line_content": "        absl::StrAppend(&str, i, \", \");",
          "content_same": false
        },
        {
          "line": 2398,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "m[i].end()",
          "old_line_content": "      str += \"]\";",
          "new_line_content": "        total_fixed_memory_cost += *std::min_element(m[i].begin(), m[i].end());",
          "content_same": false
        },
        {
          "line": 2401,
          "old_api": null,
          "new_api": "MakeRowConstraint",
          "old_text": null,
          "new_text": "solver->MakeRowConstraint(\n          -MPSolver::infinity(), M - total_fixed_memory_cost,\n          absl::StrCat(\"mem[\", t, \"] = \", str))",
          "old_line_content": "      for (auto i : L[t]) {",
          "new_line_content": "      MPConstraint* constraint = solver->MakeRowConstraint(",
          "content_same": false
        },
        {
          "line": 4452,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "spmd::CreateDifferentMeshShapesToTry(\n        absl::c_accumulate(option_.device_mesh_shape, 1,\n                           [](int64_t a, int64_t b) { return a * b; }),\n        option_.device_mesh_shape.size(),\n        /* symmetrical_mesh_dims */ !asymmetrical_mesh_dims)",
          "old_line_content": "        /* symmetrical_mesh_dims */ !asymmetrical_mesh_dims);",
          "new_line_content": "    mesh_shapes = spmd::CreateDifferentMeshShapesToTry(",
          "content_same": false
        },
        {
          "line": 2405,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "m[i].end()",
          "old_line_content": "                                     accumulated_coefficient + m[i][j]);",
          "new_line_content": "        auto fixed_memory_cost = *std::min_element(m[i].begin(), m[i].end());",
          "content_same": false
        },
        {
          "line": 2406,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "s[i].size()",
          "old_line_content": "        }",
          "new_line_content": "        for (size_t j = 0; j < s[i].size(); ++j) {",
          "content_same": false
        },
        {
          "line": 2407,
          "old_api": null,
          "new_api": "GetCoefficient",
          "old_text": null,
          "new_text": "constraint->GetCoefficient(s[i][j])",
          "old_line_content": "      }",
          "new_line_content": "          double accumulated_coefficient = constraint->GetCoefficient(s[i][j]);",
          "content_same": false
        },
        {
          "line": 2408,
          "old_api": null,
          "new_api": "SetCoefficient",
          "old_text": null,
          "new_text": "constraint->SetCoefficient(\n              s[i][j], accumulated_coefficient + m[i][j] - fixed_memory_cost)",
          "old_line_content": "    }",
          "new_line_content": "          constraint->SetCoefficient(",
          "content_same": false
        },
        {
          "line": 4453,
          "old_api": null,
          "new_api": "absl::c_accumulate(option_.device_mesh_shape, 1,\n                           [](int64_t a, int64_t b) { return a * b; })",
          "old_text": null,
          "new_text": "absl::c_accumulate(option_.device_mesh_shape, 1,\n                           [](int64_t a, int64_t b) { return a * b; })",
          "old_line_content": "  } else {",
          "new_line_content": "        absl::c_accumulate(option_.device_mesh_shape, 1,",
          "content_same": false
        },
        {
          "line": 4455,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "option_.device_mesh_shape.size()",
          "old_line_content": "  }",
          "new_line_content": "        option_.device_mesh_shape.size(),",
          "content_same": false
        },
        {
          "line": 4458,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "mesh_shapes.push_back(option_.device_mesh_shape)",
          "old_line_content": "  std::vector<std::unique_ptr<HloModule>> modules(num_meshes);",
          "new_line_content": "    mesh_shapes.push_back(option_.device_mesh_shape);",
          "content_same": false
        },
        {
          "line": 4461,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "mesh_shapes.size()",
          "old_line_content": "  std::vector<double> objective_values(num_meshes, -1);",
          "new_line_content": "  size_t num_meshes = mesh_shapes.size();",
          "content_same": false
        },
        {
          "line": 4467,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(1)",
          "old_line_content": "  bool skip_auto_sharding = true;",
          "new_line_content": "  VLOG(1) << \"Original mesh shape \"",
          "content_same": false
        },
        {
          "line": 2421,
          "old_api": null,
          "new_api": "absl::StrCat(\"sum(e[\", edge.first, \"][\", edge.second, \"][*]) = 1\")",
          "old_text": null,
          "new_text": "absl::StrCat(\"sum(e[\", edge.first, \"][\", edge.second, \"][*]) = 1\")",
          "old_line_content": "  }",
          "new_line_content": "        absl::StrCat(\"sum(e[\", edge.first, \"][\", edge.second, \"][*]) = 1\"));",
          "content_same": false
        },
        {
          "line": 2422,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "e[i].size()",
          "old_line_content": "  // f.",
          "new_line_content": "    for (size_t j = 0; j < e[i].size(); ++j) {",
          "content_same": false
        },
        {
          "line": 2423,
          "old_api": null,
          "new_api": "SetCoefficient",
          "old_text": null,
          "new_text": "constraint->SetCoefficient(e[i][j], 1.0)",
          "old_line_content": "  for (size_t i = 0; i < num_edges; ++i) {",
          "new_line_content": "      constraint->SetCoefficient(e[i][j], 1.0);",
          "content_same": false
        },
        {
          "line": 4472,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "mesh_shapes.size()",
          "old_line_content": "    auto pass = new AutoShardingImplementation(this_option);",
          "new_line_content": "  for (size_t i = 0; i < mesh_shapes.size(); ++i) {",
          "content_same": false
        },
        {
          "line": 4478,
          "old_api": null,
          "new_api": "set_layout_canonicalization_callback",
          "old_text": null,
          "new_text": "module_clone->set_layout_canonicalization_callback(\n        module->layout_canonicalization_callback())",
          "old_line_content": "",
          "new_line_content": "    module_clone->set_layout_canonicalization_callback(",
          "content_same": false
        },
        {
          "line": 2431,
          "old_api": null,
          "new_api": "absl::StrCat(\"f for i = \", i, \", p = \", p)",
          "old_text": null,
          "new_text": "absl::StrCat(\"f for i = \", i, \", p = \", p)",
          "old_line_content": "      }",
          "new_line_content": "          -MPSolver::infinity(), 0, absl::StrCat(\"f for i = \", i, \", p = \", p));",
          "content_same": false
        },
        {
          "line": 2432,
          "old_api": null,
          "new_api": "SetCoefficient",
          "old_text": null,
          "new_text": "constraint->SetCoefficient(s[edge.first][p], -1.0)",
          "old_line_content": "    }",
          "new_line_content": "      constraint->SetCoefficient(s[edge.first][p], -1.0);",
          "content_same": false
        },
        {
          "line": 2433,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "s[edge.second].size()",
          "old_line_content": "  }",
          "new_line_content": "      for (size_t q = 0; q < s[edge.second].size(); ++q) {",
          "content_same": false
        },
        {
          "line": 2434,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "s[edge.second].size()",
          "old_line_content": "  // g.",
          "new_line_content": "        constraint->SetCoefficient(e[i][p * s[edge.second].size() + q], 1.0);",
          "content_same": false
        },
        {
          "line": 4479,
          "old_api": null,
          "new_api": "layout_canonicalization_callback",
          "old_text": null,
          "new_text": "module->layout_canonicalization_callback()",
          "old_line_content": "    changed[i] = pass_result;",
          "new_line_content": "        module->layout_canonicalization_callback());",
          "content_same": false
        },
        {
          "line": 4484,
          "old_api": null,
          "new_api": "GetSolverOptimalObjectiveValue",
          "old_text": null,
          "new_text": "pass->GetSolverOptimalObjectiveValue()",
          "old_line_content": "      continue;",
          "new_line_content": "    objective_values[i] = pass->GetSolverOptimalObjectiveValue();",
          "content_same": false
        },
        {
          "line": 4485,
          "old_api": null,
          "new_api": "std::move(module_clone)",
          "old_text": null,
          "new_text": "std::move(module_clone)",
          "old_line_content": "    }",
          "new_line_content": "    modules[i] = std::move(module_clone);",
          "content_same": false
        },
        {
          "line": 4487,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "pass_result.ok()",
          "old_line_content": "            << \" has objective value \" << objective_values[i];",
          "new_line_content": "    if (!pass_result.ok()) {",
          "content_same": false
        },
        {
          "line": 4490,
          "old_api": null,
          "new_api": "spmd::ToString(mesh_shapes[i])",
          "old_text": null,
          "new_text": "spmd::ToString(mesh_shapes[i])",
          "old_line_content": "      min_objective_value = objective_values[i];",
          "new_line_content": "    VLOG(1) << \"Mesh shape \" << spmd::ToString(mesh_shapes[i])",
          "content_same": false
        },
        {
          "line": 2443,
          "old_api": null,
          "new_api": "absl::StrCat(\"g for i = \", i, \", q = \", q)",
          "old_text": null,
          "new_text": "absl::StrCat(\"g for i = \", i, \", q = \", q)",
          "old_line_content": "      }",
          "new_line_content": "          -MPSolver::infinity(), 0, absl::StrCat(\"g for i = \", i, \", q = \", q));",
          "content_same": false
        },
        {
          "line": 2444,
          "old_api": null,
          "new_api": "SetCoefficient",
          "old_text": null,
          "new_text": "constraint->SetCoefficient(s[edge.second][q], -1.0)",
          "old_line_content": "    }",
          "new_line_content": "      constraint->SetCoefficient(s[edge.second][q], -1.0);",
          "content_same": false
        },
        {
          "line": 2445,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "s[edge.first].size()",
          "old_line_content": "  }",
          "new_line_content": "      for (size_t p = 0; p < s[edge.first].size(); ++p) {",
          "content_same": false
        },
        {
          "line": 2446,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "s[edge.second].size()",
          "old_line_content": "  // h.",
          "new_line_content": "        constraint->SetCoefficient(e[i][p * s[edge.second].size() + q], 1.0);",
          "content_same": false
        },
        {
          "line": 4496,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "pass_result.ok()",
          "old_line_content": "    }",
          "new_line_content": "    if (pass_result.ok() &&",
          "content_same": false
        },
        {
          "line": 4497,
          "old_api": null,
          "new_api": "value",
          "old_text": null,
          "new_text": "pass_result.value()",
          "old_line_content": "  }",
          "new_line_content": "        pass_result.value() !=",
          "content_same": false
        },
        {
          "line": 2451,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "A.size()",
          "old_line_content": "        // if lhs == 1",
          "new_line_content": "  for (size_t i = 0; i < A.size(); ++i) {",
          "content_same": false
        },
        {
          "line": 2456,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "s[alias.second].size()",
          "old_line_content": "                           \"][\", q, \"] <= 1\"));",
          "new_line_content": "        if (v[i][p * s[alias.second].size() + q] > 0.5) {",
          "content_same": false
        },
        {
          "line": 4505,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(1)",
          "old_line_content": "          << \"The auto-sharding solver has timed out without a solution. \"",
          "new_line_content": "    VLOG(1) << \"Solver timed out. Will now rely on sharding propagation to \"",
          "content_same": false
        },
        {
          "line": 2459,
          "old_api": null,
          "new_api": "absl::StrCat(\"s[\", alias.first, \"][\", p, \"] + s[\", alias.second,\n                           \"][\", q, \"] <= 1\")",
          "old_text": null,
          "new_text": "absl::StrCat(\"s[\", alias.first, \"][\", p, \"] + s[\", alias.second,\n                           \"][\", q, \"] <= 1\")",
          "old_line_content": "        }",
          "new_line_content": "              absl::StrCat(\"s[\", alias.first, \"][\", p, \"] + s[\", alias.second,",
          "content_same": false
        },
        {
          "line": 4507,
          "old_api": null,
          "new_api": "ModuleHasUserShardings",
          "old_text": null,
          "new_text": "ModuleHasUserShardings(module)",
          "old_line_content": "             \"annotations, we cannot rely on sharding propagation to perform \"",
          "new_line_content": "    if (!ModuleHasUserShardings(module)) {",
          "content_same": false
        },
        {
          "line": 2461,
          "old_api": null,
          "new_api": "SetCoefficient",
          "old_text": null,
          "new_text": "constraint->SetCoefficient(s[alias.first][p], 1.0)",
          "old_line_content": "    }",
          "new_line_content": "          constraint->SetCoefficient(s[alias.first][p], 1.0);",
          "content_same": false
        },
        {
          "line": 2462,
          "old_api": null,
          "new_api": "SetCoefficient",
          "old_text": null,
          "new_text": "constraint->SetCoefficient(s[alias.second][q], 1.0)",
          "old_line_content": "  }",
          "new_line_content": "          constraint->SetCoefficient(s[alias.second][q], 1.0);",
          "content_same": false
        },
        {
          "line": 4508,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(WARNING)",
          "old_line_content": "             \"heuristic-guided sharding. The module therefore may not be \"",
          "new_line_content": "      LOG(WARNING)",
          "content_same": false
        },
        {
          "line": 4517,
          "old_api": null,
          "new_api": "CHECK_GE",
          "old_text": null,
          "new_text": "CHECK_GE(min_mesh_shape_index, 0)",
          "old_line_content": "           \"report this as a bug.\";",
          "new_line_content": "    CHECK_GE(min_mesh_shape_index, 0)",
          "content_same": false
        },
        {
          "line": 2476,
          "old_api": null,
          "new_api": "NumVariables",
          "old_text": null,
          "new_text": "solver->NumVariables()",
          "old_line_content": "    }",
          "new_line_content": "        absl::StrCat(\"/tmp/model_\", solver->NumVariables(), \".proto\"),",
          "content_same": false
        },
        {
          "line": 2477,
          "old_api": null,
          "new_api": "file::Defaults()",
          "old_text": null,
          "new_text": "file::Defaults()",
          "old_line_content": "  }",
          "new_line_content": "        model_proto, file::Defaults());",
          "content_same": false
        },
        {
          "line": 2478,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "write_status.ok()",
          "old_line_content": "#endif",
          "new_line_content": "    if (!write_status.ok()) {",
          "content_same": false
        },
        {
          "line": 4524,
          "old_api": null,
          "new_api": "status",
          "old_text": null,
          "new_text": "changed[min_mesh_shape_index].status()",
          "old_line_content": "          AutoShardingResult::kModuleChangedShardingPerformed) {",
          "new_line_content": "      module_is_changed = changed[min_mesh_shape_index].status();",
          "content_same": false
        },
        {
          "line": 4527,
          "old_api": null,
          "new_api": "value",
          "old_text": null,
          "new_text": "changed[min_mesh_shape_index].value()",
          "old_line_content": "                << \" which had the minimal solver objective value of \"",
          "new_line_content": "      if (changed[min_mesh_shape_index].value() ==",
          "content_same": false
        },
        {
          "line": 4529,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(1)",
          "old_line_content": "",
          "new_line_content": "        VLOG(1) << \"Choosing mesh shape \"",
          "content_same": false
        },
        {
          "line": 4530,
          "old_api": null,
          "new_api": "spmd::ToString(mesh_shapes[min_mesh_shape_index])",
          "old_text": null,
          "new_text": "spmd::ToString(mesh_shapes[min_mesh_shape_index])",
          "old_line_content": "        absl::flat_hash_map<HloComputation*, HloComputation*>",
          "new_line_content": "                << spmd::ToString(mesh_shapes[min_mesh_shape_index])",
          "content_same": false
        },
        {
          "line": 2487,
          "old_api": null,
          "new_api": "GetNumThreads",
          "old_text": null,
          "new_text": "solver->GetNumThreads()",
          "old_line_content": "          << \"Total instructions: \" << N << \"\\n\"",
          "new_line_content": "          << \"Number of threads: \" << solver->GetNumThreads() << \"\\n\"",
          "content_same": false
        },
        {
          "line": 2488,
          "old_api": null,
          "new_api": "time_limit",
          "old_text": null,
          "new_text": "solver->time_limit()",
          "old_line_content": "          << \"Memory budget: \" << M / (1024 * 1024 * 1024) << \"GB\\n\"",
          "new_line_content": "          << \"Time limit: \" << solver->time_limit() << \"\\n\"",
          "content_same": false
        },
        {
          "line": 4536,
          "old_api": null,
          "new_api": "computation_count",
          "old_text": null,
          "new_text": "module->computation_count()",
          "old_line_content": "          computation_replacements[original_computation] = new_computation;",
          "new_line_content": "        for (size_t i = 0; i < module->computation_count(); ++i) {",
          "content_same": false
        },
        {
          "line": 4537,
          "old_api": null,
          "new_api": "mutable_computation",
          "old_text": null,
          "new_text": "module->mutable_computation(i)",
          "old_line_content": "        }",
          "new_line_content": "          auto original_computation = module->mutable_computation(i);",
          "content_same": false
        },
        {
          "line": 2494,
          "old_api": null,
          "new_api": "Solve",
          "old_text": null,
          "new_text": "solver->Solve()",
          "old_line_content": "#ifdef PLATFORM_GOOGLE",
          "new_line_content": "  auto status = solver->Solve();",
          "content_same": false
        },
        {
          "line": 4544,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "modules[min_mesh_shape_index].get()",
          "old_line_content": "",
          "new_line_content": "        module->MoveComputationsFrom(modules[min_mesh_shape_index].get());",
          "content_same": false
        },
        {
          "line": 4547,
          "old_api": null,
          "new_api": "entry_computation_layout",
          "old_text": null,
          "new_text": "modules[min_mesh_shape_index]->entry_computation_layout()",
          "old_line_content": "                 AutoShardingResult::kModuleUnchanged) {",
          "new_line_content": "            modules[min_mesh_shape_index]->entry_computation_layout();",
          "content_same": false
        },
        {
          "line": 2500,
          "old_api": null,
          "new_api": "mutable_model",
          "old_text": null,
          "new_text": "model_request.mutable_model()",
          "old_line_content": "          operations_research::MPModelRequest::SAT_INTEGER_PROGRAMMING);",
          "new_line_content": "    solver->ExportModelToProto(model_request.mutable_model());",
          "content_same": false
        },
        {
          "line": 4550,
          "old_api": null,
          "new_api": "value",
          "old_text": null,
          "new_text": "changed[min_mesh_shape_index].value()",
          "old_line_content": "        module_is_changed = false;",
          "new_line_content": "      } else if (changed[min_mesh_shape_index].value() ==",
          "content_same": false
        },
        {
          "line": 2505,
          "old_api": null,
          "new_api": "ProblemType",
          "old_text": null,
          "new_text": "solver->ProblemType()",
          "old_line_content": "    }",
          "new_line_content": "    } else if (solver->ProblemType() ==",
          "content_same": false
        },
        {
          "line": 2512,
          "old_api": null,
          "new_api": "status",
          "old_text": null,
          "new_text": "iis.status().DebugString()",
          "old_line_content": "    }",
          "new_line_content": "    LOG(INFO) << iis.status().DebugString();",
          "content_same": false
        },
        {
          "line": 4560,
          "old_api": null,
          "new_api": "absl::Now()",
          "old_text": null,
          "new_text": "absl::Now()",
          "old_line_content": "#endif",
          "new_line_content": "  absl::Time end_time = absl::Now();",
          "content_same": false
        },
        {
          "line": 2515,
          "old_api": null,
          "new_api": "model",
          "old_text": null,
          "new_text": "model_request.model().constraint(index).name()",
          "old_line_content": "          << \" - \"",
          "new_line_content": "      LOG(INFO) << \" - \" << model_request.model().constraint(index).name();",
          "content_same": false
        },
        {
          "line": 2517,
          "old_api": null,
          "new_api": "general_constraint_index",
          "old_text": null,
          "new_text": "iis.general_constraint_index()",
          "old_line_content": "    }",
          "new_line_content": "    for (int index : iis.general_constraint_index()) {",
          "content_same": false
        },
        {
          "line": 2518,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(INFO)",
          "old_line_content": "#endif",
          "new_line_content": "      LOG(INFO)",
          "content_same": false
        },
        {
          "line": 4566,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "module->ToString()",
          "old_line_content": "}",
          "new_line_content": "  XLA_VLOG_LINES(6, absl::StrCat(\"After auto sharding:\\n\", module->ToString()));",
          "content_same": false
        },
        {
          "line": 4567,
          "old_api": null,
          "new_api": "DumpHloModuleIfEnabled",
          "old_text": null,
          "new_text": "DumpHloModuleIfEnabled(*module, \"after_auto_spmd_sharding\")",
          "old_line_content": "",
          "new_line_content": "  DumpHloModuleIfEnabled(*module, \"after_auto_spmd_sharding\");",
          "content_same": false
        },
        {
          "line": 2524,
          "old_api": null,
          "new_api": "ORToolsSolverResult",
          "old_text": null,
          "new_text": "ORToolsSolverResult(\n        absl::InternalError(\"MPSolver could not find any feasible solution.\"),\n        false)",
          "old_line_content": "    auto err_msg = \"Solver timed out. Will proceed without auto sharding.\";",
          "new_line_content": "    return ORToolsSolverResult(",
          "content_same": false
        },
        {
          "line": 4578,
          "old_api": null,
          "new_api": "instructions",
          "old_text": null,
          "new_text": "entry->instructions()",
          "old_line_content": "                                            HloSharding::Replicate());",
          "new_line_content": "  for (HloInstruction* inst : entry->instructions()) {",
          "content_same": false
        },
        {
          "line": 4580,
          "old_api": null,
          "new_api": "IsTuple",
          "old_text": null,
          "new_text": "out_shape.IsTuple()",
          "old_line_content": "    } else {",
          "new_line_content": "    if (out_shape.IsTuple()) {",
          "content_same": false
        },
        {
          "line": 4583,
          "old_api": null,
          "new_api": "HloSharding::Tuple(tuple_sharding)",
          "old_text": null,
          "new_text": "HloSharding::Tuple(tuple_sharding)",
          "old_line_content": "  }",
          "new_line_content": "      inst->set_sharding(HloSharding::Tuple(tuple_sharding));",
          "content_same": false
        },
        {
          "line": 2536,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(INFO)",
          "old_line_content": "                 << \") is larger than kInfinityCost. It means the solver \"",
          "new_line_content": "  LOG(INFO) << \"Solver Status: \" << status",
          "content_same": false
        },
        {
          "line": 2537,
          "old_api": null,
          "new_api": "Value",
          "old_text": null,
          "new_text": "solver->Objective().Value()",
          "old_line_content": "                    \"chooses a solution with kInfinityCost and there may be \"",
          "new_line_content": "            << \" Objective value: \" << solver->Objective().Value();",
          "content_same": false
        },
        {
          "line": 2538,
          "old_api": null,
          "new_api": "Value",
          "old_text": null,
          "new_text": "solver->Objective().Value()",
          "old_line_content": "                    \"numerical issues when the solver considering other costs.\";",
          "new_line_content": "  if (solver->Objective().Value() >= kInfinityCost) {",
          "content_same": false
        },
        {
          "line": 2539,
          "old_api": null,
          "new_api": "Value",
          "old_text": null,
          "new_text": "solver->Objective().Value()",
          "old_line_content": "  }",
          "new_line_content": "    LOG(WARNING) << \"Objective (\" << solver->Objective().Value()",
          "content_same": false
        },
        {
          "line": 4585,
          "old_api": null,
          "new_api": "HloSharding::Replicate()",
          "old_text": null,
          "new_text": "HloSharding::Replicate()",
          "old_line_content": "  return true;",
          "new_line_content": "      inst->set_sharding(HloSharding::Replicate());",
          "content_same": false
        },
        {
          "line": 2548,
          "old_api": null,
          "new_api": "ExportModelToProto",
          "old_text": null,
          "new_text": "solver->ExportModelToProto(&model_proto)",
          "old_line_content": "    operations_research::MPSolutionResponse response;",
          "new_line_content": "    solver->ExportModelToProto(&model_proto);",
          "content_same": false
        },
        {
          "line": 2551,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(10)",
          "old_line_content": "  }",
          "new_line_content": "    VLOG(10) << \"RESPONSE:\";",
          "content_same": false
        },
        {
          "line": 2553,
          "old_api": null,
          "new_api": "FillSolutionResponseProto",
          "old_text": null,
          "new_text": "solver->FillSolutionResponseProto(&response)",
          "old_line_content": "  // Return value",
          "new_line_content": "    solver->FillSolutionResponseProto(&response);",
          "content_same": false
        },
        {
          "line": 2554,
          "old_api": null,
          "new_api": "DebugString",
          "old_text": null,
          "new_text": "response.DebugString()",
          "old_line_content": "  std::vector<int64_t> chosen_strategy(N, -1), e_val(num_edges, -1);",
          "new_line_content": "    XLA_VLOG_LINES(10, response.DebugString());",
          "content_same": false
        },
        {
          "line": 2560,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "s[i].size()",
          "old_line_content": "        break;",
          "new_line_content": "    for (int j = 0; j < s[i].size(); ++j) {",
          "content_same": false
        },
        {
          "line": 2562,
          "old_api": null,
          "new_api": "solution_value",
          "old_text": null,
          "new_text": "s[i][j]->solution_value()",
          "old_line_content": "    }",
          "new_line_content": "      if (s[i][j]->solution_value() > 0.5) {",
          "content_same": false
        },
        {
          "line": 2569,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "e[i].size()",
          "old_line_content": "        break;",
          "new_line_content": "    for (int j = 0; j < e[i].size(); ++j) {",
          "content_same": false
        },
        {
          "line": 2571,
          "old_api": null,
          "new_api": "solution_value",
          "old_text": null,
          "new_text": "e[i][j]->solution_value()",
          "old_line_content": "    }",
          "new_line_content": "      if (e[i][j]->solution_value() > 0.5) {",
          "content_same": false
        },
        {
          "line": 2584,
          "old_api": null,
          "new_api": "PrintLargestInstructions",
          "old_text": null,
          "new_text": "PrintLargestInstructions(chosen_strategy, m, L, instruction_names)",
          "old_line_content": "      false);",
          "new_line_content": "  PrintLargestInstructions(chosen_strategy, m, L, instruction_names);",
          "content_same": false
        },
        {
          "line": 2585,
          "old_api": null,
          "new_api": "Value",
          "old_text": null,
          "new_text": "ORToolsSolverResult(\n      std::make_tuple(std::move(chosen_strategy), std::move(e_val),\n                      solver->Objective().Value()),\n      false)",
          "old_line_content": "}",
          "new_line_content": "  return ORToolsSolverResult(",
          "content_same": false
        },
        {
          "line": 2586,
          "old_api": null,
          "new_api": "std::move(e_val)",
          "old_text": null,
          "new_text": "std::move(e_val)",
          "old_line_content": "",
          "new_line_content": "      std::make_tuple(std::move(chosen_strategy), std::move(e_val),",
          "content_same": false
        },
        {
          "line": 2587,
          "old_api": null,
          "new_api": "Value",
          "old_text": null,
          "new_text": "solver->Objective().Value()",
          "old_line_content": "ORToolsSolverResult CallSolver(",
          "new_line_content": "                      solver->Objective().Value()),",
          "content_same": false
        },
        {
          "line": 2598,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "leaf_strategies.size()",
          "old_line_content": "  std::vector<std::pair<int, int>> E;",
          "new_line_content": "  int64_t N = leaf_strategies.size();",
          "content_same": false
        },
        {
          "line": 2605,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "E.push_back(iter.first)",
          "old_line_content": "      for (size_t j = 0; j < edge_cost.m_; j++) {",
          "new_line_content": "    E.push_back(iter.first);",
          "content_same": false
        },
        {
          "line": 2610,
          "old_api": null,
          "new_api": "edge_cost",
          "old_text": null,
          "new_text": "edge_cost(i, j)",
          "old_line_content": "  }",
          "new_line_content": "        rij.push_back(edge_cost(i, j));",
          "content_same": false
        },
        {
          "line": 2613,
          "old_api": null,
          "new_api": "std::move(rij)",
          "old_text": null,
          "new_text": "std::move(rij)",
          "old_line_content": "  std::vector<std::string> instruction_names;",
          "new_line_content": "    r.push_back(std::move(rij));",
          "content_same": false
        },
        {
          "line": 2616,
          "old_api": null,
          "new_api": "instructions",
          "old_text": null,
          "new_text": "sequence.instructions()",
          "old_line_content": "  std::vector<std::vector<double>> c, d, m;",
          "new_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "content_same": false
        },
        {
          "line": 2627,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "ci.push_back(strategies->leaf_vector[j].compute_cost)",
          "old_line_content": "    }",
          "new_line_content": "      ci.push_back(strategies->leaf_vector[j].compute_cost);",
          "content_same": false
        },
        {
          "line": 2632,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "c.push_back(ci)",
          "old_line_content": "",
          "new_line_content": "    c.push_back(ci);",
          "content_same": false
        },
        {
          "line": 2633,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "d.push_back(di)",
          "old_line_content": "  // Serialize special edges that forces a alias pair have the same sharding",
          "new_line_content": "    d.push_back(di);",
          "content_same": false
        },
        {
          "line": 2634,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "m.push_back(mi)",
          "old_line_content": "  // spec",
          "new_line_content": "    m.push_back(mi);",
          "content_same": false
        },
        {
          "line": 2644,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "src_strategies->leaf_vector.size()",
          "old_line_content": "        if (src_strategies->leaf_vector[i].output_sharding ==",
          "new_line_content": "    Matrix raw_cost(src_strategies->leaf_vector.size(),",
          "content_same": false
        },
        {
          "line": 2645,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "dst_strategies->leaf_vector.size()",
          "old_line_content": "            dst_strategies->leaf_vector[j].output_sharding) {",
          "new_line_content": "                    dst_strategies->leaf_vector.size());",
          "content_same": false
        },
        {
          "line": 2647,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "dst_strategies->leaf_vector.size()",
          "old_line_content": "        } else {",
          "new_line_content": "      for (size_t j = 0; j < dst_strategies->leaf_vector.size(); ++j) {",
          "content_same": false
        },
        {
          "line": 2650,
          "old_api": null,
          "new_api": "raw_cost",
          "old_text": null,
          "new_text": "raw_cost(i, j)",
          "old_line_content": "      }",
          "new_line_content": "          raw_cost(i, j) = 0.0;",
          "content_same": false
        },
        {
          "line": 2652,
          "old_api": null,
          "new_api": "raw_cost",
          "old_text": null,
          "new_text": "raw_cost(i, j)",
          "old_line_content": "    int idx_a = pair.first;",
          "new_line_content": "          raw_cost(i, j) = 1.0;",
          "content_same": false
        },
        {
          "line": 2665,
          "old_api": null,
          "new_api": "assign",
          "old_text": null,
          "new_text": "row_indices.assign(s_len[idx_a], 0)",
          "old_line_content": "    if (s_follow[idx_b] >= 0) {",
          "new_line_content": "      row_indices.assign(s_len[idx_a], 0);",
          "content_same": false
        },
        {
          "line": 2677,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "row_indices.size()",
          "old_line_content": "    std::vector<double> vij;",
          "new_line_content": "    CHECK_EQ(s_len[idx_a], row_indices.size());",
          "content_same": false
        },
        {
          "line": 2678,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "col_indices.size()",
          "old_line_content": "    for (int i : row_indices) {",
          "new_line_content": "    CHECK_EQ(s_len[idx_b], col_indices.size());",
          "content_same": false
        },
        {
          "line": 2684,
          "old_api": null,
          "new_api": "raw_cost",
          "old_text": null,
          "new_text": "raw_cost(i, j)",
          "old_line_content": "  }",
          "new_line_content": "        vij.push_back(raw_cost(i, j));",
          "content_same": false
        },
        {
          "line": 2691,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "liveness_set.size()",
          "old_line_content": "        traverse_live_instructions;",
          "new_line_content": "  std::vector<std::vector<int>> L(liveness_set.size());",
          "content_same": false
        },
        {
          "line": 2692,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "liveness_set.size()",
          "old_line_content": "    traverse_live_instructions = [&](const StrategyVector* strategies,",
          "new_line_content": "  for (size_t t = 0; t < liveness_set.size(); ++t) {",
          "content_same": false
        },
        {
          "line": 2699,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "current_liveness_set_indices.push_back(\n            strategies->childs.at(index.front())->id)",
          "old_line_content": "      }",
          "new_line_content": "        current_liveness_set_indices.push_back(",
          "content_same": false
        },
        {
          "line": 2700,
          "old_api": null,
          "new_api": "front",
          "old_text": null,
          "new_text": "index.front()",
          "old_line_content": "    };",
          "new_line_content": "            strategies->childs.at(index.front())->id);",
          "content_same": false
        },
        {
          "line": 2710,
          "old_api": null,
          "new_api": "index",
          "old_text": null,
          "new_text": "value->index()",
          "old_line_content": "                           instruction_names, solver_timeout_in_seconds,",
          "new_line_content": "                                 value->index());",
          "content_same": false
        },
        {
          "line": 2713,
          "old_api": null,
          "new_api": "CallORToolsSolver",
          "old_text": null,
          "new_text": "CallORToolsSolver(N, M, s_len, s_follow, E, L, c, d, m, r, A, v,\n                           instruction_names, solver_timeout_in_seconds,\n                           crash_at_infinity_costs_check)",
          "old_line_content": "",
          "new_line_content": "  return CallORToolsSolver(N, M, s_len, s_follow, E, L, c, d, m, r, A, v,",
          "content_same": false
        },
        {
          "line": 2720,
          "old_api": null,
          "new_api": "instructions",
          "old_text": null,
          "new_text": "sequence.instructions()",
          "old_line_content": "      continue;",
          "new_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "content_same": false
        },
        {
          "line": 2734,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(INFO)",
          "old_line_content": "      }",
          "new_line_content": "        LOG(INFO) << \"Instruction is not fully sharded: (\" << size << \" GB) \"",
          "content_same": false
        },
        {
          "line": 2739,
          "old_api": null,
          "new_api": "operands",
          "old_text": null,
          "new_text": "ins->operands()",
          "old_line_content": "          }",
          "new_line_content": "      for (const auto& op : ins->operands()) {",
          "content_same": false
        },
        {
          "line": 2740,
          "old_api": null,
          "new_api": "has_sharding",
          "old_text": null,
          "new_text": "op->has_sharding()",
          "old_line_content": "          std::vector<int64_t> ins_sharded_dims =",
          "new_line_content": "        if (op->has_sharding()) {",
          "content_same": false
        },
        {
          "line": 2750,
          "old_api": null,
          "new_api": "tile_assignment",
          "old_text": null,
          "new_text": "op->sharding().tile_assignment().dimensions()",
          "old_line_content": "            not_consistent = true;",
          "new_line_content": "                  op->sharding().tile_assignment().dimensions(),",
          "content_same": false
        },
        {
          "line": 2751,
          "old_api": null,
          "new_api": "ReplicateOnLastTileDim",
          "old_text": null,
          "new_text": "op->sharding().ReplicateOnLastTileDim()",
          "old_line_content": "          } else {",
          "new_line_content": "                  op->sharding().ReplicateOnLastTileDim());",
          "content_same": false
        },
        {
          "line": 2756,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "ins_sharded_dims.size()",
          "old_line_content": "              }",
          "new_line_content": "            for (size_t i = 0; i < ins_sharded_dims.size(); i++) {",
          "content_same": false
        },
        {
          "line": 2757,
          "old_api": null,
          "new_api": "at",
          "old_text": null,
          "new_text": "op_sharded_dims.at(i)",
          "old_line_content": "            }",
          "new_line_content": "              if (op->shape().dimensions().at(op_sharded_dims.at(i)) !=",
          "content_same": false
        },
        {
          "line": 2758,
          "old_api": null,
          "new_api": "at",
          "old_text": null,
          "new_text": "ins_sharded_dims.at(i)",
          "old_line_content": "          }",
          "new_line_content": "                  ins->shape().dimensions().at(ins_sharded_dims.at(i))) {",
          "content_same": false
        },
        {
          "line": 2769,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "absl::StrCat(\"Shardings not consistent (op size \",\n                                           op_size, \" GB):\", ins->ToString(),\n                                           \"\\n Operand: \", op->ToString())",
          "old_line_content": "          }",
          "new_line_content": "            std::string str = absl::StrCat(\"Shardings not consistent (op size \",",
          "content_same": false
        },
        {
          "line": 2770,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "ins->ToString()",
          "old_line_content": "        } else {",
          "new_line_content": "                                           op_size, \" GB):\", ins->ToString(),",
          "content_same": false
        },
        {
          "line": 2772,
          "old_api": null,
          "new_api": "std::move(str)",
          "old_text": null,
          "new_text": "std::move(str)",
          "old_line_content": "                    << \" does not have sharding.\";",
          "new_line_content": "            size_string.push_back(std::make_pair(op_size, std::move(str)));",
          "content_same": false
        },
        {
          "line": 2775,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "op->name()",
          "old_line_content": "    }",
          "new_line_content": "          LOG(INFO) << \"Instruction \" << op->name()",
          "content_same": false
        },
        {
          "line": 2789,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "size_string.size()",
          "old_line_content": "}",
          "new_line_content": "  k = std::min(k, size_string.size());",
          "content_same": false
        },
        {
          "line": 2791,
          "old_api": null,
          "new_api": "at",
          "old_text": null,
          "new_text": "size_string.at(t)",
          "old_line_content": "// Set the HloSharding for all instructions according to the ILP solution.",
          "new_line_content": "    LOG(INFO) << size_string.at(t).second;",
          "content_same": false
        },
        {
          "line": 2804,
          "old_api": null,
          "new_api": "find",
          "old_text": null,
          "new_text": "strategy_map.find(inst)",
          "old_line_content": "",
          "new_line_content": "    auto iter = strategy_map.find(inst);",
          "content_same": false
        },
        {
          "line": 2809,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "iter->second.get()",
          "old_line_content": "      std::vector<HloSharding> output_flattened_shardings;",
          "new_line_content": "    const StrategyVector* strategies = iter->second.get();",
          "content_same": false
        },
        {
          "line": 2811,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "inst->shape()",
          "old_line_content": "      bool set_tuple_sharding = true;",
          "new_line_content": "      const Shape& out_shape = inst->shape();",
          "content_same": false
        },
        {
          "line": 2824,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "output_flattened_shardings.push_back(\n            t->leaf_vector[stra_idx].output_sharding)",
          "old_line_content": "      int i = 0;",
          "new_line_content": "        output_flattened_shardings.push_back(",
          "content_same": false
        },
        {
          "line": 2837,
          "old_api": null,
          "new_api": "GetShardingStrategy",
          "old_text": null,
          "new_text": "GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "old_line_content": "      }",
          "new_line_content": "          GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "content_same": false
        },
        {
          "line": 2843,
          "old_api": null,
          "new_api": "IsReplicated",
          "old_text": null,
          "new_text": "sharding_spec.IsReplicated()",
          "old_line_content": "      }",
          "new_line_content": "      if (sharding_spec.IsReplicated() && !last_iteration) {",
          "content_same": false
        },
        {
          "line": 2844,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "inst->name()",
          "old_line_content": "    }",
          "new_line_content": "        LOG(INFO) << \"skip setting shardings for inst \" << inst->name();",
          "content_same": false
        },
        {
          "line": 2846,
          "old_api": null,
          "new_api": "set_sharding",
          "old_text": null,
          "new_text": "inst->set_sharding(sharding_spec)",
          "old_line_content": "}",
          "new_line_content": "        inst->set_sharding(sharding_spec);",
          "content_same": false
        },
        {
          "line": 2858,
          "old_api": null,
          "new_api": "instructions",
          "old_text": null,
          "new_text": "sequence.instructions()",
          "old_line_content": "  ReshardingCache* resharding_cache = &resharding_cache_entity;",
          "new_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "content_same": false
        },
        {
          "line": 2878,
          "old_api": null,
          "new_api": "sharding",
          "old_text": null,
          "new_text": "rhs->sharding()",
          "old_line_content": "",
          "new_line_content": "      const HloSharding& rhs_sharding = rhs->sharding();",
          "content_same": false
        },
        {
          "line": 2879,
          "old_api": null,
          "new_api": "dot_dimension_numbers",
          "old_text": null,
          "new_text": "inst->dot_dimension_numbers()",
          "old_line_content": "      const auto& lhs_tensor_dim_to_mesh_dim =",
          "new_line_content": "      const DotDimensionNumbers& dot_dnums = inst->dot_dimension_numbers();",
          "content_same": false
        },
        {
          "line": 2881,
          "old_api": null,
          "new_api": "rhs_contracting_dimensions",
          "old_text": null,
          "new_text": "dot_dnums.rhs_contracting_dimensions()",
          "old_line_content": "      const auto& rhs_tensor_dim_to_mesh_dim =",
          "new_line_content": "      const auto& rhs_con_dims = dot_dnums.rhs_contracting_dimensions();",
          "content_same": false
        },
        {
          "line": 2886,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "rhs->shape()",
          "old_line_content": "          rhs_tensor_dim_to_mesh_dim[rhs_con_dims[0]] == -1) {",
          "new_line_content": "          cluster_env.GetTensorDimToMeshDimWrapper(rhs->shape(), rhs_sharding);",
          "content_same": false
        },
        {
          "line": 2888,
          "old_api": null,
          "new_api": "absl::StrContains(stra.name, \"allreduce\")",
          "old_text": null,
          "new_text": "absl::StrContains(stra.name, \"allreduce\")",
          "old_line_content": "        // communication",
          "new_line_content": "      if (absl::StrContains(stra.name, \"allreduce\") &&",
          "content_same": false
        },
        {
          "line": 2897,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "stra.ToString()",
          "old_line_content": "                                    device_mesh, resharding_cache);",
          "new_line_content": "            << inst->ToString() << \", strategy : \" << stra.ToString();",
          "content_same": false
        },
        {
          "line": 2898,
          "old_api": null,
          "new_api": "FixMixedMeshShapeResharding",
          "old_text": null,
          "new_text": "FixMixedMeshShapeResharding(inst, 0, stra.input_shardings[0],\n                                    device_mesh, resharding_cache)",
          "old_line_content": "      }",
          "new_line_content": "        FixMixedMeshShapeResharding(inst, 0, stra.input_shardings[0],",
          "content_same": false
        },
        {
          "line": 2900,
          "old_api": null,
          "new_api": "FixMixedMeshShapeResharding",
          "old_text": null,
          "new_text": "FixMixedMeshShapeResharding(inst, 1, stra.input_shardings[1],\n                                    device_mesh, resharding_cache)",
          "old_line_content": "      const ShardingStrategy& stra =",
          "new_line_content": "        FixMixedMeshShapeResharding(inst, 1, stra.input_shardings[1],",
          "content_same": false
        },
        {
          "line": 2906,
          "old_api": null,
          "new_api": "operand",
          "old_text": null,
          "new_text": "inst->operand(0)",
          "old_line_content": "      const ConvolutionDimensionNumbers& conv_dnums =",
          "new_line_content": "      const HloInstruction* lhs = inst->operand(0);",
          "content_same": false
        },
        {
          "line": 2909,
          "old_api": null,
          "new_api": "sharding",
          "old_text": null,
          "new_text": "rhs->sharding()",
          "old_line_content": "      const int rhs_in_channel_dim =",
          "new_line_content": "      const HloSharding& rhs_sharding = rhs->sharding();",
          "content_same": false
        },
        {
          "line": 2911,
          "old_api": null,
          "new_api": "convolution_dimension_numbers",
          "old_text": null,
          "new_text": "inst->convolution_dimension_numbers()",
          "old_line_content": "",
          "new_line_content": "          inst->convolution_dimension_numbers();",
          "content_same": false
        },
        {
          "line": 2912,
          "old_api": null,
          "new_api": "input_feature_dimension",
          "old_text": null,
          "new_text": "conv_dnums.input_feature_dimension()",
          "old_line_content": "      const auto& lhs_tensor_dim_to_mesh_dim =",
          "new_line_content": "      const int lhs_in_channel_dim = conv_dnums.input_feature_dimension();",
          "content_same": false
        },
        {
          "line": 2914,
          "old_api": null,
          "new_api": "kernel_input_feature_dimension",
          "old_text": null,
          "new_text": "conv_dnums.kernel_input_feature_dimension()",
          "old_line_content": "      const auto& rhs_tensor_dim_to_mesh_dim =",
          "new_line_content": "          conv_dnums.kernel_input_feature_dimension();",
          "content_same": false
        },
        {
          "line": 2919,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "rhs->shape()",
          "old_line_content": "          rhs_tensor_dim_to_mesh_dim[rhs_in_channel_dim] == -1) {",
          "new_line_content": "          cluster_env.GetTensorDimToMeshDimWrapper(rhs->shape(), rhs_sharding);",
          "content_same": false
        },
        {
          "line": 2921,
          "old_api": null,
          "new_api": "absl::StrContains(stra.name, \"allreduce\")",
          "old_text": null,
          "new_text": "absl::StrContains(stra.name, \"allreduce\")",
          "old_line_content": "        // communication",
          "new_line_content": "      if (absl::StrContains(stra.name, \"allreduce\") &&",
          "content_same": false
        },
        {
          "line": 2927,
          "old_api": null,
          "new_api": "FixMixedMeshShapeResharding",
          "old_text": null,
          "new_text": "FixMixedMeshShapeResharding(inst, 0, stra.input_shardings[0],\n                                    device_mesh, resharding_cache)",
          "old_line_content": "      }",
          "new_line_content": "        FixMixedMeshShapeResharding(inst, 0, stra.input_shardings[0],",
          "content_same": false
        },
        {
          "line": 2929,
          "old_api": null,
          "new_api": "FixMixedMeshShapeResharding",
          "old_text": null,
          "new_text": "FixMixedMeshShapeResharding(inst, 1, stra.input_shardings[1],\n                                    device_mesh, resharding_cache)",
          "old_line_content": "      const ShardingStrategy& stra =",
          "new_line_content": "        FixMixedMeshShapeResharding(inst, 1, stra.input_shardings[1],",
          "content_same": false
        },
        {
          "line": 2934,
          "old_api": null,
          "new_api": "GetShardingStrategy",
          "old_text": null,
          "new_text": "GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "old_line_content": "      }",
          "new_line_content": "          GetShardingStrategy(inst, strategy_map, cost_graph, s_val);",
          "content_same": false
        },
        {
          "line": 2935,
          "old_api": null,
          "new_api": "empty",
          "old_text": null,
          "new_text": "stra.input_shardings.empty()",
          "old_line_content": "    } else {",
          "new_line_content": "      if (!stra.input_shardings.empty()) {",
          "content_same": false
        },
        {
          "line": 2936,
          "old_api": null,
          "new_api": "FixMixedMeshShapeResharding",
          "old_text": null,
          "new_text": "FixMixedMeshShapeResharding(inst, 0, stra.input_shardings[0],\n                                    device_mesh, resharding_cache)",
          "old_line_content": "      // TODO(pratikf): We currently skip over tuple shaped instructions here as",
          "new_line_content": "        FixMixedMeshShapeResharding(inst, 0, stra.input_shardings[0],",
          "content_same": false
        },
        {
          "line": 2943,
          "old_api": null,
          "new_api": "IsTuple",
          "old_text": null,
          "new_text": "inst->shape().IsTuple()",
          "old_line_content": "          case HloOpcode::kSort: {",
          "new_line_content": "      if (inst->shape().IsTuple()) {",
          "content_same": false
        },
        {
          "line": 2949,
          "old_api": null,
          "new_api": "GetShardingStrategyForTuple",
          "old_text": null,
          "new_text": "GetShardingStrategyForTuple(\n                  inst, i, strategy_map, cost_graph, s_val)",
          "old_line_content": "                                            device_mesh, resharding_cache);",
          "new_line_content": "              const ShardingStrategy& stra = GetShardingStrategyForTuple(",
          "content_same": false
        },
        {
          "line": 2951,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "stra.input_shardings.size()",
          "old_line_content": "            }",
          "new_line_content": "              if (stra.input_shardings.size() > i) {",
          "content_same": false
        },
        {
          "line": 2952,
          "old_api": null,
          "new_api": "FixMixedMeshShapeResharding",
          "old_text": null,
          "new_text": "FixMixedMeshShapeResharding(inst, i, stra.input_shardings[i],\n                                            device_mesh, resharding_cache)",
          "old_line_content": "            break;",
          "new_line_content": "                FixMixedMeshShapeResharding(inst, i, stra.input_shardings[i],",
          "content_same": false
        },
        {
          "line": 2960,
          "old_api": null,
          "new_api": "GetShardingStrategyForTuple",
          "old_text": null,
          "new_text": "GetShardingStrategyForTuple(\n                  inst, i, strategy_map, cost_graph, s_val)",
          "old_line_content": "                                          device_mesh, resharding_cache);",
          "new_line_content": "              const ShardingStrategy& stra = GetShardingStrategyForTuple(",
          "content_same": false
        },
        {
          "line": 2962,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "stra.input_shardings.size()",
          "old_line_content": "            break;",
          "new_line_content": "              CHECK_EQ(stra.input_shardings.size(), 1);",
          "content_same": false
        },
        {
          "line": 2963,
          "old_api": null,
          "new_api": "FixMixedMeshShapeResharding",
          "old_text": null,
          "new_text": "FixMixedMeshShapeResharding(inst, i, stra.input_shardings[0],\n                                          device_mesh, resharding_cache)",
          "old_line_content": "          }",
          "new_line_content": "              FixMixedMeshShapeResharding(inst, i, stra.input_shardings[0],",
          "content_same": false
        },
        {
          "line": 2988,
          "old_api": null,
          "new_api": "operand_count",
          "old_text": null,
          "new_text": "inst->operand_count()",
          "old_line_content": "            }",
          "new_line_content": "          for (size_t i = 0; i < inst->operand_count(); ++i) {",
          "content_same": false
        },
        {
          "line": 2989,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "stra.input_shardings.size()",
          "old_line_content": "          }",
          "new_line_content": "            if (stra.input_shardings.size() > i) {",
          "content_same": false
        },
        {
          "line": 2990,
          "old_api": null,
          "new_api": "FixMixedMeshShapeResharding",
          "old_text": null,
          "new_text": "FixMixedMeshShapeResharding(inst, i, stra.input_shardings[i],\n                                          device_mesh, resharding_cache)",
          "old_line_content": "        }",
          "new_line_content": "              FixMixedMeshShapeResharding(inst, i, stra.input_shardings[i],",
          "content_same": false
        },
        {
          "line": 3005,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "liveness_set[i].size()",
          "old_line_content": "    }",
          "new_line_content": "    names.reserve(liveness_set[i].size());",
          "content_same": false
        },
        {
          "line": 3008,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "value->index().ToString()",
          "old_line_content": "  }",
          "new_line_content": "                                   value->index().ToString()));",
          "content_same": false
        },
        {
          "line": 3010,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "names.end()",
          "old_line_content": "}",
          "new_line_content": "    std::sort(names.begin(), names.end());",
          "content_same": false
        },
        {
          "line": 3011,
          "old_api": null,
          "new_api": "absl::StrJoin(names, \", \")",
          "old_text": null,
          "new_text": "absl::StrJoin(names, \", \")",
          "old_line_content": "",
          "new_line_content": "    absl::StrAppend(&str, \"Time \", i, \": \", absl::StrJoin(names, \", \"), \"\\n\");",
          "content_same": false
        },
        {
          "line": 3019,
          "old_api": null,
          "new_api": "instructions",
          "old_text": null,
          "new_text": "sequence.instructions()",
          "old_line_content": "  }",
          "new_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "content_same": false
        },
        {
          "line": 3020,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "instructions.size()",
          "old_line_content": "  return str;",
          "new_line_content": "  for (size_t i = 0; i < instructions.size(); ++i) {",
          "content_same": false
        },
        {
          "line": 3021,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "instructions[i]->ToString()",
          "old_line_content": "}",
          "new_line_content": "    absl::StrAppend(&str, \"Instruction \", i, \": \", instructions[i]->ToString(),",
          "content_same": false
        },
        {
          "line": 3031,
          "old_api": null,
          "new_api": "instructions",
          "old_text": null,
          "new_text": "sequence.instructions()",
          "old_line_content": "  }",
          "new_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "content_same": false
        },
        {
          "line": 3032,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "instructions.size()",
          "old_line_content": "  return str;",
          "new_line_content": "  for (size_t i = 0; i < instructions.size(); ++i) {",
          "content_same": false
        },
        {
          "line": 3033,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "instructions[i]->ToString()",
          "old_line_content": "}",
          "new_line_content": "    absl::StrAppend(&str, \"Instruction \", i, \": \", instructions[i]->ToString(),",
          "content_same": false
        },
        {
          "line": 3034,
          "old_api": null,
          "new_api": "at",
          "old_text": null,
          "new_text": "strategy_map.at(instructions[i])->ToString()",
          "old_line_content": "",
          "new_line_content": "                    \"\\n\", strategy_map.at(instructions[i])->ToString());",
          "content_same": false
        },
        {
          "line": 3049,
          "old_api": null,
          "new_api": "instructions",
          "old_text": null,
          "new_text": "sequence.instructions()",
          "old_line_content": "  for (size_t i = 0; i < N; ++i) {",
          "new_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "content_same": false
        },
        {
          "line": 3055,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "instructions[leaf_strategies[i]->instruction_id]->ToString(\n                        HloPrintOptions::ShortParsable())",
          "old_line_content": "    if (cost_graph.follow_idx_[i] < 0) {",
          "new_line_content": "                    instructions[leaf_strategies[i]->instruction_id]->ToString(",
          "content_same": false
        },
        {
          "line": 3058,
          "old_api": null,
          "new_api": "RemapIndex",
          "old_text": null,
          "new_text": "cost_graph.RemapIndex(i, s_val[i])",
          "old_line_content": "    } else {",
          "new_line_content": "    int stra_idx = cost_graph.RemapIndex(i, s_val[i]);",
          "content_same": false
        },
        {
          "line": 3061,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "leaf_strategies[i]->leaf_vector[stra_idx].ToString()",
          "old_line_content": "                      \" follow \", cost_graph.follow_idx_[i], \"\\n\");",
          "new_line_content": "          &str, leaf_strategies[i]->leaf_vector[stra_idx].ToString(), \"\\n\");",
          "content_same": false
        },
        {
          "line": 3063,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "absl::StrAppend(&str,\n                      leaf_strategies[i]->leaf_vector[stra_idx].ToString(),\n                      \" follow \", cost_graph.follow_idx_[i], \"\\n\")",
          "old_line_content": "  }",
          "new_line_content": "      absl::StrAppend(&str,",
          "content_same": false
        },
        {
          "line": 3064,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "leaf_strategies[i]->leaf_vector[stra_idx].ToString()",
          "old_line_content": "",
          "new_line_content": "                      leaf_strategies[i]->leaf_vector[stra_idx].ToString(),",
          "content_same": false
        },
        {
          "line": 3086,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "child.get()",
          "old_line_content": "    int64_t ins_idx = strategies->id;",
          "new_line_content": "        m += calculate_memory_usage(child.get());",
          "content_same": false
        },
        {
          "line": 3097,
          "old_api": null,
          "new_api": "at",
          "old_text": null,
          "new_text": "liveness_set.at(t)",
          "old_line_content": "",
          "new_line_content": "    for (const auto& val : liveness_set.at(t)) {",
          "content_same": false
        },
        {
          "line": 3099,
          "old_api": null,
          "new_api": "at",
          "old_text": null,
          "new_text": "strategy_map.at(ins).get()",
          "old_line_content": "        // Prints out the largest tensors.",
          "new_line_content": "      auto tmp = calculate_memory_usage(strategy_map.at(ins).get());",
          "content_same": false
        },
        {
          "line": 3102,
          "old_api": null,
          "new_api": "VLOG_IS_ON",
          "old_text": null,
          "new_text": "VLOG_IS_ON(6)",
          "old_line_content": "                        \" MB; mem=\", mem / (1024 * 1024), \" MB\\n\");",
          "new_line_content": "      if (VLOG_IS_ON(6) && tmp / (1024 * 1024) > 1) {",
          "content_same": false
        },
        {
          "line": 3104,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "ins->name()",
          "old_line_content": "    }",
          "new_line_content": "        absl::StrAppend(&str, \"  \", ins->name(),",
          "content_same": false
        },
        {
          "line": 3109,
          "old_api": null,
          "new_api": "std::make_pair(t, mem)",
          "old_text": null,
          "new_text": "std::make_pair(t, mem)",
          "old_line_content": "  }",
          "new_line_content": "    time_memory_usage.push_back(std::make_pair(t, mem));",
          "content_same": false
        },
        {
          "line": 3110,
          "old_api": null,
          "new_api": "VLOG_IS_ON",
          "old_text": null,
          "new_text": "VLOG_IS_ON(6)",
          "old_line_content": "",
          "new_line_content": "    if (VLOG_IS_ON(6)) {",
          "content_same": false
        },
        {
          "line": 3111,
          "old_api": null,
          "new_api": "absl::StrAppend(&str, \"Time \", t, \": \", mem / (1024 * 1024), \" MB\\n\")",
          "old_text": null,
          "new_text": "absl::StrAppend(&str, \"Time \", t, \": \", mem / (1024 * 1024), \" MB\\n\")",
          "old_line_content": "  struct {",
          "new_line_content": "      absl::StrAppend(&str, \"Time \", t, \": \", mem / (1024 * 1024), \" MB\\n\");",
          "content_same": false
        },
        {
          "line": 3121,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "time_memory_usage.end()",
          "old_line_content": "                  \"consumption is \",",
          "new_line_content": "  std::sort(time_memory_usage.begin(), time_memory_usage.end(), TimeMemLarger);",
          "content_same": false
        },
        {
          "line": 3126,
          "old_api": null,
          "new_api": "front",
          "old_text": null,
          "new_text": "time_memory_usage.front()",
          "old_line_content": "  size_t k = 3;",
          "new_line_content": "                  time_memory_usage.front().second / (1024 * 1024 * 1024),",
          "content_same": false
        },
        {
          "line": 3136,
          "old_api": null,
          "new_api": "at",
          "old_text": null,
          "new_text": "strategy_map.at(ins).get()",
          "old_line_content": "      }",
          "new_line_content": "      auto mem = calculate_memory_usage(strategy_map.at(ins).get());",
          "content_same": false
        },
        {
          "line": 3138,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "std::make_pair(\n            absl::StrCat(ins->name(), val->index().ToString()), mem)",
          "old_line_content": "  }",
          "new_line_content": "        instruction_mem.push_back(std::make_pair(",
          "content_same": false
        },
        {
          "line": 3139,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "val->index().ToString()",
          "old_line_content": "",
          "new_line_content": "            absl::StrCat(ins->name(), val->index().ToString()), mem));",
          "content_same": false
        },
        {
          "line": 3156,
          "old_api": null,
          "new_api": "at",
          "old_text": null,
          "new_text": "absl::StrAppend(\n        &str, \"instruction name: \", instruction_mem.at(i).first,\n        \" memory usage: \", instruction_mem.at(i).second / (1024 * 1024 * 1024),\n        \"GB\\n\")",
          "old_line_content": "  }",
          "new_line_content": "    absl::StrAppend(",
          "content_same": false
        },
        {
          "line": 3157,
          "old_api": null,
          "new_api": "at",
          "old_text": null,
          "new_text": "instruction_mem.at(i)",
          "old_line_content": "",
          "new_line_content": "        &str, \"instruction name: \", instruction_mem.at(i).first,",
          "content_same": false
        },
        {
          "line": 3158,
          "old_api": null,
          "new_api": "at",
          "old_text": null,
          "new_text": "instruction_mem.at(i)",
          "old_line_content": "  return str;",
          "new_line_content": "        \" memory usage: \", instruction_mem.at(i).second / (1024 * 1024 * 1024),",
          "content_same": false
        },
        {
          "line": 3172,
          "old_api": null,
          "new_api": "IsTuple",
          "old_text": null,
          "new_text": "inst->sharding().IsTuple()",
          "old_line_content": "  }",
          "new_line_content": "  if (!inst->sharding().IsTuple()) {",
          "content_same": false
        },
        {
          "line": 3173,
          "old_api": null,
          "new_api": "sharding",
          "old_text": null,
          "new_text": "inst->sharding()",
          "old_line_content": "}",
          "new_line_content": "    preserve_shardings[inst->name()] = {inst->sharding()};",
          "content_same": false
        },
        {
          "line": 3175,
          "old_api": null,
          "new_api": "tuple_elements",
          "old_text": null,
          "new_text": "inst->sharding().tuple_elements()",
          "old_line_content": "// are preserved after this pass.",
          "new_line_content": "    preserve_shardings[inst->name()] = inst->sharding().tuple_elements();",
          "content_same": false
        },
        {
          "line": 3185,
          "old_api": null,
          "new_api": "computations",
          "old_text": null,
          "new_text": "module->computations()",
          "old_line_content": "          // Also preserve the shardings of copy ops that are the users of those",
          "new_line_content": "    for (const auto computation : module->computations()) {",
          "content_same": false
        },
        {
          "line": 3186,
          "old_api": null,
          "new_api": "instructions",
          "old_text": null,
          "new_text": "computation->instructions()",
          "old_line_content": "          // instructions.",
          "new_line_content": "      for (const auto inst : computation->instructions()) {",
          "content_same": false
        },
        {
          "line": 3191,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "user->opcode()",
          "old_line_content": "      }",
          "new_line_content": "          if (user->opcode() == HloOpcode::kCopy) {",
          "content_same": false
        },
        {
          "line": 3192,
          "old_api": null,
          "new_api": "SaveShardingForInstruction",
          "old_text": null,
          "new_text": "SaveShardingForInstruction(preserve_shardings, user)",
          "old_line_content": "    }",
          "new_line_content": "            SaveShardingForInstruction(preserve_shardings, user);",
          "content_same": false
        },
        {
          "line": 3201,
          "old_api": null,
          "new_api": "entry_computation",
          "old_text": null,
          "new_text": "module->entry_computation()->parameter_instructions()",
          "old_line_content": "        // instructions.",
          "new_line_content": "         module->entry_computation()->parameter_instructions()) {",
          "content_same": false
        },
        {
          "line": 3206,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "user->opcode()",
          "old_line_content": "    }",
          "new_line_content": "        if (user->opcode() == HloOpcode::kCopy) {",
          "content_same": false
        },
        {
          "line": 3207,
          "old_api": null,
          "new_api": "SaveShardingForInstruction",
          "old_text": null,
          "new_text": "SaveShardingForInstruction(preserve_shardings, user)",
          "old_line_content": "    // Saves output shardings",
          "new_line_content": "          SaveShardingForInstruction(preserve_shardings, user);",
          "content_same": false
        },
        {
          "line": 3213,
          "old_api": null,
          "new_api": "SaveShardingForInstruction",
          "old_text": null,
          "new_text": "SaveShardingForInstruction(preserve_shardings, inst)",
          "old_line_content": "                 \"elemenet of tuples): \";",
          "new_line_content": "    SaveShardingForInstruction(preserve_shardings, inst);",
          "content_same": false
        },
        {
          "line": 3215,
          "old_api": null,
          "new_api": "VLOG_IS_ON",
          "old_text": null,
          "new_text": "VLOG_IS_ON(1)",
          "old_line_content": "      std::string sharding;",
          "new_line_content": "  if (VLOG_IS_ON(1)) {",
          "content_same": false
        },
        {
          "line": 3216,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(INFO)",
          "old_line_content": "      for (const auto& s : tmp.second) {",
          "new_line_content": "    LOG(INFO) << \"User shardings that need to be kept (printing only the 1st \"",
          "content_same": false
        },
        {
          "line": 3221,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "s.ToString()",
          "old_line_content": "  }",
          "new_line_content": "        sharding += s.ToString() + \",\";",
          "content_same": false
        },
        {
          "line": 3223,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(INFO)",
          "old_line_content": "}",
          "new_line_content": "      LOG(INFO) << tmp.first << \": \" << sharding;",
          "content_same": false
        },
        {
          "line": 3234,
          "old_api": null,
          "new_api": "computations",
          "old_text": null,
          "new_text": "module->computations()",
          "old_line_content": "      }",
          "new_line_content": "  for (const auto computation : module->computations()) {",
          "content_same": false
        },
        {
          "line": 3239,
          "old_api": null,
          "new_api": "has_sharding",
          "old_text": null,
          "new_text": "inst->has_sharding()",
          "old_line_content": "                   << \"\\nbut it's empty.\";",
          "new_line_content": "      if (!inst->has_sharding()) {",
          "content_same": false
        },
        {
          "line": 3248,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "inst->name()",
          "old_line_content": "        const std::vector<HloSharding>* preserve_shardings_tuple =",
          "new_line_content": "                   << inst->name() << \" should be: \"",
          "content_same": false
        },
        {
          "line": 3254,
          "old_api": null,
          "new_api": "tuple_shapes_size",
          "old_text": null,
          "new_text": "inst->shape().tuple_shapes_size()",
          "old_line_content": "                          \"with name \"",
          "new_line_content": "        for (size_t i = 0; i < inst->shape().tuple_shapes_size(); i++) {",
          "content_same": false
        },
        {
          "line": 3256,
          "old_api": null,
          "new_api": "tuple_elements",
          "old_text": null,
          "new_text": "inst->sharding().tuple_elements().at(i).ToString()",
          "old_line_content": "                       << \" should be: \"",
          "new_line_content": "              inst->sharding().tuple_elements().at(i).ToString()) {",
          "content_same": false
        },
        {
          "line": 3261,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "preserve_shardings_tuple->at(i).ToString()",
          "old_line_content": "        }",
          "new_line_content": "                       << preserve_shardings_tuple->at(i).ToString()",
          "content_same": false
        },
        {
          "line": 3263,
          "old_api": null,
          "new_api": "tuple_elements",
          "old_text": null,
          "new_text": "inst->sharding().tuple_elements().at(i).ToString()",
          "old_line_content": "    }",
          "new_line_content": "                       << inst->sharding().tuple_elements().at(i).ToString();",
          "content_same": false
        },
        {
          "line": 3276,
          "old_api": null,
          "new_api": "empty",
          "old_text": null,
          "new_text": "value->index().empty()",
          "old_line_content": "  };",
          "new_line_content": "    return !value->index().empty()",
          "content_same": false
        },
        {
          "line": 3277,
          "old_api": null,
          "new_api": "GetSubSharding",
          "old_text": null,
          "new_text": "value->instruction()->sharding().GetSubSharding(\n                     value->instruction()->shape(), value->index())",
          "old_line_content": "",
          "new_line_content": "               ? value->instruction()->sharding().GetSubSharding(",
          "content_same": false
        },
        {
          "line": 3278,
          "old_api": null,
          "new_api": "index",
          "old_text": null,
          "new_text": "value->index()",
          "old_line_content": "  // We below, that is HloValues A and B alias, and A has a sharding specified,",
          "new_line_content": "                     value->instruction()->shape(), value->index())",
          "content_same": false
        },
        {
          "line": 3279,
          "old_api": null,
          "new_api": "instruction",
          "old_text": null,
          "new_text": "value->instruction()->sharding()",
          "old_line_content": "  // the same sharding is also used to compute the per-device memory",
          "new_line_content": "               : value->instruction()->sharding();",
          "content_same": false
        },
        {
          "line": 3292,
          "old_api": null,
          "new_api": "get_value_sharding",
          "old_text": null,
          "new_text": "get_value_sharding(value)",
          "old_line_content": "          if (this_value_sharding != buffer_value_sharding) {",
          "new_line_content": "        auto this_value_sharding = get_value_sharding(value);",
          "content_same": false
        },
        {
          "line": 3293,
          "old_api": null,
          "new_api": "id",
          "old_text": null,
          "new_text": "buffer.id()",
          "old_line_content": "            // TODO(pratikf): This is an unavoidable situation, but possibly",
          "new_line_content": "        auto iter = buffer_to_sharded_value_mapping.find(buffer.id());",
          "content_same": false
        },
        {
          "line": 3294,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "buffer_to_sharded_value_mapping.end()",
          "old_line_content": "            // there is a better design decision that can be made here.",
          "new_line_content": "        if (iter != buffer_to_sharded_value_mapping.end()) {",
          "content_same": false
        },
        {
          "line": 3299,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(1)",
          "old_line_content": "                       \"is not very accurate. The aliasing HLOs are \"",
          "new_line_content": "            VLOG(1) << \"We have a situation where two HloValues alias, but \"",
          "content_same": false
        },
        {
          "line": 3305,
          "old_api": null,
          "new_api": "ToShortString",
          "old_text": null,
          "new_text": "iter->second->ToShortString()",
          "old_line_content": "      }",
          "new_line_content": "                    << iter->second->ToShortString();",
          "content_same": false
        },
        {
          "line": 3308,
          "old_api": null,
          "new_api": "id",
          "old_text": null,
          "new_text": "buffer.id()",
          "old_line_content": "",
          "new_line_content": "        buffer_to_sharded_value_mapping[buffer.id()] = value;",
          "content_same": false
        },
        {
          "line": 3314,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "liveness_set.size()",
          "old_line_content": "        continue;",
          "new_line_content": "  for (size_t t = 0; t < liveness_set.size(); ++t) {",
          "content_same": false
        },
        {
          "line": 3323,
          "old_api": null,
          "new_api": "id",
          "old_text": null,
          "new_text": "buffer.id()",
          "old_line_content": "      }",
          "new_line_content": "      auto iter = buffer_to_sharded_value_mapping.find(buffer.id());",
          "content_same": false
        },
        {
          "line": 3326,
          "old_api": null,
          "new_api": "get_value_sharding",
          "old_text": null,
          "new_text": "get_value_sharding(iter->second)",
          "old_line_content": "    }",
          "new_line_content": "        optional_sharding = get_value_sharding(iter->second);",
          "content_same": false
        },
        {
          "line": 3329,
          "old_api": null,
          "new_api": "GetShardedInstructionSize",
          "old_text": null,
          "new_text": "GetShardedInstructionSize(shape, num_devices, optional_sharding)",
          "old_line_content": "  return max_memory_usage;",
          "new_line_content": "          GetShardedInstructionSize(shape, num_devices, optional_sharding);",
          "content_same": false
        },
        {
          "line": 3331,
          "old_api": null,
          "new_api": "std::max(max_memory_usage, memory_usage)",
          "old_text": null,
          "new_text": "std::max(max_memory_usage, memory_usage)",
          "old_line_content": "",
          "new_line_content": "    max_memory_usage = std::max(max_memory_usage, memory_usage);",
          "content_same": false
        },
        {
          "line": 3345,
          "old_api": null,
          "new_api": "Undefined",
          "old_text": null,
          "new_text": "Undefined()",
          "old_line_content": "        }",
          "new_line_content": "        ShapeTree<HloSharding> output_tuple_sharding(ins->shape(), Undefined());",
          "content_same": false
        },
        {
          "line": 3347,
          "old_api": null,
          "new_api": "leaves",
          "old_text": null,
          "new_text": "output_tuple_sharding.leaves()",
          "old_line_content": "      } else {",
          "new_line_content": "        for (auto& leaf : output_tuple_sharding.leaves()) {",
          "content_same": false
        },
        {
          "line": 3350,
          "old_api": null,
          "new_api": "HloSharding::Tuple(output_tuple_sharding)",
          "old_text": null,
          "new_text": "HloSharding::Tuple(output_tuple_sharding)",
          "old_line_content": "    }",
          "new_line_content": "        ins->set_sharding(HloSharding::Tuple(output_tuple_sharding));",
          "content_same": false
        },
        {
          "line": 3352,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "ins->name()",
          "old_line_content": "}",
          "new_line_content": "        ins->set_sharding(preserve_shardings.at(ins->name()).at(0));",
          "content_same": false
        },
        {
          "line": 3367,
          "old_api": null,
          "new_api": "insert",
          "old_text": null,
          "new_text": "visited.insert(cur)",
          "old_line_content": "  for (HloInstruction* consumer : users) {",
          "new_line_content": "  visited.insert(cur);",
          "content_same": false
        },
        {
          "line": 3370,
          "old_api": null,
          "new_api": "UsersWithAlias",
          "old_text": null,
          "new_text": "UsersWithAlias(cur, alias_map, output)",
          "old_line_content": "    // Allow at most one transpose",
          "new_line_content": "  StableHashSet<HloInstruction*> users = UsersWithAlias(cur, alias_map, output);",
          "content_same": false
        },
        {
          "line": 3375,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "consumer->opcode()",
          "old_line_content": "      transpose_inst = consumer;",
          "new_line_content": "    if (consumer->opcode() == HloOpcode::kTranspose &&",
          "content_same": false
        },
        {
          "line": 3377,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "consumer->shape()",
          "old_line_content": "    }",
          "new_line_content": "         DimensionsEqual(transpose_inst->shape(), consumer->shape()))) {",
          "content_same": false
        },
        {
          "line": 3385,
          "old_api": null,
          "new_api": "GetShardingStrategy",
          "old_text": null,
          "new_text": "GetShardingStrategy(consumer, strategy_map, cost_graph, s_val)",
          "old_line_content": "      return;",
          "new_line_content": "        GetShardingStrategy(consumer, strategy_map, cost_graph, s_val)",
          "content_same": false
        },
        {
          "line": 3387,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "shape_inst->shape()",
          "old_line_content": "  }",
          "new_line_content": "        !DimensionsEqual(consumer->shape(), shape_inst->shape())) {",
          "content_same": false
        },
        {
          "line": 3388,
          "old_api": null,
          "new_api": "insert",
          "old_text": null,
          "new_text": "boundary_set.insert(cur)",
          "old_line_content": "",
          "new_line_content": "      boundary_set.insert(cur);",
          "content_same": false
        },
        {
          "line": 3396,
          "old_api": null,
          "new_api": "contains",
          "old_text": null,
          "new_text": "visited.contains(consumer)",
          "old_line_content": "                       transpose_inst, replicated_set, boundary_set,",
          "new_line_content": "    if (!visited.contains(consumer)) {",
          "content_same": false
        },
        {
          "line": 3397,
          "old_api": null,
          "new_api": "insert",
          "old_text": null,
          "new_text": "consumer_set.insert(consumer)",
          "old_line_content": "                       consumer_set, visited);",
          "new_line_content": "      consumer_set.insert(consumer);",
          "content_same": false
        },
        {
          "line": 3398,
          "old_api": null,
          "new_api": "FindReplicateSet",
          "old_text": null,
          "new_text": "FindReplicateSet(consumer, alias_map, cost_graph, s_val, strategy_map,\n                       strategy, output, do_all_gather_after_backward,\n                       transpose_inst, replicated_set, boundary_set,\n                       consumer_set, visited)",
          "old_line_content": "    }",
          "new_line_content": "      FindReplicateSet(consumer, alias_map, cost_graph, s_val, strategy_map,",
          "content_same": false
        },
        {
          "line": 3407,
          "old_api": null,
          "new_api": "PassThroughCustomCallMarkerOperand",
          "old_text": null,
          "new_text": "PassThroughCustomCallMarkerOperand(operand, cur)",
          "old_line_content": "                .output_sharding == strategy.output_sharding &&",
          "new_line_content": "    operand = PassThroughCustomCallMarkerOperand(operand, cur);",
          "content_same": false
        },
        {
          "line": 3410,
          "old_api": null,
          "new_api": "GetShardingStrategy",
          "old_text": null,
          "new_text": "GetShardingStrategy(operand, strategy_map, cost_graph, s_val)",
          "old_line_content": "                       strategy, output, do_all_gather_after_backward,",
          "new_line_content": "        GetShardingStrategy(operand, strategy_map, cost_graph, s_val)",
          "content_same": false
        },
        {
          "line": 3412,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "cur->shape()",
          "old_line_content": "                       consumer_set, visited);",
          "new_line_content": "        DimensionsEqual(operand->shape(), cur->shape())) {",
          "content_same": false
        },
        {
          "line": 3413,
          "old_api": null,
          "new_api": "FindReplicateSet",
          "old_text": null,
          "new_text": "FindReplicateSet(operand, alias_map, cost_graph, s_val, strategy_map,\n                       strategy, output, do_all_gather_after_backward,\n                       transpose_inst, replicated_set, boundary_set,\n                       consumer_set, visited)",
          "old_line_content": "    }",
          "new_line_content": "      FindReplicateSet(operand, alias_map, cost_graph, s_val, strategy_map,",
          "content_same": false
        },
        {
          "line": 3433,
          "old_api": null,
          "new_api": "back",
          "old_text": null,
          "new_text": "instructions.back()",
          "old_line_content": "",
          "new_line_content": "  const HloInstruction* output = instructions.back();",
          "content_same": false
        },
        {
          "line": 3434,
          "old_api": null,
          "new_api": "IsCustomCallMarker",
          "old_text": null,
          "new_text": "IsCustomCallMarker(output)",
          "old_line_content": "  // A debug option: whether to do all-gather after backward pass.",
          "new_line_content": "  if (IsCustomCallMarker(output)) {",
          "content_same": false
        },
        {
          "line": 3435,
          "old_api": null,
          "new_api": "operand",
          "old_text": null,
          "new_text": "output->operand(0)",
          "old_line_content": "  // This controls the location of all-gather.",
          "new_line_content": "    output = output->operand(0);",
          "content_same": false
        },
        {
          "line": 3461,
          "old_api": null,
          "new_api": "HasReduceScatterOpportunity",
          "old_text": null,
          "new_text": "HasReduceScatterOpportunity(inst, strategy_map, cost_graph, s_val,\n                                     modified)",
          "old_line_content": "    const ShardingStrategy& strategy =",
          "new_line_content": "    if (!HasReduceScatterOpportunity(inst, strategy_map, cost_graph, s_val,",
          "content_same": false
        },
        {
          "line": 3466,
          "old_api": null,
          "new_api": "GetShardingStrategy",
          "old_text": null,
          "new_text": "GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "old_line_content": "",
          "new_line_content": "        GetShardingStrategy(inst, strategy_map, cost_graph, s_val);",
          "content_same": false
        },
        {
          "line": 3467,
          "old_api": null,
          "new_api": "absl::StrContains(strategy.name, \"allreduce\")",
          "old_text": null,
          "new_text": "absl::StrContains(strategy.name, \"allreduce\")",
          "old_line_content": "    StableHashSet<HloInstruction*> replicated_set;",
          "new_line_content": "    if (!absl::StrContains(strategy.name, \"allreduce\")) {",
          "content_same": false
        },
        {
          "line": 3480,
          "old_api": null,
          "new_api": "insert",
          "old_text": null,
          "new_text": "visited.insert(output)",
          "old_line_content": "",
          "new_line_content": "    visited.insert(output);",
          "content_same": false
        },
        {
          "line": 3481,
          "old_api": null,
          "new_api": "FindReplicateSet",
          "old_text": null,
          "new_text": "FindReplicateSet(inst, alias_map, cost_graph, s_val, strategy_map, strategy,\n                     output, do_all_gather_after_backward, transpose_inst,\n                     replicated_set, boundary_set, consumer_set, visited)",
          "old_line_content": "    // Try to reduce the boundary set to its common ancestor",
          "new_line_content": "    FindReplicateSet(inst, alias_map, cost_graph, s_val, strategy_map, strategy,",
          "content_same": false
        },
        {
          "line": 3486,
          "old_api": null,
          "new_api": "TryReduceWithCommonAncestor",
          "old_text": null,
          "new_text": "TryReduceWithCommonAncestor(replicated_set, boundary_set, consumer_set,\n                                alias_map)",
          "old_line_content": "    std::vector<HloInstruction*> need_all_gather;",
          "new_line_content": "    TryReduceWithCommonAncestor(replicated_set, boundary_set, consumer_set,",
          "content_same": false
        },
        {
          "line": 3492,
          "old_api": null,
          "new_api": "contains",
          "old_text": null,
          "new_text": "consumer_set.contains(node)",
          "old_line_content": "          // instructions.",
          "new_line_content": "      if (consumer_set.contains(node)) {",
          "content_same": false
        },
        {
          "line": 3497,
          "old_api": null,
          "new_api": "insert",
          "old_text": null,
          "new_text": "replicated_set.insert(node)",
          "old_line_content": "      }",
          "new_line_content": "          replicated_set.insert(node);",
          "content_same": false
        },
        {
          "line": 3499,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "need_all_gather.push_back(node)",
          "old_line_content": "",
          "new_line_content": "          need_all_gather.push_back(node);",
          "content_same": false
        },
        {
          "line": 3506,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "need_all_gather.size()",
          "old_line_content": "      while (true) {",
          "new_line_content": "    if (do_all_gather_after_backward && need_all_gather.size() == 1) {",
          "content_same": false
        },
        {
          "line": 3511,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "path.push_back(root)",
          "old_line_content": "        } else {",
          "new_line_content": "        path.push_back(root);",
          "content_same": false
        },
        {
          "line": 3512,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "root->opcode()",
          "old_line_content": "          break;",
          "new_line_content": "        if (root->opcode() == HloOpcode::kGetTupleElement) {",
          "content_same": false
        },
        {
          "line": 3513,
          "old_api": null,
          "new_api": "mutable_operand",
          "old_text": null,
          "new_text": "root->mutable_operand(0)",
          "old_line_content": "        }",
          "new_line_content": "          root = PassThroughCustomCallMarkerOperand(root->mutable_operand(0),",
          "content_same": false
        },
        {
          "line": 3520,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "root->opcode()",
          "old_line_content": "        }",
          "new_line_content": "      if (root->opcode() == HloOpcode::kParameter) {",
          "content_same": false
        },
        {
          "line": 3522,
          "old_api": null,
          "new_api": "erase",
          "old_text": null,
          "new_text": "replicated_set.erase(x)",
          "old_line_content": "        for (auto x : replicated_set) {",
          "new_line_content": "          replicated_set.erase(x);",
          "content_same": false
        },
        {
          "line": 3527,
          "old_api": null,
          "new_api": "find",
          "old_text": null,
          "new_text": "alias_map.find(x)",
          "old_line_content": "            break;",
          "new_line_content": "          auto iter = alias_map.find(x);",
          "content_same": false
        },
        {
          "line": 3528,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "alias_map.end()",
          "old_line_content": "          }",
          "new_line_content": "          if (iter != alias_map.end() && iter->second == root) {",
          "content_same": false
        },
        {
          "line": 3529,
          "old_api": null,
          "new_api": "insert",
          "old_text": null,
          "new_text": "boundary_set.insert(x)",
          "old_line_content": "        }",
          "new_line_content": "            boundary_set.insert(x);",
          "content_same": false
        },
        {
          "line": 3530,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "need_all_gather.push_back(x)",
          "old_line_content": "      }",
          "new_line_content": "            need_all_gather.push_back(x);",
          "content_same": false
        },
        {
          "line": 3541,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "node->opcode()",
          "old_line_content": "    for (const HloInstruction* to_split : need_all_gather) {",
          "new_line_content": "      if (node->opcode() == HloOpcode::kParameter) {",
          "content_same": false
        },
        {
          "line": 3546,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "to_split->users().size()",
          "old_line_content": "      }",
          "new_line_content": "      if (to_split->users().size() == 1 &&",
          "content_same": false
        },
        {
          "line": 3547,
          "old_api": null,
          "new_api": "contains",
          "old_text": null,
          "new_text": "alias_map.contains(to_split)",
          "old_line_content": "    }",
          "new_line_content": "          to_split->users().front() == output && alias_map.contains(to_split)) {",
          "content_same": false
        },
        {
          "line": 3555,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(10)",
          "old_line_content": "    }",
          "new_line_content": "    VLOG(10) << \"replicated set (#parameter: \" << num_replicated_parameters",
          "content_same": false
        },
        {
          "line": 3558,
          "old_api": null,
          "new_api": "HloPrintOptions::ShortParsable()",
          "old_text": null,
          "new_text": "HloPrintOptions::ShortParsable()",
          "old_line_content": "    for (auto x : boundary_set) {",
          "new_line_content": "      VLOG(10) << \"  \" << x->ToString(HloPrintOptions::ShortParsable()) << \"\\n\";",
          "content_same": false
        },
        {
          "line": 3563,
          "old_api": null,
          "new_api": "HloPrintOptions::ShortParsable()",
          "old_text": null,
          "new_text": "HloPrintOptions::ShortParsable()",
          "old_line_content": "    // If applicable, replace all-reduce with reduce-scatter by",
          "new_line_content": "      VLOG(10) << \"  \" << x->ToString(HloPrintOptions::ShortParsable()) << \" \"",
          "content_same": false
        },
        {
          "line": 3564,
          "old_api": null,
          "new_api": "absl::c_linear_search(need_all_gather, x)",
          "old_text": null,
          "new_text": "absl::c_linear_search(need_all_gather, x)",
          "old_line_content": "    // setting instructions' sharding.",
          "new_line_content": "               << absl::c_linear_search(need_all_gather, x) << \"\\n\";",
          "content_same": false
        },
        {
          "line": 3570,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "replicated_set.size()",
          "old_line_content": "        continue;",
          "new_line_content": "        replicated_set.size() >= 5) {",
          "content_same": false
        },
        {
          "line": 3572,
          "old_api": null,
          "new_api": "GetReduceScatterOutput",
          "old_text": null,
          "new_text": "GetReduceScatterOutput(inst, strategy, cluster_env)",
          "old_line_content": "",
          "new_line_content": "          GetReduceScatterOutput(inst, strategy, cluster_env);",
          "content_same": false
        },
        {
          "line": 3577,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "output_spec.ToString()",
          "old_line_content": "        // partitioner will generate bad fallback code.",
          "new_line_content": "      VLOG(10) << \"SET: \" << output_spec.ToString();",
          "content_same": false
        },
        {
          "line": 3579,
          "old_api": null,
          "new_api": "absl::StartsWith(strategy.name, \"RR = RS x SR\")",
          "old_text": null,
          "new_text": "absl::StartsWith(strategy.name, \"RR = RS x SR\")",
          "old_line_content": "      }",
          "new_line_content": "      if (absl::StartsWith(strategy.name, \"RR = RS x SR\")) {",
          "content_same": false
        },
        {
          "line": 3590,
          "old_api": null,
          "new_api": "SetSharding",
          "old_text": null,
          "new_text": "SetSharding(to_split, output_spec, inst, transpose_inst, modified)",
          "old_line_content": "        // The normal case",
          "new_line_content": "        SetSharding(to_split, output_spec, inst, transpose_inst, modified);",
          "content_same": false
        },
        {
          "line": 3598,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "to_split->users().size()",
          "old_line_content": "            // This partitions more tensors but introduces communication",
          "new_line_content": "          if (!do_all_gather_after_backward && to_split->users().size() == 1 &&",
          "content_same": false
        },
        {
          "line": 3599,
          "old_api": null,
          "new_api": "front",
          "old_text": null,
          "new_text": "to_split->users().front()",
          "old_line_content": "            // in the forward pass, which is not desired in gradient",
          "new_line_content": "              to_split->users().front() == output &&",
          "content_same": false
        },
        {
          "line": 3600,
          "old_api": null,
          "new_api": "contains",
          "old_text": null,
          "new_text": "alias_map.contains(to_split)",
          "old_line_content": "            // accumulation.",
          "new_line_content": "              alias_map.contains(to_split)) {",
          "content_same": false
        },
        {
          "line": 3613,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "to_split->users().size()",
          "old_line_content": "            }",
          "new_line_content": "                to_split->users().size() == 1 &&",
          "content_same": false
        },
        {
          "line": 3614,
          "old_api": null,
          "new_api": "front",
          "old_text": null,
          "new_text": "to_split->users().front()",
          "old_line_content": "          }",
          "new_line_content": "                to_split->users().front() == output) {",
          "content_same": false
        },
        {
          "line": 3615,
          "old_api": null,
          "new_api": "mutable_operand",
          "old_text": null,
          "new_text": "PassThroughCustomCallMarkerOperand(\n                  to_split->mutable_operand(0), to_split)",
          "old_line_content": "        }",
          "new_line_content": "              insert_all_gather.push_back(PassThroughCustomCallMarkerOperand(",
          "content_same": false
        },
        {
          "line": 3616,
          "old_api": null,
          "new_api": "mutable_operand",
          "old_text": null,
          "new_text": "to_split->mutable_operand(0)",
          "old_line_content": "      } else {",
          "new_line_content": "                  to_split->mutable_operand(0), to_split));",
          "content_same": false
        },
        {
          "line": 3629,
          "old_api": null,
          "new_api": "front",
          "old_text": null,
          "new_text": "to_split->users().front()",
          "old_line_content": "",
          "new_line_content": "              to_split->users().front() == output &&",
          "content_same": false
        },
        {
          "line": 3630,
          "old_api": null,
          "new_api": "contains",
          "old_text": null,
          "new_text": "alias_map.contains(to_split)",
          "old_line_content": "            // Find the branching point (i.e., skip elementwise ops like",
          "new_line_content": "              alias_map.contains(to_split)) {",
          "content_same": false
        },
        {
          "line": 3632,
          "old_api": null,
          "new_api": "at",
          "old_text": null,
          "new_text": "alias_map.at(to_split)",
          "old_line_content": "            HloInstruction* cur = param;",
          "new_line_content": "            HloInstruction* param = alias_map.at(to_split);",
          "content_same": false
        },
        {
          "line": 3640,
          "old_api": null,
          "new_api": "SetSharding",
          "old_text": null,
          "new_text": "SetSharding(cur, output_spec, inst, transpose_inst, modified)",
          "old_line_content": "",
          "new_line_content": "              SetSharding(cur, output_spec, inst, transpose_inst, modified);",
          "content_same": false
        },
        {
          "line": 3643,
          "old_api": null,
          "new_api": "SetSharding",
          "old_text": null,
          "new_text": "SetSharding(cur, output_spec, inst, transpose_inst, modified)",
          "old_line_content": "            // Find the first user",
          "new_line_content": "            SetSharding(cur, output_spec, inst, transpose_inst, modified);",
          "content_same": false
        },
        {
          "line": 3645,
          "old_api": null,
          "new_api": "empty",
          "old_text": null,
          "new_text": "cur->users().empty()",
          "old_line_content": "            int64_t min_depth = ((int64_t)1) << 50;",
          "new_line_content": "            CHECK(!cur->users().empty());",
          "content_same": false
        },
        {
          "line": 3650,
          "old_api": null,
          "new_api": "users",
          "old_text": null,
          "new_text": "cur->users()",
          "old_line_content": "              }",
          "new_line_content": "            for (const auto& x : cur->users()) {",
          "content_same": false
        },
        {
          "line": 3653,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "x->ToString()",
          "old_line_content": "                // Only apply this aggressive optimization for dot and conv",
          "new_line_content": "                LOG(FATAL) << \"ERROR: \" << x->ToString();",
          "content_same": false
        },
        {
          "line": 3655,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "x->opcode()",
          "old_line_content": "              }",
          "new_line_content": "              if (x->opcode() != HloOpcode::kConvolution &&",
          "content_same": false
        },
        {
          "line": 3656,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "x->opcode()",
          "old_line_content": "              if (iter->second < min_depth) {",
          "new_line_content": "                  x->opcode() != HloOpcode::kDot) {",
          "content_same": false
        },
        {
          "line": 3668,
          "old_api": null,
          "new_api": "parent",
          "old_text": null,
          "new_text": "inst->parent()->AddInstruction(\n                  HloInstruction::CreateCustomCall(cur->shape(), {cur},\n                                                   kIdentityMarker))",
          "old_line_content": "                          modified);",
          "new_line_content": "              HloInstruction* identity = inst->parent()->AddInstruction(",
          "content_same": false
        },
        {
          "line": 3671,
          "old_api": null,
          "new_api": "SetSharding",
          "old_text": null,
          "new_text": "SetSharding(identity, output_spec, inst, transpose_inst,\n                          modified)",
          "old_line_content": "          }",
          "new_line_content": "              SetSharding(identity, output_spec, inst, transpose_inst,",
          "content_same": false
        },
        {
          "line": 3673,
          "old_api": null,
          "new_api": "ReplaceOperand",
          "old_text": null,
          "new_text": "ReplaceOperand(first_user, cur, identity)",
          "old_line_content": "      }",
          "new_line_content": "              ReplaceOperand(first_user, cur, identity);",
          "content_same": false
        },
        {
          "line": 3680,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(10)",
          "old_line_content": "  // their shardings. This also works as CSE of all-gather.",
          "new_line_content": "    VLOG(10) << \"-----------------------done\\n\";",
          "content_same": false
        },
        {
          "line": 3686,
          "old_api": null,
          "new_api": "parent",
          "old_text": null,
          "new_text": "inst->parent()->AddInstruction(\n        HloInstruction::CreateReshape(inst->shape(), inst))",
          "old_line_content": "            .output_sharding);",
          "new_line_content": "    HloInstruction* replace_with = inst->parent()->AddInstruction(",
          "content_same": false
        },
        {
          "line": 3688,
          "old_api": null,
          "new_api": "set_sharding",
          "old_text": null,
          "new_text": "replace_with->set_sharding(\n        GetShardingStrategy(inst, strategy_map, cost_graph, s_val)\n            .output_sharding)",
          "old_line_content": "  }",
          "new_line_content": "    replace_with->set_sharding(",
          "content_same": false
        },
        {
          "line": 3689,
          "old_api": null,
          "new_api": "GetShardingStrategy",
          "old_text": null,
          "new_text": "GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "old_line_content": "}",
          "new_line_content": "        GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "content_same": false
        },
        {
          "line": 3691,
          "old_api": null,
          "new_api": "ReplaceAllUsesWith",
          "old_text": null,
          "new_text": "inst->ReplaceAllUsesWith(replace_with)",
          "old_line_content": "void AnnotateShardingWithSimpleHeuristic(",
          "new_line_content": "    TF_CHECK_OK(inst->ReplaceAllUsesWith(replace_with));",
          "content_same": false
        },
        {
          "line": 3704,
          "old_api": null,
          "new_api": "dimensions",
          "old_text": null,
          "new_text": "device_mesh.dimensions()",
          "old_line_content": "  }",
          "new_line_content": "  for (int dim : device_mesh.dimensions()) {",
          "content_same": false
        },
        {
          "line": 3712,
          "old_api": null,
          "new_api": "instructions",
          "old_text": null,
          "new_text": "entry_computation->instructions()",
          "old_line_content": "",
          "new_line_content": "  for (HloInstruction* inst : entry_computation->instructions()) {",
          "content_same": false
        },
        {
          "line": 3713,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "inst->opcode()",
          "old_line_content": "      if (heuristic == \"shard-largest\") {",
          "new_line_content": "    if (inst->opcode() == HloOpcode::kParameter) {",
          "content_same": false
        },
        {
          "line": 3714,
          "old_api": null,
          "new_api": "HloSharding::Replicate()",
          "old_text": null,
          "new_text": "HloSharding::Replicate()",
          "old_line_content": "        std::vector<int64_t> lengths;",
          "new_line_content": "      HloSharding output_spec = HloSharding::Replicate();",
          "content_same": false
        },
        {
          "line": 3723,
          "old_api": null,
          "new_api": "Argsort",
          "old_text": null,
          "new_text": "Argsort(lengths)",
          "old_line_content": "          continue;",
          "new_line_content": "        std::vector<int> indices = Argsort(lengths);",
          "content_same": false
        },
        {
          "line": 3724,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "indices.size()",
          "old_line_content": "        }",
          "new_line_content": "        int common_dims = std::min(mesh_nn_dims, indices.size());",
          "content_same": false
        },
        {
          "line": 3734,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "inst->shape()",
          "old_line_content": "          int length1 = lengths[dim1];",
          "new_line_content": "            output_spec = Tile(inst->shape(), {dim}, {0}, device_mesh_1d);",
          "content_same": false
        },
        {
          "line": 3742,
          "old_api": null,
          "new_api": "dim",
          "old_text": null,
          "new_text": "device_mesh.dim(0)",
          "old_line_content": "          }",
          "new_line_content": "          if (length0 % device_mesh.dim(0) == 0 &&",
          "content_same": false
        },
        {
          "line": 3743,
          "old_api": null,
          "new_api": "dim",
          "old_text": null,
          "new_text": "device_mesh.dim(1)",
          "old_line_content": "        }",
          "new_line_content": "              length1 % device_mesh.dim(1) == 0) {",
          "content_same": false
        },
        {
          "line": 3749,
          "old_api": null,
          "new_api": "rank",
          "old_text": null,
          "new_text": "inst->shape().rank()",
          "old_line_content": "      } else if (heuristic == \"shard-last\") {",
          "new_line_content": "        if (inst->shape().rank() > 0 &&",
          "content_same": false
        },
        {
          "line": 3754,
          "old_api": null,
          "new_api": "rank",
          "old_text": null,
          "new_text": "inst->shape().rank()",
          "old_line_content": "        }",
          "new_line_content": "        int64_t last_dim = inst->shape().rank() - 1;",
          "content_same": false
        },
        {
          "line": 3755,
          "old_api": null,
          "new_api": "rank",
          "old_text": null,
          "new_text": "inst->shape().rank()",
          "old_line_content": "      } else {",
          "new_line_content": "        if (inst->shape().rank() > 0 &&",
          "content_same": false
        },
        {
          "line": 3757,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "inst->shape()",
          "old_line_content": "      }",
          "new_line_content": "          output_spec = Tile(inst->shape(), {last_dim}, {0}, device_mesh_1d);",
          "content_same": false
        },
        {
          "line": 3760,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(FATAL)",
          "old_line_content": "      // std::cerr << \"ins: \" << inst->ToString() << \", spec: \" <<",
          "new_line_content": "        LOG(FATAL) << \"Invalid heuristic: \" << heuristic;",
          "content_same": false
        },
        {
          "line": 3766,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "inst->opcode()",
          "old_line_content": "      // const auto& lhs_con_dims = dot_dnums.lhs_contracting_dimensions();",
          "new_line_content": "    } else if (inst->opcode() == HloOpcode::kDot) {",
          "content_same": false
        },
        {
          "line": 3767,
          "old_api": null,
          "new_api": "operand",
          "old_text": null,
          "new_text": "inst->operand(0)",
          "old_line_content": "      // const auto& rhs_con_dims = dot_dnums.rhs_contracting_dimensions();",
          "new_line_content": "      const HloInstruction* lhs = inst->operand(0);",
          "content_same": false
        },
        {
          "line": 3768,
          "old_api": null,
          "new_api": "operand",
          "old_text": null,
          "new_text": "inst->operand(1)",
          "old_line_content": "      std::vector<int64_t> lhs_space_dims, rhs_space_dims;",
          "new_line_content": "      const HloInstruction* rhs = inst->operand(1);",
          "content_same": false
        },
        {
          "line": 3773,
          "old_api": null,
          "new_api": "std::tie(lhs_space_dims, rhs_space_dims)",
          "old_text": null,
          "new_text": "std::tie(lhs_space_dims, rhs_space_dims)",
          "old_line_content": "",
          "new_line_content": "      std::tie(lhs_space_dims, rhs_space_dims) =",
          "content_same": false
        },
        {
          "line": 3774,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "rhs->shape()",
          "old_line_content": "  // Meet the alias requirement for the output tuple.",
          "new_line_content": "          GetSpaceDims(lhs->shape(), rhs->shape(), dot_dnums);",
          "content_same": false
        },
        {
          "line": 3779,
          "old_api": null,
          "new_api": "root_instruction",
          "old_text": null,
          "new_text": "entry_computation->root_instruction()",
          "old_line_content": "",
          "new_line_content": "  HloInstruction* output = entry_computation->root_instruction();",
          "content_same": false
        },
        {
          "line": 3780,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "output->shape()",
          "old_line_content": "  std::function<void(HloInstruction*)> get_flattened_shardings;",
          "new_line_content": "  const Shape& out_shape = output->shape();",
          "content_same": false
        },
        {
          "line": 3787,
          "old_api": null,
          "new_api": "mutable_operand",
          "old_text": null,
          "new_text": "cur->mutable_operand(i)",
          "old_line_content": "      } else {",
          "new_line_content": "      HloInstruction* operand = cur->mutable_operand(i);",
          "content_same": false
        },
        {
          "line": 3790,
          "old_api": null,
          "new_api": "get_flattened_shardings",
          "old_text": null,
          "new_text": "get_flattened_shardings(operand)",
          "old_line_content": "        }",
          "new_line_content": "        get_flattened_shardings(operand);",
          "content_same": false
        },
        {
          "line": 3793,
          "old_api": null,
          "new_api": "at",
          "old_text": null,
          "new_text": "alias_map.at(operand)",
          "old_line_content": "        }",
          "new_line_content": "          operand = alias_map.at(operand);",
          "content_same": false
        },
        {
          "line": 3796,
          "old_api": null,
          "new_api": "HloSharding::Replicate()",
          "old_text": null,
          "new_text": "HloSharding::Replicate()",
          "old_line_content": "      }",
          "new_line_content": "          operand->set_sharding(HloSharding::Replicate());",
          "content_same": false
        },
        {
          "line": 3798,
          "old_api": null,
          "new_api": "has_sharding",
          "old_text": null,
          "new_text": "operand->has_sharding()",
          "old_line_content": "  };",
          "new_line_content": "        CHECK(operand->has_sharding());",
          "content_same": false
        },
        {
          "line": 3803,
          "old_api": null,
          "new_api": "get_flattened_shardings",
          "old_text": null,
          "new_text": "get_flattened_shardings(output)",
          "old_line_content": "  }",
          "new_line_content": "  get_flattened_shardings(output);",
          "content_same": false
        },
        {
          "line": 3808,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "flattened_shardings.size()",
          "old_line_content": "// Filter strategies according to the solver_option.force_batch_dim_to_mesh_dim.",
          "new_line_content": "  CHECK_EQ(i, flattened_shardings.size());",
          "content_same": false
        },
        {
          "line": 3809,
          "old_api": null,
          "new_api": "HloSharding::Tuple(tuple_sharding)",
          "old_text": null,
          "new_text": "HloSharding::Tuple(tuple_sharding)",
          "old_line_content": "// This can be used to forcibly generate data-parallel strategies.",
          "new_line_content": "  output->set_sharding(HloSharding::Tuple(tuple_sharding));",
          "content_same": false
        },
        {
          "line": 3823,
          "old_api": null,
          "new_api": "dim",
          "old_text": null,
          "new_text": "device_mesh.dim(mesh_dim)",
          "old_line_content": "  }",
          "new_line_content": "  if (shape.dimensions(batch_dim) % device_mesh.dim(mesh_dim) != 0) {",
          "content_same": false
        },
        {
          "line": 3824,
          "old_api": null,
          "new_api": "absl::InvalidArgumentError(\n        \"The length of batch dimension is \"\n        \"not divisible by the number of devices\")",
          "old_text": null,
          "new_text": "absl::InvalidArgumentError(\n        \"The length of batch dimension is \"\n        \"not divisible by the number of devices\")",
          "old_line_content": "",
          "new_line_content": "    return absl::InvalidArgumentError(",
          "content_same": false
        },
        {
          "line": 3832,
          "old_api": null,
          "new_api": "GetTensorDimToMeshDimWrapper",
          "old_text": null,
          "new_text": "cluster_env.GetTensorDimToMeshDimWrapper(shape, stra.output_sharding)",
          "old_line_content": "      // tiled along the mesh dim.",
          "new_line_content": "        cluster_env.GetTensorDimToMeshDimWrapper(shape, stra.output_sharding);",
          "content_same": false
        },
        {
          "line": 3838,
          "old_api": null,
          "new_api": "std::move(stra)",
          "old_text": null,
          "new_text": "std::move(stra)",
          "old_line_content": "      // on the mesh dim.",
          "new_line_content": "        new_leaf_vector.push_back(std::move(stra));",
          "content_same": false
        },
        {
          "line": 3849,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "ins->ToString()",
          "old_line_content": "}",
          "new_line_content": "      << ins->ToString() << \" does not have any valid strategies\";",
          "content_same": false
        },
        {
          "line": 3850,
          "old_api": null,
          "new_api": "std::move(new_leaf_vector)",
          "old_text": null,
          "new_text": "std::move(new_leaf_vector)",
          "old_line_content": "",
          "new_line_content": "  strategies->leaf_vector = std::move(new_leaf_vector);",
          "content_same": false
        },
        {
          "line": 3852,
          "old_api": null,
          "new_api": "OkStatus",
          "old_text": null,
          "new_text": "OkStatus()",
          "old_line_content": "HloSharding GetReduceScatterOutput(const HloInstruction* ins,",
          "new_line_content": "  return OkStatus();",
          "content_same": false
        },
        {
          "line": 3864,
          "old_api": null,
          "new_api": "lhs_batch_dimensions_size",
          "old_text": null,
          "new_text": "dot_dnums.lhs_batch_dimensions_size()",
          "old_line_content": "      int mesh_dim0, mesh_dim1;",
          "new_line_content": "    int64_t space_base_dim = dot_dnums.lhs_batch_dimensions_size();",
          "content_same": false
        },
        {
          "line": 3866,
          "old_api": null,
          "new_api": "absl::StartsWith(strategy.name, \"SR = SS x SR\")",
          "old_text": null,
          "new_text": "absl::StartsWith(strategy.name, \"SR = SS x SR\")",
          "old_line_content": "",
          "new_line_content": "    if (absl::StartsWith(strategy.name, \"SR = SS x SR\") ||",
          "content_same": false
        },
        {
          "line": 3869,
          "old_api": null,
          "new_api": "ParseMeshDims",
          "old_text": null,
          "new_text": "ParseMeshDims(strategy.name)",
          "old_line_content": "        // XLA supports uneven partitioning by adding padding.",
          "new_line_content": "      std::tie(mesh_dim0, mesh_dim1) = ParseMeshDims(strategy.name);",
          "content_same": false
        },
        {
          "line": 3871,
          "old_api": null,
          "new_api": "IsDivisible",
          "old_text": null,
          "new_text": "IsDivisible(ins, device_mesh, {space_base_dim, space_base_dim + 1},\n                       {mesh_dim0, mesh_dim1})",
          "old_line_content": "        // partitioning.",
          "new_line_content": "      if (!IsDivisible(ins, device_mesh, {space_base_dim, space_base_dim + 1},",
          "content_same": false
        },
        {
          "line": 3876,
          "old_api": null,
          "new_api": "Undefined",
          "old_text": null,
          "new_text": "Undefined()",
          "old_line_content": "                  {mesh_dim0, mesh_dim1}, device_mesh);",
          "new_line_content": "        return Undefined();",
          "content_same": false
        },
        {
          "line": 3879,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "ins->shape()",
          "old_line_content": "      int mesh_dim0, mesh_dim1;",
          "new_line_content": "      return Tile(ins->shape(), {space_base_dim, space_base_dim + 1},",
          "content_same": false
        },
        {
          "line": 3884,
          "old_api": null,
          "new_api": "ParseMeshDims",
          "old_text": null,
          "new_text": "ParseMeshDims(strategy.name)",
          "old_line_content": "        // XLA supports uneven partitioning by adding padding.",
          "new_line_content": "      std::tie(mesh_dim0, mesh_dim1) = ParseMeshDims(strategy.name);",
          "content_same": false
        },
        {
          "line": 3886,
          "old_api": null,
          "new_api": "IsDivisible",
          "old_text": null,
          "new_text": "IsDivisible(ins, device_mesh, {0, space_base_dim},\n                       {mesh_dim0, mesh_dim1})",
          "old_line_content": "        // partitioning.",
          "new_line_content": "      if (!IsDivisible(ins, device_mesh, {0, space_base_dim},",
          "content_same": false
        },
        {
          "line": 3891,
          "old_api": null,
          "new_api": "Undefined",
          "old_text": null,
          "new_text": "Undefined()",
          "old_line_content": "                  device_mesh);",
          "new_line_content": "        return Undefined();",
          "content_same": false
        },
        {
          "line": 3898,
          "old_api": null,
          "new_api": "absl::StrContains(strategy.name, \"{0}\")",
          "old_text": null,
          "new_text": "absl::StrContains(strategy.name, \"{0}\")",
          "old_line_content": "      }",
          "new_line_content": "      int mesh_dim = absl::StrContains(strategy.name, \"{0}\") ? 0 : 1;",
          "content_same": false
        },
        {
          "line": 3901,
          "old_api": null,
          "new_api": "Undefined",
          "old_text": null,
          "new_text": "Undefined()",
          "old_line_content": "    }",
          "new_line_content": "        return Undefined();",
          "content_same": false
        },
        {
          "line": 3904,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "ins->shape()",
          "old_line_content": "",
          "new_line_content": "      return Tile(ins->shape(), {space_base_dim}, {mesh_dim}, device_mesh);",
          "content_same": false
        },
        {
          "line": 3910,
          "old_api": null,
          "new_api": "Undefined",
          "old_text": null,
          "new_text": "Undefined()",
          "old_line_content": "    }",
          "new_line_content": "        return Undefined();",
          "content_same": false
        },
        {
          "line": 3919,
          "old_api": null,
          "new_api": "output_feature_dimension",
          "old_text": null,
          "new_text": "conv_dnums.output_feature_dimension()",
          "old_line_content": "      int mesh_dim0, mesh_dim1;",
          "new_line_content": "    int out_out_channel_dim = conv_dnums.output_feature_dimension();",
          "content_same": false
        },
        {
          "line": 3921,
          "old_api": null,
          "new_api": "absl::StartsWith(strategy.name, \"SR = SS x SR\")",
          "old_text": null,
          "new_text": "absl::StartsWith(strategy.name, \"SR = SS x SR\")",
          "old_line_content": "",
          "new_line_content": "    if (absl::StartsWith(strategy.name, \"SR = SS x SR\") ||",
          "content_same": false
        },
        {
          "line": 3926,
          "old_api": null,
          "new_api": "IsDivisible",
          "old_text": null,
          "new_text": "IsDivisible(ins, device_mesh, {out_batch_dim, out_out_channel_dim},\n                       {mesh_dim0, mesh_dim1})",
          "old_line_content": "",
          "new_line_content": "      if (!IsDivisible(ins, device_mesh, {out_batch_dim, out_out_channel_dim},",
          "content_same": false
        },
        {
          "line": 3928,
          "old_api": null,
          "new_api": "Undefined",
          "old_text": null,
          "new_text": "Undefined()",
          "old_line_content": "                  {mesh_dim0, mesh_dim1}, device_mesh);",
          "new_line_content": "        return Undefined();",
          "content_same": false
        },
        {
          "line": 3931,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "ins->shape()",
          "old_line_content": "      int mesh_dim = 0;",
          "new_line_content": "      return Tile(ins->shape(), {out_batch_dim, out_out_channel_dim},",
          "content_same": false
        },
        {
          "line": 3938,
          "old_api": null,
          "new_api": "Undefined",
          "old_text": null,
          "new_text": "Undefined()",
          "old_line_content": "    }",
          "new_line_content": "        return Undefined();",
          "content_same": false
        },
        {
          "line": 3943,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "ins->opcode()",
          "old_line_content": "    int mesh_dim;",
          "new_line_content": "  } else if (ins->opcode() == HloOpcode::kReduce) {",
          "content_same": false
        },
        {
          "line": 3945,
          "old_api": null,
          "new_api": "rank",
          "old_text": null,
          "new_text": "ins->shape().rank()",
          "old_line_content": "      mesh_dim = 0;",
          "new_line_content": "    CHECK_EQ(ins->shape().rank(), 1);",
          "content_same": false
        },
        {
          "line": 3948,
          "old_api": null,
          "new_api": "absl::StrContains(strategy.name, \"allreduce @ [0]\")",
          "old_text": null,
          "new_text": "absl::StrContains(strategy.name, \"allreduce @ [0]\")",
          "old_line_content": "    }",
          "new_line_content": "    if (absl::StrContains(strategy.name, \"allreduce @ [0]\")) {",
          "content_same": false
        },
        {
          "line": 3954,
          "old_api": null,
          "new_api": "IsReplicated",
          "old_text": null,
          "new_text": "strategy.output_sharding.IsReplicated()",
          "old_line_content": "        }",
          "new_line_content": "    if (strategy.output_sharding.IsReplicated()) {",
          "content_same": false
        },
        {
          "line": 3955,
          "old_api": null,
          "new_api": "absl::StrContains(strategy.name, \"1d\")",
          "old_text": null,
          "new_text": "absl::StrContains(strategy.name, \"1d\")",
          "old_line_content": "",
          "new_line_content": "      if (absl::StrContains(strategy.name, \"1d\")) {",
          "content_same": false
        },
        {
          "line": 3957,
          "old_api": null,
          "new_api": "Undefined",
          "old_text": null,
          "new_text": "Undefined()",
          "old_line_content": "      }",
          "new_line_content": "          return Undefined();",
          "content_same": false
        },
        {
          "line": 3960,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "ins->shape()",
          "old_line_content": "      }",
          "new_line_content": "        return Tile(ins->shape(), {0}, {mesh_dim}, device_mesh_1d);",
          "content_same": false
        },
        {
          "line": 3963,
          "old_api": null,
          "new_api": "Undefined",
          "old_text": null,
          "new_text": "Undefined()",
          "old_line_content": "    }",
          "new_line_content": "        return Undefined();",
          "content_same": false
        },
        {
          "line": 3966,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "ins->shape()",
          "old_line_content": "    }",
          "new_line_content": "      return Tile(ins->shape(), {0}, {mesh_dim}, device_mesh);",
          "content_same": false
        },
        {
          "line": 3972,
          "old_api": null,
          "new_api": "tile_assignment",
          "old_text": null,
          "new_text": "strategy.output_sharding.tile_assignment()",
          "old_line_content": "  } else {",
          "new_line_content": "    Array<int64_t> tile_assignment = strategy.output_sharding.tile_assignment();",
          "content_same": false
        },
        {
          "line": 3974,
          "old_api": null,
          "new_api": "std::move(tile_assignment)",
          "old_text": null,
          "new_text": "std::move(tile_assignment)",
          "old_line_content": "  }",
          "new_line_content": "    return HloSharding::Tile(std::move(tile_assignment));",
          "content_same": false
        },
        {
          "line": 3977,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "ins->ToString()",
          "old_line_content": "}",
          "new_line_content": "    LOG(FATAL) << \"Invalid instruction: \" << ins->ToString();",
          "content_same": false
        },
        {
          "line": 3980,
          "old_api": null,
          "new_api": "Undefined",
          "old_text": null,
          "new_text": "Undefined()",
          "old_line_content": "bool HasReduceScatterOpportunity(",
          "new_line_content": "  return Undefined();",
          "content_same": false
        },
        {
          "line": 3990,
          "old_api": null,
          "new_api": "operands",
          "old_text": null,
          "new_text": "inst->operands()",
          "old_line_content": "  }",
          "new_line_content": "  for (const HloInstruction* operand : inst->operands()) {",
          "content_same": false
        },
        {
          "line": 4002,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "inst->opcode()",
          "old_line_content": "            .output_sharding.IsReplicated()) {",
          "new_line_content": "  if (inst->opcode() == HloOpcode::kDot) {",
          "content_same": false
        },
        {
          "line": 4003,
          "old_api": null,
          "new_api": "operand",
          "old_text": null,
          "new_text": "inst->operand(0)",
          "old_line_content": "      // This dot is replicated on all devices. Do not split it.",
          "new_line_content": "    if (GetShardingStrategy(inst->operand(0), strategy_map, cost_graph, s_val)",
          "content_same": false
        },
        {
          "line": 4005,
          "old_api": null,
          "new_api": "operand",
          "old_text": null,
          "new_text": "inst->operand(1)",
          "old_line_content": "      return false;",
          "new_line_content": "        GetShardingStrategy(inst->operand(1), strategy_map, cost_graph, s_val)",
          "content_same": false
        },
        {
          "line": 4014,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "inst->opcode()",
          "old_line_content": "  return false;",
          "new_line_content": "  if (inst->opcode() == HloOpcode::kConvolution) {",
          "content_same": false
        },
        {
          "line": 4033,
          "old_api": null,
          "new_api": "computations",
          "old_text": null,
          "new_text": "module->computations(execution_threads)",
          "old_line_content": "      // Do not remove entry computation's parameter and root instruction's",
          "new_line_content": "  for (HloComputation* computation : module->computations(execution_threads)) {",
          "content_same": false
        },
        {
          "line": 4034,
          "old_api": null,
          "new_api": "IsEntryComputation",
          "old_text": null,
          "new_text": "computation->IsEntryComputation()",
          "old_line_content": "      // sharding if preserve_shardings is kKeepInputOutputShardings.",
          "new_line_content": "    bool is_entry_computation = computation->IsEntryComputation();",
          "content_same": false
        },
        {
          "line": 4036,
          "old_api": null,
          "new_api": "instructions",
          "old_text": null,
          "new_text": "computation->instructions()",
          "old_line_content": "              AutoShardingOption::PreserveShardingsType::",
          "new_line_content": "    for (HloInstruction* ins : computation->instructions()) {",
          "content_same": false
        },
        {
          "line": 4048,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "keep_inst.end()",
          "old_line_content": "        changed |= true;",
          "new_line_content": "          keep_inst.find(ins->operand(0)) != keep_inst.end()) {",
          "content_same": false
        },
        {
          "line": 4051,
          "old_api": null,
          "new_api": "has_sharding",
          "old_text": null,
          "new_text": "ins->has_sharding()",
          "old_line_content": "    }",
          "new_line_content": "      if (ins->has_sharding()) {",
          "content_same": false
        },
        {
          "line": 4053,
          "old_api": null,
          "new_api": "clear_sharding",
          "old_text": null,
          "new_text": "ins->clear_sharding()",
          "old_line_content": "  return changed;",
          "new_line_content": "        ins->clear_sharding();",
          "content_same": false
        },
        {
          "line": 4061,
          "old_api": null,
          "new_api": "layout_canonicalization_callback",
          "old_text": null,
          "new_text": "module->layout_canonicalization_callback()",
          "old_line_content": "  TF_ASSIGN_OR_RETURN(auto layouts,",
          "new_line_content": "  if (!module->layout_canonicalization_callback()) {",
          "content_same": false
        },
        {
          "line": 4062,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(INFO)",
          "old_line_content": "                      module->layout_canonicalization_callback()(*module));",
          "new_line_content": "    LOG(INFO) << \"There is no registered layout_canonicalization_callback.\";",
          "content_same": false
        },
        {
          "line": 4063,
          "old_api": null,
          "new_api": "OkStatus",
          "old_text": null,
          "new_text": "OkStatus()",
          "old_line_content": "  std::vector<Shape>& argument_shapes = layouts.first;",
          "new_line_content": "    return OkStatus();",
          "content_same": false
        },
        {
          "line": 4075,
          "old_api": null,
          "new_api": "parameter_count",
          "old_text": null,
          "new_text": "entry_computation_layout.parameter_count()",
          "old_line_content": "  }",
          "new_line_content": "  CHECK_EQ(argument_shapes.size(), entry_computation_layout.parameter_count());",
          "content_same": false
        },
        {
          "line": 4077,
          "old_api": null,
          "new_api": "mutable_parameter_layout",
          "old_text": null,
          "new_text": "entry_computation_layout.mutable_parameter_layout(i)\n                           ->CopyLayoutFromShape(argument_shapes.at(i))",
          "old_line_content": "      entry_computation_layout;",
          "new_line_content": "    TF_RETURN_IF_ERROR(entry_computation_layout.mutable_parameter_layout(i)",
          "content_same": false
        },
        {
          "line": 4080,
          "old_api": null,
          "new_api": "mutable_entry_computation_layout",
          "old_text": null,
          "new_text": "module->config().mutable_entry_computation_layout()",
          "old_line_content": "",
          "new_line_content": "  *module->config().mutable_entry_computation_layout() =",
          "content_same": false
        },
        {
          "line": 4082,
          "old_api": null,
          "new_api": "OkStatus",
          "old_text": null,
          "new_text": "OkStatus()",
          "old_line_content": "    const AutoShardingOption& option)",
          "new_line_content": "  return OkStatus();",
          "content_same": false
        }
      ],
      "deletions": [
        {
          "line": 4134,
          "old_api": "spmd::ComputeInstructionExecutionCounts(\n          module, option_.loop_iteration_count_estimate)",
          "new_api": null,
          "old_text": "spmd::ComputeInstructionExecutionCounts(\n          module, option_.loop_iteration_count_estimate)",
          "new_text": null,
          "old_line_content": "      instruction_execution_counts = spmd::ComputeInstructionExecutionCounts(",
          "new_line_content": "  solver_option.only_allow_divisible_intermediate = false;",
          "content_same": false
        },
        {
          "line": 4146,
          "old_api": "ProcessShardingInstruction",
          "new_api": null,
          "old_text": "ProcessShardingInstruction(\n      module, execution_threads, /*replace_sharding_with_copy=*/true,\n      &unspecified_dims, /*saved_root_shardings=*/nullptr,\n      /*saved_parameter_shardings=*/nullptr)",
          "new_text": null,
          "old_line_content": "  auto status_or_changed = ProcessShardingInstruction(",
          "new_line_content": "  // sharding pass, instead of fixing the shardings, mark all the replicated",
          "content_same": false
        },
        {
          "line": 4151,
          "old_api": "status",
          "new_api": null,
          "old_text": "status_or_changed.status()",
          "new_text": null,
          "old_line_content": "    return status_or_changed.status();",
          "new_line_content": "      module, execution_threads, /*replace_sharding_with_copy=*/true,",
          "content_same": false
        },
        {
          "line": 4153,
          "old_api": "value",
          "new_api": null,
          "old_text": "status_or_changed.value()",
          "new_text": null,
          "old_line_content": "  if (status_or_changed.value()) {",
          "new_line_content": "      /*saved_parameter_shardings=*/nullptr);",
          "content_same": false
        },
        {
          "line": 4158,
          "old_api": "VLOG",
          "new_api": null,
          "old_text": "VLOG(3)",
          "new_text": null,
          "old_line_content": "    VLOG(3) << \"This workload does not have CustomCalls with \"",
          "new_line_content": "    module_is_changed = true;",
          "content_same": false
        },
        {
          "line": 4164,
          "old_api": "spmd::SaveUserShardings(module, option_.preserve_shardings)",
          "new_api": null,
          "old_text": "spmd::SaveUserShardings(module, option_.preserve_shardings)",
          "new_text": null,
          "old_line_content": "          spmd::SaveUserShardings(module, option_.preserve_shardings);",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 4170,
          "old_api": "RemoveShardingAnnotation",
          "new_api": null,
          "old_text": "RemoveShardingAnnotation(module, execution_threads)",
          "new_text": null,
          "old_line_content": "        RemoveShardingAnnotation(module, execution_threads);",
          "new_line_content": "  // Remove xla sharding annotations, if there is any.",
          "content_same": false
        },
        {
          "line": 4171,
          "old_api": "ok",
          "new_api": null,
          "old_text": "status_or_changed.ok()",
          "new_text": null,
          "old_line_content": "    if (!status_or_changed.ok()) {",
          "new_line_content": "  if (option_.preserve_shardings !=",
          "content_same": false
        },
        {
          "line": 4172,
          "old_api": "status",
          "new_api": null,
          "old_text": "status_or_changed.status()",
          "new_text": null,
          "old_line_content": "      return status_or_changed.status();",
          "new_line_content": "      AutoShardingOption::PreserveShardingsType::kKeepAllShardings) {",
          "content_same": false
        },
        {
          "line": 4184,
          "old_api": "shape",
          "new_api": null,
          "old_text": "buffer.shape()",
          "new_text": null,
          "old_line_content": "    return spmd::GetBytes(buffer.shape());",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 4191,
          "old_api": "entry_computation",
          "new_api": null,
          "old_text": "module->entry_computation()",
          "new_text": null,
          "old_line_content": "  const HloComputation* entry_computation = module->entry_computation();",
          "new_line_content": "      HloSchedule schedule,",
          "content_same": false
        },
        {
          "line": 4193,
          "old_api": "value",
          "new_api": null,
          "old_text": "HloAliasAnalysis::Run(module).value()",
          "new_text": null,
          "old_line_content": "      HloAliasAnalysis::Run(module).value();",
          "new_line_content": "                     ComputationSchedulerToModuleScheduler(DFSMemoryScheduler),",
          "content_same": false
        },
        {
          "line": 4194,
          "old_api": "spmd::BuildAliasMap(module)",
          "new_api": null,
          "old_text": "spmd::BuildAliasMap(module)",
          "new_text": null,
          "old_line_content": "  spmd::AliasMap alias_map = spmd::BuildAliasMap(module);",
          "new_line_content": "                     execution_threads));",
          "content_same": false
        },
        {
          "line": 4196,
          "old_api": "TF_ASSIGN_OR_RETURN",
          "new_api": null,
          "old_text": "TF_ASSIGN_OR_RETURN(\n      std::unique_ptr<HloLiveRange> hlo_live_range,\n      HloLiveRange::Run(schedule, *alias_analysis, entry_computation))",
          "new_text": null,
          "old_line_content": "  TF_ASSIGN_OR_RETURN(",
          "new_line_content": "  std::unique_ptr<HloAliasAnalysis> alias_analysis =",
          "content_same": false
        },
        {
          "line": 4201,
          "old_api": "schedule_end_time",
          "new_api": null,
          "old_text": "hlo_live_range->schedule_end_time()",
          "new_text": null,
          "old_line_content": "  spmd::LivenessSet liveness_set(hlo_live_range->schedule_end_time() + 1);",
          "new_line_content": "      std::unique_ptr<HloLiveRange> hlo_live_range,",
          "content_same": false
        },
        {
          "line": 4207,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "hlo_live_range->ToString()",
          "new_text": null,
          "old_line_content": "  VLOG(10) << hlo_live_range->ToString();",
          "new_line_content": "    for (int64_t i = iter.second.start; i <= iter.second.end; ++i) {",
          "content_same": false
        },
        {
          "line": 4209,
          "old_api": "spmd::PrintLivenessSet(liveness_set)",
          "new_api": null,
          "old_text": "spmd::PrintLivenessSet(liveness_set)",
          "new_text": null,
          "old_line_content": "  XLA_VLOG_LINES(10, spmd::PrintLivenessSet(liveness_set));",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 4221,
          "old_api": "SetValues",
          "new_api": null,
          "old_text": "original_device_mesh.SetValues(option_.device_mesh_ids)",
          "new_text": null,
          "old_line_content": "  original_device_mesh.SetValues(option_.device_mesh_ids);",
          "new_line_content": "  // both 1D and 2D mesh shapes.",
          "content_same": false
        },
        {
          "line": 4227,
          "old_api": "spmd::DecomposeMeshShapes(option_.device_mesh_shape)",
          "new_api": null,
          "old_text": "spmd::DecomposeMeshShapes(option_.device_mesh_shape)",
          "new_text": null,
          "old_line_content": "    partial_mesh_shapes = spmd::DecomposeMeshShapes(option_.device_mesh_shape);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 4232,
          "old_api": "CallGraph::Build(module)",
          "new_api": null,
          "old_text": "CallGraph::Build(module)",
          "new_text": null,
          "old_line_content": "  std::unique_ptr<CallGraph> call_graph = CallGraph::Build(module);",
          "new_line_content": "  } else {",
          "content_same": false
        },
        {
          "line": 4234,
          "old_api": "size",
          "new_api": null,
          "old_text": "partial_mesh_shapes.size()",
          "new_text": null,
          "old_line_content": "  for (size_t mesh_idx = 0; mesh_idx < partial_mesh_shapes.size(); ++mesh_idx) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 4237,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(INFO)",
          "new_text": null,
          "old_line_content": "    LOG(INFO) << \"Processing partial mesh shape: \"",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 4245,
          "old_api": "size",
          "new_api": null,
          "old_text": "partial_mesh_shapes.size()",
          "new_text": null,
          "old_line_content": "    if (mesh_idx != partial_mesh_shapes.size() - 1) {",
          "new_line_content": "    int64_t total_devices = 1;",
          "content_same": false
        },
        {
          "line": 4246,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "spmd::AdjustShardingsWithPartialMeshShape(\n          sequence.instructions(), mesh_shape, total_devices,\n          /* crash_on_error */ !option_.try_multiple_mesh_shapes)",
          "new_text": null,
          "old_line_content": "      auto changed_or = spmd::AdjustShardingsWithPartialMeshShape(",
          "new_line_content": "    for (auto i : mesh_shape) {",
          "content_same": false
        },
        {
          "line": 4247,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "sequence.instructions()",
          "new_text": null,
          "old_line_content": "          sequence.instructions(), mesh_shape, total_devices,",
          "new_line_content": "      total_devices *= i;",
          "content_same": false
        },
        {
          "line": 4257,
          "old_api": "std::vector<int64_t>(total_devices)",
          "new_api": null,
          "old_text": "std::vector<int64_t>(total_devices)",
          "new_text": null,
          "old_line_content": "    std::vector<int64_t> device_mesh_ids = std::vector<int64_t>(total_devices);",
          "new_line_content": "      } else {",
          "content_same": false
        },
        {
          "line": 4259,
          "old_api": "SetValues",
          "new_api": null,
          "old_text": "device_mesh.SetValues(device_mesh_ids)",
          "new_text": null,
          "old_line_content": "    device_mesh.SetValues(device_mesh_ids);",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 4267,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "module->ToString()",
          "new_text": null,
          "old_line_content": "    XLA_VLOG_LINES(1, module->ToString());",
          "new_line_content": "    spmd::ClusterEnvironment cluster_env(",
          "content_same": false
        },
        {
          "line": 4268,
          "old_api": "get",
          "new_api": null,
          "old_text": "spmd::MemoryBudgetLowerBound(\n        *module, liveness_set, alias_analysis.get(),\n        device_mesh.num_elements())",
          "new_text": null,
          "old_line_content": "    int64_t memory_lower_bound = spmd::MemoryBudgetLowerBound(",
          "new_line_content": "        original_device_mesh, device_mesh, option_.device_mesh_alpha,",
          "content_same": false
        },
        {
          "line": 4269,
          "old_api": "get",
          "new_api": null,
          "old_text": "alias_analysis.get()",
          "new_text": null,
          "old_line_content": "        *module, liveness_set, alias_analysis.get(),",
          "new_line_content": "        option_.device_mesh_beta, prof_result, solver_option);",
          "content_same": false
        },
        {
          "line": 4270,
          "old_api": "num_elements",
          "new_api": null,
          "old_text": "device_mesh.num_elements()",
          "new_text": null,
          "old_line_content": "        device_mesh.num_elements());",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 4277,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(INFO)",
          "new_text": null,
          "old_line_content": "      LOG(INFO)",
          "new_line_content": "        1 + memory_lower_bound / (1024 * 1024 * 1024);",
          "content_same": false
        },
        {
          "line": 4291,
          "old_api": "num_elements",
          "new_api": null,
          "old_text": "original_device_mesh.num_elements()",
          "new_text": null,
          "old_line_content": "                                         original_device_mesh.num_elements() /",
          "new_line_content": "                                         (1024 * 1024 * 1024) *",
          "content_same": false
        },
        {
          "line": 4292,
          "old_api": "num_elements",
          "new_api": null,
          "old_text": "device_mesh.num_elements()",
          "new_text": null,
          "old_line_content": "                                         device_mesh.num_elements();",
          "new_line_content": "                                         option_.memory_budget_ratio;",
          "content_same": false
        },
        {
          "line": 4293,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(INFO)",
          "new_text": null,
          "old_line_content": "      LOG(INFO) << \"Setting option.memory_budget_per_device to \"",
          "new_line_content": "    } else if (option_.memory_budget_per_device > 0) {",
          "content_same": false
        },
        {
          "line": 4298,
          "old_api": "AnnotateShardingWithSimpleHeuristic",
          "new_api": null,
          "old_text": "AnnotateShardingWithSimpleHeuristic(\n          module, solver_option.force_simple_heuristic, alias_map, cluster_env)",
          "new_text": null,
          "old_line_content": "      AnnotateShardingWithSimpleHeuristic(",
          "new_line_content": "                << option_.memory_budget_per_device;",
          "content_same": false
        },
        {
          "line": 4304,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "DisableIncompatibleMixedMeshShapeAndForceBatchDim(\n          batch_dim_map, sequence.instructions(), device_mesh.num_elements(),\n          solver_option)",
          "new_text": null,
          "old_line_content": "      DisableIncompatibleMixedMeshShapeAndForceBatchDim(",
          "new_line_content": "      return AutoShardingResult::kModuleChangedShardingPerformed;",
          "content_same": false
        },
        {
          "line": 4305,
          "old_api": "num_elements",
          "new_api": null,
          "old_text": "device_mesh.num_elements()",
          "new_text": null,
          "old_line_content": "          batch_dim_map, sequence.instructions(), device_mesh.num_elements(),",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 4311,
          "old_api": "spmd::BuildInstructionDepthMap(sequence, batch_dim_map)",
          "new_api": null,
          "old_text": "spmd::BuildInstructionDepthMap(sequence, batch_dim_map)",
          "new_text": null,
          "old_line_content": "    ins_depth_map = spmd::BuildInstructionDepthMap(sequence, batch_dim_map);",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 4317,
          "old_api": "TF_ASSIGN_OR_RETURN",
          "new_api": null,
          "old_text": "TF_ASSIGN_OR_RETURN(\n        std::tie(strategy_map, leaf_strategies, associative_dot_pairs),\n        BuildStrategyAndCost(sequence, module, instruction_execution_counts,\n                             ins_depth_map, batch_dim_map, alias_map,\n                             cluster_env, solver_option, *call_graph,\n                             option_.try_multiple_mesh_shapes))",
          "new_text": null,
          "old_line_content": "    TF_ASSIGN_OR_RETURN(",
          "new_line_content": "    spmd::StrategyMap strategy_map;",
          "content_same": false
        },
        {
          "line": 4318,
          "old_api": "std::tie(strategy_map, leaf_strategies, associative_dot_pairs)",
          "new_api": null,
          "old_text": "std::tie(strategy_map, leaf_strategies, associative_dot_pairs)",
          "new_text": null,
          "old_line_content": "        std::tie(strategy_map, leaf_strategies, associative_dot_pairs),",
          "new_line_content": "    spmd::LeafStrategies leaf_strategies;",
          "content_same": false
        },
        {
          "line": 4319,
          "old_api": "BuildStrategyAndCost",
          "new_api": null,
          "old_text": "BuildStrategyAndCost(sequence, module, instruction_execution_counts,\n                             ins_depth_map, batch_dim_map, alias_map,\n                             cluster_env, solver_option, *call_graph,\n                             option_.try_multiple_mesh_shapes)",
          "new_text": null,
          "old_line_content": "        BuildStrategyAndCost(sequence, module, instruction_execution_counts,",
          "new_line_content": "    spmd::AssociativeDotPairs associative_dot_pairs;",
          "content_same": false
        },
        {
          "line": 4324,
          "old_api": "CheckAliasSetCompatibility",
          "new_api": null,
          "old_text": "CheckAliasSetCompatibility(alias_set, leaf_strategies, sequence)",
          "new_text": null,
          "old_line_content": "    CheckAliasSetCompatibility(alias_set, leaf_strategies, sequence);",
          "new_line_content": "                             ins_depth_map, batch_dim_map, alias_map,",
          "content_same": false
        },
        {
          "line": 4325,
          "old_api": "PrintStrategyMap",
          "new_api": null,
          "old_text": "PrintStrategyMap(strategy_map, sequence)",
          "new_text": null,
          "old_line_content": "    XLA_VLOG_LINES(8, PrintStrategyMap(strategy_map, sequence));",
          "new_line_content": "                             cluster_env, solver_option, *call_graph,",
          "content_same": false
        },
        {
          "line": 4335,
          "old_api": "CallSolver",
          "new_api": null,
          "old_text": "CallSolver(\n          sequence, liveness_set, strategy_map, leaf_strategies, cost_graph,\n          alias_set, option_.memory_budget_per_device,\n          /*crash_at_infinity_costs_check*/\n          !option_.try_multiple_mesh_shapes, option_.solver_timeout_in_seconds)",
          "new_text": null,
          "old_line_content": "      auto solver_result = CallSolver(",
          "new_line_content": "    // ----- Call the ILP Solver -----",
          "content_same": false
        },
        {
          "line": 4342,
          "old_api": "ok",
          "new_api": null,
          "old_text": "solver_result.status.ok()",
          "new_text": null,
          "old_line_content": "      } else if (!solver_result.status.ok()) {",
          "new_line_content": "          /*crash_at_infinity_costs_check*/",
          "content_same": false
        },
        {
          "line": 4347,
          "old_api": "size",
          "new_api": null,
          "old_text": "partial_mesh_shapes.size()",
          "new_text": null,
          "old_line_content": "        if (mesh_idx == partial_mesh_shapes.size() - 1) {",
          "new_line_content": "        return AutoShardingResult::kModuleUnchanged;",
          "content_same": false
        },
        {
          "line": 4355,
          "old_api": "PrintAutoShardingSolution",
          "new_api": null,
          "old_text": "PrintAutoShardingSolution(sequence, liveness_set,\n                                                strategy_map, leaf_strategies,\n                                                cost_graph, s_val, objective)",
          "new_text": null,
          "old_line_content": "    XLA_VLOG_LINES(5, PrintAutoShardingSolution(sequence, liveness_set,",
          "new_line_content": "    } else {",
          "content_same": false
        },
        {
          "line": 4358,
          "old_api": "PrintSolutionMemoryUsage",
          "new_api": null,
          "old_text": "PrintSolutionMemoryUsage(liveness_set, strategy_map,\n                                               cost_graph, s_val)",
          "new_text": null,
          "old_line_content": "    XLA_VLOG_LINES(1, PrintSolutionMemoryUsage(liveness_set, strategy_map,",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 4363,
          "old_api": "GenerateReduceScatter",
          "new_api": null,
          "old_text": "GenerateReduceScatter(sequence, alias_map, ins_depth_map, strategy_map,\n                            cost_graph, s_val, cluster_env, solver_option)",
          "new_text": null,
          "old_line_content": "      GenerateReduceScatter(sequence, alias_map, ins_depth_map, strategy_map,",
          "new_line_content": "                                               cost_graph, s_val));",
          "content_same": false
        },
        {
          "line": 4368,
          "old_api": "size",
          "new_api": null,
          "old_text": "partial_mesh_shapes.size()",
          "new_text": null,
          "old_line_content": "                   (mesh_idx == partial_mesh_shapes.size() - 1));",
          "new_line_content": "                            cost_graph, s_val, cluster_env, solver_option);",
          "content_same": false
        },
        {
          "line": 4369,
          "old_api": "size",
          "new_api": null,
          "old_text": "partial_mesh_shapes.size()",
          "new_text": null,
          "old_line_content": "    if (mesh_idx == partial_mesh_shapes.size() - 1) {",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 4370,
          "old_api": "SetHloShardingPostProcessing",
          "new_api": null,
          "old_text": "SetHloShardingPostProcessing(sequence, strategy_map, cost_graph, s_val,\n                                   cluster_env, &preserve_shardings)",
          "new_text": null,
          "old_line_content": "      SetHloShardingPostProcessing(sequence, strategy_map, cost_graph, s_val,",
          "new_line_content": "    // ----- Set Sharding -----",
          "content_same": false
        },
        {
          "line": 4378,
          "old_api": "num_elements",
          "new_api": null,
          "old_text": "original_device_mesh.num_elements()",
          "new_text": null,
          "old_line_content": "    spmd::CheckHloSharding(sequence, original_device_mesh.num_elements());",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 4383,
          "old_api": "spmd::CheckUserShardingPreservation(module, preserve_shardings)",
          "new_api": null,
          "old_text": "spmd::CheckUserShardingPreservation(module, preserve_shardings)",
          "new_text": null,
          "old_line_content": "    spmd::CheckUserShardingPreservation(module, preserve_shardings);",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 4388,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "absl::StrCat(\"After auto sharding for mesh \",\n                                 spmd::ToString(option_.device_mesh_shape),\n                                 \":\\n\", module->ToString())",
          "new_text": null,
          "old_line_content": "  XLA_VLOG_LINES(7, absl::StrCat(\"After auto sharding for mesh \",",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 4389,
          "old_api": "spmd::ToString(option_.device_mesh_shape)",
          "new_api": null,
          "old_text": "spmd::ToString(option_.device_mesh_shape)",
          "new_text": null,
          "old_line_content": "                                 spmd::ToString(option_.device_mesh_shape),",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 4390,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "module->ToString()",
          "new_text": null,
          "old_line_content": "                                 \":\\n\", module->ToString()));",
          "new_line_content": "  // ----- Canonicalize layouts based on LayoutCanonicalizationCallback. -----",
          "content_same": false
        },
        {
          "line": 4399,
          "old_api": "computations",
          "new_api": null,
          "old_text": "module->computations()",
          "new_text": null,
          "old_line_content": "  for (auto computation : module->computations()) {",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 4400,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "computation->instructions()",
          "new_text": null,
          "old_line_content": "    for (auto instruction : computation->instructions()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 4401,
          "old_api": "has_sharding",
          "new_api": null,
          "old_text": "instruction->has_sharding()",
          "new_text": null,
          "old_line_content": "      if (instruction->has_sharding()) {",
          "new_line_content": "bool ModuleHasUserShardings(const HloModule* module) {",
          "content_same": false
        },
        {
          "line": 4422,
          "old_api": "VLOG",
          "new_api": null,
          "old_text": "VLOG(1)",
          "new_text": null,
          "old_line_content": "  VLOG(1) << \"Start auto sharding pass\";",
          "new_line_content": "    const absl::flat_hash_set<absl::string_view>& execution_threads) {",
          "content_same": false
        },
        {
          "line": 4424,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "XLA_VLOG_LINES(6,\n                 absl::StrCat(\"Before auto sharding:\\n\", module->ToString()))",
          "new_text": null,
          "old_line_content": "  XLA_VLOG_LINES(6,",
          "new_line_content": "    return false;",
          "content_same": false
        },
        {
          "line": 4425,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "module->ToString()",
          "new_text": null,
          "old_line_content": "                 absl::StrCat(\"Before auto sharding:\\n\", module->ToString()));",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 4431,
          "old_api": "metrics::RecordAutoShardingInvocations()",
          "new_api": null,
          "old_text": "metrics::RecordAutoShardingInvocations()",
          "new_text": null,
          "old_line_content": "  metrics::RecordAutoShardingInvocations();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 2396,
          "old_api": "absl::StrAppend(&str, i, \", \")",
          "new_api": null,
          "old_text": "absl::StrAppend(&str, i, \", \")",
          "new_text": null,
          "old_line_content": "        absl::StrAppend(&str, i, \", \");",
          "new_line_content": "      for (auto i : L[t]) {",
          "content_same": false
        },
        {
          "line": 2399,
          "old_api": "MakeRowConstraint",
          "new_api": null,
          "old_text": "solver->MakeRowConstraint(\n          -MPSolver::infinity(), M, absl::StrCat(\"mem[\", t, \"] = \", str))",
          "new_text": null,
          "old_line_content": "      MPConstraint* constraint = solver->MakeRowConstraint(",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 2400,
          "old_api": "absl::StrCat(\"mem[\", t, \"] = \", str)",
          "new_api": null,
          "old_text": "absl::StrCat(\"mem[\", t, \"] = \", str)",
          "new_text": null,
          "old_line_content": "          -MPSolver::infinity(), M, absl::StrCat(\"mem[\", t, \"] = \", str));",
          "new_line_content": "      str += \"]\";",
          "content_same": false
        },
        {
          "line": 4448,
          "old_api": "size",
          "new_api": null,
          "old_text": "spmd::CreateDifferentMeshShapesToTry(\n        absl::c_accumulate(option_.device_mesh_shape, 1,\n                           [](int64_t a, int64_t b) { return a * b; }),\n        option_.device_mesh_shape.size(),\n        /* symmetrical_mesh_dims */ !asymmetrical_mesh_dims)",
          "new_text": null,
          "old_line_content": "    mesh_shapes = spmd::CreateDifferentMeshShapesToTry(",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 4449,
          "old_api": "absl::c_accumulate(option_.device_mesh_shape, 1,\n                           [](int64_t a, int64_t b) { return a * b; })",
          "new_api": null,
          "old_text": "absl::c_accumulate(option_.device_mesh_shape, 1,\n                           [](int64_t a, int64_t b) { return a * b; })",
          "new_text": null,
          "old_line_content": "        absl::c_accumulate(option_.device_mesh_shape, 1,",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 4451,
          "old_api": "size",
          "new_api": null,
          "old_text": "option_.device_mesh_shape.size()",
          "new_text": null,
          "old_line_content": "        option_.device_mesh_shape.size(),",
          "new_line_content": "  if (option_.try_multiple_mesh_shapes) {",
          "content_same": false
        },
        {
          "line": 2404,
          "old_api": "SetCoefficient",
          "new_api": null,
          "old_text": "constraint->SetCoefficient(s[i][j],\n                                     accumulated_coefficient + m[i][j])",
          "new_text": null,
          "old_line_content": "          constraint->SetCoefficient(s[i][j],",
          "new_line_content": "      for (auto i : L[t]) {",
          "content_same": false
        },
        {
          "line": 4454,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "mesh_shapes.push_back(option_.device_mesh_shape)",
          "new_text": null,
          "old_line_content": "    mesh_shapes.push_back(option_.device_mesh_shape);",
          "new_line_content": "                           [](int64_t a, int64_t b) { return a * b; }),",
          "content_same": false
        },
        {
          "line": 4457,
          "old_api": "size",
          "new_api": null,
          "old_text": "mesh_shapes.size()",
          "new_text": null,
          "old_line_content": "  size_t num_meshes = mesh_shapes.size();",
          "new_line_content": "  } else {",
          "content_same": false
        },
        {
          "line": 2415,
          "old_api": "MakeRowConstraint",
          "new_api": null,
          "old_text": "solver->MakeRowConstraint(\n        1.0, 1.0,\n        absl::StrCat(\"sum(e[\", edge.first, \"][\", edge.second, \"][*]) = 1\"))",
          "new_text": null,
          "old_line_content": "    MPConstraint* constraint = solver->MakeRowConstraint(",
          "new_line_content": "  // d. specified via \"BoolVarArray\"",
          "content_same": false
        },
        {
          "line": 4463,
          "old_api": "VLOG",
          "new_api": null,
          "old_text": "VLOG(1)",
          "new_text": null,
          "old_line_content": "  VLOG(1) << \"Original mesh shape \"",
          "new_line_content": "  std::vector<StatusOr<AutoShardingResult>> changed(",
          "content_same": false
        },
        {
          "line": 2417,
          "old_api": "absl::StrCat(\"sum(e[\", edge.first, \"][\", edge.second, \"][*]) = 1\")",
          "new_api": null,
          "old_text": "absl::StrCat(\"sum(e[\", edge.first, \"][\", edge.second, \"][*]) = 1\")",
          "new_text": null,
          "old_line_content": "        absl::StrCat(\"sum(e[\", edge.first, \"][\", edge.second, \"][*]) = 1\"));",
          "new_line_content": "  for (size_t i = 0; i < num_edges; ++i) {",
          "content_same": false
        },
        {
          "line": 2418,
          "old_api": "size",
          "new_api": null,
          "old_text": "e[i].size()",
          "new_text": null,
          "old_line_content": "    for (size_t j = 0; j < e[i].size(); ++j) {",
          "new_line_content": "    std::pair<int, int> edge = E[i];",
          "content_same": false
        },
        {
          "line": 4464,
          "old_api": "spmd::ToString(option_.device_mesh_shape)",
          "new_api": null,
          "old_text": "spmd::ToString(option_.device_mesh_shape)",
          "new_text": null,
          "old_line_content": "          << spmd::ToString(option_.device_mesh_shape);",
          "new_line_content": "      num_meshes, AutoShardingResult::kModuleUnchanged);",
          "content_same": false
        },
        {
          "line": 4465,
          "old_api": "std::numeric_limits<double>::max()",
          "new_api": null,
          "old_text": "std::numeric_limits<double>::max()",
          "new_text": null,
          "old_line_content": "  double min_objective_value = std::numeric_limits<double>::max();",
          "new_line_content": "  std::vector<double> objective_values(num_meshes, -1);",
          "content_same": false
        },
        {
          "line": 2425,
          "old_api": "size",
          "new_api": null,
          "old_text": "s[edge.first].size()",
          "new_text": null,
          "old_line_content": "    for (size_t p = 0; p < s[edge.first].size(); ++p) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 2426,
          "old_api": "MakeRowConstraint",
          "new_api": null,
          "old_text": "solver->MakeRowConstraint(\n          -MPSolver::infinity(), 0, absl::StrCat(\"f for i = \", i, \", p = \", p))",
          "new_text": null,
          "old_line_content": "      MPConstraint* constraint = solver->MakeRowConstraint(",
          "new_line_content": "  // f.",
          "content_same": false
        },
        {
          "line": 2427,
          "old_api": "absl::StrCat(\"f for i = \", i, \", p = \", p)",
          "new_api": null,
          "old_text": "absl::StrCat(\"f for i = \", i, \", p = \", p)",
          "new_text": null,
          "old_line_content": "          -MPSolver::infinity(), 0, absl::StrCat(\"f for i = \", i, \", p = \", p));",
          "new_line_content": "  for (size_t i = 0; i < num_edges; ++i) {",
          "content_same": false
        },
        {
          "line": 2428,
          "old_api": "SetCoefficient",
          "new_api": null,
          "old_text": "constraint->SetCoefficient(s[edge.first][p], -1.0)",
          "new_text": null,
          "old_line_content": "      constraint->SetCoefficient(s[edge.first][p], -1.0);",
          "new_line_content": "    std::pair<int, int> edge = E[i];",
          "content_same": false
        },
        {
          "line": 4474,
          "old_api": "set_layout_canonicalization_callback",
          "new_api": null,
          "old_text": "module_clone->set_layout_canonicalization_callback(\n        module->layout_canonicalization_callback())",
          "new_text": null,
          "old_line_content": "    module_clone->set_layout_canonicalization_callback(",
          "new_line_content": "    AutoShardingOption this_option = option_;",
          "content_same": false
        },
        {
          "line": 4475,
          "old_api": "layout_canonicalization_callback",
          "new_api": null,
          "old_text": "module->layout_canonicalization_callback()",
          "new_text": null,
          "old_line_content": "        module->layout_canonicalization_callback());",
          "new_line_content": "    this_option.device_mesh_shape = mesh_shapes[i];",
          "content_same": false
        },
        {
          "line": 4480,
          "old_api": "GetSolverOptimalObjectiveValue",
          "new_api": null,
          "old_text": "pass->GetSolverOptimalObjectiveValue()",
          "new_text": null,
          "old_line_content": "    objective_values[i] = pass->GetSolverOptimalObjectiveValue();",
          "new_line_content": "    auto pass_result =",
          "content_same": false
        },
        {
          "line": 4483,
          "old_api": "ok",
          "new_api": null,
          "old_text": "pass_result.ok()",
          "new_text": null,
          "old_line_content": "    if (!pass_result.ok()) {",
          "new_line_content": "    changed[i] = pass_result;",
          "content_same": false
        },
        {
          "line": 2437,
          "old_api": "size",
          "new_api": null,
          "old_text": "s[edge.second].size()",
          "new_text": null,
          "old_line_content": "    for (size_t q = 0; q < s[edge.second].size(); ++q) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 2438,
          "old_api": "MakeRowConstraint",
          "new_api": null,
          "old_text": "solver->MakeRowConstraint(\n          -MPSolver::infinity(), 0, absl::StrCat(\"g for i = \", i, \", q = \", q))",
          "new_text": null,
          "old_line_content": "      MPConstraint* constraint = solver->MakeRowConstraint(",
          "new_line_content": "  // g.",
          "content_same": false
        },
        {
          "line": 2439,
          "old_api": "absl::StrCat(\"g for i = \", i, \", q = \", q)",
          "new_api": null,
          "old_text": "absl::StrCat(\"g for i = \", i, \", q = \", q)",
          "new_text": null,
          "old_line_content": "          -MPSolver::infinity(), 0, absl::StrCat(\"g for i = \", i, \", q = \", q));",
          "new_line_content": "  for (size_t i = 0; i < num_edges; ++i) {",
          "content_same": false
        },
        {
          "line": 2440,
          "old_api": "SetCoefficient",
          "new_api": null,
          "old_text": "constraint->SetCoefficient(s[edge.second][q], -1.0)",
          "new_text": null,
          "old_line_content": "      constraint->SetCoefficient(s[edge.second][q], -1.0);",
          "new_line_content": "    std::pair<int, int> edge = E[i];",
          "content_same": false
        },
        {
          "line": 4486,
          "old_api": "spmd::ToString(mesh_shapes[i])",
          "new_api": null,
          "old_text": "spmd::ToString(mesh_shapes[i])",
          "new_text": null,
          "old_line_content": "    VLOG(1) << \"Mesh shape \" << spmd::ToString(mesh_shapes[i])",
          "new_line_content": "    delete pass;",
          "content_same": false
        },
        {
          "line": 4492,
          "old_api": "ok",
          "new_api": null,
          "old_text": "pass_result.ok()",
          "new_text": null,
          "old_line_content": "    if (pass_result.ok() &&",
          "new_line_content": "    if (objective_values[i] >= 0 && min_objective_value > objective_values[i]) {",
          "content_same": false
        },
        {
          "line": 4493,
          "old_api": "value",
          "new_api": null,
          "old_text": "pass_result.value()",
          "new_text": null,
          "old_line_content": "        pass_result.value() !=",
          "new_line_content": "      min_mesh_shape_index = i;",
          "content_same": false
        },
        {
          "line": 2447,
          "old_api": "size",
          "new_api": null,
          "old_text": "A.size()",
          "new_text": null,
          "old_line_content": "  for (size_t i = 0; i < A.size(); ++i) {",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 2449,
          "old_api": "size",
          "new_api": null,
          "old_text": "s[alias.first].size()",
          "new_text": null,
          "old_line_content": "    for (size_t p = 0; p < s[alias.first].size(); ++p) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 2450,
          "old_api": "size",
          "new_api": null,
          "old_text": "s[alias.second].size()",
          "new_text": null,
          "old_line_content": "      for (size_t q = 0; q < s[alias.second].size(); ++q) {",
          "new_line_content": "  // h.",
          "content_same": false
        },
        {
          "line": 2452,
          "old_api": "size",
          "new_api": null,
          "old_text": "s[alias.second].size()",
          "new_text": null,
          "old_line_content": "        if (v[i][p * s[alias.second].size() + q] > 0.5) {",
          "new_line_content": "    std::pair<int, int> alias = A[i];",
          "content_same": false
        },
        {
          "line": 4501,
          "old_api": "VLOG",
          "new_api": null,
          "old_text": "VLOG(1)",
          "new_text": null,
          "old_line_content": "    VLOG(1) << \"Solver timed out. Will now rely on sharding propagation to \"",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 2455,
          "old_api": "absl::StrCat(\"s[\", alias.first, \"][\", p, \"] + s[\", alias.second,\n                           \"][\", q, \"] <= 1\")",
          "new_api": null,
          "old_text": "absl::StrCat(\"s[\", alias.first, \"][\", p, \"] + s[\", alias.second,\n                           \"][\", q, \"] <= 1\")",
          "new_text": null,
          "old_line_content": "              absl::StrCat(\"s[\", alias.first, \"][\", p, \"] + s[\", alias.second,",
          "new_line_content": "        // if lhs == 1",
          "content_same": false
        },
        {
          "line": 4503,
          "old_api": "ModuleHasUserShardings",
          "new_api": null,
          "old_text": "ModuleHasUserShardings(module)",
          "new_text": null,
          "old_line_content": "    if (!ModuleHasUserShardings(module)) {",
          "new_line_content": "  StatusOr<bool> module_is_changed;",
          "content_same": false
        },
        {
          "line": 4504,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(WARNING)",
          "new_text": null,
          "old_line_content": "      LOG(WARNING)",
          "new_line_content": "  if (skip_auto_sharding) {",
          "content_same": false
        },
        {
          "line": 4513,
          "old_api": "CHECK_GE",
          "new_api": null,
          "old_text": "CHECK_GE(min_mesh_shape_index, 0)",
          "new_text": null,
          "old_line_content": "    CHECK_GE(min_mesh_shape_index, 0)",
          "new_line_content": "             \"sharded leading to low performance.\";",
          "content_same": false
        },
        {
          "line": 2469,
          "old_api": "ExportModelToProto",
          "new_api": null,
          "old_text": "solver->ExportModelToProto(&model_proto)",
          "new_text": null,
          "old_line_content": "    solver->ExportModelToProto(&model_proto);",
          "new_line_content": "  // Exports the model for debugging.",
          "content_same": false
        },
        {
          "line": 2470,
          "old_api": "NumVariables",
          "new_api": null,
          "old_text": "file::SetTextProto(\n        // Modify this file path if needed.\n        absl::StrCat(\"/tmp/model_\", solver->NumVariables(), \".proto\"),\n        model_proto, file::Defaults())",
          "new_text": null,
          "old_line_content": "    auto write_status = file::SetTextProto(",
          "new_line_content": "  bool dump_model = false;",
          "content_same": false
        },
        {
          "line": 4519,
          "old_api": "ok",
          "new_api": null,
          "old_text": "changed[min_mesh_shape_index].ok()",
          "new_text": null,
          "old_line_content": "    if (!changed[min_mesh_shape_index].ok()) {",
          "new_line_content": "           \"this input. This could be the result of a low memory budget. If \"",
          "content_same": false
        },
        {
          "line": 2472,
          "old_api": "NumVariables",
          "new_api": null,
          "old_text": "solver->NumVariables()",
          "new_text": null,
          "old_line_content": "        absl::StrCat(\"/tmp/model_\", solver->NumVariables(), \".proto\"),",
          "new_line_content": "    operations_research::MPModelProto model_proto;",
          "content_same": false
        },
        {
          "line": 4520,
          "old_api": "status",
          "new_api": null,
          "old_text": "changed[min_mesh_shape_index].status()",
          "new_text": null,
          "old_line_content": "      module_is_changed = changed[min_mesh_shape_index].status();",
          "new_line_content": "           \"you think you have set a reasonably large memory budget, please \"",
          "content_same": false
        },
        {
          "line": 2475,
          "old_api": "message",
          "new_api": null,
          "old_text": "write_status.message()",
          "new_text": null,
          "old_line_content": "      LOG(ERROR) << write_status.message();",
          "new_line_content": "        // Modify this file path if needed.",
          "content_same": false
        },
        {
          "line": 4525,
          "old_api": "VLOG",
          "new_api": null,
          "old_text": "VLOG(1)",
          "new_text": null,
          "old_line_content": "        VLOG(1) << \"Choosing mesh shape \"",
          "new_line_content": "    } else {",
          "content_same": false
        },
        {
          "line": 4526,
          "old_api": "spmd::ToString(mesh_shapes[min_mesh_shape_index])",
          "new_api": null,
          "old_text": "spmd::ToString(mesh_shapes[min_mesh_shape_index])",
          "new_text": null,
          "old_line_content": "                << spmd::ToString(mesh_shapes[min_mesh_shape_index])",
          "new_line_content": "      solver_optimal_objective_value_ = min_objective_value;",
          "content_same": false
        },
        {
          "line": 2480,
          "old_api": "ProblemType",
          "new_api": null,
          "old_text": "solver->ProblemType()",
          "new_text": null,
          "old_line_content": "  VLOG(0) << \"Starting solver \" << solver->ProblemType() << \"\\n\"",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 4532,
          "old_api": "computation_count",
          "new_api": null,
          "old_text": "module->computation_count()",
          "new_text": null,
          "old_line_content": "        for (size_t i = 0; i < module->computation_count(); ++i) {",
          "new_line_content": "                << min_objective_value;",
          "content_same": false
        },
        {
          "line": 2485,
          "old_api": "NumVariables",
          "new_api": null,
          "old_text": "solver->NumVariables()",
          "new_text": null,
          "old_line_content": "          << \"Number variables for ILP: \" << solver->NumVariables() << \"\\n\"",
          "new_line_content": "          << \"Solver parameter string: \" << solver_parameter_str << \"\\n\"",
          "content_same": false
        },
        {
          "line": 4533,
          "old_api": "mutable_computation",
          "new_api": null,
          "old_text": "module->mutable_computation(i)",
          "new_text": null,
          "old_line_content": "          auto original_computation = module->mutable_computation(i);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 4535,
          "old_api": "mutable_computation",
          "new_api": null,
          "old_text": "modules[min_mesh_shape_index]->mutable_computation(i)",
          "new_text": null,
          "old_line_content": "              modules[min_mesh_shape_index]->mutable_computation(i);",
          "new_line_content": "            computation_replacements;",
          "content_same": false
        },
        {
          "line": 2490,
          "old_api": "Solve",
          "new_api": null,
          "old_text": "solver->Solve()",
          "new_text": null,
          "old_line_content": "  auto status = solver->Solve();",
          "new_line_content": "          << \"Total vector of variables: \" << var_vector_cnt << \"\\n\"",
          "content_same": false
        },
        {
          "line": 4540,
          "old_api": "get",
          "new_api": null,
          "old_text": "modules[min_mesh_shape_index].get()",
          "new_text": null,
          "old_line_content": "        module->MoveComputationsFrom(modules[min_mesh_shape_index].get());",
          "new_line_content": "          computation_replacements[original_computation] = new_computation;",
          "content_same": false
        },
        {
          "line": 4542,
          "old_api": "mutable_entry_computation_layout",
          "new_api": null,
          "old_text": "module->config().mutable_entry_computation_layout()",
          "new_text": null,
          "old_line_content": "        *module->config().mutable_entry_computation_layout() =",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 2496,
          "old_api": "mutable_model",
          "new_api": null,
          "old_text": "model_request.mutable_model()",
          "new_text": null,
          "old_line_content": "    solver->ExportModelToProto(model_request.mutable_model());",
          "new_line_content": "  if (status == operations_research::MPSolver::INFEASIBLE) {",
          "content_same": false
        },
        {
          "line": 2499,
          "old_api": "set_solver_type",
          "new_api": null,
          "old_text": "model_request.set_solver_type(\n          operations_research::MPModelRequest::SAT_INTEGER_PROGRAMMING)",
          "new_text": null,
          "old_line_content": "      model_request.set_solver_type(",
          "new_line_content": "    operations_research::MPModelRequest model_request;",
          "content_same": false
        },
        {
          "line": 2506,
          "old_api": "set_solver_time_limit_seconds",
          "new_api": null,
          "old_text": "model_request.set_solver_time_limit_seconds(100)",
          "new_text": null,
          "old_line_content": "    model_request.set_solver_time_limit_seconds(100);",
          "new_line_content": "               operations_research::MPSolver::SCIP_MIXED_INTEGER_PROGRAMMING) {",
          "content_same": false
        },
        {
          "line": 2508,
          "old_api": "status",
          "new_api": null,
          "old_text": "iis.status().DebugString()",
          "new_text": null,
          "old_line_content": "    LOG(INFO) << iis.status().DebugString();",
          "new_line_content": "          operations_research::MPModelRequest::SCIP_MIXED_INTEGER_PROGRAMMING);",
          "content_same": false
        },
        {
          "line": 2509,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(INFO)",
          "new_text": null,
          "old_line_content": "    LOG(INFO) << \"Infeasible constraints: \";",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 4556,
          "old_api": "absl::Now()",
          "new_api": null,
          "old_text": "absl::Now()",
          "new_text": null,
          "old_line_content": "  absl::Time end_time = absl::Now();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 4558,
          "old_api": "metrics::RecordAutoShardingCompilationTime(\n      absl::ToInt64Microseconds(duration))",
          "new_api": null,
          "old_text": "metrics::RecordAutoShardingCompilationTime(\n      absl::ToInt64Microseconds(duration))",
          "new_text": null,
          "old_line_content": "  metrics::RecordAutoShardingCompilationTime(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 4559,
          "old_api": "absl::ToInt64Microseconds(duration)",
          "new_api": null,
          "old_text": "absl::ToInt64Microseconds(duration)",
          "new_text": null,
          "old_line_content": "      absl::ToInt64Microseconds(duration));",
          "new_line_content": "#if !defined(__APPLE__)",
          "content_same": false
        },
        {
          "line": 2516,
          "old_api": "model",
          "new_api": null,
          "old_text": "model_request.model().general_constraint(index).DebugString()",
          "new_text": null,
          "old_line_content": "          << model_request.model().general_constraint(index).DebugString();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 2521,
          "old_api": "absl::InternalError(\"MPSolver could not find any feasible solution.\")",
          "new_api": null,
          "old_text": "absl::InternalError(\"MPSolver could not find any feasible solution.\")",
          "new_text": null,
          "old_line_content": "        absl::InternalError(\"MPSolver could not find any feasible solution.\"),",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 4572,
          "old_api": "entry_computation",
          "new_api": null,
          "old_text": "module->entry_computation()",
          "new_text": null,
          "old_line_content": "  HloComputation* entry = module->entry_computation();",
          "new_line_content": "StatusOr<bool> DummyAutoSharding::Run(",
          "content_same": false
        },
        {
          "line": 4574,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "entry->instructions()",
          "new_text": null,
          "old_line_content": "  for (HloInstruction* inst : entry->instructions()) {",
          "new_line_content": "    const absl::flat_hash_set<absl::string_view>& execution_threads) {",
          "content_same": false
        },
        {
          "line": 4575,
          "old_api": "shape",
          "new_api": null,
          "old_text": "inst->shape()",
          "new_text": null,
          "old_line_content": "    const Shape& out_shape = inst->shape();",
          "new_line_content": "  // ----- Set Dummy Replicated Sharding -----",
          "content_same": false
        },
        {
          "line": 2532,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(INFO)",
          "new_text": null,
          "old_line_content": "  LOG(INFO) << \"Solver Status: \" << status",
          "new_line_content": "    // to degrade gracefully.",
          "content_same": false
        },
        {
          "line": 4581,
          "old_api": "HloSharding::Replicate()",
          "new_api": null,
          "old_text": "HloSharding::Replicate()",
          "new_text": null,
          "old_line_content": "      inst->set_sharding(HloSharding::Replicate());",
          "new_line_content": "      ShapeTree<HloSharding> tuple_sharding(out_shape,",
          "content_same": false
        },
        {
          "line": 2534,
          "old_api": "Value",
          "new_api": null,
          "old_text": "solver->Objective().Value()",
          "new_text": null,
          "old_line_content": "  if (solver->Objective().Value() >= kInfinityCost) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 2535,
          "old_api": "Value",
          "new_api": null,
          "old_text": "solver->Objective().Value()",
          "new_text": null,
          "old_line_content": "    LOG(WARNING) << \"Objective (\" << solver->Objective().Value()",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 2540,
          "old_api": "VLOG_IS_ON",
          "new_api": null,
          "old_text": "VLOG_IS_ON(10)",
          "new_text": null,
          "old_line_content": "  if (VLOG_IS_ON(10)) {",
          "new_line_content": "                 << \") is larger than kInfinityCost. It means the solver \"",
          "content_same": false
        },
        {
          "line": 2545,
          "old_api": "VLOG",
          "new_api": null,
          "old_text": "VLOG(10)",
          "new_text": null,
          "old_line_content": "    VLOG(10) << \"MODEL:\";",
          "new_line_content": "    // Print solver information for debugging. This hasn't been useful so far,",
          "content_same": false
        },
        {
          "line": 2546,
          "old_api": "DebugString",
          "new_api": null,
          "old_text": "model_proto.DebugString()",
          "new_text": null,
          "old_line_content": "    XLA_VLOG_LINES(10, model_proto.DebugString());",
          "new_line_content": "    // so leave it at VLOG level 10.",
          "content_same": false
        },
        {
          "line": 2547,
          "old_api": "VLOG",
          "new_api": null,
          "old_text": "VLOG(10)",
          "new_text": null,
          "old_line_content": "    VLOG(10) << \"RESPONSE:\";",
          "new_line_content": "    operations_research::MPModelProto model_proto;",
          "content_same": false
        },
        {
          "line": 2556,
          "old_api": "size",
          "new_api": null,
          "old_text": "s[i].size()",
          "new_text": null,
          "old_line_content": "    for (int j = 0; j < s[i].size(); ++j) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 2558,
          "old_api": "solution_value",
          "new_api": null,
          "old_text": "s[i][j]->solution_value()",
          "new_text": null,
          "old_line_content": "      if (s[i][j]->solution_value() > 0.5) {",
          "new_line_content": "  std::vector<int64_t> chosen_strategy(N, -1), e_val(num_edges, -1);",
          "content_same": false
        },
        {
          "line": 2565,
          "old_api": "size",
          "new_api": null,
          "old_text": "e[i].size()",
          "new_text": null,
          "old_line_content": "    for (int j = 0; j < e[i].size(); ++j) {",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 2567,
          "old_api": "solution_value",
          "new_api": null,
          "old_text": "e[i][j]->solution_value()",
          "new_text": null,
          "old_line_content": "      if (e[i][j]->solution_value() > 0.5) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 2574,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(INFO)",
          "new_text": null,
          "old_line_content": "  LOG(INFO) << \"N = \" << N;",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 2576,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(INFO)",
          "new_text": null,
          "old_line_content": "    LOG(INFO) << \"memory budget: -1\";",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 2581,
          "old_api": "Value",
          "new_api": null,
          "old_text": "ORToolsSolverResult(\n      std::make_tuple(std::move(chosen_strategy), std::move(e_val),\n                      solver->Objective().Value()),\n      false)",
          "new_text": null,
          "old_line_content": "  return ORToolsSolverResult(",
          "new_line_content": "  } else {",
          "content_same": false
        },
        {
          "line": 2583,
          "old_api": "Value",
          "new_api": null,
          "old_text": "solver->Objective().Value()",
          "new_text": null,
          "old_line_content": "                      solver->Objective().Value()),",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 2594,
          "old_api": "size",
          "new_api": null,
          "old_text": "leaf_strategies.size()",
          "new_text": null,
          "old_line_content": "  int64_t N = leaf_strategies.size();",
          "new_line_content": "    const CostGraph& cost_graph, const AliasSet& alias_set,",
          "content_same": false
        },
        {
          "line": 2601,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "E.push_back(iter.first)",
          "new_text": null,
          "old_line_content": "    E.push_back(iter.first);",
          "new_line_content": "  const std::vector<int>& s_follow = cost_graph.follow_idx_;",
          "content_same": false
        },
        {
          "line": 2606,
          "old_api": "edge_cost",
          "new_api": null,
          "old_text": "edge_cost(i, j)",
          "new_text": null,
          "old_line_content": "        rij.push_back(edge_cost(i, j));",
          "new_line_content": "    std::vector<double> rij;",
          "content_same": false
        },
        {
          "line": 2609,
          "old_api": "std::move(rij)",
          "new_api": null,
          "old_text": "std::move(rij)",
          "new_text": null,
          "old_line_content": "    r.push_back(std::move(rij));",
          "new_line_content": "      for (size_t j = 0; j < edge_cost.m_; j++) {",
          "content_same": false
        },
        {
          "line": 2612,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "sequence.instructions()",
          "new_text": null,
          "old_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 2619,
          "old_api": "at",
          "new_api": null,
          "old_text": "absl::StrCat(\n        instructions.at(strategies->instruction_id)->name(), \" (id: \", i, \")\")",
          "new_text": null,
          "old_line_content": "    instruction_names.push_back(absl::StrCat(",
          "new_line_content": "  // Serialize node costs",
          "content_same": false
        },
        {
          "line": 2620,
          "old_api": "at",
          "new_api": null,
          "old_text": "instructions.at(strategies->instruction_id)->name()",
          "new_text": null,
          "old_line_content": "        instructions.at(strategies->instruction_id)->name(), \" (id: \", i, \")\"));",
          "new_line_content": "  std::vector<std::vector<double>> c, d, m;",
          "content_same": false
        },
        {
          "line": 2622,
          "old_api": "size",
          "new_api": null,
          "old_text": "strategies->leaf_vector.size()",
          "new_text": null,
          "old_line_content": "    for (size_t j = 0; j < strategies->leaf_vector.size(); ++j) {",
          "new_line_content": "    const StrategyVector* strategies = leaf_strategies[i];",
          "content_same": false
        },
        {
          "line": 2629,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "d.push_back(di)",
          "new_text": null,
          "old_line_content": "    d.push_back(di);",
          "new_line_content": "                   cost_graph.extra_node_costs_[i][j]);",
          "content_same": false
        },
        {
          "line": 2640,
          "old_api": "size",
          "new_api": null,
          "old_text": "src_strategies->leaf_vector.size()",
          "new_text": null,
          "old_line_content": "    Matrix raw_cost(src_strategies->leaf_vector.size(),",
          "new_line_content": "  std::vector<std::vector<double>> v;",
          "content_same": false
        },
        {
          "line": 2641,
          "old_api": "size",
          "new_api": null,
          "old_text": "dst_strategies->leaf_vector.size()",
          "new_text": null,
          "old_line_content": "                    dst_strategies->leaf_vector.size());",
          "new_line_content": "  for (const auto& pair : alias_set) {",
          "content_same": false
        },
        {
          "line": 2642,
          "old_api": "size",
          "new_api": null,
          "old_text": "src_strategies->leaf_vector.size()",
          "new_text": null,
          "old_line_content": "    for (size_t i = 0; i < src_strategies->leaf_vector.size(); ++i) {",
          "new_line_content": "    const StrategyVector* src_strategies = leaf_strategies[pair.first];",
          "content_same": false
        },
        {
          "line": 2643,
          "old_api": "size",
          "new_api": null,
          "old_text": "dst_strategies->leaf_vector.size()",
          "new_text": null,
          "old_line_content": "      for (size_t j = 0; j < dst_strategies->leaf_vector.size(); ++j) {",
          "new_line_content": "    const StrategyVector* dst_strategies = leaf_strategies[pair.second];",
          "content_same": false
        },
        {
          "line": 2648,
          "old_api": "raw_cost",
          "new_api": null,
          "old_text": "raw_cost(i, j)",
          "new_text": null,
          "old_line_content": "          raw_cost(i, j) = 1.0;",
          "new_line_content": "        if (src_strategies->leaf_vector[i].output_sharding ==",
          "content_same": false
        },
        {
          "line": 2658,
          "old_api": "at",
          "new_api": null,
          "old_text": "cost_graph.reindexing_vector_.at(idx_a)",
          "new_text": null,
          "old_line_content": "      row_indices = cost_graph.reindexing_vector_.at(idx_a);",
          "new_line_content": "    std::vector<int> row_indices;",
          "content_same": false
        },
        {
          "line": 2661,
          "old_api": "assign",
          "new_api": null,
          "old_text": "row_indices.assign(s_len[idx_a], 0)",
          "new_text": null,
          "old_line_content": "      row_indices.assign(s_len[idx_a], 0);",
          "new_line_content": "    if (s_follow[idx_a] >= 0) {",
          "content_same": false
        },
        {
          "line": 2669,
          "old_api": "assign",
          "new_api": null,
          "old_text": "col_indices.assign(s_len[idx_b], 0)",
          "new_text": null,
          "old_line_content": "      col_indices.assign(s_len[idx_b], 0);",
          "new_line_content": "    if (s_follow[idx_b] >= 0) {",
          "content_same": false
        },
        {
          "line": 2676,
          "old_api": "std::make_pair(idx_a, idx_b)",
          "new_api": null,
          "old_text": "std::make_pair(idx_a, idx_b)",
          "new_text": null,
          "old_line_content": "    A.push_back(std::make_pair(idx_a, idx_b));",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 2683,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "v.push_back(vij)",
          "new_text": null,
          "old_line_content": "    v.push_back(vij);",
          "new_line_content": "      for (int j : col_indices) {",
          "content_same": false
        },
        {
          "line": 2688,
          "old_api": "size",
          "new_api": null,
          "old_text": "liveness_set.size()",
          "new_text": null,
          "old_line_content": "  for (size_t t = 0; t < liveness_set.size(); ++t) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 2694,
          "old_api": "empty",
          "new_api": null,
          "old_text": "index.empty()",
          "new_text": null,
          "old_line_content": "      if (!index.empty()) {",
          "new_line_content": "    std::function<void(const StrategyVector*, const ShapeIndex&)>",
          "content_same": false
        },
        {
          "line": 2695,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "current_liveness_set_indices.push_back(\n            strategies->childs.at(index.front())->id)",
          "new_text": null,
          "old_line_content": "        current_liveness_set_indices.push_back(",
          "new_line_content": "        traverse_live_instructions;",
          "content_same": false
        },
        {
          "line": 2696,
          "old_api": "front",
          "new_api": null,
          "old_text": "index.front()",
          "new_text": null,
          "old_line_content": "            strategies->childs.at(index.front())->id);",
          "new_line_content": "    traverse_live_instructions = [&](const StrategyVector* strategies,",
          "content_same": false
        },
        {
          "line": 2705,
          "old_api": "instruction",
          "new_api": null,
          "old_text": "value->instruction()",
          "new_text": null,
          "old_line_content": "      traverse_live_instructions(strategy_map.at(value->instruction()).get(),",
          "new_line_content": "    for (const HloValue* value : liveness_set[t]) {",
          "content_same": false
        },
        {
          "line": 2716,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "sequence.instructions()",
          "new_text": null,
          "old_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 2719,
          "old_api": "has_sharding",
          "new_api": null,
          "old_text": "ins->has_sharding()",
          "new_text": null,
          "old_line_content": "    if (!ins->has_sharding()) {",
          "new_line_content": "                      size_t total_num_devices) {",
          "content_same": false
        },
        {
          "line": 2722,
          "old_api": "IsTuple",
          "new_api": null,
          "old_text": "ins->shape().IsTuple()",
          "new_text": null,
          "old_line_content": "    if (!ins->shape().IsTuple() &&",
          "new_line_content": "  for (HloInstruction* ins : instructions) {",
          "content_same": false
        },
        {
          "line": 2728,
          "old_api": "IsReplicated",
          "new_api": null,
          "old_text": "ins->sharding().IsReplicated()",
          "new_text": null,
          "old_line_content": "           ins->sharding().IsReplicated()) &&",
          "new_line_content": "      // TODO(yuemmawang) Check other cases when it's helpful (it's not",
          "content_same": false
        },
        {
          "line": 2733,
          "old_api": "name",
          "new_api": null,
          "old_text": "ins->name()",
          "new_text": null,
          "old_line_content": "        LOG(INFO) << \"Instruction does not have sharding: \" << ins->name();",
          "new_line_content": "          size > 1) {",
          "content_same": false
        },
        {
          "line": 2742,
          "old_api": "tile_assignment",
          "new_api": null,
          "old_text": "ins->sharding().tile_assignment().dimensions()",
          "new_text": null,
          "old_line_content": "                  ins->sharding().tile_assignment().dimensions(),",
          "new_line_content": "            continue;",
          "content_same": false
        },
        {
          "line": 2743,
          "old_api": "ReplicateOnLastTileDim",
          "new_api": null,
          "old_text": "ins->sharding().ReplicateOnLastTileDim()",
          "new_text": null,
          "old_line_content": "                  ins->sharding().ReplicateOnLastTileDim());",
          "new_line_content": "          }",
          "content_same": false
        },
        {
          "line": 2752,
          "old_api": "size",
          "new_api": null,
          "old_text": "ins_sharded_dims.size()",
          "new_text": null,
          "old_line_content": "            for (size_t i = 0; i < ins_sharded_dims.size(); i++) {",
          "new_line_content": "          bool not_consistent = false;",
          "content_same": false
        },
        {
          "line": 2754,
          "old_api": "at",
          "new_api": null,
          "old_text": "ins_sharded_dims.at(i)",
          "new_text": null,
          "old_line_content": "                  ins->shape().dimensions().at(ins_sharded_dims.at(i))) {",
          "new_line_content": "            not_consistent = true;",
          "content_same": false
        },
        {
          "line": 2764,
          "old_api": "shape",
          "new_api": null,
          "old_text": "op->shape()",
          "new_text": null,
          "old_line_content": "                GetInstructionSize(op->shape()) / (1024.0 * 1024 * 1024);",
          "new_line_content": "            // Prints the inconsistent shardings, which may indicate causes",
          "content_same": false
        },
        {
          "line": 2765,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "absl::StrCat(\"Shardings not consistent (op size \",\n                                           op_size, \" GB):\", ins->ToString(),\n                                           \"\\n Operand: \", op->ToString())",
          "new_text": null,
          "old_line_content": "            std::string str = absl::StrCat(\"Shardings not consistent (op size \",",
          "new_line_content": "            // of resharding overheads, and some inconsistent shardings are",
          "content_same": false
        },
        {
          "line": 2766,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "ins->ToString()",
          "new_text": null,
          "old_line_content": "                                           op_size, \" GB):\", ins->ToString(),",
          "new_line_content": "            // unavoidable.",
          "content_same": false
        },
        {
          "line": 2767,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "op->ToString()",
          "new_text": null,
          "old_line_content": "                                           \"\\n Operand: \", op->ToString());",
          "new_line_content": "            size_t op_size =",
          "content_same": false
        },
        {
          "line": 2783,
          "old_api": "end",
          "new_api": null,
          "old_text": "size_string.end()",
          "new_text": null,
          "old_line_content": "  std::sort(size_string.begin(), size_string.end(), MemLarger);",
          "new_line_content": "                    const std::pair<size_t, std::string>& b) const {",
          "content_same": false
        },
        {
          "line": 2785,
          "old_api": "size",
          "new_api": null,
          "old_text": "size_string.size()",
          "new_text": null,
          "old_line_content": "  k = std::min(k, size_string.size());",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 2797,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "sequence.instructions()",
          "new_text": null,
          "old_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "new_line_content": "                    const StrategyMap& strategy_map,",
          "content_same": false
        },
        {
          "line": 2800,
          "old_api": "find",
          "new_api": null,
          "old_text": "strategy_map.find(inst)",
          "new_text": null,
          "old_line_content": "    auto iter = strategy_map.find(inst);",
          "new_line_content": "  // Set the HloSharding for every instruction",
          "content_same": false
        },
        {
          "line": 2807,
          "old_api": "shape",
          "new_api": null,
          "old_text": "inst->shape()",
          "new_text": null,
          "old_line_content": "      const Shape& out_shape = inst->shape();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 2816,
          "old_api": "IsReplicated",
          "new_api": null,
          "old_text": "t->leaf_vector[stra_idx].output_sharding.IsReplicated()",
          "new_text": null,
          "old_line_content": "        if (t->leaf_vector[stra_idx].output_sharding.IsReplicated() &&",
          "new_line_content": "      for (const auto& t : strategies->childs) {",
          "content_same": false
        },
        {
          "line": 2825,
          "old_api": "leaves",
          "new_api": null,
          "old_text": "output_tuple_sharding.leaves()",
          "new_text": null,
          "old_line_content": "      for (auto& leaf : output_tuple_sharding.leaves()) {",
          "new_line_content": "            t->leaf_vector[stra_idx].output_sharding);",
          "content_same": false
        },
        {
          "line": 2835,
          "old_api": "IsUndefined",
          "new_api": null,
          "old_text": "IsUndefined(sharding_spec)",
          "new_text": null,
          "old_line_content": "      if (IsUndefined(sharding_spec)) {",
          "new_line_content": "    } else {",
          "content_same": false
        },
        {
          "line": 2840,
          "old_api": "name",
          "new_api": null,
          "old_text": "inst->name()",
          "new_text": null,
          "old_line_content": "        LOG(INFO) << \"skip setting shardings for inst \" << inst->name();",
          "new_line_content": "        continue;",
          "content_same": false
        },
        {
          "line": 2842,
          "old_api": "set_sharding",
          "new_api": null,
          "old_text": "inst->set_sharding(sharding_spec)",
          "new_text": null,
          "old_line_content": "        inst->set_sharding(sharding_spec);",
          "new_line_content": "      // Do not overwrite existing complete shardings.",
          "content_same": false
        },
        {
          "line": 2854,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "sequence.instructions()",
          "new_text": null,
          "old_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "new_line_content": "    const CostGraph& cost_graph, absl::Span<const int64_t> s_val,",
          "content_same": false
        },
        {
          "line": 2868,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "inst->opcode()",
          "new_text": null,
          "old_line_content": "    if (inst->opcode() == HloOpcode::kDot) {",
          "new_line_content": "    // It then generates bad fallback code.",
          "content_same": false
        },
        {
          "line": 2870,
          "old_api": "GetShardingStrategy",
          "new_api": null,
          "old_text": "GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "new_text": null,
          "old_line_content": "          GetShardingStrategy(inst, strategy_map, cost_graph, s_val);",
          "new_line_content": "    // spmd partitioner generate correct code.",
          "content_same": false
        },
        {
          "line": 2871,
          "old_api": "operand",
          "new_api": null,
          "old_text": "inst->operand(0)",
          "new_text": null,
          "old_line_content": "      const HloInstruction* lhs = inst->operand(0);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 2873,
          "old_api": "sharding",
          "new_api": null,
          "old_text": "lhs->sharding()",
          "new_text": null,
          "old_line_content": "      const HloSharding& lhs_sharding = lhs->sharding();",
          "new_line_content": "      const ShardingStrategy& stra =",
          "content_same": false
        },
        {
          "line": 2882,
          "old_api": "shape",
          "new_api": null,
          "old_text": "rhs->shape()",
          "new_text": null,
          "old_line_content": "          cluster_env.GetTensorDimToMeshDimWrapper(rhs->shape(), rhs_sharding);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 2890,
          "old_api": "size",
          "new_api": null,
          "old_text": "stra.input_shardings.size()",
          "new_text": null,
          "old_line_content": "        CHECK(stra.input_shardings.size() == 2)",
          "new_line_content": "          rhs_tensor_dim_to_mesh_dim[rhs_con_dims[0]] == -1) {",
          "content_same": false
        },
        {
          "line": 2893,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "stra.ToString()",
          "new_text": null,
          "old_line_content": "            << inst->ToString() << \", strategy : \" << stra.ToString();",
          "new_line_content": "      } else {",
          "content_same": false
        },
        {
          "line": 2896,
          "old_api": "FixMixedMeshShapeResharding",
          "new_api": null,
          "old_text": "FixMixedMeshShapeResharding(inst, 1, stra.input_shardings[1],\n                                    device_mesh, resharding_cache)",
          "new_text": null,
          "old_line_content": "        FixMixedMeshShapeResharding(inst, 1, stra.input_shardings[1],",
          "new_line_content": "               \"but get instruction: \"",
          "content_same": false
        },
        {
          "line": 2899,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "inst->opcode()",
          "new_text": null,
          "old_line_content": "    } else if (inst->opcode() == HloOpcode::kConvolution) {",
          "new_line_content": "                                    device_mesh, resharding_cache);",
          "content_same": false
        },
        {
          "line": 2901,
          "old_api": "GetShardingStrategy",
          "new_api": null,
          "old_text": "GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "new_text": null,
          "old_line_content": "          GetShardingStrategy(inst, strategy_map, cost_graph, s_val);",
          "new_line_content": "                                    device_mesh, resharding_cache);",
          "content_same": false
        },
        {
          "line": 2902,
          "old_api": "operand",
          "new_api": null,
          "old_text": "inst->operand(0)",
          "new_text": null,
          "old_line_content": "      const HloInstruction* lhs = inst->operand(0);",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 2904,
          "old_api": "sharding",
          "new_api": null,
          "old_text": "lhs->sharding()",
          "new_text": null,
          "old_line_content": "      const HloSharding& lhs_sharding = lhs->sharding();",
          "new_line_content": "      const ShardingStrategy& stra =",
          "content_same": false
        },
        {
          "line": 2910,
          "old_api": "kernel_input_feature_dimension",
          "new_api": null,
          "old_text": "conv_dnums.kernel_input_feature_dimension()",
          "new_text": null,
          "old_line_content": "          conv_dnums.kernel_input_feature_dimension();",
          "new_line_content": "      const ConvolutionDimensionNumbers& conv_dnums =",
          "content_same": false
        },
        {
          "line": 2913,
          "old_api": "shape",
          "new_api": null,
          "old_text": "lhs->shape()",
          "new_text": null,
          "old_line_content": "          cluster_env.GetTensorDimToMeshDimWrapper(lhs->shape(), lhs_sharding);",
          "new_line_content": "      const int rhs_in_channel_dim =",
          "content_same": false
        },
        {
          "line": 2915,
          "old_api": "shape",
          "new_api": null,
          "old_text": "rhs->shape()",
          "new_text": null,
          "old_line_content": "          cluster_env.GetTensorDimToMeshDimWrapper(rhs->shape(), rhs_sharding);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 2923,
          "old_api": "FixMixedMeshShapeResharding",
          "new_api": null,
          "old_text": "FixMixedMeshShapeResharding(inst, 0, stra.input_shardings[0],\n                                    device_mesh, resharding_cache)",
          "new_text": null,
          "old_line_content": "        FixMixedMeshShapeResharding(inst, 0, stra.input_shardings[0],",
          "new_line_content": "          rhs_tensor_dim_to_mesh_dim[rhs_in_channel_dim] == -1) {",
          "content_same": false
        },
        {
          "line": 2925,
          "old_api": "FixMixedMeshShapeResharding",
          "new_api": null,
          "old_text": "FixMixedMeshShapeResharding(inst, 1, stra.input_shardings[1],\n                                    device_mesh, resharding_cache)",
          "new_text": null,
          "old_line_content": "        FixMixedMeshShapeResharding(inst, 1, stra.input_shardings[1],",
          "new_line_content": "        // communication",
          "content_same": false
        },
        {
          "line": 2928,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "inst->opcode()",
          "new_text": null,
          "old_line_content": "    } else if (inst->opcode() == HloOpcode::kReshape) {",
          "new_line_content": "                                    device_mesh, resharding_cache);",
          "content_same": false
        },
        {
          "line": 2930,
          "old_api": "GetShardingStrategy",
          "new_api": null,
          "old_text": "GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "new_text": null,
          "old_line_content": "          GetShardingStrategy(inst, strategy_map, cost_graph, s_val);",
          "new_line_content": "                                    device_mesh, resharding_cache);",
          "content_same": false
        },
        {
          "line": 2931,
          "old_api": "empty",
          "new_api": null,
          "old_text": "stra.input_shardings.empty()",
          "new_text": null,
          "old_line_content": "      if (!stra.input_shardings.empty()) {",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 2939,
          "old_api": "IsTuple",
          "new_api": null,
          "old_text": "inst->shape().IsTuple()",
          "new_text": null,
          "old_line_content": "      if (inst->shape().IsTuple()) {",
          "new_line_content": "    } else {",
          "content_same": false
        },
        {
          "line": 2940,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "inst->opcode()",
          "new_text": null,
          "old_line_content": "        switch (inst->opcode()) {",
          "new_line_content": "      // TODO(pratikf): We currently skip over tuple shaped instructions here as",
          "content_same": false
        },
        {
          "line": 2945,
          "old_api": "GetShardingStrategyForTuple",
          "new_api": null,
          "old_text": "GetShardingStrategyForTuple(\n                  inst, i, strategy_map, cost_graph, s_val)",
          "new_text": null,
          "old_line_content": "              const ShardingStrategy& stra = GetShardingStrategyForTuple(",
          "new_line_content": "          case HloOpcode::kReduce:",
          "content_same": false
        },
        {
          "line": 2947,
          "old_api": "size",
          "new_api": null,
          "old_text": "stra.input_shardings.size()",
          "new_text": null,
          "old_line_content": "              if (stra.input_shardings.size() > i) {",
          "new_line_content": "          case HloOpcode::kSort: {",
          "content_same": false
        },
        {
          "line": 2955,
          "old_api": "tuple_shapes_size",
          "new_api": null,
          "old_text": "inst->shape().tuple_shapes_size()",
          "new_text": null,
          "old_line_content": "            for (size_t i = 0; i < inst->shape().tuple_shapes_size(); ++i) {",
          "new_line_content": "            }",
          "content_same": false
        },
        {
          "line": 2956,
          "old_api": "GetShardingStrategyForTuple",
          "new_api": null,
          "old_text": "GetShardingStrategyForTuple(\n                  inst, i, strategy_map, cost_graph, s_val)",
          "new_text": null,
          "old_line_content": "              const ShardingStrategy& stra = GetShardingStrategyForTuple(",
          "new_line_content": "            break;",
          "content_same": false
        },
        {
          "line": 2958,
          "old_api": "size",
          "new_api": null,
          "old_text": "stra.input_shardings.size()",
          "new_text": null,
          "old_line_content": "              CHECK_EQ(stra.input_shardings.size(), 1);",
          "new_line_content": "          case HloOpcode::kTuple: {",
          "content_same": false
        },
        {
          "line": 2972,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "inst->ToString()",
          "new_text": null,
          "old_line_content": "            LOG(FATAL) << \"Unhandled instruction: \" + inst->ToString();",
          "new_line_content": "          case HloOpcode::kParameter: {",
          "content_same": false
        },
        {
          "line": 2977,
          "old_api": "empty",
          "new_api": null,
          "old_text": "stra.input_shardings.empty()",
          "new_text": null,
          "old_line_content": "        if (stra.input_shardings.empty()) {",
          "new_line_content": "        }",
          "content_same": false
        },
        {
          "line": 2982,
          "old_api": "sharding",
          "new_api": null,
          "old_text": "inst->sharding()",
          "new_text": null,
          "old_line_content": "              inst, inst->sharding(), device_mesh, preserve_shardings);",
          "new_line_content": "          continue;",
          "content_same": false
        },
        {
          "line": 2999,
          "old_api": "size",
          "new_api": null,
          "old_text": "liveness_set.size()",
          "new_text": null,
          "old_line_content": "  for (size_t i = 0; i < liveness_set.size(); ++i) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3001,
          "old_api": "size",
          "new_api": null,
          "old_text": "liveness_set[i].size()",
          "new_text": null,
          "old_line_content": "    names.reserve(liveness_set[i].size());",
          "new_line_content": "std::string PrintLivenessSet(const LivenessSet& liveness_set) {",
          "content_same": false
        },
        {
          "line": 3004,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "value->index().ToString()",
          "new_text": null,
          "old_line_content": "                                   value->index().ToString()));",
          "new_line_content": "    std::vector<std::string> names;",
          "content_same": false
        },
        {
          "line": 3006,
          "old_api": "end",
          "new_api": null,
          "old_text": "names.end()",
          "new_text": null,
          "old_line_content": "    std::sort(names.begin(), names.end());",
          "new_line_content": "    for (const HloValue* value : liveness_set[i]) {",
          "content_same": false
        },
        {
          "line": 3015,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "sequence.instructions()",
          "new_text": null,
          "old_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3016,
          "old_api": "size",
          "new_api": null,
          "old_text": "instructions.size()",
          "new_text": null,
          "old_line_content": "  for (size_t i = 0; i < instructions.size(); ++i) {",
          "new_line_content": "// Print sorted instructions.",
          "content_same": false
        },
        {
          "line": 3017,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "instructions[i]->ToString()",
          "new_text": null,
          "old_line_content": "    absl::StrAppend(&str, \"Instruction \", i, \": \", instructions[i]->ToString(),",
          "new_line_content": "std::string PrintInstructions(const HloInstructionSequence& sequence) {",
          "content_same": false
        },
        {
          "line": 3027,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "sequence.instructions()",
          "new_text": null,
          "old_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "new_line_content": "// Print strategy map for debugging.",
          "content_same": false
        },
        {
          "line": 3028,
          "old_api": "size",
          "new_api": null,
          "old_text": "instructions.size()",
          "new_text": null,
          "old_line_content": "  for (size_t i = 0; i < instructions.size(); ++i) {",
          "new_line_content": "std::string PrintStrategyMap(const StrategyMap& strategy_map,",
          "content_same": false
        },
        {
          "line": 3029,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "instructions[i]->ToString()",
          "new_text": null,
          "old_line_content": "    absl::StrAppend(&str, \"Instruction \", i, \": \", instructions[i]->ToString(),",
          "new_line_content": "                             const HloInstructionSequence& sequence) {",
          "content_same": false
        },
        {
          "line": 3030,
          "old_api": "at",
          "new_api": null,
          "old_text": "strategy_map.at(instructions[i])->ToString()",
          "new_text": null,
          "old_line_content": "                    \"\\n\", strategy_map.at(instructions[i])->ToString());",
          "new_line_content": "  std::string str(\"Strategy Map\\n\");",
          "content_same": false
        },
        {
          "line": 3045,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "sequence.instructions()",
          "new_text": null,
          "old_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "new_line_content": "                                      const CostGraph& cost_graph,",
          "content_same": false
        },
        {
          "line": 3046,
          "old_api": "size",
          "new_api": null,
          "old_text": "leaf_strategies.size()",
          "new_text": null,
          "old_line_content": "  size_t N = leaf_strategies.size();",
          "new_line_content": "                                      absl::Span<const int64_t> s_val,",
          "content_same": false
        },
        {
          "line": 3051,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "instructions[leaf_strategies[i]->instruction_id]->ToString(\n                        HloPrintOptions::ShortParsable())",
          "new_text": null,
          "old_line_content": "                    instructions[leaf_strategies[i]->instruction_id]->ToString(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3052,
          "old_api": "HloPrintOptions::ShortParsable()",
          "new_api": null,
          "old_text": "HloPrintOptions::ShortParsable()",
          "new_text": null,
          "old_line_content": "                        HloPrintOptions::ShortParsable()),",
          "new_line_content": "  // Print the chosen strategy",
          "content_same": false
        },
        {
          "line": 3057,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "leaf_strategies[i]->leaf_vector[stra_idx].ToString()",
          "new_text": null,
          "old_line_content": "          &str, leaf_strategies[i]->leaf_vector[stra_idx].ToString(), \"\\n\");",
          "new_line_content": "                    \" \");",
          "content_same": false
        },
        {
          "line": 3059,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "absl::StrAppend(&str,\n                      leaf_strategies[i]->leaf_vector[stra_idx].ToString(),\n                      \" follow \", cost_graph.follow_idx_[i], \"\\n\")",
          "new_text": null,
          "old_line_content": "      absl::StrAppend(&str,",
          "new_line_content": "    if (cost_graph.follow_idx_[i] < 0) {",
          "content_same": false
        },
        {
          "line": 3082,
          "old_api": "get",
          "new_api": null,
          "old_text": "child.get()",
          "new_text": null,
          "old_line_content": "        m += calculate_memory_usage(child.get());",
          "new_line_content": "  calculate_memory_usage = [&](const StrategyVector* strategies) {",
          "content_same": false
        },
        {
          "line": 3087,
          "old_api": "RemapIndex",
          "new_api": null,
          "old_text": "cost_graph.RemapIndex(ins_idx, s_val[ins_idx])",
          "new_text": null,
          "old_line_content": "    int stra_idx = cost_graph.RemapIndex(ins_idx, s_val[ins_idx]);",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3093,
          "old_api": "at",
          "new_api": null,
          "old_text": "liveness_set.at(t)",
          "new_text": null,
          "old_line_content": "    for (const auto& val : liveness_set.at(t)) {",
          "new_line_content": "    return strategy.memory_cost;",
          "content_same": false
        },
        {
          "line": 3094,
          "old_api": "instruction",
          "new_api": null,
          "old_text": "val->instruction()",
          "new_text": null,
          "old_line_content": "      const HloInstruction* ins = val->instruction();",
          "new_line_content": "  };",
          "content_same": false
        },
        {
          "line": 3100,
          "old_api": "name",
          "new_api": null,
          "old_text": "ins->name()",
          "new_text": null,
          "old_line_content": "        absl::StrAppend(&str, \"  \", ins->name(),",
          "new_line_content": "      mem += tmp;",
          "content_same": false
        },
        {
          "line": 3105,
          "old_api": "std::make_pair(t, mem)",
          "new_api": null,
          "old_text": "std::make_pair(t, mem)",
          "new_text": null,
          "old_line_content": "    time_memory_usage.push_back(std::make_pair(t, mem));",
          "new_line_content": "                        \": mem += \", tmp / (1024 * 1024),",
          "content_same": false
        },
        {
          "line": 3106,
          "old_api": "VLOG_IS_ON",
          "new_api": null,
          "old_text": "VLOG_IS_ON(6)",
          "new_text": null,
          "old_line_content": "    if (VLOG_IS_ON(6)) {",
          "new_line_content": "                        \" MB; mem=\", mem / (1024 * 1024), \" MB\\n\");",
          "content_same": false
        },
        {
          "line": 3107,
          "old_api": "absl::StrAppend(&str, \"Time \", t, \": \", mem / (1024 * 1024), \" MB\\n\")",
          "new_api": null,
          "old_text": "absl::StrAppend(&str, \"Time \", t, \": \", mem / (1024 * 1024), \" MB\\n\")",
          "new_text": null,
          "old_line_content": "      absl::StrAppend(&str, \"Time \", t, \": \", mem / (1024 * 1024), \" MB\\n\");",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3117,
          "old_api": "end",
          "new_api": null,
          "old_text": "time_memory_usage.end()",
          "new_text": null,
          "old_line_content": "  std::sort(time_memory_usage.begin(), time_memory_usage.end(), TimeMemLarger);",
          "new_line_content": "                    std::pair<size_t, double> b) const {",
          "content_same": false
        },
        {
          "line": 3119,
          "old_api": "front",
          "new_api": null,
          "old_text": "absl::StrAppend(&str,\n                  \"Using memory costs from ShardingStrategy, the max memory \"\n                  \"consumption is \",\n                  time_memory_usage.front().second / (1024 * 1024 * 1024),\n                  \" GB at time \", time_memory_usage.front().first, \"\\n\")",
          "new_text": null,
          "old_line_content": "  absl::StrAppend(&str,",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3122,
          "old_api": "front",
          "new_api": null,
          "old_text": "time_memory_usage.front()",
          "new_text": null,
          "old_line_content": "                  time_memory_usage.front().second / (1024 * 1024 * 1024),",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3130,
          "old_api": "at",
          "new_api": null,
          "old_text": "time_memory_usage.at(t)",
          "new_text": null,
          "old_line_content": "    for (const auto& val : liveness_set[time_memory_usage.at(t).first]) {",
          "new_line_content": "  size_t k = 3;",
          "content_same": false
        },
        {
          "line": 3132,
          "old_api": "at",
          "new_api": null,
          "old_text": "strategy_map.at(ins).get()",
          "new_text": null,
          "old_line_content": "      auto mem = calculate_memory_usage(strategy_map.at(ins).get());",
          "new_line_content": "  std::vector<std::pair<std::string, double>> instruction_mem;",
          "content_same": false
        },
        {
          "line": 3146,
          "old_api": "end",
          "new_api": null,
          "old_text": "instruction_mem.end()",
          "new_text": null,
          "old_line_content": "  std::sort(instruction_mem.begin(), instruction_mem.end(), NameMemLarger);",
          "new_line_content": "                    std::pair<std::string, double> b) const {",
          "content_same": false
        },
        {
          "line": 3149,
          "old_api": "size",
          "new_api": null,
          "old_text": "instruction_mem.size()",
          "new_text": null,
          "old_line_content": "  top_tensors = std::min(top_tensors, instruction_mem.size());",
          "new_line_content": "  } NameMemLarger;",
          "content_same": false
        },
        {
          "line": 3152,
          "old_api": "at",
          "new_api": null,
          "old_text": "absl::StrAppend(\n        &str, \"instruction name: \", instruction_mem.at(i).first,\n        \" memory usage: \", instruction_mem.at(i).second / (1024 * 1024 * 1024),\n        \"GB\\n\")",
          "new_text": null,
          "old_line_content": "    absl::StrAppend(",
          "new_line_content": "  size_t top_tensors = 10;",
          "content_same": false
        },
        {
          "line": 3165,
          "old_api": "has_sharding",
          "new_api": null,
          "old_text": "inst->has_sharding()",
          "new_text": null,
          "old_line_content": "  if (!inst->has_sharding()) {",
          "new_line_content": "void SaveShardingForInstruction(",
          "content_same": false
        },
        {
          "line": 3168,
          "old_api": "IsTuple",
          "new_api": null,
          "old_text": "inst->sharding().IsTuple()",
          "new_text": null,
          "old_line_content": "  if (!inst->sharding().IsTuple()) {",
          "new_line_content": "    HloInstruction* inst) {",
          "content_same": false
        },
        {
          "line": 3171,
          "old_api": "tuple_elements",
          "new_api": null,
          "old_text": "inst->sharding().tuple_elements()",
          "new_text": null,
          "old_line_content": "    preserve_shardings[inst->name()] = inst->sharding().tuple_elements();",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 3181,
          "old_api": "computations",
          "new_api": null,
          "old_text": "module->computations()",
          "new_text": null,
          "old_line_content": "    for (const auto computation : module->computations()) {",
          "new_line_content": "    HloModule* module, AutoShardingOption::PreserveShardingsType type) {",
          "content_same": false
        },
        {
          "line": 3182,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "computation->instructions()",
          "new_text": null,
          "old_line_content": "      for (const auto inst : computation->instructions()) {",
          "new_line_content": "  absl::flat_hash_map<std::string, std::vector<HloSharding>> preserve_shardings;",
          "content_same": false
        },
        {
          "line": 3183,
          "old_api": "SaveShardingForInstruction",
          "new_api": null,
          "old_text": "SaveShardingForInstruction(preserve_shardings, inst)",
          "new_text": null,
          "old_line_content": "        SaveShardingForInstruction(preserve_shardings, inst);",
          "new_line_content": "  if (type == AutoShardingOption::PreserveShardingsType::kKeepAllShardings) {",
          "content_same": false
        },
        {
          "line": 3184,
          "old_api": "users",
          "new_api": null,
          "old_text": "inst->users()",
          "new_text": null,
          "old_line_content": "        for (const auto user : inst->users()) {",
          "new_line_content": "    // Saves shardings for all instructions.",
          "content_same": false
        },
        {
          "line": 3197,
          "old_api": "entry_computation",
          "new_api": null,
          "old_text": "module->entry_computation()->parameter_instructions()",
          "new_text": null,
          "old_line_content": "         module->entry_computation()->parameter_instructions()) {",
          "new_line_content": "  } else if (type == AutoShardingOption::PreserveShardingsType::",
          "content_same": false
        },
        {
          "line": 3198,
          "old_api": "SaveShardingForInstruction",
          "new_api": null,
          "old_text": "SaveShardingForInstruction(preserve_shardings, inst)",
          "new_text": null,
          "old_line_content": "      SaveShardingForInstruction(preserve_shardings, inst);",
          "new_line_content": "                         kKeepInputOutputShardings) {",
          "content_same": false
        },
        {
          "line": 3199,
          "old_api": "users",
          "new_api": null,
          "old_text": "inst->users()",
          "new_text": null,
          "old_line_content": "      for (const auto user : inst->users()) {",
          "new_line_content": "    // Saves parameter shardings",
          "content_same": false
        },
        {
          "line": 3208,
          "old_api": "entry_computation",
          "new_api": null,
          "old_text": "module->entry_computation()->root_instruction()",
          "new_text": null,
          "old_line_content": "    auto inst = module->entry_computation()->root_instruction();",
          "new_line_content": "        }",
          "content_same": false
        },
        {
          "line": 3209,
          "old_api": "SaveShardingForInstruction",
          "new_api": null,
          "old_text": "SaveShardingForInstruction(preserve_shardings, inst)",
          "new_text": null,
          "old_line_content": "    SaveShardingForInstruction(preserve_shardings, inst);",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3211,
          "old_api": "VLOG_IS_ON",
          "new_api": null,
          "old_text": "VLOG_IS_ON(1)",
          "new_text": null,
          "old_line_content": "  if (VLOG_IS_ON(1)) {",
          "new_line_content": "    // Saves output shardings",
          "content_same": false
        },
        {
          "line": 3217,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "s.ToString()",
          "new_text": null,
          "old_line_content": "        sharding += s.ToString() + \",\";",
          "new_line_content": "                 \"elemenet of tuples): \";",
          "content_same": false
        },
        {
          "line": 3219,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(INFO)",
          "new_text": null,
          "old_line_content": "      LOG(INFO) << tmp.first << \": \" << sharding;",
          "new_line_content": "      std::string sharding;",
          "content_same": false
        },
        {
          "line": 3230,
          "old_api": "computations",
          "new_api": null,
          "old_text": "module->computations()",
          "new_text": null,
          "old_line_content": "  for (const auto computation : module->computations()) {",
          "new_line_content": "void CheckUserShardingPreservation(",
          "content_same": false
        },
        {
          "line": 3231,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "computation->instructions()",
          "new_text": null,
          "old_line_content": "    for (const auto inst : computation->instructions()) {",
          "new_line_content": "    HloModule* module,",
          "content_same": false
        },
        {
          "line": 3232,
          "old_api": "end",
          "new_api": null,
          "old_text": "preserve_shardings.end()",
          "new_text": null,
          "old_line_content": "      if (preserve_shardings.find(inst->name()) == preserve_shardings.end()) {",
          "new_line_content": "    const absl::flat_hash_map<std::string, std::vector<HloSharding>>&",
          "content_same": false
        },
        {
          "line": 3237,
          "old_api": "name",
          "new_api": null,
          "old_text": "inst->name()",
          "new_text": null,
          "old_line_content": "                   << inst->name() << \" should be: \"",
          "new_line_content": "        continue;",
          "content_same": false
        },
        {
          "line": 3238,
          "old_api": "name",
          "new_api": null,
          "old_text": "inst->name()",
          "new_text": null,
          "old_line_content": "                   << preserve_shardings.at(inst->name())[0].ToString()",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3243,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(FATAL)",
          "new_text": null,
          "old_line_content": "        LOG(FATAL) << \"User sharding is not preserved! Instruction with name \"",
          "new_line_content": "                   << \"\\nbut it's empty.\";",
          "content_same": false
        },
        {
          "line": 3252,
          "old_api": "tuple_elements",
          "new_api": null,
          "old_text": "inst->sharding().tuple_elements().at(i).ToString()",
          "new_text": null,
          "old_line_content": "              inst->sharding().tuple_elements().at(i).ToString()) {",
          "new_line_content": "        const std::vector<HloSharding>* preserve_shardings_tuple =",
          "content_same": false
        },
        {
          "line": 3272,
          "old_api": "empty",
          "new_api": null,
          "old_text": "value->index().empty()",
          "new_text": null,
          "old_line_content": "    return !value->index().empty()",
          "new_line_content": "                               const LivenessSet& liveness_set,",
          "content_same": false
        },
        {
          "line": 3273,
          "old_api": "GetSubSharding",
          "new_api": null,
          "old_text": "value->instruction()->sharding().GetSubSharding(\n                     value->instruction()->shape(), value->index())",
          "new_text": null,
          "old_line_content": "               ? value->instruction()->sharding().GetSubSharding(",
          "new_line_content": "                               const HloAliasAnalysis* alias_analysis,",
          "content_same": false
        },
        {
          "line": 3274,
          "old_api": "index",
          "new_api": null,
          "old_text": "value->index()",
          "new_text": null,
          "old_line_content": "                     value->instruction()->shape(), value->index())",
          "new_line_content": "                               int64_t num_devices) {",
          "content_same": false
        },
        {
          "line": 3275,
          "old_api": "instruction",
          "new_api": null,
          "old_text": "value->instruction()->sharding()",
          "new_text": null,
          "old_line_content": "               : value->instruction()->sharding();",
          "new_line_content": "  auto get_value_sharding = [](const HloValue* value) {",
          "content_same": false
        },
        {
          "line": 3284,
          "old_api": "size",
          "new_api": null,
          "old_text": "liveness_set.size()",
          "new_text": null,
          "old_line_content": "  for (size_t t = 0; t < liveness_set.size(); ++t) {",
          "new_line_content": "  // requirements of B. This can be done by associating shardings with buffers",
          "content_same": false
        },
        {
          "line": 3286,
          "old_api": "GetBufferContainingValue",
          "new_api": null,
          "old_text": "alias_analysis->GetBufferContainingValue(*value)",
          "new_text": null,
          "old_line_content": "      auto buffer = alias_analysis->GetBufferContainingValue(*value);",
          "new_line_content": "  absl::flat_hash_map<HloBuffer::Id, const HloValue*>",
          "content_same": false
        },
        {
          "line": 3287,
          "old_api": "instruction",
          "new_api": null,
          "old_text": "value->instruction()->has_sharding()",
          "new_text": null,
          "old_line_content": "      if (value->instruction()->has_sharding()) {",
          "new_line_content": "      buffer_to_sharded_value_mapping;",
          "content_same": false
        },
        {
          "line": 3289,
          "old_api": "id",
          "new_api": null,
          "old_text": "buffer.id()",
          "new_text": null,
          "old_line_content": "        auto iter = buffer_to_sharded_value_mapping.find(buffer.id());",
          "new_line_content": "    for (const HloValue* value : liveness_set[t]) {",
          "content_same": false
        },
        {
          "line": 3300,
          "old_api": "ToShortString",
          "new_api": null,
          "old_text": "value->ToShortString()",
          "new_text": null,
          "old_line_content": "                    << value->ToShortString() << \" and \"",
          "new_line_content": "                       \"they have different shardings. This can happen in the \"",
          "content_same": false
        },
        {
          "line": 3301,
          "old_api": "ToShortString",
          "new_api": null,
          "old_text": "iter->second->ToShortString()",
          "new_text": null,
          "old_line_content": "                    << iter->second->ToShortString();",
          "new_line_content": "                       \"presence of user-specified shardings, and is expected. \"",
          "content_same": false
        },
        {
          "line": 3310,
          "old_api": "size",
          "new_api": null,
          "old_text": "liveness_set.size()",
          "new_text": null,
          "old_line_content": "  for (size_t t = 0; t < liveness_set.size(); ++t) {",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3313,
          "old_api": "empty",
          "new_api": null,
          "old_text": "value->index().empty()",
          "new_text": null,
          "old_line_content": "      if (value->instruction()->shape().IsTuple() && value->index().empty()) {",
          "new_line_content": "  int64_t max_memory_usage = 0;",
          "content_same": false
        },
        {
          "line": 3318,
          "old_api": "GetBufferContainingValue",
          "new_api": null,
          "old_text": "alias_analysis->GetBufferContainingValue(*value)",
          "new_text": null,
          "old_line_content": "      auto buffer = alias_analysis->GetBufferContainingValue(*value);",
          "new_line_content": "        continue;",
          "content_same": false
        },
        {
          "line": 3319,
          "old_api": "id",
          "new_api": null,
          "old_text": "buffer.id()",
          "new_text": null,
          "old_line_content": "      auto iter = buffer_to_sharded_value_mapping.find(buffer.id());",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3327,
          "old_api": "std::max(max_memory_usage, memory_usage)",
          "new_api": null,
          "old_text": "std::max(max_memory_usage, memory_usage)",
          "new_text": null,
          "old_line_content": "    max_memory_usage = std::max(max_memory_usage, memory_usage);",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3336,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "sequence.instructions()",
          "new_text": null,
          "old_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "new_line_content": "void RecoverShardingsFromPartialMesh(",
          "content_same": false
        },
        {
          "line": 3339,
          "old_api": "end",
          "new_api": null,
          "old_text": "preserve_shardings.end()",
          "new_text": null,
          "old_line_content": "    if (preserve_shardings.find(ins->name()) != preserve_shardings.end()) {",
          "new_line_content": "        preserve_shardings) {",
          "content_same": false
        },
        {
          "line": 3341,
          "old_api": "Undefined",
          "new_api": null,
          "old_text": "Undefined()",
          "new_text": null,
          "old_line_content": "        ShapeTree<HloSharding> output_tuple_sharding(ins->shape(), Undefined());",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3346,
          "old_api": "HloSharding::Tuple(output_tuple_sharding)",
          "new_api": null,
          "old_text": "HloSharding::Tuple(output_tuple_sharding)",
          "new_text": null,
          "old_line_content": "        ins->set_sharding(HloSharding::Tuple(output_tuple_sharding));",
          "new_line_content": "        size_t i = 0;",
          "content_same": false
        },
        {
          "line": 3363,
          "old_api": "insert",
          "new_api": null,
          "old_text": "visited.insert(cur)",
          "new_text": null,
          "old_line_content": "  visited.insert(cur);",
          "new_line_content": "    StableHashSet<HloInstruction*>& replicated_set,",
          "content_same": false
        },
        {
          "line": 3366,
          "old_api": "UsersWithAlias",
          "new_api": null,
          "old_text": "UsersWithAlias(cur, alias_map, output)",
          "new_text": null,
          "old_line_content": "  StableHashSet<HloInstruction*> users = UsersWithAlias(cur, alias_map, output);",
          "new_line_content": "    StableHashSet<const HloInstruction*>& visited) {",
          "content_same": false
        },
        {
          "line": 3371,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "consumer->opcode()",
          "new_text": null,
          "old_line_content": "    if (consumer->opcode() == HloOpcode::kTranspose &&",
          "new_line_content": "  for (HloInstruction* consumer : users) {",
          "content_same": false
        },
        {
          "line": 3373,
          "old_api": "shape",
          "new_api": null,
          "old_text": "consumer->shape()",
          "new_text": null,
          "old_line_content": "         DimensionsEqual(transpose_inst->shape(), consumer->shape()))) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3379,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "consumer->opcode()",
          "new_text": null,
          "old_line_content": "    if (consumer->opcode() == HloOpcode::kTuple ||",
          "new_line_content": "      transpose_inst = consumer;",
          "content_same": false
        },
        {
          "line": 3380,
          "old_api": "IsParameterConvert",
          "new_api": null,
          "old_text": "IsParameterConvert(consumer)",
          "new_text": null,
          "old_line_content": "        (do_all_gather_after_backward && IsParameterConvert(consumer)) ||",
          "new_line_content": "      // TODO(zhuohan): fix output_sharding comparison.",
          "content_same": false
        },
        {
          "line": 3381,
          "old_api": "GetShardingStrategy",
          "new_api": null,
          "old_text": "GetShardingStrategy(consumer, strategy_map, cost_graph, s_val)",
          "new_text": null,
          "old_line_content": "        GetShardingStrategy(consumer, strategy_map, cost_graph, s_val)",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3390,
          "old_api": "insert",
          "new_api": null,
          "old_text": "replicated_set.insert(cur)",
          "new_text": null,
          "old_line_content": "  replicated_set.insert(cur);",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3392,
          "old_api": "contains",
          "new_api": null,
          "old_text": "visited.contains(consumer)",
          "new_text": null,
          "old_line_content": "    if (!visited.contains(consumer)) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3393,
          "old_api": "insert",
          "new_api": null,
          "old_text": "consumer_set.insert(consumer)",
          "new_text": null,
          "old_line_content": "      consumer_set.insert(consumer);",
          "new_line_content": "  // If this node is not a boundary node, propagate from this node.",
          "content_same": false
        },
        {
          "line": 3401,
          "old_api": "operand_count",
          "new_api": null,
          "old_text": "cur->operand_count()",
          "new_text": null,
          "old_line_content": "  for (size_t i = 0; i < cur->operand_count(); ++i) {",
          "new_line_content": "                       consumer_set, visited);",
          "content_same": false
        },
        {
          "line": 3402,
          "old_api": "mutable_operand",
          "new_api": null,
          "old_text": "cur->mutable_operand(i)",
          "new_text": null,
          "old_line_content": "    HloInstruction* operand = cur->mutable_operand(i);",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3403,
          "old_api": "PassThroughCustomCallMarkerOperand",
          "new_api": null,
          "old_text": "PassThroughCustomCallMarkerOperand(operand, cur)",
          "new_text": null,
          "old_line_content": "    operand = PassThroughCustomCallMarkerOperand(operand, cur);",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 3408,
          "old_api": "shape",
          "new_api": null,
          "old_text": "cur->shape()",
          "new_text": null,
          "old_line_content": "        DimensionsEqual(operand->shape(), cur->shape())) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3426,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "sequence.instructions()",
          "new_text": null,
          "old_line_content": "  const std::vector<HloInstruction*>& instructions = sequence.instructions();",
          "new_line_content": "                           const CostGraph& cost_graph,",
          "content_same": false
        },
        {
          "line": 3429,
          "old_api": "back",
          "new_api": null,
          "old_text": "instructions.back()",
          "new_text": null,
          "old_line_content": "  const HloInstruction* output = instructions.back();",
          "new_line_content": "                           const AutoShardingSolverOption& solver_option) {",
          "content_same": false
        },
        {
          "line": 3431,
          "old_api": "operand",
          "new_api": null,
          "old_text": "output->operand(0)",
          "new_text": null,
          "old_line_content": "    output = output->operand(0);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3457,
          "old_api": "HasReduceScatterOpportunity",
          "new_api": null,
          "old_text": "HasReduceScatterOpportunity(inst, strategy_map, cost_graph, s_val,\n                                     modified)",
          "new_text": null,
          "old_line_content": "    if (!HasReduceScatterOpportunity(inst, strategy_map, cost_graph, s_val,",
          "new_line_content": "  std::vector<HloInstruction*> insert_all_gather;",
          "content_same": false
        },
        {
          "line": 3462,
          "old_api": "GetShardingStrategy",
          "new_api": null,
          "old_text": "GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "new_text": null,
          "old_line_content": "        GetShardingStrategy(inst, strategy_map, cost_graph, s_val);",
          "new_line_content": "                                     modified)) {",
          "content_same": false
        },
        {
          "line": 3463,
          "old_api": "absl::StrContains(strategy.name, \"allreduce\")",
          "new_api": null,
          "old_text": "absl::StrContains(strategy.name, \"allreduce\")",
          "new_text": null,
          "old_line_content": "    if (!absl::StrContains(strategy.name, \"allreduce\")) {",
          "new_line_content": "      continue;",
          "content_same": false
        },
        {
          "line": 3476,
          "old_api": "insert",
          "new_api": null,
          "old_text": "visited.insert(output)",
          "new_text": null,
          "old_line_content": "    visited.insert(output);",
          "new_line_content": "    // We allow at most one transpose in the path of replication analysis.",
          "content_same": false
        },
        {
          "line": 3477,
          "old_api": "FindReplicateSet",
          "new_api": null,
          "old_text": "FindReplicateSet(inst, alias_map, cost_graph, s_val, strategy_map, strategy,\n                     output, do_all_gather_after_backward, transpose_inst,\n                     replicated_set, boundary_set, consumer_set, visited)",
          "new_text": null,
          "old_line_content": "    FindReplicateSet(inst, alias_map, cost_graph, s_val, strategy_map, strategy,",
          "new_line_content": "    HloInstruction* transpose_inst = nullptr;",
          "content_same": false
        },
        {
          "line": 3482,
          "old_api": "TryReduceWithCommonAncestor",
          "new_api": null,
          "old_text": "TryReduceWithCommonAncestor(replicated_set, boundary_set, consumer_set,\n                                alias_map)",
          "new_text": null,
          "old_line_content": "    TryReduceWithCommonAncestor(replicated_set, boundary_set, consumer_set,",
          "new_line_content": "                     output, do_all_gather_after_backward, transpose_inst,",
          "content_same": false
        },
        {
          "line": 3488,
          "old_api": "contains",
          "new_api": null,
          "old_text": "consumer_set.contains(node)",
          "new_text": null,
          "old_line_content": "      if (consumer_set.contains(node)) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3489,
          "old_api": "AllUsersAreReduce",
          "new_api": null,
          "old_text": "AllUsersAreReduce(node)",
          "new_text": null,
          "old_line_content": "        if (AllUsersAreReduce(node)) {",
          "new_line_content": "    // Analyze the instructions after which all-gather should be inserted.",
          "content_same": false
        },
        {
          "line": 3495,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "need_all_gather.push_back(node)",
          "new_text": null,
          "old_line_content": "          need_all_gather.push_back(node);",
          "new_line_content": "          // should be small, so we ignore all-gather cost of these",
          "content_same": false
        },
        {
          "line": 3502,
          "old_api": "size",
          "new_api": null,
          "old_text": "need_all_gather.size()",
          "new_text": null,
          "old_line_content": "    if (do_all_gather_after_backward && need_all_gather.size() == 1) {",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3503,
          "old_api": "front",
          "new_api": null,
          "old_text": "need_all_gather.front()",
          "new_text": null,
          "old_line_content": "      HloInstruction* point = need_all_gather.front();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3508,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "root->opcode()",
          "new_text": null,
          "old_line_content": "        if (root->opcode() == HloOpcode::kGetTupleElement) {",
          "new_line_content": "      std::vector<HloInstruction*> path;",
          "content_same": false
        },
        {
          "line": 3509,
          "old_api": "mutable_operand",
          "new_api": null,
          "old_text": "root->mutable_operand(0)",
          "new_text": null,
          "old_line_content": "          root = PassThroughCustomCallMarkerOperand(root->mutable_operand(0),",
          "new_line_content": "      HloInstruction* root = point;",
          "content_same": false
        },
        {
          "line": 3516,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "root->opcode()",
          "new_text": null,
          "old_line_content": "      if (root->opcode() == HloOpcode::kParameter) {",
          "new_line_content": "          break;",
          "content_same": false
        },
        {
          "line": 3518,
          "old_api": "erase",
          "new_api": null,
          "old_text": "replicated_set.erase(x)",
          "new_text": null,
          "old_line_content": "          replicated_set.erase(x);",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3519,
          "old_api": "erase",
          "new_api": null,
          "old_text": "boundary_set.erase(x)",
          "new_text": null,
          "old_line_content": "          boundary_set.erase(x);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3521,
          "old_api": "clear",
          "new_api": null,
          "old_text": "need_all_gather.clear()",
          "new_text": null,
          "old_line_content": "        need_all_gather.clear();",
          "new_line_content": "        for (auto x : path) {",
          "content_same": false
        },
        {
          "line": 3524,
          "old_api": "end",
          "new_api": null,
          "old_text": "alias_map.end()",
          "new_text": null,
          "old_line_content": "          if (iter != alias_map.end() && iter->second == root) {",
          "new_line_content": "        }",
          "content_same": false
        },
        {
          "line": 3526,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "need_all_gather.push_back(x)",
          "new_text": null,
          "old_line_content": "            need_all_gather.push_back(x);",
          "new_line_content": "        for (auto x : replicated_set) {",
          "content_same": false
        },
        {
          "line": 3537,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "node->opcode()",
          "new_text": null,
          "old_line_content": "      if (node->opcode() == HloOpcode::kParameter) {",
          "new_line_content": "    // Analyze how many parameters can be partitioned if we do this",
          "content_same": false
        },
        {
          "line": 3542,
          "old_api": "size",
          "new_api": null,
          "old_text": "to_split->users().size()",
          "new_text": null,
          "old_line_content": "      if (to_split->users().size() == 1 &&",
          "new_line_content": "        num_replicated_parameters++;",
          "content_same": false
        },
        {
          "line": 3543,
          "old_api": "contains",
          "new_api": null,
          "old_text": "alias_map.contains(to_split)",
          "new_text": null,
          "old_line_content": "          to_split->users().front() == output && alias_map.contains(to_split)) {",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3550,
          "old_api": "HloPrintOptions::ShortParsable()",
          "new_api": null,
          "old_text": "HloPrintOptions::ShortParsable()",
          "new_text": null,
          "old_line_content": "    VLOG(10) << inst->ToString(HloPrintOptions::ShortParsable()) << \"\\n\";",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3551,
          "old_api": "VLOG",
          "new_api": null,
          "old_text": "VLOG(10)",
          "new_text": null,
          "old_line_content": "    VLOG(10) << \"replicated set (#parameter: \" << num_replicated_parameters",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3556,
          "old_api": "size",
          "new_api": null,
          "old_text": "need_all_gather.size()",
          "new_text": null,
          "old_line_content": "    VLOG(10) << \"boundary set (#incompatible: \" << need_all_gather.size()",
          "new_line_content": "             << \"):\\n\";",
          "content_same": false
        },
        {
          "line": 3559,
          "old_api": "HloPrintOptions::ShortParsable()",
          "new_api": null,
          "old_text": "HloPrintOptions::ShortParsable()",
          "new_text": null,
          "old_line_content": "      VLOG(10) << \"  \" << x->ToString(HloPrintOptions::ShortParsable()) << \" \"",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3565,
          "old_api": "size",
          "new_api": null,
          "old_text": "need_all_gather.size()",
          "new_text": null,
          "old_line_content": "    if (num_replicated_parameters >= 1 && need_all_gather.size() <= 1 &&",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3566,
          "old_api": "size",
          "new_api": null,
          "old_text": "replicated_set.size()",
          "new_text": null,
          "old_line_content": "        replicated_set.size() >= 5) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3568,
          "old_api": "GetReduceScatterOutput",
          "new_api": null,
          "old_text": "GetReduceScatterOutput(inst, strategy, cluster_env)",
          "new_text": null,
          "old_line_content": "          GetReduceScatterOutput(inst, strategy, cluster_env);",
          "new_line_content": "    // setting instructions' sharding.",
          "content_same": false
        },
        {
          "line": 3575,
          "old_api": "absl::StartsWith(strategy.name, \"RR = RS x SR\")",
          "new_api": null,
          "old_text": "absl::StartsWith(strategy.name, \"RR = RS x SR\")",
          "new_text": null,
          "old_line_content": "      if (absl::StartsWith(strategy.name, \"RR = RS x SR\")) {",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3578,
          "old_api": "erase",
          "new_api": null,
          "old_text": "replicated_set.erase(inst)",
          "new_text": null,
          "old_line_content": "        replicated_set.erase(inst);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3592,
          "old_api": "SetSharding",
          "new_api": null,
          "old_text": "SetSharding(to_split, output_spec, inst, transpose_inst, modified)",
          "new_text": null,
          "old_line_content": "          SetSharding(to_split, output_spec, inst, transpose_inst, modified);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3594,
          "old_api": "size",
          "new_api": null,
          "old_text": "to_split->users().size()",
          "new_text": null,
          "old_line_content": "          if (!do_all_gather_after_backward && to_split->users().size() == 1 &&",
          "new_line_content": "        // The normal case",
          "content_same": false
        },
        {
          "line": 3595,
          "old_api": "front",
          "new_api": null,
          "old_text": "to_split->users().front()",
          "new_text": null,
          "old_line_content": "              to_split->users().front() == output &&",
          "new_line_content": "        for (HloInstruction* to_split : need_all_gather) {",
          "content_same": false
        },
        {
          "line": 3601,
          "old_api": "at",
          "new_api": null,
          "old_text": "alias_map.at(to_split)",
          "new_text": null,
          "old_line_content": "            SetSharding(alias_map.at(to_split), output_spec, inst,",
          "new_line_content": "            // Move the all-gather to its alias parameter.",
          "content_same": false
        },
        {
          "line": 3603,
          "old_api": "at",
          "new_api": null,
          "old_text": "alias_map.at(to_split)",
          "new_text": null,
          "old_line_content": "            insert_all_gather.push_back(alias_map.at(to_split));",
          "new_line_content": "            // in the forward pass, which is not desired in gradient",
          "content_same": false
        },
        {
          "line": 3608,
          "old_api": "operand",
          "new_api": null,
          "old_text": "to_split->operand(0)",
          "new_text": null,
          "old_line_content": "                IsCustomCallMarker(to_split->operand(0)) &&",
          "new_line_content": "          } else {",
          "content_same": false
        },
        {
          "line": 3610,
          "old_api": "front",
          "new_api": null,
          "old_text": "to_split->users().front()",
          "new_text": null,
          "old_line_content": "                to_split->users().front() == output) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3622,
          "old_api": "SetSharding",
          "new_api": null,
          "old_text": "SetSharding(to_split, output_spec, inst, transpose_inst, modified)",
          "new_text": null,
          "old_line_content": "          SetSharding(to_split, output_spec, inst, transpose_inst, modified);",
          "new_line_content": "        // This can result in a strategy similar to ZeRO stage 3.",
          "content_same": false
        },
        {
          "line": 3624,
          "old_api": "size",
          "new_api": null,
          "old_text": "to_split->users().size()",
          "new_text": null,
          "old_line_content": "          if (to_split->users().size() == 1 &&",
          "new_line_content": "        // tested.",
          "content_same": false
        },
        {
          "line": 3625,
          "old_api": "front",
          "new_api": null,
          "old_text": "to_split->users().front()",
          "new_text": null,
          "old_line_content": "              to_split->users().front() == output &&",
          "new_line_content": "        for (HloInstruction* to_split : need_all_gather) {",
          "content_same": false
        },
        {
          "line": 3633,
          "old_api": "size",
          "new_api": null,
          "old_text": "cur->users().size()",
          "new_text": null,
          "old_line_content": "            while (cur->users().size() == 1) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3635,
          "old_api": "IsArray",
          "new_api": null,
          "old_text": "cur->shape().IsArray()",
          "new_text": null,
          "old_line_content": "              CHECK(cur->shape().IsArray());",
          "new_line_content": "            // convert)",
          "content_same": false
        },
        {
          "line": 3636,
          "old_api": "SetSharding",
          "new_api": null,
          "old_text": "SetSharding(cur, output_spec, inst, transpose_inst, modified)",
          "new_text": null,
          "old_line_content": "              SetSharding(cur, output_spec, inst, transpose_inst, modified);",
          "new_line_content": "            HloInstruction* cur = param;",
          "content_same": false
        },
        {
          "line": 3646,
          "old_api": "users",
          "new_api": null,
          "old_text": "cur->users()",
          "new_text": null,
          "old_line_content": "            for (const auto& x : cur->users()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3647,
          "old_api": "find",
          "new_api": null,
          "old_text": "depth_map.find(x)",
          "new_text": null,
          "old_line_content": "              auto iter = depth_map.find(x);",
          "new_line_content": "            // Find the first user",
          "content_same": false
        },
        {
          "line": 3648,
          "old_api": "end",
          "new_api": null,
          "old_text": "depth_map.end()",
          "new_text": null,
          "old_line_content": "              if (iter == depth_map.end()) {",
          "new_line_content": "            HloInstruction* first_user = nullptr;",
          "content_same": false
        },
        {
          "line": 3649,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "x->ToString()",
          "new_text": null,
          "old_line_content": "                LOG(FATAL) << \"ERROR: \" << x->ToString();",
          "new_line_content": "            int64_t min_depth = ((int64_t)1) << 50;",
          "content_same": false
        },
        {
          "line": 3664,
          "old_api": "parent",
          "new_api": null,
          "old_text": "inst->parent()->AddInstruction(\n                  HloInstruction::CreateCustomCall(cur->shape(), {cur},\n                                                   kIdentityMarker))",
          "new_text": null,
          "old_line_content": "              HloInstruction* identity = inst->parent()->AddInstruction(",
          "new_line_content": "            }",
          "content_same": false
        },
        {
          "line": 3665,
          "old_api": "shape",
          "new_api": null,
          "old_text": "cur->shape()",
          "new_text": null,
          "old_line_content": "                  HloInstruction::CreateCustomCall(cur->shape(), {cur},",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3667,
          "old_api": "SetSharding",
          "new_api": null,
          "old_text": "SetSharding(identity, output_spec, inst, transpose_inst,\n                          modified)",
          "new_text": null,
          "old_line_content": "              SetSharding(identity, output_spec, inst, transpose_inst,",
          "new_line_content": "              // Insert an identity to prevent CSE of all-gather",
          "content_same": false
        },
        {
          "line": 3676,
          "old_api": "VLOG",
          "new_api": null,
          "old_text": "VLOG(10)",
          "new_text": null,
          "old_line_content": "    VLOG(10) << \"-----------------------done\\n\";",
          "new_line_content": "        }",
          "content_same": false
        },
        {
          "line": 3682,
          "old_api": "parent",
          "new_api": null,
          "old_text": "inst->parent()->AddInstruction(\n        HloInstruction::CreateReshape(inst->shape(), inst))",
          "new_text": null,
          "old_line_content": "    HloInstruction* replace_with = inst->parent()->AddInstruction(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3683,
          "old_api": "shape",
          "new_api": null,
          "old_text": "inst->shape()",
          "new_text": null,
          "old_line_content": "        HloInstruction::CreateReshape(inst->shape(), inst));",
          "new_line_content": "  // Insert all-gather on the output of boundary nodes by setting",
          "content_same": false
        },
        {
          "line": 3684,
          "old_api": "set_sharding",
          "new_api": null,
          "old_text": "replace_with->set_sharding(\n        GetShardingStrategy(inst, strategy_map, cost_graph, s_val)\n            .output_sharding)",
          "new_text": null,
          "old_line_content": "    replace_with->set_sharding(",
          "new_line_content": "  // their shardings. This also works as CSE of all-gather.",
          "content_same": false
        },
        {
          "line": 3685,
          "old_api": "GetShardingStrategy",
          "new_api": null,
          "old_text": "GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "new_text": null,
          "old_line_content": "        GetShardingStrategy(inst, strategy_map, cost_graph, s_val)",
          "new_line_content": "  for (HloInstruction* inst : insert_all_gather) {",
          "content_same": false
        },
        {
          "line": 3696,
          "old_api": "num_elements",
          "new_api": null,
          "old_text": "device_mesh.num_elements()",
          "new_text": null,
          "old_line_content": "  int64_t num_devices = device_mesh.num_elements();",
          "new_line_content": "    HloModule* module, const std::string& heuristic, const AliasMap& alias_map,",
          "content_same": false
        },
        {
          "line": 3707,
          "old_api": "entry_computation",
          "new_api": null,
          "old_text": "module->entry_computation()",
          "new_text": null,
          "old_line_content": "  HloComputation* entry_computation = module->entry_computation();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3708,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "entry_computation->instructions()",
          "new_text": null,
          "old_line_content": "  for (HloInstruction* inst : entry_computation->instructions()) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 3709,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "inst->opcode()",
          "new_text": null,
          "old_line_content": "    if (inst->opcode() == HloOpcode::kParameter) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3710,
          "old_api": "HloSharding::Replicate()",
          "new_api": null,
          "old_text": "HloSharding::Replicate()",
          "new_text": null,
          "old_line_content": "      HloSharding output_spec = HloSharding::Replicate();",
          "new_line_content": "  // Shard instructions",
          "content_same": false
        },
        {
          "line": 3716,
          "old_api": "dimensions",
          "new_api": null,
          "old_text": "inst->shape().dimensions(i)",
          "new_text": null,
          "old_line_content": "          lengths.push_back(inst->shape().dimensions(i));",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3730,
          "old_api": "shape",
          "new_api": null,
          "old_text": "inst->shape()",
          "new_text": null,
          "old_line_content": "            output_spec = Tile(inst->shape(), {dim}, {0}, device_mesh_1d);",
          "new_line_content": "        if (common_dims == 1) {",
          "content_same": false
        },
        {
          "line": 3738,
          "old_api": "dim",
          "new_api": null,
          "old_text": "device_mesh.dim(0)",
          "new_text": null,
          "old_line_content": "          if (length0 % device_mesh.dim(0) == 0 &&",
          "new_line_content": "          int length1 = lengths[dim1];",
          "content_same": false
        },
        {
          "line": 3739,
          "old_api": "dim",
          "new_api": null,
          "old_text": "device_mesh.dim(1)",
          "new_text": null,
          "old_line_content": "              length1 % device_mesh.dim(1) == 0) {",
          "new_line_content": "          int dim0 = indices[1];",
          "content_same": false
        },
        {
          "line": 3741,
          "old_api": "shape",
          "new_api": null,
          "old_text": "inst->shape()",
          "new_text": null,
          "old_line_content": "                Tile(inst->shape(), {dim0, dim1}, {0, 1}, device_mesh);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3746,
          "old_api": "dimensions",
          "new_api": null,
          "old_text": "inst->shape().dimensions(0)",
          "new_text": null,
          "old_line_content": "            inst->shape().dimensions(0) % num_devices == 0) {",
          "new_line_content": "          }",
          "content_same": false
        },
        {
          "line": 3747,
          "old_api": "shape",
          "new_api": null,
          "old_text": "inst->shape()",
          "new_text": null,
          "old_line_content": "          output_spec = Tile(inst->shape(), {0}, {0}, device_mesh_1d);",
          "new_line_content": "        }",
          "content_same": false
        },
        {
          "line": 3752,
          "old_api": "dimensions",
          "new_api": null,
          "old_text": "inst->shape().dimensions(last_dim)",
          "new_text": null,
          "old_line_content": "            inst->shape().dimensions(last_dim) % num_devices == 0) {",
          "new_line_content": "        }",
          "content_same": false
        },
        {
          "line": 3753,
          "old_api": "shape",
          "new_api": null,
          "old_text": "inst->shape()",
          "new_text": null,
          "old_line_content": "          output_spec = Tile(inst->shape(), {last_dim}, {0}, device_mesh_1d);",
          "new_line_content": "      } else if (heuristic == \"shard-last\") {",
          "content_same": false
        },
        {
          "line": 3759,
          "old_api": "set_sharding",
          "new_api": null,
          "old_text": "inst->set_sharding(output_spec)",
          "new_text": null,
          "old_line_content": "      inst->set_sharding(output_spec);",
          "new_line_content": "      } else {",
          "content_same": false
        },
        {
          "line": 3762,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "inst->opcode()",
          "new_text": null,
          "old_line_content": "    } else if (inst->opcode() == HloOpcode::kDot) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3764,
          "old_api": "operand",
          "new_api": null,
          "old_text": "inst->operand(1)",
          "new_text": null,
          "old_line_content": "      const HloInstruction* rhs = inst->operand(1);",
          "new_line_content": "      // std::cerr << \"ins: \" << inst->ToString() << \", spec: \" <<",
          "content_same": false
        },
        {
          "line": 3765,
          "old_api": "dot_dimension_numbers",
          "new_api": null,
          "old_text": "inst->dot_dimension_numbers()",
          "new_text": null,
          "old_line_content": "      const DotDimensionNumbers& dot_dnums = inst->dot_dimension_numbers();",
          "new_line_content": "      // output_spec.ToString() << std::endl;",
          "content_same": false
        },
        {
          "line": 3770,
          "old_api": "shape",
          "new_api": null,
          "old_text": "rhs->shape()",
          "new_text": null,
          "old_line_content": "          GetSpaceDims(lhs->shape(), rhs->shape(), dot_dnums);",
          "new_line_content": "      // const auto& lhs_con_dims = dot_dnums.lhs_contracting_dimensions();",
          "content_same": false
        },
        {
          "line": 3775,
          "old_api": "root_instruction",
          "new_api": null,
          "old_text": "entry_computation->root_instruction()",
          "new_text": null,
          "old_line_content": "  HloInstruction* output = entry_computation->root_instruction();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3776,
          "old_api": "shape",
          "new_api": null,
          "old_text": "output->shape()",
          "new_text": null,
          "old_line_content": "  const Shape& out_shape = output->shape();",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 3782,
          "old_api": "operand_count",
          "new_api": null,
          "old_text": "cur->operand_count()",
          "new_text": null,
          "old_line_content": "    for (int64_t i = 0; i < cur->operand_count(); ++i) {",
          "new_line_content": "  std::vector<HloSharding> flattened_shardings;",
          "content_same": false
        },
        {
          "line": 3783,
          "old_api": "mutable_operand",
          "new_api": null,
          "old_text": "cur->mutable_operand(i)",
          "new_text": null,
          "old_line_content": "      HloInstruction* operand = cur->mutable_operand(i);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3785,
          "old_api": "IsTuple",
          "new_api": null,
          "old_text": "operand->shape().IsTuple()",
          "new_text": null,
          "old_line_content": "      if (operand->shape().IsTuple()) {",
          "new_line_content": "  get_flattened_shardings = [&](HloInstruction* cur) {",
          "content_same": false
        },
        {
          "line": 3788,
          "old_api": "contains",
          "new_api": null,
          "old_text": "alias_map.contains(operand)",
          "new_text": null,
          "old_line_content": "        if (alias_map.contains(operand)) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3791,
          "old_api": "has_sharding",
          "new_api": null,
          "old_text": "operand->has_sharding()",
          "new_text": null,
          "old_line_content": "        if (!operand->has_sharding()) {",
          "new_line_content": "      } else {",
          "content_same": false
        },
        {
          "line": 3794,
          "old_api": "has_sharding",
          "new_api": null,
          "old_text": "operand->has_sharding()",
          "new_text": null,
          "old_line_content": "        CHECK(operand->has_sharding());",
          "new_line_content": "        }",
          "content_same": false
        },
        {
          "line": 3801,
          "old_api": "leaves",
          "new_api": null,
          "old_text": "tuple_sharding.leaves()",
          "new_text": null,
          "old_line_content": "  for (auto& leaf : tuple_sharding.leaves()) {",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3804,
          "old_api": "size",
          "new_api": null,
          "old_text": "flattened_shardings.size()",
          "new_text": null,
          "old_line_content": "  CHECK_EQ(i, flattened_shardings.size());",
          "new_line_content": "  int i = 0;",
          "content_same": false
        },
        {
          "line": 3816,
          "old_api": "GetBatchDimMapKey",
          "new_api": null,
          "old_text": "GetBatchDimMapKey(ins)",
          "new_text": null,
          "old_line_content": "  int batch_dim = batch_map.at(GetBatchDimMapKey(ins));",
          "new_line_content": "                      const ClusterEnvironment& cluster_env,",
          "content_same": false
        },
        {
          "line": 3819,
          "old_api": "dim",
          "new_api": null,
          "old_text": "device_mesh.dim(mesh_dim)",
          "new_text": null,
          "old_line_content": "  if (shape.dimensions(batch_dim) % device_mesh.dim(mesh_dim) != 0) {",
          "new_line_content": "  int mesh_dim = solver_option.force_batch_dim_to_mesh_dim;",
          "content_same": false
        },
        {
          "line": 3828,
          "old_api": "GetTensorDimToMeshDimWrapper",
          "new_api": null,
          "old_text": "cluster_env.GetTensorDimToMeshDimWrapper(shape, stra.output_sharding)",
          "new_text": null,
          "old_line_content": "        cluster_env.GetTensorDimToMeshDimWrapper(shape, stra.output_sharding);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3830,
          "old_api": "dim",
          "new_api": null,
          "old_text": "device_mesh.dim(mesh_dim)",
          "new_text": null,
          "old_line_content": "    if (device_mesh.dim(mesh_dim) > 1) {",
          "new_line_content": "  for (auto& stra : strategies->leaf_vector) {",
          "content_same": false
        },
        {
          "line": 3840,
          "old_api": "std::move(stra)",
          "new_api": null,
          "old_text": "std::move(stra)",
          "new_text": null,
          "old_line_content": "        new_leaf_vector.push_back(std::move(stra));",
          "new_line_content": "    } else {",
          "content_same": false
        },
        {
          "line": 3845,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "ins->ToString()",
          "new_text": null,
          "old_line_content": "      << ins->ToString() << \" does not have any valid strategies\";",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3846,
          "old_api": "std::move(new_leaf_vector)",
          "new_api": null,
          "old_text": "std::move(new_leaf_vector)",
          "new_text": null,
          "old_line_content": "  strategies->leaf_vector = std::move(new_leaf_vector);",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3858,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "ins->opcode()",
          "new_text": null,
          "old_line_content": "  if (ins->opcode() == HloOpcode::kDot) {",
          "new_line_content": "                                   const ClusterEnvironment& cluster_env) {",
          "content_same": false
        },
        {
          "line": 3859,
          "old_api": "dot_dimension_numbers",
          "new_api": null,
          "old_text": "ins->dot_dimension_numbers()",
          "new_text": null,
          "old_line_content": "    const DotDimensionNumbers& dot_dnums = ins->dot_dimension_numbers();",
          "new_line_content": "  const Array<int64_t>& device_mesh = cluster_env.device_mesh_;",
          "content_same": false
        },
        {
          "line": 3860,
          "old_api": "lhs_batch_dimensions_size",
          "new_api": null,
          "old_text": "dot_dnums.lhs_batch_dimensions_size()",
          "new_text": null,
          "old_line_content": "    int64_t space_base_dim = dot_dnums.lhs_batch_dimensions_size();",
          "new_line_content": "  const Array<int64_t>& device_mesh_1d = cluster_env.device_mesh_1d_;",
          "content_same": false
        },
        {
          "line": 3865,
          "old_api": "ParseMeshDims",
          "new_api": null,
          "old_text": "ParseMeshDims(strategy.name)",
          "new_text": null,
          "old_line_content": "      std::tie(mesh_dim0, mesh_dim1) = ParseMeshDims(strategy.name);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3872,
          "old_api": "Undefined",
          "new_api": null,
          "old_text": "Undefined()",
          "new_text": null,
          "old_line_content": "        return Undefined();",
          "new_line_content": "                       {mesh_dim0, mesh_dim1})) {",
          "content_same": false
        },
        {
          "line": 3875,
          "old_api": "shape",
          "new_api": null,
          "old_text": "ins->shape()",
          "new_text": null,
          "old_line_content": "      return Tile(ins->shape(), {space_base_dim, space_base_dim + 1},",
          "new_line_content": "        // partitioning.",
          "content_same": false
        },
        {
          "line": 3878,
          "old_api": "absl::StartsWith(strategy.name, \"SbR = SbSk x SbSk\")",
          "new_api": null,
          "old_text": "absl::StartsWith(strategy.name, \"SbR = SbSk x SbSk\")",
          "new_text": null,
          "old_line_content": "    if (absl::StartsWith(strategy.name, \"SbR = SbSk x SbSk\")) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3880,
          "old_api": "ParseMeshDims",
          "new_api": null,
          "old_text": "ParseMeshDims(strategy.name)",
          "new_text": null,
          "old_line_content": "      std::tie(mesh_dim0, mesh_dim1) = ParseMeshDims(strategy.name);",
          "new_line_content": "                  {mesh_dim0, mesh_dim1}, device_mesh);",
          "content_same": false
        },
        {
          "line": 3887,
          "old_api": "Undefined",
          "new_api": null,
          "old_text": "Undefined()",
          "new_text": null,
          "old_line_content": "        return Undefined();",
          "new_line_content": "                       {mesh_dim0, mesh_dim1})) {",
          "content_same": false
        },
        {
          "line": 3890,
          "old_api": "shape",
          "new_api": null,
          "old_text": "ins->shape()",
          "new_text": null,
          "old_line_content": "      return Tile(ins->shape(), {0, space_base_dim}, {mesh_dim0, mesh_dim1},",
          "new_line_content": "        // partitioning.",
          "content_same": false
        },
        {
          "line": 3893,
          "old_api": "absl::StartsWith(strategy.name, \"RR = RS x SR\")",
          "new_api": null,
          "old_text": "absl::StartsWith(strategy.name, \"RR = RS x SR\")",
          "new_text": null,
          "old_line_content": "    if (absl::StartsWith(strategy.name, \"RR = RS x SR\")) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3896,
          "old_api": "IsDivisible",
          "new_api": null,
          "old_text": "IsDivisible(ins, device_mesh, {space_base_dim}, {mesh_dim})",
          "new_text": null,
          "old_line_content": "      if (!IsDivisible(ins, device_mesh, {space_base_dim}, {mesh_dim})) {",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3902,
          "old_api": "absl::StartsWith(strategy.name, \"R = Sk x Sk\")",
          "new_api": null,
          "old_text": "absl::StartsWith(strategy.name, \"R = Sk x Sk\")",
          "new_text": null,
          "old_line_content": "    if (absl::StartsWith(strategy.name, \"R = Sk x Sk\")) {",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3905,
          "old_api": "IsDivisible",
          "new_api": null,
          "old_text": "IsDivisible(ins, device_mesh_1d, {space_base_dim}, {mesh_dim})",
          "new_text": null,
          "old_line_content": "      if (!IsDivisible(ins, device_mesh_1d, {space_base_dim}, {mesh_dim})) {",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3911,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "ins->opcode()",
          "new_text": null,
          "old_line_content": "  } else if (ins->opcode() == HloOpcode::kConvolution) {",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3914,
          "old_api": "output_batch_dimension",
          "new_api": null,
          "old_text": "conv_dnums.output_batch_dimension()",
          "new_text": null,
          "old_line_content": "    int out_batch_dim = conv_dnums.output_batch_dimension();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3920,
          "old_api": "ParseMeshDims",
          "new_api": null,
          "old_text": "ParseMeshDims(strategy.name)",
          "new_text": null,
          "old_line_content": "      std::tie(mesh_dim0, mesh_dim1) = ParseMeshDims(strategy.name);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3927,
          "old_api": "shape",
          "new_api": null,
          "old_text": "ins->shape()",
          "new_text": null,
          "old_line_content": "      return Tile(ins->shape(), {out_batch_dim, out_out_channel_dim},",
          "new_line_content": "                       {mesh_dim0, mesh_dim1})) {",
          "content_same": false
        },
        {
          "line": 3930,
          "old_api": "absl::StartsWith(strategy.name, \"R = Sk x Sk\")",
          "new_api": null,
          "old_text": "absl::StartsWith(strategy.name, \"R = Sk x Sk\")",
          "new_text": null,
          "old_line_content": "    if (absl::StartsWith(strategy.name, \"R = Sk x Sk\")) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3933,
          "old_api": "IsDivisible",
          "new_api": null,
          "old_text": "IsDivisible(ins, device_mesh_1d, {out_batch_dim}, {mesh_dim})",
          "new_text": null,
          "old_line_content": "      if (!IsDivisible(ins, device_mesh_1d, {out_batch_dim}, {mesh_dim})) {",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3939,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "ins->opcode()",
          "new_text": null,
          "old_line_content": "  } else if (ins->opcode() == HloOpcode::kReduce) {",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3944,
          "old_api": "absl::StrContains(strategy.name, \"allreduce @ [0]\")",
          "new_api": null,
          "old_text": "absl::StrContains(strategy.name, \"allreduce @ [0]\")",
          "new_text": null,
          "old_line_content": "    if (absl::StrContains(strategy.name, \"allreduce @ [0]\")) {",
          "new_line_content": "    // TODO(zhuohan): support more cases.",
          "content_same": false
        },
        {
          "line": 3950,
          "old_api": "IsReplicated",
          "new_api": null,
          "old_text": "strategy.output_sharding.IsReplicated()",
          "new_text": null,
          "old_line_content": "    if (strategy.output_sharding.IsReplicated()) {",
          "new_line_content": "    } else {",
          "content_same": false
        },
        {
          "line": 3951,
          "old_api": "absl::StrContains(strategy.name, \"1d\")",
          "new_api": null,
          "old_text": "absl::StrContains(strategy.name, \"1d\")",
          "new_text": null,
          "old_line_content": "      if (absl::StrContains(strategy.name, \"1d\")) {",
          "new_line_content": "      mesh_dim = 1;",
          "content_same": false
        },
        {
          "line": 3952,
          "old_api": "IsDivisible",
          "new_api": null,
          "old_text": "IsDivisible(ins, device_mesh_1d, {0}, {mesh_dim})",
          "new_text": null,
          "old_line_content": "        if (!IsDivisible(ins, device_mesh_1d, {0}, {mesh_dim})) {",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3953,
          "old_api": "Undefined",
          "new_api": null,
          "old_text": "Undefined()",
          "new_text": null,
          "old_line_content": "          return Undefined();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3958,
          "old_api": "IsDivisible",
          "new_api": null,
          "old_text": "IsDivisible(ins, device_mesh, {0}, {mesh_dim})",
          "new_text": null,
          "old_line_content": "      if (!IsDivisible(ins, device_mesh, {0}, {mesh_dim})) {",
          "new_line_content": "        }",
          "content_same": false
        },
        {
          "line": 3959,
          "old_api": "Undefined",
          "new_api": null,
          "old_text": "Undefined()",
          "new_text": null,
          "old_line_content": "        return Undefined();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3964,
          "old_api": "IsDivisible",
          "new_api": null,
          "old_text": "IsDivisible(ins, device_mesh_1d, {0}, {0})",
          "new_text": null,
          "old_line_content": "    if (!IsDivisible(ins, device_mesh_1d, {0}, {0})) {",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3965,
          "old_api": "Undefined",
          "new_api": null,
          "old_text": "Undefined()",
          "new_text": null,
          "old_line_content": "      return Undefined();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3970,
          "old_api": "std::move(tile_assignment)",
          "new_api": null,
          "old_text": "std::move(tile_assignment)",
          "new_text": null,
          "old_line_content": "    return HloSharding::Tile(std::move(tile_assignment));",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3976,
          "old_api": "Undefined",
          "new_api": null,
          "old_text": "Undefined()",
          "new_text": null,
          "old_line_content": "  return Undefined();",
          "new_line_content": "  } else {",
          "content_same": false
        },
        {
          "line": 3986,
          "old_api": "operands",
          "new_api": null,
          "old_text": "inst->operands()",
          "new_text": null,
          "old_line_content": "  for (const HloInstruction* operand : inst->operands()) {",
          "new_line_content": "    const CostGraph& cost_graph, absl::Span<const int64_t> s_val,",
          "content_same": false
        },
        {
          "line": 3987,
          "old_api": "contains",
          "new_api": null,
          "old_text": "modified.contains(operand)",
          "new_text": null,
          "old_line_content": "    if (modified.contains(operand)) {",
          "new_line_content": "    const StableHashSet<const HloInstruction*>& modified) {",
          "content_same": false
        },
        {
          "line": 3998,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "inst->opcode()",
          "new_text": null,
          "old_line_content": "  if (inst->opcode() == HloOpcode::kDot) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 4001,
          "old_api": "operand",
          "new_api": null,
          "old_text": "inst->operand(1)",
          "new_text": null,
          "old_line_content": "        GetShardingStrategy(inst->operand(1), strategy_map, cost_graph, s_val)",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 4010,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "inst->opcode()",
          "new_text": null,
          "old_line_content": "  if (inst->opcode() == HloOpcode::kConvolution) {",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 4026,
          "old_api": "VLOG",
          "new_api": null,
          "old_text": "VLOG(0)",
          "new_text": null,
          "old_line_content": "  VLOG(0) << \"Removing user sharding annotations.\";",
          "new_line_content": "  if (option_.preserve_shardings ==",
          "content_same": false
        },
        {
          "line": 4029,
          "old_api": "computations",
          "new_api": null,
          "old_text": "module->computations(execution_threads)",
          "new_text": null,
          "old_line_content": "  for (HloComputation* computation : module->computations(execution_threads)) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 4032,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "computation->instructions()",
          "new_text": null,
          "old_line_content": "    for (HloInstruction* ins : computation->instructions()) {",
          "new_line_content": "  absl::flat_hash_set<HloInstruction*> keep_inst;",
          "content_same": false
        },
        {
          "line": 4039,
          "old_api": "IsRoot",
          "new_api": null,
          "old_text": "ins->IsRoot()",
          "new_text": null,
          "old_line_content": "           (ins->opcode() == HloOpcode::kParameter || ins->IsRoot()))) {",
          "new_line_content": "      if (option_.preserve_shardings ==",
          "content_same": false
        },
        {
          "line": 4040,
          "old_api": "insert",
          "new_api": null,
          "old_text": "keep_inst.insert(ins)",
          "new_text": null,
          "old_line_content": "        keep_inst.insert(ins);",
          "new_line_content": "              AutoShardingOption::PreserveShardingsType::",
          "content_same": false
        },
        {
          "line": 4049,
          "old_api": "clear_sharding",
          "new_api": null,
          "old_text": "ins->clear_sharding()",
          "new_text": null,
          "old_line_content": "        ins->clear_sharding();",
          "new_line_content": "        continue;",
          "content_same": false
        },
        {
          "line": 4057,
          "old_api": "layout_canonicalization_callback",
          "new_api": null,
          "old_text": "module->layout_canonicalization_callback()",
          "new_text": null,
          "old_line_content": "  if (!module->layout_canonicalization_callback()) {",
          "new_line_content": "  return changed;",
          "content_same": false
        },
        {
          "line": 4058,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(INFO)",
          "new_text": null,
          "old_line_content": "    LOG(INFO) << \"There is no registered layout_canonicalization_callback.\";",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 4059,
          "old_api": "OkStatus",
          "new_api": null,
          "old_text": "OkStatus()",
          "new_text": null,
          "old_line_content": "    return OkStatus();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 4066,
          "old_api": "entry_computation_layout",
          "new_api": null,
          "old_text": "module->config().entry_computation_layout()",
          "new_text": null,
          "old_line_content": "      module->config().entry_computation_layout();",
          "new_line_content": "                      module->layout_canonicalization_callback()(*module));",
          "content_same": false
        },
        {
          "line": 4067,
          "old_api": "mutable_result_layout",
          "new_api": null,
          "old_text": "TF_RETURN_IF_ERROR(\n      entry_computation_layout.mutable_result_layout()->CopyLayoutFromShape(\n          result_shape))",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(",
          "new_line_content": "  std::vector<Shape>& argument_shapes = layouts.first;",
          "content_same": false
        },
        {
          "line": 4068,
          "old_api": "mutable_result_layout",
          "new_api": null,
          "old_text": "entry_computation_layout.mutable_result_layout()->CopyLayoutFromShape(\n          result_shape)",
          "new_text": null,
          "old_line_content": "      entry_computation_layout.mutable_result_layout()->CopyLayoutFromShape(",
          "new_line_content": "  Shape& result_shape = layouts.second;",
          "content_same": false
        },
        {
          "line": 4073,
          "old_api": "mutable_parameter_layout",
          "new_api": null,
          "old_text": "entry_computation_layout.mutable_parameter_layout(i)\n                           ->CopyLayoutFromShape(argument_shapes.at(i))",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(entry_computation_layout.mutable_parameter_layout(i)",
          "new_line_content": "          result_shape));",
          "content_same": false
        }
      ]
    },
    "api_summary": {
      "total_replacements": 264,
      "total_additions": 463,
      "total_deletions": 460,
      "total_api_changes": 1187
    },
    "non_api_changes": {
      "has_non_api_changes": true,
      "evidence": {
        "total_diff_lines": 9,
        "api_related_lines": 1187,
        "non_api_lines": 2,
        "non_api_line_numbers": [
          2409,
          2395
        ]
      }
    },
    "api_calls_before": 2123,
    "api_calls_after": 2129,
    "diff_info": {
      "added_lines": 7,
      "removed_lines": 3,
      "total_diff_lines": 30
    }
  }
}