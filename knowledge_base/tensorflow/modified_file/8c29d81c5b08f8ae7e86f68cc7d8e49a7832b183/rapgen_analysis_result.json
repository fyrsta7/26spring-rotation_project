{
  "status": "completed",
  "commit_dir": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/8c29d81c5b08f8ae7e86f68cc7d8e49a7832b183",
  "file_info": {
    "before_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/8c29d81c5b08f8ae7e86f68cc7d8e49a7832b183/before.cc",
    "after_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/8c29d81c5b08f8ae7e86f68cc7d8e49a7832b183/after.cc",
    "diff_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/8c29d81c5b08f8ae7e86f68cc7d8e49a7832b183/diff.txt"
  },
  "semgrep_analysis": {
    "is_api_change": false,
    "api_changes": {
      "replacements": [
        {
          "line": 234,
          "old_api": "empty",
          "new_api": "GetBlasGemmAlgorithms",
          "old_text": "algorithms.empty()",
          "new_text": "blas->GetBlasGemmAlgorithms(stream_, desc.lhs, desc.rhs, &desc.output,\n                                &gemm_config.alpha, &gemm_config.beta,\n                                &algorithms)",
          "old_line_content": "    if (algorithms.empty()) {  // nothing to autotune",
          "new_line_content": "    blas->GetBlasGemmAlgorithms(stream_, desc.lhs, desc.rhs, &desc.output,",
          "content_same": false
        },
        {
          "line": 258,
          "old_api": "has_gemm",
          "new_api": "std::move(profile_result)",
          "old_text": "best_algorithm.has_gemm()",
          "new_text": "std::move(profile_result)",
          "old_line_content": "    if (best_algorithm.has_gemm()) {",
          "new_line_content": "      return std::move(profile_result);",
          "content_same": false
        },
        {
          "line": 284,
          "old_api": "AllocateBytes",
          "new_api": "GetModule",
          "old_text": "redzone_allocator_->AllocateBytes(\n                              ShapeUtil::ByteSizeOf(output_shape))",
          "new_text": "gemm->GetModule()->mutable_config()",
          "old_line_content": "                          redzone_allocator_->AllocateBytes(",
          "new_line_content": "    auto& hlo_module_config = gemm->GetModule()->mutable_config();",
          "content_same": false
        },
        {
          "line": 285,
          "old_api": "ShapeUtil::ByteSizeOf(output_shape)",
          "new_api": "GetOutputShape",
          "old_text": "ShapeUtil::ByteSizeOf(output_shape)",
          "new_text": "GetOutputShape(gemm)",
          "old_line_content": "                              ShapeUtil::ByteSizeOf(output_shape)));",
          "new_line_content": "    const auto& output_shape = GetOutputShape(gemm);",
          "content_same": false
        },
        {
          "line": 290,
          "old_api": "size",
          "new_api": "AllocateBytes",
          "old_text": "algorithms.size()",
          "new_text": "redzone_allocator_->AllocateBytes(\n                              ShapeUtil::ByteSizeOf(output_shape))",
          "old_line_content": "    results.reserve(algorithms.size());",
          "new_line_content": "                          redzone_allocator_->AllocateBytes(",
          "content_same": false
        },
        {
          "line": 296,
          "old_api": "should_reinit_output_buffer",
          "new_api": "size",
          "old_text": "autotune_config_.should_reinit_output_buffer()",
          "new_text": "algorithms.size()",
          "old_line_content": "      if (autotune_config_.should_reinit_output_buffer() && beta != 0) {",
          "new_line_content": "    results.reserve(algorithms.size());",
          "content_same": false
        },
        {
          "line": 304,
          "old_api": "algorithm",
          "new_api": "element_type",
          "old_text": "profile_result.algorithm()",
          "new_text": "output_shape.element_type()",
          "old_line_content": "      result.mutable_gemm()->set_algorithm(profile_result.algorithm());",
          "new_line_content": "        InitializeBuffer(stream_, output_shape.element_type(), &rng_state,",
          "content_same": false
        },
        {
          "line": 312,
          "old_api": "elapsed_time_in_ms",
          "new_api": "is_valid",
          "old_text": "profile_result.elapsed_time_in_ms()",
          "new_text": "profile_result.is_valid()",
          "old_line_content": "              << profile_result.elapsed_time_in_ms() << \"ms\";",
          "new_line_content": "      if (!profile_result.is_valid()) {  // Unsupported algorithm.",
          "content_same": false
        },
        {
          "line": 317,
          "old_api": "should_check_correctness",
          "new_api": "algorithm",
          "old_text": "autotune_config_.should_check_correctness()",
          "new_text": "profile_result.algorithm()",
          "old_line_content": "      if (!autotune_config_.should_check_correctness()) {",
          "new_line_content": "      VLOG(2) << \"gemm algorithm \" << profile_result.algorithm() << \" took \"",
          "content_same": false
        },
        {
          "line": 334,
          "old_api": "size",
          "new_api": "LOG",
          "old_text": "stream_->Memcpy(&reference_buffer, output_buffer_,\n                                           output_buffer_.size())",
          "new_text": "LOG(ERROR)",
          "old_line_content": "        TF_RETURN_IF_ERROR(stream_->Memcpy(&reference_buffer, output_buffer_,",
          "new_line_content": "        LOG(ERROR) << \"Detected out-of-bounds write in gemm buffer\";",
          "content_same": false
        },
        {
          "line": 335,
          "old_api": "size",
          "new_api": "should_crash_on_check_failure",
          "old_text": "output_buffer_.size()",
          "new_text": "autotune_config_.should_crash_on_check_failure()",
          "old_line_content": "                                           output_buffer_.size()));",
          "new_line_content": "        CHECK(!autotune_config_.should_crash_on_check_failure());",
          "content_same": false
        },
        {
          "line": 364,
          "old_api": "Internal",
          "new_api": "size",
          "old_text": "Internal(\"unknown best algorithm\")",
          "new_text": "results.size()",
          "old_line_content": "      return Internal(\"unknown best algorithm\");",
          "new_line_content": "      for (size_t i = 0; i < results.size(); ++i) {",
          "content_same": false
        },
        {
          "line": 366,
          "old_api": "LOG",
          "new_api": "mutable_gemm",
          "old_text": "LOG(WARNING)",
          "new_text": "best->mutable_gemm()->set_algorithm(i)",
          "old_line_content": "    LOG(WARNING) << \"Failed to find best cuBLAS algorithm, GEMM performance \"",
          "new_line_content": "          best->mutable_gemm()->set_algorithm(i);",
          "content_same": false
        },
        {
          "line": 388,
          "old_api": "VLOG",
          "new_api": "value",
          "old_text": "VLOG(3)",
          "new_text": "gemm->backend_config<GpuBackendConfig>().value()",
          "old_line_content": "    VLOG(3) << \"Skip degenerate gemm instruction auto tuning\";",
          "new_line_content": "      gemm->backend_config<GpuBackendConfig>().value();",
          "content_same": false
        },
        {
          "line": 392,
          "old_api": "GetModelStr",
          "new_api": "alpha_real",
          "old_text": "config.GetModelStr()",
          "new_text": "backend_config.alpha_real()",
          "old_line_content": "  AutotuneCacheKey key(config.GetModelStr(), *gemm);",
          "new_line_content": "  if (backend_config.alpha_real() == 0.0 &&",
          "content_same": false
        },
        {
          "line": 411,
          "old_api": "GetGpuComputeCapability",
          "new_api": "IsAtLeast",
          "old_text": "config.GetGpuComputeCapability()",
          "new_text": "cc.IsAtLeast(\n                                      se::CudaComputeCapability::AMPERE)",
          "old_line_content": "                 config.GetGpuComputeCapability());",
          "new_line_content": "                                  return !cc.IsAtLeast(",
          "content_same": false
        },
        {
          "line": 452,
          "old_api": "MakeNonfusionComputations",
          "new_api": "VLOG",
          "old_text": "module->MakeNonfusionComputations(execution_threads)",
          "new_text": "VLOG(2)",
          "old_line_content": "       module->MakeNonfusionComputations(execution_threads)) {",
          "new_line_content": "    VLOG(2) << \"GEMM auto-tuning disabled, GemmAlgorithmPicker returning early\";",
          "content_same": false
        }
      ],
      "additions": [
        {
          "line": 385,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "gemm->ToString()",
          "old_line_content": "  // Degenerate gemms replaced with memzero operation, no need to auto tune it.",
          "new_line_content": "  VLOG(3) << \"Loading the autotune result of GemmThunk \" << gemm->ToString();",
          "content_same": false
        },
        {
          "line": 261,
          "old_api": null,
          "new_api": "TF_ASSIGN_OR_RETURN",
          "old_text": null,
          "new_text": "TF_ASSIGN_OR_RETURN(best_algorithm,\n                        GetBestAlgorithm<se::blas::AlgorithmType>(\n                            gemm, algorithms, gemm_config.beta, tuned_func))",
          "old_line_content": "    }",
          "new_line_content": "    TF_ASSIGN_OR_RETURN(best_algorithm,",
          "content_same": false
        },
        {
          "line": 262,
          "old_api": null,
          "new_api": "GetBestAlgorithm<se::blas::AlgorithmType>(\n                            gemm, algorithms, gemm_config.beta, tuned_func)",
          "old_text": null,
          "new_text": "GetBestAlgorithm<se::blas::AlgorithmType>(\n                            gemm, algorithms, gemm_config.beta, tuned_func)",
          "old_line_content": "    return best_algorithm;",
          "new_line_content": "                        GetBestAlgorithm<se::blas::AlgorithmType>(",
          "content_same": false
        },
        {
          "line": 389,
          "old_api": null,
          "new_api": "mutable_gemm_backend_config",
          "old_text": null,
          "new_text": "gpu_config.mutable_gemm_backend_config()",
          "old_line_content": "    return false;",
          "new_line_content": "  GemmBackendConfig& backend_config = *gpu_config.mutable_gemm_backend_config();",
          "content_same": false
        },
        {
          "line": 264,
          "old_api": null,
          "new_api": "has_gemm",
          "old_text": null,
          "new_text": "best_algorithm.has_gemm()",
          "old_line_content": "",
          "new_line_content": "    if (best_algorithm.has_gemm()) {",
          "content_same": false
        },
        {
          "line": 265,
          "old_api": null,
          "new_api": "gemm",
          "old_text": null,
          "new_text": "best_algorithm.gemm().algorithm()",
          "old_line_content": "  // Returns the index (into `algorithms`) of the fastest algorithm.",
          "new_line_content": "      int alg_idx = best_algorithm.gemm().algorithm();",
          "content_same": false
        },
        {
          "line": 266,
          "old_api": null,
          "new_api": "mutable_gemm",
          "old_text": null,
          "new_text": "best_algorithm.mutable_gemm()->set_algorithm(algorithms[alg_idx])",
          "old_line_content": "  template <typename AlgoT, typename TunedFunc>",
          "new_line_content": "      best_algorithm.mutable_gemm()->set_algorithm(algorithms[alg_idx]);",
          "content_same": false
        },
        {
          "line": 393,
          "old_api": null,
          "new_api": "beta",
          "old_text": null,
          "new_text": "backend_config.beta()",
          "old_line_content": "  GemmAutotuner autotuner(config);",
          "new_line_content": "      backend_config.alpha_imag() == 0.0 && backend_config.beta() == 0.0) {",
          "content_same": false
        },
        {
          "line": 394,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(3)",
          "old_line_content": "  TF_ASSIGN_OR_RETURN(AutotuneResult algorithm,",
          "new_line_content": "    VLOG(3) << \"Skip degenerate gemm instruction auto tuning\";",
          "content_same": false
        },
        {
          "line": 398,
          "old_api": null,
          "new_api": "GetModelStr",
          "old_text": null,
          "new_text": "config.GetModelStr()",
          "old_line_content": "  auto old_algorithm = backend_config.selected_algorithm();",
          "new_line_content": "  AutotuneCacheKey key(config.GetModelStr(), *gemm);",
          "content_same": false
        },
        {
          "line": 406,
          "old_api": null,
          "new_api": "IsCublasLtMatmulF8",
          "old_text": null,
          "new_text": "IsCublasLtMatmulF8(*gemm)",
          "old_line_content": "                                      se::CudaComputeCapability::AMPERE);",
          "new_line_content": "      IsCublasLtMatmulF8(*gemm) ||",
          "content_same": false
        },
        {
          "line": 407,
          "old_api": null,
          "new_api": "IsAtLeast",
          "old_text": null,
          "new_text": "std::visit(VariantVisitor{[](const se::CudaComputeCapability& cc) {\n                                  // We only set the 'algorithm' field on\n                                  // non-Ampere architectures, as for Ampere\n                                  // it's ignored in any case.\n                                  return !cc.IsAtLeast(\n                                      se::CudaComputeCapability::AMPERE);\n                                },\n                                [](const se::RocmComputeCapability&) {\n                                  return true;  // TODO: not decided yet\n                                }},\n                 config.GetGpuComputeCapability())",
          "old_line_content": "                                },",
          "new_line_content": "      std::visit(VariantVisitor{[](const se::CudaComputeCapability& cc) {",
          "content_same": false
        },
        {
          "line": 280,
          "old_api": null,
          "new_api": "parent",
          "old_text": null,
          "new_text": "stream_->parent()->SynchronizeAllActivity()",
          "old_line_content": "",
          "new_line_content": "    if (!stream_->parent()->SynchronizeAllActivity()) {",
          "content_same": false
        },
        {
          "line": 281,
          "old_api": null,
          "new_api": "Internal",
          "old_text": null,
          "new_text": "Internal(\"Failed to synchronize GPU for autotuning.\")",
          "old_line_content": "    se::DeviceMemoryBase reference_buffer;",
          "new_line_content": "      return Internal(\"Failed to synchronize GPU for autotuning.\");",
          "content_same": false
        },
        {
          "line": 288,
          "old_api": null,
          "new_api": "should_check_correctness",
          "old_text": null,
          "new_text": "autotune_config_.should_check_correctness()",
          "old_line_content": "    BufferComparator comparator(output_shape, hlo_module_config);",
          "new_line_content": "    if (autotune_config_.should_check_correctness()) {",
          "content_same": false
        },
        {
          "line": 289,
          "old_api": null,
          "new_api": "AllocateBytes",
          "old_text": null,
          "new_text": "TF_ASSIGN_OR_RETURN(reference_buffer,\n                          redzone_allocator_->AllocateBytes(\n                              ShapeUtil::ByteSizeOf(output_shape)))",
          "old_line_content": "    std::vector<AutotuneResult> results;",
          "new_line_content": "      TF_ASSIGN_OR_RETURN(reference_buffer,",
          "content_same": false
        },
        {
          "line": 417,
          "old_api": null,
          "new_api": "GetGpuComputeCapability",
          "old_text": null,
          "new_text": "config.GetGpuComputeCapability()",
          "old_line_content": "      // NOTE: runtime autotuning is no longer available => set to default",
          "new_line_content": "                 config.GetGpuComputeCapability());",
          "content_same": false
        },
        {
          "line": 291,
          "old_api": null,
          "new_api": "ShapeUtil::ByteSizeOf(output_shape)",
          "old_text": null,
          "new_text": "ShapeUtil::ByteSizeOf(output_shape)",
          "old_line_content": "    std::optional<int64_t> reference_algorithm;",
          "new_line_content": "                              ShapeUtil::ByteSizeOf(output_shape)));",
          "content_same": false
        },
        {
          "line": 420,
          "old_api": null,
          "new_api": "has_gemm",
          "old_text": null,
          "new_text": "algorithm.has_gemm()",
          "old_line_content": "  }",
          "new_line_content": "    if (algorithm.has_gemm()) {",
          "content_same": false
        },
        {
          "line": 421,
          "old_api": null,
          "new_api": "gemm",
          "old_text": null,
          "new_text": "algorithm.gemm().algorithm()",
          "old_line_content": "  TF_RETURN_IF_ERROR(gemm->set_backend_config(gpu_config));",
          "new_line_content": "      backend_config.set_selected_algorithm(algorithm.gemm().algorithm());",
          "content_same": false
        },
        {
          "line": 302,
          "old_api": null,
          "new_api": "should_reinit_output_buffer",
          "old_text": null,
          "new_text": "autotune_config_.should_reinit_output_buffer()",
          "old_line_content": "",
          "new_line_content": "      if (autotune_config_.should_reinit_output_buffer() && beta != 0) {",
          "content_same": false
        },
        {
          "line": 434,
          "old_api": null,
          "new_api": "instructions",
          "old_text": null,
          "new_text": "computation->instructions()",
          "old_line_content": "  return changed;",
          "new_line_content": "  for (HloInstruction* instr : computation->instructions()) {",
          "content_same": false
        },
        {
          "line": 435,
          "old_api": null,
          "new_api": "IsCublasLtMatmulF8",
          "old_text": null,
          "new_text": "IsCublasLtMatmulF8(*instr)",
          "old_line_content": "}",
          "new_line_content": "    if (IsCublasGemm(*instr) || IsCublasLtMatmulF8(*instr)) {",
          "content_same": false
        },
        {
          "line": 309,
          "old_api": null,
          "new_api": "emplace_back",
          "old_text": null,
          "new_text": "results.emplace_back()",
          "old_line_content": "      }",
          "new_line_content": "      AutotuneResult& result = results.emplace_back();",
          "content_same": false
        },
        {
          "line": 310,
          "old_api": null,
          "new_api": "algorithm",
          "old_text": null,
          "new_text": "profile_result.algorithm()",
          "old_line_content": "",
          "new_line_content": "      result.mutable_gemm()->set_algorithm(profile_result.algorithm());",
          "content_same": false
        },
        {
          "line": 313,
          "old_api": null,
          "new_api": "mutable_failure",
          "old_text": null,
          "new_text": "result.mutable_failure()->set_kind(AutotuneResult::DISQUALIFIED)",
          "old_line_content": "",
          "new_line_content": "        result.mutable_failure()->set_kind(AutotuneResult::DISQUALIFIED);",
          "content_same": false
        },
        {
          "line": 318,
          "old_api": null,
          "new_api": "elapsed_time_in_ms",
          "old_text": null,
          "new_text": "profile_result.elapsed_time_in_ms()",
          "old_line_content": "        continue;",
          "new_line_content": "              << profile_result.elapsed_time_in_ms() << \"ms\";",
          "content_same": false
        },
        {
          "line": 320,
          "old_api": null,
          "new_api": "elapsed_time_in_ms",
          "old_text": null,
          "new_text": "tsl::proto_utils::ToDurationProto(\n          absl::Milliseconds(profile_result.elapsed_time_in_ms()))",
          "old_line_content": "      TF_ASSIGN_OR_RETURN(",
          "new_line_content": "      *result.mutable_run_time() = tsl::proto_utils::ToDurationProto(",
          "content_same": false
        },
        {
          "line": 321,
          "old_api": null,
          "new_api": "elapsed_time_in_ms",
          "old_text": null,
          "new_text": "profile_result.elapsed_time_in_ms()",
          "old_line_content": "          se::RedzoneAllocator::RedzoneCheckStatus rz_check_status,",
          "new_line_content": "          absl::Milliseconds(profile_result.elapsed_time_in_ms()));",
          "content_same": false
        },
        {
          "line": 448,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "XLA_SCOPED_LOGGING_TIMER(\n      absl::StrCat(\"GemmAlgorithmPicker for \", module->name()))",
          "old_line_content": "  }",
          "new_line_content": "  XLA_SCOPED_LOGGING_TIMER(",
          "content_same": false
        },
        {
          "line": 323,
          "old_api": null,
          "new_api": "should_check_correctness",
          "old_text": null,
          "new_text": "autotune_config_.should_check_correctness()",
          "old_line_content": "",
          "new_line_content": "      if (!autotune_config_.should_check_correctness()) {",
          "content_same": false
        },
        {
          "line": 196,
          "old_api": null,
          "new_api": "ExecuteOnStream",
          "old_text": null,
          "new_text": "plan->ExecuteOnStream(\n          stream_, lhs_buffer_, rhs_buffer_, output_buffer_, output_buffer_,\n          bias_buffer, aux_buffer, a_scale_buffer, b_scale_buffer,\n          c_scale_buffer, d_scale_buffer, d_amax_buffer, algorithm,\n          scratch_allocator, &profile_result)",
          "old_line_content": "    };",
          "new_line_content": "      TF_RETURN_IF_ERROR(plan->ExecuteOnStream(",
          "content_same": false
        },
        {
          "line": 449,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "module->name()",
          "old_line_content": "",
          "new_line_content": "      absl::StrCat(\"GemmAlgorithmPicker for \", module->name()));",
          "content_same": false
        },
        {
          "line": 451,
          "old_api": null,
          "new_api": "debug_options",
          "old_text": null,
          "new_text": "module->config().debug_options().xla_gpu_autotune_level()",
          "old_line_content": "  for (HloComputation* computation :",
          "new_line_content": "  if (module->config().debug_options().xla_gpu_autotune_level() == 0) {",
          "content_same": false
        },
        {
          "line": 201,
          "old_api": null,
          "new_api": "std::move(profile_result)",
          "old_text": null,
          "new_text": "std::move(profile_result)",
          "old_line_content": "",
          "new_line_content": "      return std::move(profile_result);",
          "content_same": false
        },
        {
          "line": 330,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "rz_check_status.ok()",
          "old_line_content": "        continue;",
          "new_line_content": "      if (!rz_check_status.ok()) {",
          "content_same": false
        },
        {
          "line": 331,
          "old_api": null,
          "new_api": "mutable_failure",
          "old_text": null,
          "new_text": "result.mutable_failure()->set_kind(AutotuneResult::REDZONE_MODIFIED)",
          "old_line_content": "      }",
          "new_line_content": "        result.mutable_failure()->set_kind(AutotuneResult::REDZONE_MODIFIED);",
          "content_same": false
        },
        {
          "line": 204,
          "old_api": null,
          "new_api": "GetBestAlgorithm<BlasLt::MatmulAlgorithm>(\n        gemm, algorithms, gemm_config.beta, tuned_func)",
          "old_text": null,
          "new_text": "GetBestAlgorithm<BlasLt::MatmulAlgorithm>(\n        gemm, algorithms, gemm_config.beta, tuned_func)",
          "old_line_content": "    int64_t workspace_size =",
          "new_line_content": "    return GetBestAlgorithm<BlasLt::MatmulAlgorithm>(",
          "content_same": false
        },
        {
          "line": 332,
          "old_api": null,
          "new_api": "mutable_failure",
          "old_text": null,
          "new_text": "result.mutable_failure()->mutable_msg()",
          "old_line_content": "",
          "new_line_content": "        *result.mutable_failure()->mutable_msg() =",
          "content_same": false
        },
        {
          "line": 333,
          "old_api": null,
          "new_api": "RedzoneFailureMsg",
          "old_text": null,
          "new_text": "rz_check_status.RedzoneFailureMsg()",
          "old_line_content": "      if (!reference_algorithm) {",
          "new_line_content": "            rz_check_status.RedzoneFailureMsg();",
          "content_same": false
        },
        {
          "line": 458,
          "old_api": null,
          "new_api": "MakeNonfusionComputations",
          "old_text": null,
          "new_text": "module->MakeNonfusionComputations(execution_threads)",
          "old_line_content": "",
          "new_line_content": "       module->MakeNonfusionComputations(execution_threads)) {",
          "content_same": false
        },
        {
          "line": 211,
          "old_api": null,
          "new_api": "IsAtLeastHopper",
          "old_text": null,
          "new_text": "std::visit(VariantVisitor{[](const se::CudaComputeCapability& cc) {\n                                    return cc.IsAtLeastHopper()\n                                               ? GemmConfig::kHopperWorkspace\n                                               : GemmConfig::kDefaultWorkspace;\n                                  },\n                                  [](const se::RocmComputeCapability&) {\n                                    return GemmConfig::kDefaultWorkspace;\n                                  }},\n                   autotune_config_.GetGpuComputeCapability())",
          "old_line_content": "                                    return GemmConfig::kDefaultWorkspace;",
          "new_line_content": "        std::visit(VariantVisitor{[](const se::CudaComputeCapability& cc) {",
          "content_same": false
        },
        {
          "line": 212,
          "old_api": null,
          "new_api": "IsAtLeastHopper",
          "old_text": null,
          "new_text": "cc.IsAtLeastHopper()",
          "old_line_content": "                                  }},",
          "new_line_content": "                                    return cc.IsAtLeastHopper()",
          "content_same": false
        },
        {
          "line": 340,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "stream_->Memcpy(&reference_buffer, output_buffer_,\n                                           output_buffer_.size())",
          "old_line_content": "            bool outputs_match,",
          "new_line_content": "        TF_RETURN_IF_ERROR(stream_->Memcpy(&reference_buffer, output_buffer_,",
          "content_same": false
        },
        {
          "line": 341,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "output_buffer_.size()",
          "old_line_content": "            comparator.CompareEqual(stream_, /*current=*/output_buffer_,",
          "new_line_content": "                                           output_buffer_.size()));",
          "content_same": false
        },
        {
          "line": 342,
          "old_api": null,
          "new_api": "algorithm",
          "old_text": null,
          "new_text": "profile_result.algorithm()",
          "old_line_content": "                                    /*expected=*/reference_buffer));",
          "new_line_content": "        reference_algorithm = profile_result.algorithm();",
          "content_same": false
        },
        {
          "line": 219,
          "old_api": null,
          "new_api": "GetGpuComputeCapability",
          "old_text": null,
          "new_text": "autotune_config_.GetGpuComputeCapability()",
          "old_line_content": "    std::vector<se::blas::AlgorithmType> algorithms;",
          "new_line_content": "                   autotune_config_.GetGpuComputeCapability());",
          "content_same": false
        },
        {
          "line": 350,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(ERROR)",
          "old_line_content": "              *reference_algorithm);",
          "new_line_content": "          LOG(ERROR) << \"Results mismatch between different GEMM algorithms. \"",
          "content_same": false
        },
        {
          "line": 352,
          "old_api": null,
          "new_api": "should_crash_on_check_failure",
          "old_text": null,
          "new_text": "autotune_config_.should_crash_on_check_failure()",
          "old_line_content": "      }",
          "new_line_content": "          CHECK(!autotune_config_.should_crash_on_check_failure());",
          "content_same": false
        },
        {
          "line": 354,
          "old_api": null,
          "new_api": "mutable_failure",
          "old_text": null,
          "new_text": "result.mutable_failure()->set_kind(AutotuneResult::WRONG_RESULT)",
          "old_line_content": "",
          "new_line_content": "          result.mutable_failure()->set_kind(AutotuneResult::WRONG_RESULT);",
          "content_same": false
        },
        {
          "line": 355,
          "old_api": null,
          "new_api": "mutable_failure",
          "old_text": null,
          "new_text": "result.mutable_failure()->mutable_reference_gemm()->set_algorithm(\n              *reference_algorithm)",
          "old_line_content": "    absl::StatusOr<AutotuneResult> best =",
          "new_line_content": "          result.mutable_failure()->mutable_reference_gemm()->set_algorithm(",
          "content_same": false
        },
        {
          "line": 230,
          "old_api": null,
          "new_api": "parent",
          "old_text": null,
          "new_text": "stream_->parent()->AsBlas()",
          "old_line_content": "                                &algorithms);",
          "new_line_content": "    auto blas = stream_->parent()->AsBlas();",
          "content_same": false
        },
        {
          "line": 232,
          "old_api": null,
          "new_api": "absl::InternalError(\"No BLAS support for stream\")",
          "old_text": null,
          "new_text": "absl::InternalError(\"No BLAS support for stream\")",
          "old_line_content": "    AutotuneResult best_algorithm;",
          "new_line_content": "      return absl::InternalError(\"No BLAS support for stream\");",
          "content_same": false
        },
        {
          "line": 362,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "gemm->ToString()",
          "old_line_content": "        }",
          "new_line_content": "        PickBestResult(results, gemm->ToString(), hlo_module_config);",
          "content_same": false
        },
        {
          "line": 363,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "best.ok()",
          "old_line_content": "      }",
          "new_line_content": "    if (best.ok()) {",
          "content_same": false
        },
        {
          "line": 365,
          "old_api": null,
          "new_api": "gemm",
          "old_text": null,
          "new_text": "results[i].gemm().algorithm()",
          "old_line_content": "    }",
          "new_line_content": "        if (best->gemm().algorithm() == results[i].gemm().algorithm()) {",
          "content_same": false
        },
        {
          "line": 240,
          "old_api": null,
          "new_api": "empty",
          "old_text": null,
          "new_text": "algorithms.empty()",
          "old_line_content": "",
          "new_line_content": "    if (algorithms.empty()) {  // nothing to autotune",
          "content_same": false
        },
        {
          "line": 241,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(WARNING)",
          "old_line_content": "    auto tuned_func = [&](const se::blas::AlgorithmType& algorithm)",
          "new_line_content": "      LOG(WARNING) << \"No solutions found: skipping autotuning for ROCM..\";",
          "content_same": false
        },
        {
          "line": 242,
          "old_api": null,
          "new_api": "mutable_gemm",
          "old_text": null,
          "new_text": "best_algorithm.mutable_gemm()->set_algorithm(se::blas::kDefaultAlgorithm)",
          "old_line_content": "        -> absl::StatusOr<se::blas::ProfileResult> {",
          "new_line_content": "      best_algorithm.mutable_gemm()->set_algorithm(se::blas::kDefaultAlgorithm);",
          "content_same": false
        },
        {
          "line": 370,
          "old_api": null,
          "new_api": "Internal",
          "old_text": null,
          "new_text": "Internal(\"unknown best algorithm\")",
          "old_line_content": "  }  // GetBestAlgorithm",
          "new_line_content": "      return Internal(\"unknown best algorithm\");",
          "content_same": false
        },
        {
          "line": 372,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(WARNING)",
          "old_line_content": "",
          "new_line_content": "    LOG(WARNING) << \"Failed to find best cuBLAS algorithm, GEMM performance \"",
          "content_same": false
        },
        {
          "line": 374,
          "old_api": null,
          "new_api": "status",
          "old_text": null,
          "new_text": "best.status()",
          "old_line_content": "",
          "new_line_content": "                 << best.status();",
          "content_same": false
        },
        {
          "line": 254,
          "old_api": null,
          "new_api": "RunGemm",
          "old_text": null,
          "new_text": "RunGemm(gemm_config, lhs_buffer_, rhs_buffer_,\n                                 output_buffer_, workspace_buffer,\n                                 deterministic_ops_, stream_, algorithm,\n                                 &profile_result)",
          "old_line_content": "",
          "new_line_content": "      TF_RETURN_IF_ERROR(RunGemm(gemm_config, lhs_buffer_, rhs_buffer_,",
          "content_same": false
        }
      ],
      "deletions": [
        {
          "line": 256,
          "old_api": "GetBestAlgorithm<se::blas::AlgorithmType>(\n                            gemm, algorithms, gemm_config.beta, tuned_func)",
          "new_api": null,
          "old_text": "GetBestAlgorithm<se::blas::AlgorithmType>(\n                            gemm, algorithms, gemm_config.beta, tuned_func)",
          "new_text": null,
          "old_line_content": "                        GetBestAlgorithm<se::blas::AlgorithmType>(",
          "new_line_content": "                                 deterministic_ops_, stream_, algorithm,",
          "content_same": false
        },
        {
          "line": 386,
          "old_api": "alpha_real",
          "new_api": null,
          "old_text": "backend_config.alpha_real()",
          "new_text": null,
          "old_line_content": "  if (backend_config.alpha_real() == 0.0 &&",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 259,
          "old_api": "gemm",
          "new_api": null,
          "old_text": "best_algorithm.gemm().algorithm()",
          "new_text": null,
          "old_line_content": "      int alg_idx = best_algorithm.gemm().algorithm();",
          "new_line_content": "    };",
          "content_same": false
        },
        {
          "line": 260,
          "old_api": "mutable_gemm",
          "new_api": null,
          "old_text": "best_algorithm.mutable_gemm()->set_algorithm(algorithms[alg_idx])",
          "new_text": null,
          "old_line_content": "      best_algorithm.mutable_gemm()->set_algorithm(algorithms[alg_idx]);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 387,
          "old_api": "beta",
          "new_api": null,
          "old_text": "backend_config.beta()",
          "new_text": null,
          "old_line_content": "      backend_config.alpha_imag() == 0.0 && backend_config.beta() == 0.0) {",
          "new_line_content": "  GpuBackendConfig gpu_config =",
          "content_same": false
        },
        {
          "line": 383,
          "old_api": "mutable_gemm_backend_config",
          "new_api": null,
          "old_text": "gpu_config.mutable_gemm_backend_config()",
          "new_text": null,
          "old_line_content": "  GemmBackendConfig& backend_config = *gpu_config.mutable_gemm_backend_config();",
          "new_line_content": "absl::StatusOr<bool> RunOnInstruction(HloInstruction* gemm,",
          "content_same": false
        },
        {
          "line": 399,
          "old_api": "IsAtLeast",
          "new_api": null,
          "old_text": "update_algorithm =\n      IsCublasLtMatmulF8(*gemm) ||\n      std::visit(VariantVisitor{[](const se::CudaComputeCapability& cc) {\n                                  // We only set the 'algorithm' field on\n                                  // non-Ampere architectures, as for Ampere\n                                  // it's ignored in any case.\n                                  return !cc.IsAtLeast(\n                                      se::CudaComputeCapability::AMPERE);\n                                },\n                                [](const se::RocmComputeCapability&) {\n                                  return true;  // TODO: not decided yet\n                                }},\n                 config.GetGpuComputeCapability());\n\n  if (update_algorithm) {\n    if (algorithm.has_gemm()) {\n      backend_config.set_selected_algorithm(algorithm.gemm().algorithm());\n    } else {\n      // NOTE: runtime autotuning is no longer available => set to default\n      backend_config.set_selected_algorithm(se::blas::kDefaultAlgorithm);\n    }\n  }\n  TF_RETURN_IF_ERROR(gemm->set_backend_config(gpu_config)",
          "new_text": null,
          "old_line_content": "  bool update_algorithm =",
          "new_line_content": "  GemmAutotuner autotuner(config);",
          "content_same": false
        },
        {
          "line": 400,
          "old_api": "IsCublasLtMatmulF8",
          "new_api": null,
          "old_text": "IsCublasLtMatmulF8(*gemm)",
          "new_text": null,
          "old_line_content": "      IsCublasLtMatmulF8(*gemm) ||",
          "new_line_content": "  TF_ASSIGN_OR_RETURN(AutotuneResult algorithm,",
          "content_same": false
        },
        {
          "line": 401,
          "old_api": "IsAtLeast",
          "new_api": null,
          "old_text": "std::visit(VariantVisitor{[](const se::CudaComputeCapability& cc) {\n                                  // We only set the 'algorithm' field on\n                                  // non-Ampere architectures, as for Ampere\n                                  // it's ignored in any case.\n                                  return !cc.IsAtLeast(\n                                      se::CudaComputeCapability::AMPERE);\n                                },\n                                [](const se::RocmComputeCapability&) {\n                                  return true;  // TODO: not decided yet\n                                }},\n                 config.GetGpuComputeCapability())",
          "new_text": null,
          "old_line_content": "      std::visit(VariantVisitor{[](const se::CudaComputeCapability& cc) {",
          "new_line_content": "                      AutotunerUtil::Autotune(",
          "content_same": false
        },
        {
          "line": 274,
          "old_api": "parent",
          "new_api": null,
          "old_text": "stream_->parent()->SynchronizeAllActivity()",
          "new_text": null,
          "old_line_content": "    if (!stream_->parent()->SynchronizeAllActivity()) {",
          "new_line_content": "      const HloInstruction* gemm, absl::Span<const AlgoT> algorithms,",
          "content_same": false
        },
        {
          "line": 275,
          "old_api": "Internal",
          "new_api": null,
          "old_text": "Internal(\"Failed to synchronize GPU for autotuning.\")",
          "new_text": null,
          "old_line_content": "      return Internal(\"Failed to synchronize GPU for autotuning.\");",
          "new_line_content": "      double beta, TunedFunc&& run_benchmark) {",
          "content_same": false
        },
        {
          "line": 278,
          "old_api": "GetModule",
          "new_api": null,
          "old_text": "gemm->GetModule()->mutable_config()",
          "new_text": null,
          "old_line_content": "    auto& hlo_module_config = gemm->GetModule()->mutable_config();",
          "new_line_content": "                  \"Tuned function has incorrect prototype!\");",
          "content_same": false
        },
        {
          "line": 279,
          "old_api": "GetOutputShape",
          "new_api": null,
          "old_text": "GetOutputShape(gemm)",
          "new_text": null,
          "old_line_content": "    const auto& output_shape = GetOutputShape(gemm);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 282,
          "old_api": "should_check_correctness",
          "new_api": null,
          "old_text": "autotune_config_.should_check_correctness()",
          "new_text": null,
          "old_line_content": "    if (autotune_config_.should_check_correctness()) {",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 283,
          "old_api": "AllocateBytes",
          "new_api": null,
          "old_text": "TF_ASSIGN_OR_RETURN(reference_buffer,\n                          redzone_allocator_->AllocateBytes(\n                              ShapeUtil::ByteSizeOf(output_shape)))",
          "new_text": null,
          "old_line_content": "      TF_ASSIGN_OR_RETURN(reference_buffer,",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 414,
          "old_api": "has_gemm",
          "new_api": null,
          "old_text": "algorithm.has_gemm()",
          "new_text": null,
          "old_line_content": "    if (algorithm.has_gemm()) {",
          "new_line_content": "                                [](const se::RocmComputeCapability&) {",
          "content_same": false
        },
        {
          "line": 415,
          "old_api": "gemm",
          "new_api": null,
          "old_text": "algorithm.gemm().algorithm()",
          "new_text": null,
          "old_line_content": "      backend_config.set_selected_algorithm(algorithm.gemm().algorithm());",
          "new_line_content": "                                  return true;  // TODO: not decided yet",
          "content_same": false
        },
        {
          "line": 298,
          "old_api": "element_type",
          "new_api": null,
          "old_text": "output_shape.element_type()",
          "new_text": null,
          "old_line_content": "        InitializeBuffer(stream_, output_shape.element_type(), &rng_state,",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 428,
          "old_api": "instructions",
          "new_api": null,
          "old_text": "computation->instructions()",
          "new_text": null,
          "old_line_content": "  for (HloInstruction* instr : computation->instructions()) {",
          "new_line_content": "  return old_algorithm != backend_config.selected_algorithm();",
          "content_same": false
        },
        {
          "line": 429,
          "old_api": "IsCublasLtMatmulF8",
          "new_api": null,
          "old_text": "IsCublasLtMatmulF8(*instr)",
          "new_text": null,
          "old_line_content": "    if (IsCublasGemm(*instr) || IsCublasLtMatmulF8(*instr)) {",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 303,
          "old_api": "emplace_back",
          "new_api": null,
          "old_text": "results.emplace_back()",
          "new_text": null,
          "old_line_content": "      AutotuneResult& result = results.emplace_back();",
          "new_line_content": "        int64_t rng_state = 0;",
          "content_same": false
        },
        {
          "line": 306,
          "old_api": "is_valid",
          "new_api": null,
          "old_text": "profile_result.is_valid()",
          "new_text": null,
          "old_line_content": "      if (!profile_result.is_valid()) {  // Unsupported algorithm.",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 307,
          "old_api": "mutable_failure",
          "new_api": null,
          "old_text": "result.mutable_failure()->set_kind(AutotuneResult::DISQUALIFIED)",
          "new_text": null,
          "old_line_content": "        result.mutable_failure()->set_kind(AutotuneResult::DISQUALIFIED);",
          "new_line_content": "      TF_ASSIGN_OR_RETURN(auto profile_result, run_benchmark(algorithm));",
          "content_same": false
        },
        {
          "line": 311,
          "old_api": "algorithm",
          "new_api": null,
          "old_text": "profile_result.algorithm()",
          "new_text": null,
          "old_line_content": "      VLOG(2) << \"gemm algorithm \" << profile_result.algorithm() << \" took \"",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 314,
          "old_api": "elapsed_time_in_ms",
          "new_api": null,
          "old_text": "tsl::proto_utils::ToDurationProto(\n          absl::Milliseconds(profile_result.elapsed_time_in_ms()))",
          "new_text": null,
          "old_line_content": "      *result.mutable_run_time() = tsl::proto_utils::ToDurationProto(",
          "new_line_content": "        continue;",
          "content_same": false
        },
        {
          "line": 315,
          "old_api": "elapsed_time_in_ms",
          "new_api": null,
          "old_text": "profile_result.elapsed_time_in_ms()",
          "new_text": null,
          "old_line_content": "          absl::Milliseconds(profile_result.elapsed_time_in_ms()));",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 442,
          "old_api": "name",
          "new_api": null,
          "old_text": "XLA_SCOPED_LOGGING_TIMER(\n      absl::StrCat(\"GemmAlgorithmPicker for \", module->name()))",
          "new_text": null,
          "old_line_content": "  XLA_SCOPED_LOGGING_TIMER(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 443,
          "old_api": "name",
          "new_api": null,
          "old_text": "module->name()",
          "new_text": null,
          "old_line_content": "      absl::StrCat(\"GemmAlgorithmPicker for \", module->name()));",
          "new_line_content": "}  // namespace",
          "content_same": false
        },
        {
          "line": 445,
          "old_api": "debug_options",
          "new_api": null,
          "old_text": "module->config().debug_options().xla_gpu_autotune_level()",
          "new_text": null,
          "old_line_content": "  if (module->config().debug_options().xla_gpu_autotune_level() == 0) {",
          "new_line_content": "absl::StatusOr<bool> GemmAlgorithmPicker::Run(",
          "content_same": false
        },
        {
          "line": 446,
          "old_api": "VLOG",
          "new_api": null,
          "old_text": "VLOG(2)",
          "new_text": null,
          "old_line_content": "    VLOG(2) << \"GEMM auto-tuning disabled, GemmAlgorithmPicker returning early\";",
          "new_line_content": "    HloModule* module,",
          "content_same": false
        },
        {
          "line": 195,
          "old_api": "std::move(profile_result)",
          "new_api": null,
          "old_text": "std::move(profile_result)",
          "new_text": null,
          "old_line_content": "      return std::move(profile_result);",
          "new_line_content": "      se::blas::ProfileResult profile_result;",
          "content_same": false
        },
        {
          "line": 324,
          "old_api": "ok",
          "new_api": null,
          "old_text": "rz_check_status.ok()",
          "new_text": null,
          "old_line_content": "      if (!rz_check_status.ok()) {",
          "new_line_content": "        continue;",
          "content_same": false
        },
        {
          "line": 325,
          "old_api": "mutable_failure",
          "new_api": null,
          "old_text": "result.mutable_failure()->set_kind(AutotuneResult::REDZONE_MODIFIED)",
          "new_text": null,
          "old_line_content": "        result.mutable_failure()->set_kind(AutotuneResult::REDZONE_MODIFIED);",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 198,
          "old_api": "GetBestAlgorithm<BlasLt::MatmulAlgorithm>(\n        gemm, algorithms, gemm_config.beta, tuned_func)",
          "new_api": null,
          "old_text": "GetBestAlgorithm<BlasLt::MatmulAlgorithm>(\n        gemm, algorithms, gemm_config.beta, tuned_func)",
          "new_text": null,
          "old_line_content": "    return GetBestAlgorithm<BlasLt::MatmulAlgorithm>(",
          "new_line_content": "          bias_buffer, aux_buffer, a_scale_buffer, b_scale_buffer,",
          "content_same": false
        },
        {
          "line": 326,
          "old_api": "mutable_failure",
          "new_api": null,
          "old_text": "result.mutable_failure()->mutable_msg()",
          "new_text": null,
          "old_line_content": "        *result.mutable_failure()->mutable_msg() =",
          "new_line_content": "      TF_ASSIGN_OR_RETURN(",
          "content_same": false
        },
        {
          "line": 327,
          "old_api": "RedzoneFailureMsg",
          "new_api": null,
          "old_text": "rz_check_status.RedzoneFailureMsg()",
          "new_text": null,
          "old_line_content": "            rz_check_status.RedzoneFailureMsg();",
          "new_line_content": "          se::RedzoneAllocator::RedzoneCheckStatus rz_check_status,",
          "content_same": false
        },
        {
          "line": 328,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(ERROR)",
          "new_text": null,
          "old_line_content": "        LOG(ERROR) << \"Detected out-of-bounds write in gemm buffer\";",
          "new_line_content": "          redzone_allocator_->CheckRedzones());",
          "content_same": false
        },
        {
          "line": 329,
          "old_api": "should_crash_on_check_failure",
          "new_api": null,
          "old_text": "autotune_config_.should_crash_on_check_failure()",
          "new_text": null,
          "old_line_content": "        CHECK(!autotune_config_.should_crash_on_check_failure());",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 205,
          "old_api": "IsAtLeastHopper",
          "new_api": null,
          "old_text": "std::visit(VariantVisitor{[](const se::CudaComputeCapability& cc) {\n                                    return cc.IsAtLeastHopper()\n                                               ? GemmConfig::kHopperWorkspace\n                                               : GemmConfig::kDefaultWorkspace;\n                                  },\n                                  [](const se::RocmComputeCapability&) {\n                                    return GemmConfig::kDefaultWorkspace;\n                                  }},\n                   autotune_config_.GetGpuComputeCapability())",
          "new_text": null,
          "old_line_content": "        std::visit(VariantVisitor{[](const se::CudaComputeCapability& cc) {",
          "new_line_content": "        gemm, algorithms, gemm_config.beta, tuned_func);",
          "content_same": false
        },
        {
          "line": 206,
          "old_api": "IsAtLeastHopper",
          "new_api": null,
          "old_text": "cc.IsAtLeastHopper()",
          "new_text": null,
          "old_line_content": "                                    return cc.IsAtLeastHopper()",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 336,
          "old_api": "algorithm",
          "new_api": null,
          "old_text": "profile_result.algorithm()",
          "new_text": null,
          "old_line_content": "        reference_algorithm = profile_result.algorithm();",
          "new_line_content": "        continue;",
          "content_same": false
        },
        {
          "line": 213,
          "old_api": "GetGpuComputeCapability",
          "new_api": null,
          "old_text": "autotune_config_.GetGpuComputeCapability()",
          "new_text": null,
          "old_line_content": "                   autotune_config_.GetGpuComputeCapability());",
          "new_line_content": "                                               ? GemmConfig::kHopperWorkspace",
          "content_same": false
        },
        {
          "line": 344,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(ERROR)",
          "new_text": null,
          "old_line_content": "          LOG(ERROR) << \"Results mismatch between different GEMM algorithms. \"",
          "new_line_content": "        // Perform the comparison.",
          "content_same": false
        },
        {
          "line": 346,
          "old_api": "should_crash_on_check_failure",
          "new_api": null,
          "old_text": "autotune_config_.should_crash_on_check_failure()",
          "new_text": null,
          "old_line_content": "          CHECK(!autotune_config_.should_crash_on_check_failure());",
          "new_line_content": "            bool outputs_match,",
          "content_same": false
        },
        {
          "line": 348,
          "old_api": "mutable_failure",
          "new_api": null,
          "old_text": "result.mutable_failure()->set_kind(AutotuneResult::WRONG_RESULT)",
          "new_text": null,
          "old_line_content": "          result.mutable_failure()->set_kind(AutotuneResult::WRONG_RESULT);",
          "new_line_content": "                                    /*expected=*/reference_buffer));",
          "content_same": false
        },
        {
          "line": 349,
          "old_api": "mutable_failure",
          "new_api": null,
          "old_text": "result.mutable_failure()->mutable_reference_gemm()->set_algorithm(\n              *reference_algorithm)",
          "new_text": null,
          "old_line_content": "          result.mutable_failure()->mutable_reference_gemm()->set_algorithm(",
          "new_line_content": "        if (!outputs_match) {",
          "content_same": false
        },
        {
          "line": 224,
          "old_api": "parent",
          "new_api": null,
          "old_text": "stream_->parent()->AsBlas()",
          "new_text": null,
          "old_line_content": "    auto blas = stream_->parent()->AsBlas();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 226,
          "old_api": "absl::InternalError(\"No BLAS support for stream\")",
          "new_api": null,
          "old_text": "absl::InternalError(\"No BLAS support for stream\")",
          "new_text": null,
          "old_line_content": "      return absl::InternalError(\"No BLAS support for stream\");",
          "new_line_content": "    TF_ASSIGN_OR_RETURN(GemmConfig::DescriptorsTuple desc,",
          "content_same": false
        },
        {
          "line": 228,
          "old_api": "GetBlasGemmAlgorithms",
          "new_api": null,
          "old_text": "blas->GetBlasGemmAlgorithms(stream_, desc.lhs, desc.rhs, &desc.output,\n                                &gemm_config.alpha, &gemm_config.beta,\n                                &algorithms)",
          "new_text": null,
          "old_line_content": "    blas->GetBlasGemmAlgorithms(stream_, desc.lhs, desc.rhs, &desc.output,",
          "new_line_content": "                            lhs_buffer_, rhs_buffer_, output_buffer_));",
          "content_same": false
        },
        {
          "line": 356,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "gemm->ToString()",
          "new_text": null,
          "old_line_content": "        PickBestResult(results, gemm->ToString(), hlo_module_config);",
          "new_line_content": "              *reference_algorithm);",
          "content_same": false
        },
        {
          "line": 357,
          "old_api": "ok",
          "new_api": null,
          "old_text": "best.ok()",
          "new_text": null,
          "old_line_content": "    if (best.ok()) {",
          "new_line_content": "        }",
          "content_same": false
        },
        {
          "line": 358,
          "old_api": "size",
          "new_api": null,
          "old_text": "results.size()",
          "new_text": null,
          "old_line_content": "      for (size_t i = 0; i < results.size(); ++i) {",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 359,
          "old_api": "gemm",
          "new_api": null,
          "old_text": "results[i].gemm().algorithm()",
          "new_text": null,
          "old_line_content": "        if (best->gemm().algorithm() == results[i].gemm().algorithm()) {",
          "new_line_content": "    }  // for algorithms",
          "content_same": false
        },
        {
          "line": 360,
          "old_api": "mutable_gemm",
          "new_api": null,
          "old_text": "best->mutable_gemm()->set_algorithm(i)",
          "new_text": null,
          "old_line_content": "          best->mutable_gemm()->set_algorithm(i);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 235,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(WARNING)",
          "new_text": null,
          "old_line_content": "      LOG(WARNING) << \"No solutions found: skipping autotuning for ROCM..\";",
          "new_line_content": "                                &gemm_config.alpha, &gemm_config.beta,",
          "content_same": false
        },
        {
          "line": 236,
          "old_api": "mutable_gemm",
          "new_api": null,
          "old_text": "best_algorithm.mutable_gemm()->set_algorithm(se::blas::kDefaultAlgorithm)",
          "new_text": null,
          "old_line_content": "      best_algorithm.mutable_gemm()->set_algorithm(se::blas::kDefaultAlgorithm);",
          "new_line_content": "                                &algorithms);",
          "content_same": false
        },
        {
          "line": 368,
          "old_api": "status",
          "new_api": null,
          "old_text": "best.status()",
          "new_text": null,
          "old_line_content": "                 << best.status();",
          "new_line_content": "        }",
          "content_same": false
        },
        {
          "line": 248,
          "old_api": "RunGemm",
          "new_api": null,
          "old_text": "RunGemm(gemm_config, lhs_buffer_, rhs_buffer_,\n                                 output_buffer_, workspace_buffer,\n                                 deterministic_ops_, stream_, algorithm,\n                                 &profile_result)",
          "new_text": null,
          "old_line_content": "      TF_RETURN_IF_ERROR(RunGemm(gemm_config, lhs_buffer_, rhs_buffer_,",
          "new_line_content": "        -> absl::StatusOr<se::blas::ProfileResult> {",
          "content_same": false
        },
        {
          "line": 379,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "gemm->ToString()",
          "new_text": null,
          "old_line_content": "  VLOG(3) << \"Loading the autotune result of GemmThunk \" << gemm->ToString();",
          "new_line_content": "#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
          "content_same": false
        },
        {
          "line": 252,
          "old_api": "std::move(profile_result)",
          "new_api": null,
          "old_text": "std::move(profile_result)",
          "new_text": null,
          "old_line_content": "      return std::move(profile_result);",
          "new_line_content": "      // non-null ProfileResult, DoGemmWithAlgorithm should always return true,",
          "content_same": false
        },
        {
          "line": 382,
          "old_api": "value",
          "new_api": null,
          "old_text": "gemm->backend_config<GpuBackendConfig>().value()",
          "new_text": null,
          "old_line_content": "      gemm->backend_config<GpuBackendConfig>().value();",
          "new_line_content": "// only.",
          "content_same": false
        },
        {
          "line": 255,
          "old_api": "TF_ASSIGN_OR_RETURN",
          "new_api": null,
          "old_text": "TF_ASSIGN_OR_RETURN(best_algorithm,\n                        GetBestAlgorithm<se::blas::AlgorithmType>(\n                            gemm, algorithms, gemm_config.beta, tuned_func))",
          "new_text": null,
          "old_line_content": "    TF_ASSIGN_OR_RETURN(best_algorithm,",
          "new_line_content": "                                 output_buffer_, workspace_buffer,",
          "content_same": false
        }
      ]
    },
    "api_summary": {
      "total_replacements": 17,
      "total_additions": 63,
      "total_deletions": 62,
      "total_api_changes": 142
    },
    "non_api_changes": {
      "has_non_api_changes": true,
      "evidence": {
        "total_diff_lines": 6,
        "api_related_lines": 142,
        "non_api_lines": 6,
        "non_api_line_numbers": [
          192,
          193,
          194,
          189,
          190,
          191
        ]
      }
    },
    "api_calls_before": 172,
    "api_calls_after": 174,
    "diff_info": {
      "added_lines": 6,
      "removed_lines": 0,
      "total_diff_lines": 18
    }
  }
}