{
  "status": "completed",
  "commit_dir": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/67d1f027b19a0dfb581cd19e08d062648eff40c7",
  "file_info": {
    "before_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/67d1f027b19a0dfb581cd19e08d062648eff40c7/before.cc",
    "after_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/67d1f027b19a0dfb581cd19e08d062648eff40c7/after.cc",
    "diff_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/67d1f027b19a0dfb581cd19e08d062648eff40c7/diff.txt"
  },
  "semgrep_analysis": {
    "is_api_change": false,
    "api_changes": {
      "replacements": [
        {
          "line": 426,
          "old_api": "alignof",
          "new_api": "shape",
          "old_text": "alignof(TfLiteIntArray)",
          "new_text": "const_cast<TfLiteIntArray*>(\n      reinterpret_cast<const TfLiteIntArray*>(flatbuffer_tensor.shape()))",
          "old_line_content": "          alignof(TfLiteIntArray)));",
          "new_line_content": "  result->dims = const_cast<TfLiteIntArray*>(",
          "content_same": false
        },
        {
          "line": 432,
          "old_api": "quantization",
          "new_api": "scale",
          "old_text": "flatbuffer_tensor.quantization()",
          "new_text": "src_quantization->scale()->size()",
          "old_line_content": "  const auto* src_quantization = flatbuffer_tensor.quantization();",
          "new_line_content": "      (src_quantization->scale()->size() > 0) &&",
          "content_same": false
        },
        {
          "line": 433,
          "old_api": "scale",
          "new_api": "zero_point",
          "old_text": "src_quantization->scale()",
          "new_text": "src_quantization->zero_point()",
          "old_line_content": "  if (src_quantization && src_quantization->scale() &&",
          "new_line_content": "      src_quantization->zero_point() &&",
          "content_same": false
        },
        {
          "line": 434,
          "old_api": "scale",
          "new_api": "zero_point",
          "old_text": "src_quantization->scale()->size()",
          "new_text": "src_quantization->zero_point()->size()",
          "old_line_content": "      (src_quantization->scale()->size() > 0) &&",
          "new_line_content": "      (src_quantization->zero_point()->size() > 0)) {",
          "content_same": false
        },
        {
          "line": 435,
          "old_api": "zero_point",
          "new_api": "scale",
          "old_text": "src_quantization->zero_point()",
          "new_text": "src_quantization->scale()->Get(0)",
          "old_line_content": "      src_quantization->zero_point() &&",
          "new_line_content": "    result->params.scale = src_quantization->scale()->Get(0);",
          "content_same": false
        },
        {
          "line": 440,
          "old_api": "reinterpret_cast<char*>(&result->params.zero_point)",
          "new_api": "zero_point",
          "old_text": "reinterpret_cast<char*>(&result->params.zero_point)",
          "new_text": "src_quantization->zero_point()->Data()",
          "old_line_content": "      *(reinterpret_cast<char*>(&result->params.zero_point) + b) =",
          "new_line_content": "                src_quantization->zero_point()->Data()) +",
          "content_same": false
        },
        {
          "line": 448,
          "old_api": "scale",
          "new_api": "AllocateFromTail",
          "old_text": "src_quantization->scale()->size()",
          "new_text": "reinterpret_cast<TfLiteAffineQuantization*>(\n            memory_allocator_.AllocateFromTail(\n                sizeof(TfLiteAffineQuantization),\n                alignof(TfLiteAffineQuantization)))",
          "old_line_content": "    int channels = src_quantization->scale()->size();",
          "new_line_content": "        reinterpret_cast<TfLiteAffineQuantization*>(",
          "content_same": false
        },
        {
          "line": 451,
          "old_api": "AllocateFromTail",
          "new_api": "alignof",
          "old_text": "memory_allocator_.AllocateFromTail(\n                sizeof(TfLiteAffineQuantization),\n                alignof(TfLiteAffineQuantization))",
          "new_text": "alignof(TfLiteAffineQuantization)",
          "old_line_content": "            memory_allocator_.AllocateFromTail(",
          "new_line_content": "                alignof(TfLiteAffineQuantization)));",
          "content_same": false
        },
        {
          "line": 453,
          "old_api": "alignof",
          "new_api": "AllocateFromTail",
          "old_text": "alignof(TfLiteAffineQuantization)",
          "new_text": "memory_allocator_.AllocateFromTail(\n            TfLiteIntArrayGetSizeInBytes(channels), alignof(TfLiteIntArray))",
          "old_line_content": "                alignof(TfLiteAffineQuantization)));",
          "new_line_content": "        reinterpret_cast<TfLiteIntArray*>(memory_allocator_.AllocateFromTail(",
          "content_same": false
        },
        {
          "line": 456,
          "old_api": "alignof",
          "new_api": "AllocateFromTail",
          "old_text": "alignof(TfLiteIntArray)",
          "new_text": "memory_allocator_.AllocateFromTail(\n            TfLiteFloatArrayGetSizeInBytes(channels),\n            alignof(TfLiteFloatArray))",
          "old_line_content": "            TfLiteIntArrayGetSizeInBytes(channels), alignof(TfLiteIntArray)));",
          "new_line_content": "        reinterpret_cast<TfLiteFloatArray*>(memory_allocator_.AllocateFromTail(",
          "content_same": false
        },
        {
          "line": 458,
          "old_api": "AllocateFromTail",
          "new_api": "alignof",
          "old_text": "memory_allocator_.AllocateFromTail(\n            TfLiteFloatArrayGetSizeInBytes(channels),\n            alignof(TfLiteFloatArray))",
          "new_text": "alignof(TfLiteFloatArray)",
          "old_line_content": "        reinterpret_cast<TfLiteFloatArray*>(memory_allocator_.AllocateFromTail(",
          "new_line_content": "            alignof(TfLiteFloatArray)));",
          "content_same": false
        }
      ],
      "additions": [
        {
          "line": 449,
          "old_api": null,
          "new_api": "AllocateFromTail",
          "old_text": null,
          "new_text": "memory_allocator_.AllocateFromTail(\n                sizeof(TfLiteAffineQuantization),\n                alignof(TfLiteAffineQuantization))",
          "old_line_content": "    TfLiteAffineQuantization* quantization =",
          "new_line_content": "            memory_allocator_.AllocateFromTail(",
          "content_same": false
        },
        {
          "line": 454,
          "old_api": null,
          "new_api": "alignof",
          "old_text": null,
          "new_text": "alignof(TfLiteIntArray)",
          "old_line_content": "    quantization->zero_point =",
          "new_line_content": "            TfLiteIntArrayGetSizeInBytes(channels), alignof(TfLiteIntArray)));",
          "content_same": false
        },
        {
          "line": 457,
          "old_api": null,
          "new_api": "TfLiteFloatArrayGetSizeInBytes",
          "old_text": null,
          "new_text": "TfLiteFloatArrayGetSizeInBytes(channels)",
          "old_line_content": "    quantization->scale =",
          "new_line_content": "            TfLiteFloatArrayGetSizeInBytes(channels),",
          "content_same": false
        },
        {
          "line": 430,
          "old_api": null,
          "new_api": "quantization",
          "old_text": null,
          "new_text": "flatbuffer_tensor.quantization()",
          "old_line_content": "  }",
          "new_line_content": "  const auto* src_quantization = flatbuffer_tensor.quantization();",
          "content_same": false
        },
        {
          "line": 431,
          "old_api": null,
          "new_api": "scale",
          "old_text": null,
          "new_text": "src_quantization->scale()",
          "old_line_content": "  // Copy the quantization information from the serialized data.",
          "new_line_content": "  if (src_quantization && src_quantization->scale() &&",
          "content_same": false
        },
        {
          "line": 464,
          "old_api": null,
          "new_api": "zero_point",
          "old_text": null,
          "new_text": "src_quantization->zero_point()->Get(i)",
          "old_line_content": "    float* scale_data = quantization->scale->data;",
          "new_line_content": "      zero_point_data[i] = src_quantization->zero_point()->Get(i);",
          "content_same": false
        },
        {
          "line": 465,
          "old_api": null,
          "new_api": "scale",
          "old_text": null,
          "new_text": "src_quantization->scale()->Get(i)",
          "old_line_content": "    for (int i = 0; i < channels; i++) {",
          "new_line_content": "      scale_data[i] = src_quantization->scale()->Get(i);",
          "content_same": false
        },
        {
          "line": 469,
          "old_api": null,
          "new_api": "quantized_dimension",
          "old_text": null,
          "new_text": "src_quantization->quantized_dimension()",
          "old_line_content": "    // TODO(rocky): Need to add a micro_allocator test case that fails when",
          "new_line_content": "    quantization->quantized_dimension = src_quantization->quantized_dimension();",
          "content_same": false
        },
        {
          "line": 438,
          "old_api": null,
          "new_api": "reinterpret_cast<char*>(&result->params.zero_point)",
          "old_text": null,
          "new_text": "reinterpret_cast<char*>(&result->params.zero_point)",
          "old_line_content": "    // This magic handles issues with little-endianness.",
          "new_line_content": "      *(reinterpret_cast<char*>(&result->params.zero_point) + b) =",
          "content_same": false
        },
        {
          "line": 439,
          "old_api": null,
          "new_api": "zero_point",
          "old_text": null,
          "new_text": "reinterpret_cast<const char*>(\n                src_quantization->zero_point()->Data())",
          "old_line_content": "    for (unsigned int b = 0; b < sizeof(int64_t); ++b)",
          "new_line_content": "          *(reinterpret_cast<const char*>(",
          "content_same": false
        },
        {
          "line": 475,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "flatbuffer_tensor.name()->c_str()",
          "old_line_content": "  // Copy the name, if there is one.",
          "new_line_content": "    result->name = flatbuffer_tensor.name()->c_str();",
          "content_same": false
        },
        {
          "line": 474,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "flatbuffer_tensor.name()->c_str()",
          "old_line_content": "  }",
          "new_line_content": "  if (flatbuffer_tensor.name()->c_str() != nullptr) {",
          "content_same": false
        },
        {
          "line": 443,
          "old_api": null,
          "new_api": "flatbuffers::EndianScalar(result->params.zero_point)",
          "old_text": null,
          "new_text": "flatbuffers::EndianScalar(result->params.zero_point)",
          "old_line_content": "            b);",
          "new_line_content": "        flatbuffers::EndianScalar(result->params.zero_point);",
          "content_same": false
        },
        {
          "line": 446,
          "old_api": null,
          "new_api": "scale",
          "old_text": null,
          "new_text": "src_quantization->scale()->size()",
          "old_line_content": "",
          "new_line_content": "    int channels = src_quantization->scale()->size();",
          "content_same": false
        }
      ],
      "deletions": [
        {
          "line": 477,
          "old_api": "name",
          "new_api": null,
          "old_text": "flatbuffer_tensor.name()->c_str()",
          "new_text": null,
          "old_line_content": "    result->name = flatbuffer_tensor.name()->c_str();",
          "new_line_content": "    result->name = \"<No name>\";",
          "content_same": false
        },
        {
          "line": 450,
          "old_api": "AllocateFromTail",
          "new_api": null,
          "old_text": "reinterpret_cast<TfLiteAffineQuantization*>(\n            memory_allocator_.AllocateFromTail(\n                sizeof(TfLiteAffineQuantization),\n                alignof(TfLiteAffineQuantization)))",
          "new_text": null,
          "old_line_content": "        reinterpret_cast<TfLiteAffineQuantization*>(",
          "new_line_content": "                sizeof(TfLiteAffineQuantization),",
          "content_same": false
        },
        {
          "line": 455,
          "old_api": "AllocateFromTail",
          "new_api": null,
          "old_text": "memory_allocator_.AllocateFromTail(\n            TfLiteIntArrayGetSizeInBytes(channels), alignof(TfLiteIntArray))",
          "new_text": null,
          "old_line_content": "        reinterpret_cast<TfLiteIntArray*>(memory_allocator_.AllocateFromTail(",
          "new_line_content": "    quantization->scale =",
          "content_same": false
        },
        {
          "line": 424,
          "old_api": "AllocateFromTail",
          "new_api": null,
          "old_text": "memory_allocator_.AllocateFromTail(\n          TfLiteIntArrayGetSizeInBytes(flatbuffer_tensor.shape()->Length()),\n          alignof(TfLiteIntArray))",
          "new_text": null,
          "old_line_content": "      reinterpret_cast<TfLiteIntArray*>(memory_allocator_.AllocateFromTail(",
          "new_line_content": "  // really want to update the tensor shape, we can always pass in a new",
          "content_same": false
        },
        {
          "line": 425,
          "old_api": "shape",
          "new_api": null,
          "old_text": "flatbuffer_tensor.shape()->Length()",
          "new_text": null,
          "old_line_content": "          TfLiteIntArrayGetSizeInBytes(flatbuffer_tensor.shape()->Length()),",
          "new_line_content": "  // TfLiteIntArray - especially we have to do so if the dimension is changed.",
          "content_same": false
        },
        {
          "line": 459,
          "old_api": "TfLiteFloatArrayGetSizeInBytes",
          "new_api": null,
          "old_text": "TfLiteFloatArrayGetSizeInBytes(channels)",
          "new_text": null,
          "old_line_content": "            TfLiteFloatArrayGetSizeInBytes(channels),",
          "new_line_content": "    quantization->zero_point->size = channels;",
          "content_same": false
        },
        {
          "line": 428,
          "old_api": "shape",
          "new_api": null,
          "old_text": "flatbuffer_tensor.shape()->Length()",
          "new_text": null,
          "old_line_content": "  for (size_t n = 0; n < flatbuffer_tensor.shape()->Length(); ++n) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 429,
          "old_api": "shape",
          "new_api": null,
          "old_text": "flatbuffer_tensor.shape()->Get(n)",
          "new_text": null,
          "old_line_content": "    result->dims->data[n] = flatbuffer_tensor.shape()->Get(n);",
          "new_line_content": "  // Copy the quantization information from the serialized data.",
          "content_same": false
        },
        {
          "line": 460,
          "old_api": "alignof",
          "new_api": null,
          "old_text": "alignof(TfLiteFloatArray)",
          "new_text": null,
          "old_line_content": "            alignof(TfLiteFloatArray)));",
          "new_line_content": "    quantization->scale->size = channels;",
          "content_same": false
        },
        {
          "line": 466,
          "old_api": "zero_point",
          "new_api": null,
          "old_text": "src_quantization->zero_point()->Get(i)",
          "new_text": null,
          "old_line_content": "      zero_point_data[i] = src_quantization->zero_point()->Get(i);",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 467,
          "old_api": "scale",
          "new_api": null,
          "old_text": "src_quantization->scale()->Get(i)",
          "new_text": null,
          "old_line_content": "      scale_data[i] = src_quantization->scale()->Get(i);",
          "new_line_content": "    // TODO(rocky): Need to add a micro_allocator test case that fails when",
          "content_same": false
        },
        {
          "line": 436,
          "old_api": "zero_point",
          "new_api": null,
          "old_text": "src_quantization->zero_point()->size()",
          "new_text": null,
          "old_line_content": "      (src_quantization->zero_point()->size() > 0)) {",
          "new_line_content": "    // This magic handles issues with little-endianness.",
          "content_same": false
        },
        {
          "line": 437,
          "old_api": "scale",
          "new_api": null,
          "old_text": "src_quantization->scale()->Get(0)",
          "new_text": null,
          "old_line_content": "    result->params.scale = src_quantization->scale()->Get(0);",
          "new_line_content": "    for (unsigned int b = 0; b < sizeof(int64_t); ++b)",
          "content_same": false
        },
        {
          "line": 471,
          "old_api": "quantized_dimension",
          "new_api": null,
          "old_text": "src_quantization->quantized_dimension()",
          "new_text": null,
          "old_line_content": "    quantization->quantized_dimension = src_quantization->quantized_dimension();",
          "new_line_content": "    result->quantization = {kTfLiteAffineQuantization, quantization};",
          "content_same": false
        },
        {
          "line": 441,
          "old_api": "zero_point",
          "new_api": null,
          "old_text": "reinterpret_cast<const char*>(\n                src_quantization->zero_point()->Data())",
          "new_text": null,
          "old_line_content": "          *(reinterpret_cast<const char*>(",
          "new_line_content": "            b);",
          "content_same": false
        },
        {
          "line": 442,
          "old_api": "zero_point",
          "new_api": null,
          "old_text": "src_quantization->zero_point()->Data()",
          "new_text": null,
          "old_line_content": "                src_quantization->zero_point()->Data()) +",
          "new_line_content": "    result->params.zero_point =",
          "content_same": false
        },
        {
          "line": 476,
          "old_api": "name",
          "new_api": null,
          "old_text": "flatbuffer_tensor.name()->c_str()",
          "new_text": null,
          "old_line_content": "  if (flatbuffer_tensor.name()->c_str() != nullptr) {",
          "new_line_content": "  } else {",
          "content_same": false
        },
        {
          "line": 445,
          "old_api": "flatbuffers::EndianScalar(result->params.zero_point)",
          "new_api": null,
          "old_text": "flatbuffers::EndianScalar(result->params.zero_point)",
          "new_text": null,
          "old_line_content": "        flatbuffers::EndianScalar(result->params.zero_point);",
          "new_line_content": "    // Populate per-channel quantization params.",
          "content_same": false
        }
      ]
    },
    "api_summary": {
      "total_replacements": 11,
      "total_additions": 14,
      "total_deletions": 18,
      "total_api_changes": 43
    },
    "non_api_changes": {
      "has_non_api_changes": true,
      "evidence": {
        "total_diff_lines": 10,
        "api_related_lines": 43,
        "non_api_lines": 4,
        "non_api_line_numbers": [
          427,
          421,
          422,
          423
        ]
      }
    },
    "api_calls_before": 163,
    "api_calls_after": 154,
    "diff_info": {
      "added_lines": 8,
      "removed_lines": 10,
      "total_diff_lines": 30
    }
  }
}