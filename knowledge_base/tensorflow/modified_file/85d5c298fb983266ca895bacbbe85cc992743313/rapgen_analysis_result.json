{
  "status": "completed",
  "commit_dir": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/85d5c298fb983266ca895bacbbe85cc992743313",
  "file_info": {
    "before_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/85d5c298fb983266ca895bacbbe85cc992743313/before.cc",
    "after_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/85d5c298fb983266ca895bacbbe85cc992743313/after.cc",
    "diff_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/85d5c298fb983266ca895bacbbe85cc992743313/diff.txt"
  },
  "semgrep_analysis": {
    "is_api_change": false,
    "api_changes": {
      "replacements": [
        {
          "line": 199,
          "old_api": "Ref",
          "new_api": "front",
          "old_text": "context_->Ref()",
          "new_text": "device_mgr_->ListDevices().front()",
          "old_line_content": "  context_->Ref();",
          "new_line_content": "  device_ = device_mgr_->ListDevices().front();",
          "content_same": false
        },
        {
          "line": 201,
          "old_api": "CreateDeviceMgr",
          "new_api": "resource_manager",
          "old_text": "CreateDeviceMgr(device_type_)",
          "new_text": "device_->resource_manager()",
          "old_line_content": "  device_mgr_ = CreateDeviceMgr(device_type_);",
          "new_line_content": "  params_.resource_manager = device_->resource_manager();",
          "content_same": false
        },
        {
          "line": 208,
          "old_api": "resource_manager",
          "new_api": "std::make_unique<tensorflow::ScopedStepContainer>(\n      /*step_id=*/0, cleanup)",
          "old_text": "device_->resource_manager()",
          "new_text": "std::make_unique<tensorflow::ScopedStepContainer>(\n      /*step_id=*/0, cleanup)",
          "old_line_content": "  params_.resource_manager = device_->resource_manager();",
          "new_line_content": "  step_container_ = std::make_unique<tensorflow::ScopedStepContainer>(",
          "content_same": false
        },
        {
          "line": 215,
          "old_api": "std::make_unique<tensorflow::ScopedStepContainer>(\n      /*step_id=*/0, cleanup)",
          "new_api": "ToString",
          "old_text": "std::make_unique<tensorflow::ScopedStepContainer>(\n      /*step_id=*/0, cleanup)",
          "new_text": "status.ToString()",
          "old_line_content": "  step_container_ = std::make_unique<tensorflow::ScopedStepContainer>(",
          "new_line_content": "           << \"failed to create XlaContext resource: \" << status.ToString();",
          "content_same": false
        },
        {
          "line": 217,
          "old_api": "Create",
          "new_api": "get",
          "old_text": "step_container_->Create(\n      device_->resource_manager(),\n      tensorflow::XlaContext::kXlaContextResourceName, context_)",
          "new_text": "step_container_.get()",
          "old_line_content": "  tsl::Status status = step_container_->Create(",
          "new_line_content": "  params_.step_container = step_container_.get();",
          "content_same": false
        },
        {
          "line": 220,
          "old_api": "ok",
          "new_api": "op_->getParentOfType<mlir::ModuleOp>()",
          "old_text": "status.ok()",
          "new_text": "op_->getParentOfType<mlir::ModuleOp>()",
          "old_line_content": "  if (!status.ok()) {",
          "new_line_content": "      op_->getParentOfType<mlir::ModuleOp>());",
          "content_same": false
        },
        {
          "line": 221,
          "old_api": "getLoc",
          "new_api": "ok",
          "old_text": "op_->getLoc()",
          "new_text": "version_or.ok()",
          "old_line_content": "    return emitRemark(op_->getLoc())",
          "new_line_content": "  if (!version_or.ok()) {",
          "content_same": false
        },
        {
          "line": 222,
          "old_api": "ToString",
          "new_api": "status",
          "old_text": "status.ToString()",
          "new_text": "version_or.status().ToString()",
          "old_line_content": "           << \"failed to create XlaContext resource: \" << status.ToString();",
          "new_line_content": "    return emitError(op_->getLoc()) << version_or.status().ToString();",
          "content_same": false
        },
        {
          "line": 226,
          "old_api": "tensorflow::GetTfGraphProducerVersion(\n      op_->getParentOfType<mlir::ModuleOp>())",
          "new_api": "tensorflow::FunctionDefLibrary()",
          "old_text": "tensorflow::GetTfGraphProducerVersion(\n      op_->getParentOfType<mlir::ModuleOp>())",
          "new_text": "tensorflow::FunctionDefLibrary()",
          "old_line_content": "  tsl::StatusOr<int64_t> version_or = tensorflow::GetTfGraphProducerVersion(",
          "new_line_content": "      tensorflow::OpRegistry::Global(), tensorflow::FunctionDefLibrary());",
          "content_same": false
        },
        {
          "line": 227,
          "old_api": "op_->getParentOfType<mlir::ModuleOp>()",
          "new_api": "get",
          "old_text": "op_->getParentOfType<mlir::ModuleOp>()",
          "new_text": "std::make_unique<tensorflow::ProcessFunctionLibraryRuntime>(\n      device_mgr_.get(), tensorflow::Env::Default(), /*config=*/nullptr,\n      version_or.value(), flib_def_.get(), tensorflow::OptimizerOptions())",
          "old_line_content": "      op_->getParentOfType<mlir::ModuleOp>());",
          "new_line_content": "  pflr_ = std::make_unique<tensorflow::ProcessFunctionLibraryRuntime>(",
          "content_same": false
        },
        {
          "line": 228,
          "old_api": "ok",
          "new_api": "tensorflow::Env::Default()",
          "old_text": "version_or.ok()",
          "new_text": "tensorflow::Env::Default()",
          "old_line_content": "  if (!version_or.ok()) {",
          "new_line_content": "      device_mgr_.get(), tensorflow::Env::Default(), /*config=*/nullptr,",
          "content_same": false
        },
        {
          "line": 229,
          "old_api": "status",
          "new_api": "tensorflow::OptimizerOptions()",
          "old_text": "version_or.status().ToString()",
          "new_text": "tensorflow::OptimizerOptions()",
          "old_line_content": "    return emitError(op_->getLoc()) << version_or.status().ToString();",
          "new_line_content": "      version_or.value(), flib_def_.get(), tensorflow::OptimizerOptions());",
          "content_same": false
        },
        {
          "line": 237,
          "old_api": "name",
          "new_api": "ty.dyn_cast<RankedTensorType>()",
          "old_text": "device_->name()",
          "new_text": "ty.dyn_cast<RankedTensorType>()",
          "old_line_content": "  params_.function_library = pflr_->GetFLR(device_->name());",
          "new_line_content": "  auto ranked_ty = ty.dyn_cast<RankedTensorType>();",
          "content_same": false
        },
        {
          "line": 247,
          "old_api": "hasStaticShape",
          "new_api": "isDynamicDim",
          "old_text": "ranked_ty.hasStaticShape()",
          "new_text": "ranked_ty.isDynamicDim(i)",
          "old_line_content": "  if (ranked_ty.hasStaticShape()) return true;",
          "new_line_content": "    if (ranked_ty.isDynamicDim(i) &&",
          "content_same": false
        },
        {
          "line": 282,
          "old_api": "getOperands",
          "new_api": "count",
          "old_text": "op_->getOperands()",
          "new_text": "required_consts.count(idx)",
          "old_line_content": "  for (auto it : llvm::enumerate(op_->getOperands())) {",
          "new_line_content": "    if (required_consts.count(idx) &&",
          "content_same": false
        },
        {
          "line": 284,
          "old_api": "index",
          "new_api": "emitRemark",
          "old_text": "it.index()",
          "new_text": "op_->emitRemark()",
          "old_line_content": "    size_t idx = it.index();",
          "new_line_content": "      return op_->emitRemark()",
          "content_same": false
        },
        {
          "line": 287,
          "old_api": "kind",
          "new_api": "push_back",
          "old_text": "expr.kind()",
          "new_text": "expressions.push_back(expr)",
          "old_line_content": "    tensorflow::XlaExpression::Kind kind = expr.kind();",
          "new_line_content": "    expressions.push_back(expr);",
          "content_same": false
        },
        {
          "line": 289,
          "old_api": "count",
          "new_api": "dtype",
          "old_text": "required_consts.count(idx)",
          "new_text": "expr.dtype()",
          "old_line_content": "    if (required_consts.count(idx) &&",
          "new_line_content": "    if (!tensorflow::DataTypeCanUseMemcpy(expr.dtype())) {",
          "content_same": false
        },
        {
          "line": 296,
          "old_api": "dtype",
          "new_api": "ok",
          "old_text": "expr.dtype()",
          "new_text": "shape_or.ok()",
          "old_line_content": "    if (!tensorflow::DataTypeCanUseMemcpy(expr.dtype())) {",
          "new_line_content": "    if (!shape_or.ok()) {",
          "content_same": false
        },
        {
          "line": 302,
          "old_api": "GetShape",
          "new_api": "dtype",
          "old_text": "expr.GetShape()",
          "new_text": "expr.dtype()",
          "old_line_content": "    auto shape_or = expr.GetShape();",
          "new_line_content": "        device_->GetAllocator(tensorflow::AllocatorAttributes()), expr.dtype(),",
          "content_same": false
        },
        {
          "line": 303,
          "old_api": "ok",
          "new_api": "value",
          "old_text": "shape_or.ok()",
          "new_text": "shape_or.value()",
          "old_line_content": "    if (!shape_or.ok()) {",
          "new_line_content": "        shape_or.value());",
          "content_same": false
        },
        {
          "line": 305,
          "old_api": "HumanString",
          "new_api": "back",
          "old_text": "expr.HumanString()",
          "new_text": "tensors.back()",
          "old_line_content": "             << \"failed to get shape for expression. \" << expr.HumanString();",
          "new_line_content": "    tensorflow::Tensor& tensor = tensors.back();",
          "content_same": false
        },
        {
          "line": 310,
          "old_api": "value",
          "new_api": "success",
          "old_text": "shape_or.value()",
          "new_text": "success()",
          "old_line_content": "        shape_or.value());",
          "new_line_content": "  return success();",
          "content_same": false
        },
        {
          "line": 314,
          "old_api": "emplace_back",
          "new_api": "getOperandTypes",
          "old_text": "inputs.emplace_back(&tensor)",
          "new_text": "op_->getOperandTypes()",
          "old_line_content": "    inputs.emplace_back(&tensor);",
          "new_line_content": "  for (Type ty : op_->getOperandTypes()) {",
          "content_same": false
        },
        {
          "line": 317,
          "old_api": "success",
          "new_api": "IsBounded",
          "old_text": "success()",
          "new_text": "IsBounded(ranked_ty)",
          "old_line_content": "  return success();",
          "new_line_content": "    if (!IsBounded(ranked_ty)) {",
          "content_same": false
        },
        {
          "line": 324,
          "old_api": "IsBounded",
          "new_api": "emitRemark",
          "old_text": "IsBounded(ranked_ty)",
          "new_text": "op_->emitRemark()",
          "old_line_content": "    if (!IsBounded(ranked_ty)) {",
          "new_line_content": "    return op_->emitRemark() << \"ops with symbol references are not supported\";",
          "content_same": false
        },
        {
          "line": 330,
          "old_api": "HasSymbolRefAttr",
          "new_api": "ok",
          "old_text": "HasSymbolRefAttr(op_)",
          "new_text": "nodedef_or.ok()",
          "old_line_content": "  if (HasSymbolRefAttr(op_)) {",
          "new_line_content": "  if (!nodedef_or.ok()) {",
          "content_same": false
        },
        {
          "line": 335,
          "old_api": "GetUniqueName",
          "new_api": "failure",
          "old_text": "name_mapper_.GetUniqueName(op_)",
          "new_text": "failure()",
          "old_line_content": "      op_, name_mapper_.GetUniqueName(op_),",
          "new_line_content": "  if (failed(PrepareParams())) return failure();",
          "content_same": false
        },
        {
          "line": 338,
          "old_api": "emitRemark",
          "new_api": "value",
          "old_text": "op_->emitRemark()",
          "new_text": "tensorflow::NodeProperties::CreateFromNodeDef(\n      *nodedef_or.value(),\n      params_.function_library->GetFunctionLibraryDefinition(), &props)",
          "old_line_content": "    return op_->emitRemark() << \"failed to convert op to NodeDef: \"",
          "new_line_content": "  tsl::Status status = tensorflow::NodeProperties::CreateFromNodeDef(",
          "content_same": false
        },
        {
          "line": 339,
          "old_api": "status",
          "new_api": "value",
          "old_text": "nodedef_or.status().ToString()",
          "new_text": "nodedef_or.value()",
          "old_line_content": "                             << nodedef_or.status().ToString();",
          "new_line_content": "      *nodedef_or.value(),",
          "content_same": false
        },
        {
          "line": 342,
          "old_api": "failure",
          "new_api": "emitRemark",
          "old_text": "failure()",
          "new_text": "op_->emitRemark()",
          "old_line_content": "  if (failed(PrepareParams())) return failure();",
          "new_line_content": "    return op_->emitRemark()",
          "content_same": false
        },
        {
          "line": 346,
          "old_api": "value",
          "new_api": "CreateKernel",
          "old_text": "nodedef_or.value()",
          "new_text": "params_.function_library->CreateKernel(props, &op_kernel_raw)",
          "old_line_content": "      *nodedef_or.value(),",
          "new_line_content": "  status = params_.function_library->CreateKernel(props, &op_kernel_raw);",
          "content_same": false
        },
        {
          "line": 347,
          "old_api": "GetFunctionLibraryDefinition",
          "new_api": "ok",
          "old_text": "params_.function_library->GetFunctionLibraryDefinition()",
          "new_text": "status.ok()",
          "old_line_content": "      params_.function_library->GetFunctionLibraryDefinition(), &props);",
          "new_line_content": "  if (!status.ok()) {",
          "content_same": false
        },
        {
          "line": 348,
          "old_api": "ok",
          "new_api": "emitRemark",
          "old_text": "status.ok()",
          "new_text": "op_->emitRemark()",
          "old_line_content": "  if (!status.ok()) {",
          "new_line_content": "    return op_->emitRemark()",
          "content_same": false
        },
        {
          "line": 349,
          "old_api": "emitRemark",
          "new_api": "ToString",
          "old_text": "op_->emitRemark()",
          "new_text": "status.ToString()",
          "old_line_content": "    return op_->emitRemark()",
          "new_line_content": "           << \"failed to create tf2xla kernel: \" << status.ToString();",
          "content_same": false
        },
        {
          "line": 355,
          "old_api": "emitRemark",
          "new_api": "tensorflow::XlaOpRegistry::CompileTimeConstantInputs(\n      *op_kernel, &required_constants)",
          "old_text": "op_->emitRemark()",
          "new_text": "tensorflow::XlaOpRegistry::CompileTimeConstantInputs(\n      *op_kernel, &required_constants)",
          "old_line_content": "    return op_->emitRemark()",
          "new_line_content": "  status = tensorflow::XlaOpRegistry::CompileTimeConstantInputs(",
          "content_same": false
        },
        {
          "line": 359,
          "old_api": "absl::WrapUnique(op_kernel_raw)",
          "new_api": "ToString",
          "old_text": "absl::WrapUnique(op_kernel_raw)",
          "new_text": "status.ToString()",
          "old_line_content": "  auto op_kernel = absl::WrapUnique(op_kernel_raw);",
          "new_line_content": "           << \"failed to compute required constants: \" << status.ToString();",
          "content_same": false
        },
        {
          "line": 381,
          "old_api": "getNumOperands",
          "new_api": "get",
          "old_text": "op_->getNumOperands()",
          "new_text": "op_kernel.get()",
          "old_line_content": "  inputs.reserve(op_->getNumOperands());",
          "new_line_content": "  params_.op_kernel = op_kernel.get();",
          "content_same": false
        },
        {
          "line": 383,
          "old_api": "failed",
          "new_api": "getNumResults",
          "old_text": "failed(\n          PrepareKernelInputs(required_consts, expressions, tensors, inputs))",
          "new_text": "op_->getNumResults()",
          "old_line_content": "  if (failed(",
          "new_line_content": "      op_->getNumResults());",
          "content_same": false
        },
        {
          "line": 384,
          "old_api": "PrepareKernelInputs",
          "new_api": "data",
          "old_text": "PrepareKernelInputs(required_consts, expressions, tensors, inputs)",
          "new_text": "output_attr.data()",
          "old_line_content": "          PrepareKernelInputs(required_consts, expressions, tensors, inputs)))",
          "new_line_content": "  params_.output_attr_array = output_attr.data();",
          "content_same": false
        },
        {
          "line": 390,
          "old_api": "getNumResults",
          "new_api": "Compute",
          "old_text": "op_->getNumResults()",
          "new_text": "device_->Compute(params_.op_kernel, &op_context)",
          "old_line_content": "      op_->getNumResults());",
          "new_line_content": "  device_->Compute(params_.op_kernel, &op_context);",
          "content_same": false
        },
        {
          "line": 393,
          "old_api": "setInsertionPoint",
          "new_api": "GetCurrentStatus",
          "old_text": "hlo_builder_.setInsertionPoint(op_)",
          "new_text": "hlo_builder_.GetCurrentStatus()",
          "old_line_content": "  hlo_builder_.setInsertionPoint(op_);",
          "new_line_content": "  status.Update(hlo_builder_.GetCurrentStatus());",
          "content_same": false
        },
        {
          "line": 394,
          "old_api": "getLoc",
          "new_api": "ok",
          "old_text": "op_->getLoc()",
          "new_text": "status.ok()",
          "old_line_content": "  hlo_builder_.SetLocation(op_->getLoc());",
          "new_line_content": "  if (!status.ok()) {",
          "content_same": false
        },
        {
          "line": 396,
          "old_api": "getNumResults",
          "new_api": "ToString",
          "old_text": "op_->getNumResults()",
          "new_text": "status.ToString()",
          "old_line_content": "  tensorflow::OpKernelContext op_context(&params_, op_->getNumResults());",
          "new_line_content": "           << \"compilation to HLO failed: \" << status.ToString();",
          "content_same": false
        },
        {
          "line": 399,
          "old_api": "status",
          "new_api": "failure",
          "old_text": "op_context.status()",
          "new_text": "failure()",
          "old_line_content": "  status = op_context.status();",
          "new_line_content": "  if (failed(VerifyOpResults(op_context))) return failure();",
          "content_same": false
        },
        {
          "line": 406,
          "old_api": "failure",
          "new_api": "emitRemark",
          "old_text": "failure()",
          "new_text": "op_->emitRemark()",
          "old_line_content": "  if (failed(VerifyOpResults(op_context))) return failure();",
          "new_line_content": "      return op_->emitRemark()",
          "content_same": false
        },
        {
          "line": 413,
          "old_api": "emitRemark",
          "new_api": "failed",
          "old_text": "op_->emitRemark()",
          "new_text": "failed(\n          GetKernelOutputs(op_context, translated_function, output_values))",
          "old_line_content": "      return op_->emitRemark()",
          "new_line_content": "  if (failed(",
          "content_same": false
        },
        {
          "line": 414,
          "old_api": "status",
          "new_api": "GetKernelOutputs",
          "old_text": "translated_function_or_status.status().ToString()",
          "new_text": "GetKernelOutputs(op_context, translated_function, output_values)",
          "old_line_content": "             << translated_function_or_status.status().ToString();",
          "new_line_content": "          GetKernelOutputs(op_context, translated_function, output_values))) {",
          "content_same": false
        },
        {
          "line": 439,
          "old_api": "set_name",
          "new_api": "mutable_proto",
          "old_text": "sub_computation.set_name(renamed_computation)",
          "new_text": "computation.mutable_proto()->set_entry_computation_name(\n      new_entry_computation_name)",
          "old_line_content": "    sub_computation.set_name(renamed_computation);",
          "new_line_content": "  computation.mutable_proto()->set_entry_computation_name(",
          "content_same": false
        },
        {
          "line": 441,
          "old_api": "id",
          "new_api": "mutable_proto",
          "old_text": "sub_computation.id()",
          "new_text": "computation.mutable_proto()->set_name(new_entry_computation_name)",
          "old_line_content": "    if (sub_computation.id() == entry_computation) {",
          "new_line_content": "  computation.mutable_proto()->set_name(new_entry_computation_name);",
          "content_same": false
        },
        {
          "line": 448,
          "old_api": "mutable_proto",
          "new_api": "tsl::errors::InvalidArgument(\n        \"Cannot compile with HloImporter because it isn't supported\")",
          "old_text": "computation.mutable_proto()->set_name(new_entry_computation_name)",
          "new_text": "tsl::errors::InvalidArgument(\n        \"Cannot compile with HloImporter because it isn't supported\")",
          "old_line_content": "  computation.mutable_proto()->set_name(new_entry_computation_name);",
          "new_line_content": "    return tsl::errors::InvalidArgument(",
          "content_same": false
        },
        {
          "line": 455,
          "old_api": "tsl::errors::InvalidArgument(\n        \"Cannot compile with HloImporter because it isn't supported\")",
          "new_api": "getNumResults",
          "old_text": "tsl::errors::InvalidArgument(\n        \"Cannot compile with HloImporter because it isn't supported\")",
          "new_text": "op_->getNumResults()",
          "old_line_content": "    return tsl::errors::InvalidArgument(",
          "new_line_content": "  for (int i = 0, e = op_->getNumResults(); i < e; i++) {",
          "content_same": false
        },
        {
          "line": 463,
          "old_api": "mutable_output",
          "new_api": "xla::Tuple(&xla_builder_, return_values)",
          "old_text": "op_context.mutable_output(i)",
          "new_text": "xla::Tuple(&xla_builder_, return_values)",
          "old_line_content": "    tensorflow::Tensor* output = op_context.mutable_output(i);",
          "new_line_content": "  xla::XlaOp root_value = xla::Tuple(&xla_builder_, return_values);",
          "content_same": false
        },
        {
          "line": 470,
          "old_api": "xla::Tuple(&xla_builder_, return_values)",
          "new_api": "ImportXlaComputation",
          "old_text": "xla::Tuple(&xla_builder_, return_values)",
          "new_text": "ImportXlaComputation(computation)",
          "old_line_content": "  xla::XlaOp root_value = xla::Tuple(&xla_builder_, return_values);",
          "new_line_content": "  return ImportXlaComputation(computation);",
          "content_same": false
        },
        {
          "line": 475,
          "old_api": "CreateUniqueComputationNames",
          "new_api": "getNumResults",
          "old_text": "CreateUniqueComputationNames(computation)",
          "new_text": "op_->getNumResults()",
          "old_line_content": "  TF_RETURN_IF_ERROR(CreateUniqueComputationNames(computation));",
          "new_line_content": "  for (int i = 0, e = op_->getNumResults(); i < e; i++) {",
          "content_same": false
        },
        {
          "line": 482,
          "old_api": "getNumResults",
          "new_api": "absl::StrCat(\n          \"expects XlaExpression of kind kXlaOp or kConstant in compiled \"\n          \"output index \",\n          i)",
          "old_text": "op_->getNumResults()",
          "new_text": "absl::StrCat(\n          \"expects XlaExpression of kind kXlaOp or kConstant in compiled \"\n          \"output index \",\n          i)",
          "old_line_content": "  for (int i = 0, e = op_->getNumResults(); i < e; i++) {",
          "new_line_content": "      return op_->emitRemark(absl::StrCat(",
          "content_same": false
        },
        {
          "line": 488,
          "old_api": "kind",
          "new_api": "success",
          "old_text": "expr->kind()",
          "new_text": "success()",
          "old_line_content": "        expr->kind() != tensorflow::XlaExpression::Kind::kConstant) {",
          "new_line_content": "  return success();",
          "content_same": false
        },
        {
          "line": 508,
          "old_api": "back",
          "new_api": "emitRemark",
          "old_text": "llvm::dyn_cast<func::ReturnOp>(\n      translated_function.back().getTerminator())",
          "new_text": "op_->emitRemark()",
          "old_line_content": "  func::ReturnOp xla_return_op = llvm::dyn_cast<func::ReturnOp>(",
          "new_line_content": "    return op_->emitRemark() << \"Return value has more than one op, returning\";",
          "content_same": false
        },
        {
          "line": 511,
          "old_api": "emitRemark",
          "new_api": "getDefiningOp",
          "old_text": "op_->emitRemark()",
          "new_text": "llvm::dyn_cast<mhlo::TupleOp>(\n      xla_return_op->getOperand(0).getDefiningOp())",
          "old_line_content": "    return op_->emitRemark() << \"Could not find return value\";",
          "new_line_content": "  mhlo::TupleOp tuple_result = llvm::dyn_cast<mhlo::TupleOp>(",
          "content_same": false
        },
        {
          "line": 514,
          "old_api": "getNumOperands",
          "new_api": "emitRemark",
          "old_text": "xla_return_op->getNumOperands()",
          "new_text": "op_->emitRemark()",
          "old_line_content": "  if (xla_return_op->getNumOperands() != 1) {",
          "new_line_content": "    return op_->emitRemark()",
          "content_same": false
        },
        {
          "line": 518,
          "old_api": "getDefiningOp",
          "new_api": "getNumResults",
          "old_text": "llvm::dyn_cast<mhlo::TupleOp>(\n      xla_return_op->getOperand(0).getDefiningOp())",
          "new_text": "op_->getNumResults()",
          "old_line_content": "  mhlo::TupleOp tuple_result = llvm::dyn_cast<mhlo::TupleOp>(",
          "new_line_content": "  if (tuple_result->getNumOperands() != op_->getNumResults()) {",
          "content_same": false
        },
        {
          "line": 519,
          "old_api": "getDefiningOp",
          "new_api": "emitRemark",
          "old_text": "xla_return_op->getOperand(0).getDefiningOp()",
          "new_text": "op_->emitRemark()",
          "old_line_content": "      xla_return_op->getOperand(0).getDefiningOp());",
          "new_line_content": "    return op_->emitRemark() << \"Translated function tuple has different \"",
          "content_same": false
        },
        {
          "line": 531,
          "old_api": "getOperandTypes",
          "new_api": "getOperands",
          "old_text": "op_->getOperandTypes()",
          "new_text": "tuple_result->getOperands()",
          "old_line_content": "      FunctionType::get(op_->getContext(), op_->getOperandTypes(),",
          "new_line_content": "  xla_return_op->setOperands(tuple_result->getOperands());",
          "content_same": false
        },
        {
          "line": 539,
          "old_api": "getOperation",
          "new_api": "getFunctionType",
          "old_text": "tuple_result.getOperation()->erase()",
          "new_text": "translated_function.getFunctionType().getNumResults()",
          "old_line_content": "  tuple_result.getOperation()->erase();",
          "new_line_content": "  if (translated_function.getFunctionType().getNumResults() !=",
          "content_same": false
        },
        {
          "line": 541,
          "old_api": "success",
          "new_api": "emitRemark",
          "old_text": "success()",
          "new_text": "op_->emitRemark()",
          "old_line_content": "  return success();",
          "new_line_content": "    return op_->emitRemark() << \"Translated function doesn't have the same \"",
          "content_same": false
        },
        {
          "line": 546,
          "old_api": "getFunctionType",
          "new_api": "getLoc",
          "old_text": "translated_function.getFunctionType().getNumResults()",
          "new_text": "builder.create<mlir::func::CallOp>(\n      op_->getLoc(), translated_function, op_->getOperands())",
          "old_line_content": "  if (translated_function.getFunctionType().getNumResults() !=",
          "new_line_content": "  auto call_op = builder.create<mlir::func::CallOp>(",
          "content_same": false
        },
        {
          "line": 547,
          "old_api": "getNumResults",
          "new_api": "getOperands",
          "old_text": "op_->getNumResults()",
          "new_text": "op_->getOperands()",
          "old_line_content": "      op_->getNumResults()) {",
          "new_line_content": "      op_->getLoc(), translated_function, op_->getOperands());",
          "content_same": false
        },
        {
          "line": 553,
          "old_api": "getLoc",
          "new_api": "success",
          "old_text": "builder.create<mlir::func::CallOp>(\n      op_->getLoc(), translated_function, op_->getOperands())",
          "new_text": "success()",
          "old_line_content": "  auto call_op = builder.create<mlir::func::CallOp>(",
          "new_line_content": "  return success();",
          "content_same": false
        },
        {
          "line": 569,
          "old_api": "failure",
          "new_api": "tensorflow::XlaExpression::CastExpressionFromTensor(*output)",
          "old_text": "failure()",
          "new_text": "tensorflow::XlaExpression::CastExpressionFromTensor(*output)",
          "old_line_content": "    if (failed(UnpackTupleResults(translated_function))) return failure();",
          "new_line_content": "        tensorflow::XlaExpression::CastExpressionFromTensor(*output);",
          "content_same": false
        },
        {
          "line": 592,
          "old_api": "getType",
          "new_api": "tensorflow::ConvertToTensor(const_attr, &tensor)",
          "old_text": "xla::Parameter(&xla_builder_, operand_index,\n                            xla::TypeToShape(operand.getType()),\n                            std::to_string(operand_index))",
          "new_text": "tensorflow::ConvertToTensor(const_attr, &tensor)",
          "old_line_content": "    xla_op = xla::Parameter(&xla_builder_, operand_index,",
          "new_line_content": "    auto status = tensorflow::ConvertToTensor(const_attr, &tensor);",
          "content_same": false
        },
        {
          "line": 593,
          "old_api": "getType",
          "new_api": "ok",
          "old_text": "operand.getType()",
          "new_text": "status.ok()",
          "old_line_content": "                            xla::TypeToShape(operand.getType()),",
          "new_line_content": "    if (!status.ok()) {",
          "content_same": false
        },
        {
          "line": 594,
          "old_api": "std::to_string(operand_index)",
          "new_api": "emitRemark",
          "old_text": "std::to_string(operand_index)",
          "new_text": "op->emitRemark()",
          "old_line_content": "                            std::to_string(operand_index));",
          "new_line_content": "      op->emitRemark() << \"skipping legalization due to failed const conversion\"",
          "content_same": false
        },
        {
          "line": 599,
          "old_api": "tensorflow::ConvertToTensor(const_attr, &tensor)",
          "new_api": "tensorflow::XlaExpression::Constant(tensor)",
          "old_text": "tensorflow::ConvertToTensor(const_attr, &tensor)",
          "new_text": "tensorflow::XlaExpression::Constant(tensor)",
          "old_line_content": "    auto status = tensorflow::ConvertToTensor(const_attr, &tensor);",
          "new_line_content": "    return tensorflow::XlaExpression::Constant(tensor);",
          "content_same": false
        },
        {
          "line": 603,
          "old_api": "tensorflow::XlaExpression::Invalid()",
          "new_api": "MakeXlaOp",
          "old_text": "tensorflow::XlaExpression::Invalid()",
          "new_text": "hlo_builder_.MakeXlaOp(operand)",
          "old_line_content": "      return tensorflow::XlaExpression::Invalid();",
          "new_line_content": "    auto xla_op_or = hlo_builder_.MakeXlaOp(operand);",
          "content_same": false
        },
        {
          "line": 606,
          "old_api": "tensorflow::XlaExpression::Constant(tensor)",
          "new_api": "status",
          "old_text": "tensorflow::XlaExpression::Constant(tensor)",
          "new_text": "xla_op_or.status().ToString()",
          "old_line_content": "    return tensorflow::XlaExpression::Constant(tensor);",
          "new_line_content": "                       << xla_op_or.status().ToString();",
          "content_same": false
        },
        {
          "line": 613,
          "old_api": "status",
          "new_api": "getType",
          "old_text": "xla_op_or.status().ToString()",
          "new_text": "operand.getType()",
          "old_line_content": "                       << xla_op_or.status().ToString();",
          "new_line_content": "  auto status = tensorflow::ConvertToDataType(operand.getType(), &dtype);",
          "content_same": false
        },
        {
          "line": 614,
          "old_api": "tensorflow::XlaExpression::Invalid()",
          "new_api": "ok",
          "old_text": "tensorflow::XlaExpression::Invalid()",
          "new_text": "status.ok()",
          "old_line_content": "      return tensorflow::XlaExpression::Invalid();",
          "new_line_content": "  if (!status.ok()) {",
          "content_same": false
        },
        {
          "line": 616,
          "old_api": "value",
          "new_api": "tensorflow::XlaExpression::Invalid()",
          "old_text": "xla_op_or.value()",
          "new_text": "tensorflow::XlaExpression::Invalid()",
          "old_line_content": "    xla_op = xla_op_or.value();",
          "new_line_content": "    return tensorflow::XlaExpression::Invalid();",
          "content_same": false
        }
      ],
      "additions": [
        {
          "line": 512,
          "old_api": null,
          "new_api": "getDefiningOp",
          "old_text": null,
          "new_text": "xla_return_op->getOperand(0).getDefiningOp()",
          "old_line_content": "  }",
          "new_line_content": "      xla_return_op->getOperand(0).getDefiningOp());",
          "content_same": false
        },
        {
          "line": 524,
          "old_api": null,
          "new_api": "getOperandTypes",
          "old_text": null,
          "new_text": "op_->getOperandTypes()",
          "old_line_content": "",
          "new_line_content": "      FunctionType::get(op_->getContext(), op_->getOperandTypes(),",
          "content_same": false
        },
        {
          "line": 528,
          "old_api": null,
          "new_api": "getOperandTypes",
          "old_text": null,
          "new_text": "tuple_result->getOperandTypes()",
          "old_line_content": "  }",
          "new_line_content": "                        tuple_result->getOperandTypes());",
          "content_same": false
        },
        {
          "line": 529,
          "old_api": null,
          "new_api": "setType",
          "old_text": null,
          "new_text": "translated_function.setType(new_type)",
          "old_line_content": "",
          "new_line_content": "  translated_function.setType(new_type);",
          "content_same": false
        },
        {
          "line": 532,
          "old_api": null,
          "new_api": "getOperation",
          "old_text": null,
          "new_text": "tuple_result.getOperation()->erase()",
          "old_line_content": "                        // Note: Tuple results might have been type specialized",
          "new_line_content": "  tuple_result.getOperation()->erase();",
          "content_same": false
        },
        {
          "line": 534,
          "old_api": null,
          "new_api": "success",
          "old_text": null,
          "new_text": "success()",
          "old_line_content": "                        // types instead of the original op_ return type.",
          "new_line_content": "  return success();",
          "content_same": false
        },
        {
          "line": 540,
          "old_api": null,
          "new_api": "getNumResults",
          "old_text": null,
          "new_text": "op_->getNumResults()",
          "old_line_content": "",
          "new_line_content": "      op_->getNumResults()) {",
          "content_same": false
        },
        {
          "line": 549,
          "old_api": null,
          "new_api": "getNumResults",
          "old_text": null,
          "new_text": "op_->getNumResults()",
          "old_line_content": "                                \"number of results as the original op\";",
          "new_line_content": "  for (int i = 0; i < op_->getNumResults(); i++) {",
          "content_same": false
        },
        {
          "line": 550,
          "old_api": null,
          "new_api": "getResult",
          "old_text": null,
          "new_text": "call_op.getResult(i)",
          "old_line_content": "  }",
          "new_line_content": "    outputs.emplace_back(call_op.getResult(i));",
          "content_same": false
        },
        {
          "line": 559,
          "old_api": null,
          "new_api": "getNumResults",
          "old_text": null,
          "new_text": "op_->getNumResults()",
          "old_line_content": "",
          "new_line_content": "  outputs.reserve(op_->getNumResults());",
          "content_same": false
        },
        {
          "line": 562,
          "old_api": null,
          "new_api": "failure",
          "old_text": null,
          "new_text": "failure()",
          "old_line_content": "",
          "new_line_content": "    if (failed(UnpackTupleResults(translated_function))) return failure();",
          "content_same": false
        },
        {
          "line": 563,
          "old_api": null,
          "new_api": "InsertCallToTranslatedFunction",
          "old_text": null,
          "new_text": "InsertCallToTranslatedFunction(translated_function, outputs)",
          "old_line_content": "mlir::LogicalResult Tf2XlaRewriter::GetKernelOutputs(",
          "new_line_content": "    return InsertCallToTranslatedFunction(translated_function, outputs);",
          "content_same": false
        },
        {
          "line": 567,
          "old_api": null,
          "new_api": "mutable_output",
          "old_text": null,
          "new_text": "op_context.mutable_output(i)",
          "old_line_content": "",
          "new_line_content": "    tensorflow::Tensor* output = op_context.mutable_output(i);",
          "content_same": false
        },
        {
          "line": 571,
          "old_api": null,
          "new_api": "AsXlaOp",
          "old_text": null,
          "new_text": "expr->AsXlaOp(&hlo_builder_)",
          "old_line_content": "  }",
          "new_line_content": "    mlir::Value value = hlo_builder_.GetValue(expr->AsXlaOp(&hlo_builder_));",
          "content_same": false
        },
        {
          "line": 572,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "outputs.push_back(value)",
          "old_line_content": "",
          "new_line_content": "    outputs.push_back(value);",
          "content_same": false
        },
        {
          "line": 575,
          "old_api": null,
          "new_api": "success",
          "old_text": null,
          "new_text": "success()",
          "old_line_content": "    const tensorflow::XlaExpression* expr =",
          "new_line_content": "  return success();",
          "content_same": false
        },
        {
          "line": 581,
          "old_api": null,
          "new_api": "getDefiningOp",
          "old_text": null,
          "new_text": "operand.getDefiningOp()",
          "old_line_content": "",
          "new_line_content": "  auto defining_op = operand.getDefiningOp();",
          "content_same": false
        },
        {
          "line": 585,
          "old_api": null,
          "new_api": "getType",
          "old_text": null,
          "new_text": "xla::Parameter(&xla_builder_, operand_index,\n                            xla::TypeToShape(operand.getType()),\n                            std::to_string(operand_index))",
          "old_line_content": "tensorflow::XlaExpression Tf2XlaRewriter::GetExprForOperand(",
          "new_line_content": "    xla_op = xla::Parameter(&xla_builder_, operand_index,",
          "content_same": false
        },
        {
          "line": 586,
          "old_api": null,
          "new_api": "getType",
          "old_text": null,
          "new_text": "operand.getType()",
          "old_line_content": "    Value operand, Operation* op, int64_t operand_index) {",
          "new_line_content": "                            xla::TypeToShape(operand.getType()),",
          "content_same": false
        },
        {
          "line": 587,
          "old_api": null,
          "new_api": "std::to_string(operand_index)",
          "old_text": null,
          "new_text": "std::to_string(operand_index)",
          "old_line_content": "  ElementsAttr const_attr;",
          "new_line_content": "                            std::to_string(operand_index));",
          "content_same": false
        },
        {
          "line": 590,
          "old_api": null,
          "new_api": "m_Constant",
          "old_text": null,
          "new_text": "m_Constant(&const_attr)",
          "old_line_content": "  ::xla::XlaOp xla_op;",
          "new_line_content": "  if (defining_op && matchPattern(defining_op, m_Constant(&const_attr))) {",
          "content_same": false
        },
        {
          "line": 595,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "status.ToString()",
          "old_line_content": "  }",
          "new_line_content": "                       << status.ToString();",
          "content_same": false
        },
        {
          "line": 596,
          "old_api": null,
          "new_api": "tensorflow::XlaExpression::Invalid()",
          "old_text": null,
          "new_text": "tensorflow::XlaExpression::Invalid()",
          "old_line_content": "",
          "new_line_content": "      return tensorflow::XlaExpression::Invalid();",
          "content_same": false
        },
        {
          "line": 604,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "xla_op_or.ok()",
          "old_line_content": "    }",
          "new_line_content": "    if (!xla_op_or.ok()) {",
          "content_same": false
        },
        {
          "line": 605,
          "old_api": null,
          "new_api": "emitRemark",
          "old_text": null,
          "new_text": "op->emitRemark()",
          "old_line_content": "",
          "new_line_content": "      op->emitRemark() << \"skipping legalization due to \"",
          "content_same": false
        },
        {
          "line": 607,
          "old_api": null,
          "new_api": "tensorflow::XlaExpression::Invalid()",
          "old_text": null,
          "new_text": "tensorflow::XlaExpression::Invalid()",
          "old_line_content": "  }",
          "new_line_content": "      return tensorflow::XlaExpression::Invalid();",
          "content_same": false
        },
        {
          "line": 609,
          "old_api": null,
          "new_api": "value",
          "old_text": null,
          "new_text": "xla_op_or.value()",
          "old_line_content": "  if (!use_tf2xla_hlo_importer_) {",
          "new_line_content": "    xla_op = xla_op_or.value();",
          "content_same": false
        },
        {
          "line": 615,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "status.ToString()",
          "old_line_content": "    }",
          "new_line_content": "    op->emitRemark() << \"skipping legalization due to \" << status.ToString();",
          "content_same": false
        },
        {
          "line": 618,
          "old_api": null,
          "new_api": "tensorflow::XlaExpression::XlaOp(xla_op, dtype)",
          "old_text": null,
          "new_text": "tensorflow::XlaExpression::XlaOp(xla_op, dtype)",
          "old_line_content": "",
          "new_line_content": "  return tensorflow::XlaExpression::XlaOp(xla_op, dtype);",
          "content_same": false
        },
        {
          "line": 192,
          "old_api": null,
          "new_api": "Ref",
          "old_text": null,
          "new_text": "context_->Ref()",
          "old_line_content": "  if (use_tf2xla_hlo_importer_) {",
          "new_line_content": "  context_->Ref();",
          "content_same": false
        },
        {
          "line": 194,
          "old_api": null,
          "new_api": "CreateDeviceMgr",
          "old_text": null,
          "new_text": "CreateDeviceMgr(device_type_)",
          "old_line_content": "                                          /*graph=*/nullptr);",
          "new_line_content": "  device_mgr_ = CreateDeviceMgr(device_type_);",
          "content_same": false
        },
        {
          "line": 195,
          "old_api": null,
          "new_api": "failure",
          "old_text": null,
          "new_text": "failure()",
          "old_line_content": "  } else {",
          "new_line_content": "  if (!device_mgr_) return failure();",
          "content_same": false
        },
        {
          "line": 210,
          "old_api": null,
          "new_api": "Create",
          "old_text": null,
          "new_text": "step_container_->Create(\n      device_->resource_manager(),\n      tensorflow::XlaContext::kXlaContextResourceName, context_)",
          "old_line_content": "  // Resources are cleared at the time of device manager destruction so pass",
          "new_line_content": "  tsl::Status status = step_container_->Create(",
          "content_same": false
        },
        {
          "line": 211,
          "old_api": null,
          "new_api": "resource_manager",
          "old_text": null,
          "new_text": "device_->resource_manager()",
          "old_line_content": "  // no-op cleanup function.",
          "new_line_content": "      device_->resource_manager(),",
          "content_same": false
        },
        {
          "line": 213,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "status.ok()",
          "old_line_content": "  // Use step_id zero as we only have a single context concurrently and",
          "new_line_content": "  if (!status.ok()) {",
          "content_same": false
        },
        {
          "line": 214,
          "old_api": null,
          "new_api": "getLoc",
          "old_text": null,
          "new_text": "op_->getLoc()",
          "old_line_content": "  // concurrently running each of the MLIR functions create a new device.",
          "new_line_content": "    return emitRemark(op_->getLoc())",
          "content_same": false
        },
        {
          "line": 219,
          "old_api": null,
          "new_api": "tensorflow::GetTfGraphProducerVersion(\n      op_->getParentOfType<mlir::ModuleOp>())",
          "old_text": null,
          "new_text": "tensorflow::GetTfGraphProducerVersion(\n      op_->getParentOfType<mlir::ModuleOp>())",
          "old_line_content": "      tensorflow::XlaContext::kXlaContextResourceName, context_);",
          "new_line_content": "  tsl::StatusOr<int64_t> version_or = tensorflow::GetTfGraphProducerVersion(",
          "content_same": false
        },
        {
          "line": 225,
          "old_api": null,
          "new_api": "std::make_unique<tensorflow::FunctionLibraryDefinition>(\n      tensorflow::OpRegistry::Global(), tensorflow::FunctionDefLibrary())",
          "old_text": null,
          "new_text": "std::make_unique<tensorflow::FunctionLibraryDefinition>(\n      tensorflow::OpRegistry::Global(), tensorflow::FunctionDefLibrary())",
          "old_line_content": "",
          "new_line_content": "  flib_def_ = std::make_unique<tensorflow::FunctionLibraryDefinition>(",
          "content_same": false
        },
        {
          "line": 230,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "device_->name()",
          "old_line_content": "  }",
          "new_line_content": "  params_.function_library = pflr_->GetFLR(device_->name());",
          "content_same": false
        },
        {
          "line": 231,
          "old_api": null,
          "new_api": "success",
          "old_text": null,
          "new_text": "success()",
          "old_line_content": "",
          "new_line_content": "  return success();",
          "content_same": false
        },
        {
          "line": 240,
          "old_api": null,
          "new_api": "hasStaticShape",
          "old_text": null,
          "new_text": "ranked_ty.hasStaticShape()",
          "old_line_content": "",
          "new_line_content": "  if (ranked_ty.hasStaticShape()) return true;",
          "content_same": false
        },
        {
          "line": 243,
          "old_api": null,
          "new_api": "getEncoding",
          "old_text": null,
          "new_text": "ranked_ty.getEncoding().dyn_cast_or_null<TypeExtensionsAttr>()",
          "old_line_content": "bool IsBounded(Type ty) {",
          "new_line_content": "      ranked_ty.getEncoding().dyn_cast_or_null<TypeExtensionsAttr>();",
          "content_same": false
        },
        {
          "line": 246,
          "old_api": null,
          "new_api": "getRank",
          "old_text": null,
          "new_text": "ranked_ty.getRank()",
          "old_line_content": "",
          "new_line_content": "  for (int i = 0; i < ranked_ty.getRank(); ++i) {",
          "content_same": false
        },
        {
          "line": 248,
          "old_api": null,
          "new_api": "getBounds",
          "old_text": null,
          "new_text": "encoding.getBounds()",
          "old_line_content": "",
          "new_line_content": "        encoding.getBounds()[i] == ShapedType::kDynamic) {",
          "content_same": false
        },
        {
          "line": 256,
          "old_api": null,
          "new_api": "getAttrs",
          "old_text": null,
          "new_text": "op->getAttrs()",
          "old_line_content": "      return false;",
          "new_line_content": "  for (const auto& attr : op->getAttrs()) {",
          "content_same": false
        },
        {
          "line": 257,
          "old_api": null,
          "new_api": "getValue",
          "old_text": null,
          "new_text": "attr.getValue()",
          "old_line_content": "    }",
          "new_line_content": "    Attribute attr_value = attr.getValue();",
          "content_same": false
        },
        {
          "line": 258,
          "old_api": null,
          "new_api": "attr_value.isa<SymbolRefAttr>()",
          "old_text": null,
          "new_text": "attr_value.isa<SymbolRefAttr>()",
          "old_line_content": "  }",
          "new_line_content": "    if (attr_value.isa<SymbolRefAttr>()) {",
          "content_same": false
        },
        {
          "line": 260,
          "old_api": null,
          "new_api": "attr_value.dyn_cast<ArrayAttr>()",
          "old_text": null,
          "new_text": "attr_value.dyn_cast<ArrayAttr>()",
          "old_line_content": "}",
          "new_line_content": "    } else if (auto array_attr = attr_value.dyn_cast<ArrayAttr>()) {",
          "content_same": false
        },
        {
          "line": 261,
          "old_api": null,
          "new_api": "begin",
          "old_text": null,
          "new_text": "array_attr.begin()->isa<SymbolRefAttr>()",
          "old_line_content": "",
          "new_line_content": "      if (!array_attr.empty() && array_attr.begin()->isa<SymbolRefAttr>()) {",
          "content_same": false
        },
        {
          "line": 275,
          "old_api": null,
          "new_api": "getOperands",
          "old_text": null,
          "new_text": "op_->getOperands()",
          "old_line_content": "",
          "new_line_content": "  for (auto it : llvm::enumerate(op_->getOperands())) {",
          "content_same": false
        },
        {
          "line": 276,
          "old_api": null,
          "new_api": "value",
          "old_text": null,
          "new_text": "it.value()",
          "old_line_content": "LogicalResult Tf2XlaRewriter::PrepareKernelInputs(",
          "new_line_content": "    Value operand = it.value();",
          "content_same": false
        },
        {
          "line": 277,
          "old_api": null,
          "new_api": "index",
          "old_text": null,
          "new_text": "it.index()",
          "old_line_content": "    const llvm::SmallDenseSet<int>& required_consts,",
          "new_line_content": "    size_t idx = it.index();",
          "content_same": false
        },
        {
          "line": 279,
          "old_api": null,
          "new_api": "GetExprForOperand",
          "old_text": null,
          "new_text": "GetExprForOperand(operand, op_, idx)",
          "old_line_content": "    std::vector<tensorflow::Tensor>& tensors,",
          "new_line_content": "    tensorflow::XlaExpression expr = GetExprForOperand(operand, op_, idx);",
          "content_same": false
        },
        {
          "line": 280,
          "old_api": null,
          "new_api": "kind",
          "old_text": null,
          "new_text": "expr.kind()",
          "old_line_content": "    std::vector<tensorflow::TensorValue>& inputs) {",
          "new_line_content": "    tensorflow::XlaExpression::Kind kind = expr.kind();",
          "content_same": false
        },
        {
          "line": 281,
          "old_api": null,
          "new_api": "failure",
          "old_text": null,
          "new_text": "failure()",
          "old_line_content": "  // Prepare the list of Tensor inputs for the kernel.",
          "new_line_content": "    if (kind == tensorflow::XlaExpression::Kind::kInvalid) return failure();",
          "content_same": false
        },
        {
          "line": 290,
          "old_api": null,
          "new_api": "emitRemark",
          "old_text": null,
          "new_text": "op_->emitRemark()",
          "old_line_content": "        kind != tensorflow::XlaExpression::Kind::kConstant) {",
          "new_line_content": "      return op_->emitRemark()",
          "content_same": false
        },
        {
          "line": 292,
          "old_api": null,
          "new_api": "getType",
          "old_text": null,
          "new_text": "operand.getType()",
          "old_line_content": "             << \"lowering requires operand #\" << idx << \" to be a constant\";",
          "new_line_content": "             << operand.getType();",
          "content_same": false
        },
        {
          "line": 295,
          "old_api": null,
          "new_api": "GetShape",
          "old_text": null,
          "new_text": "expr.GetShape()",
          "old_line_content": "",
          "new_line_content": "    auto shape_or = expr.GetShape();",
          "content_same": false
        },
        {
          "line": 298,
          "old_api": null,
          "new_api": "HumanString",
          "old_text": null,
          "new_text": "expr.HumanString()",
          "old_line_content": "             << \"skipping legalization due to unsupported type \"",
          "new_line_content": "             << \"failed to get shape for expression. \" << expr.HumanString();",
          "content_same": false
        },
        {
          "line": 301,
          "old_api": null,
          "new_api": "emplace_back",
          "old_text": null,
          "new_text": "tensors.emplace_back(\n        device_->GetAllocator(tensorflow::AllocatorAttributes()), expr.dtype(),\n        shape_or.value())",
          "old_line_content": "",
          "new_line_content": "    tensors.emplace_back(",
          "content_same": false
        },
        {
          "line": 306,
          "old_api": null,
          "new_api": "tensorflow::XlaExpression::AssignExpressionToTensor(expr, &tensor)",
          "old_text": null,
          "new_text": "tensorflow::XlaExpression::AssignExpressionToTensor(expr, &tensor)",
          "old_line_content": "    }",
          "new_line_content": "    tensorflow::XlaExpression::AssignExpressionToTensor(expr, &tensor);",
          "content_same": false
        },
        {
          "line": 307,
          "old_api": null,
          "new_api": "emplace_back",
          "old_text": null,
          "new_text": "inputs.emplace_back(&tensor)",
          "old_line_content": "",
          "new_line_content": "    inputs.emplace_back(&tensor);",
          "content_same": false
        },
        {
          "line": 315,
          "old_api": null,
          "new_api": "ty.dyn_cast<ShapedType>()",
          "old_text": null,
          "new_text": "ty.dyn_cast<ShapedType>()",
          "old_line_content": "  }",
          "new_line_content": "    auto ranked_ty = ty.dyn_cast<ShapedType>();",
          "content_same": false
        },
        {
          "line": 318,
          "old_api": null,
          "new_api": "emitRemark",
          "old_text": null,
          "new_text": "op_->emitRemark()",
          "old_line_content": "}",
          "new_line_content": "      return op_->emitRemark()",
          "content_same": false
        },
        {
          "line": 323,
          "old_api": null,
          "new_api": "HasSymbolRefAttr",
          "old_text": null,
          "new_text": "HasSymbolRefAttr(op_)",
          "old_line_content": "    // Only bounded operands are supported in the XLA builders.",
          "new_line_content": "  if (HasSymbolRefAttr(op_)) {",
          "content_same": false
        },
        {
          "line": 327,
          "old_api": null,
          "new_api": "GetUniqueName",
          "old_text": null,
          "new_text": "tensorflow::ConvertTFDialectOpToNodeDef(\n      op_, name_mapper_.GetUniqueName(op_),\n      /*ignore_unregistered_attrs=*/true)",
          "old_line_content": "    }",
          "new_line_content": "  auto nodedef_or = tensorflow::ConvertTFDialectOpToNodeDef(",
          "content_same": false
        },
        {
          "line": 328,
          "old_api": null,
          "new_api": "GetUniqueName",
          "old_text": null,
          "new_text": "name_mapper_.GetUniqueName(op_)",
          "old_line_content": "  }",
          "new_line_content": "      op_, name_mapper_.GetUniqueName(op_),",
          "content_same": false
        },
        {
          "line": 332,
          "old_api": null,
          "new_api": "status",
          "old_text": null,
          "new_text": "nodedef_or.status().ToString()",
          "old_line_content": "  }",
          "new_line_content": "                             << nodedef_or.status().ToString();",
          "content_same": false
        },
        {
          "line": 340,
          "old_api": null,
          "new_api": "GetFunctionLibraryDefinition",
          "old_text": null,
          "new_text": "params_.function_library->GetFunctionLibraryDefinition()",
          "old_line_content": "  }",
          "new_line_content": "      params_.function_library->GetFunctionLibraryDefinition(), &props);",
          "content_same": false
        },
        {
          "line": 341,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "status.ok()",
          "old_line_content": "",
          "new_line_content": "  if (!status.ok()) {",
          "content_same": false
        },
        {
          "line": 343,
          "old_api": null,
          "new_api": "ToString",
          "old_text": null,
          "new_text": "status.ToString()",
          "old_line_content": "",
          "new_line_content": "           << \"failed to create NodeProperties: \" << status.ToString();",
          "content_same": false
        },
        {
          "line": 352,
          "old_api": null,
          "new_api": "absl::WrapUnique(op_kernel_raw)",
          "old_text": null,
          "new_text": "absl::WrapUnique(op_kernel_raw)",
          "old_line_content": "  tensorflow::OpKernel* op_kernel_raw;",
          "new_line_content": "  auto op_kernel = absl::WrapUnique(op_kernel_raw);",
          "content_same": false
        },
        {
          "line": 357,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "status.ok()",
          "old_line_content": "  }",
          "new_line_content": "  if (!status.ok()) {",
          "content_same": false
        },
        {
          "line": 358,
          "old_api": null,
          "new_api": "emitRemark",
          "old_text": null,
          "new_text": "op_->emitRemark()",
          "old_line_content": "  // Transfer ownership of the kernel to a local smart pointer.",
          "new_line_content": "    return op_->emitRemark()",
          "content_same": false
        },
        {
          "line": 363,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "required_constants.end()",
          "old_line_content": "      *op_kernel, &required_constants);",
          "new_line_content": "  required_consts.insert(required_constants.begin(), required_constants.end());",
          "content_same": false
        },
        {
          "line": 372,
          "old_api": null,
          "new_api": "getNumOperands",
          "old_text": null,
          "new_text": "op_->getNumOperands()",
          "old_line_content": "  // TensorValue in inputs are backed by tensors which in turn depend on",
          "new_line_content": "  expressions.reserve(op_->getNumOperands());",
          "content_same": false
        },
        {
          "line": 373,
          "old_api": null,
          "new_api": "getNumOperands",
          "old_text": null,
          "new_text": "op_->getNumOperands()",
          "old_line_content": "  // expressions. So, pre-allocate them to the required size. Subtle note:",
          "new_line_content": "  tensors.reserve(op_->getNumOperands());",
          "content_same": false
        },
        {
          "line": 374,
          "old_api": null,
          "new_api": "getNumOperands",
          "old_text": null,
          "new_text": "op_->getNumOperands()",
          "old_line_content": "  // Since these are assigned to params_, these have to live past the kernel",
          "new_line_content": "  inputs.reserve(op_->getNumOperands());",
          "content_same": false
        },
        {
          "line": 376,
          "old_api": null,
          "new_api": "failed",
          "old_text": null,
          "new_text": "failed(\n          PrepareKernelInputs(required_consts, expressions, tensors, inputs))",
          "old_line_content": "  std::vector<tensorflow::XlaExpression> expressions;",
          "new_line_content": "  if (failed(",
          "content_same": false
        },
        {
          "line": 377,
          "old_api": null,
          "new_api": "PrepareKernelInputs",
          "old_text": null,
          "new_text": "PrepareKernelInputs(required_consts, expressions, tensors, inputs)",
          "old_line_content": "  std::vector<tensorflow::Tensor> tensors;",
          "new_line_content": "          PrepareKernelInputs(required_consts, expressions, tensors, inputs)))",
          "content_same": false
        },
        {
          "line": 378,
          "old_api": null,
          "new_api": "failure",
          "old_text": null,
          "new_text": "failure()",
          "old_line_content": "  std::vector<tensorflow::TensorValue> inputs;",
          "new_line_content": "    return failure();",
          "content_same": false
        },
        {
          "line": 386,
          "old_api": null,
          "new_api": "setInsertionPoint",
          "old_text": null,
          "new_text": "hlo_builder_.setInsertionPoint(op_)",
          "old_line_content": "",
          "new_line_content": "  hlo_builder_.setInsertionPoint(op_);",
          "content_same": false
        },
        {
          "line": 387,
          "old_api": null,
          "new_api": "getLoc",
          "old_text": null,
          "new_text": "op_->getLoc()",
          "old_line_content": "  params_.inputs = inputs;",
          "new_line_content": "  hlo_builder_.SetLocation(op_->getLoc());",
          "content_same": false
        },
        {
          "line": 389,
          "old_api": null,
          "new_api": "getNumResults",
          "old_text": null,
          "new_text": "op_->getNumResults()",
          "old_line_content": "  llvm::SmallVector<tensorflow::AllocatorAttributes, 4> output_attr(",
          "new_line_content": "  tensorflow::OpKernelContext op_context(&params_, op_->getNumResults());",
          "content_same": false
        },
        {
          "line": 392,
          "old_api": null,
          "new_api": "status",
          "old_text": null,
          "new_text": "op_context.status()",
          "old_line_content": "",
          "new_line_content": "  status = op_context.status();",
          "content_same": false
        },
        {
          "line": 395,
          "old_api": null,
          "new_api": "emitRemark",
          "old_text": null,
          "new_text": "op_->emitRemark()",
          "old_line_content": "",
          "new_line_content": "    return op_->emitRemark()",
          "content_same": false
        },
        {
          "line": 404,
          "old_api": null,
          "new_api": "CompileWithHloImporter",
          "old_text": null,
          "new_text": "CompileWithHloImporter(op_context)",
          "old_line_content": "  }",
          "new_line_content": "        CompileWithHloImporter(op_context);",
          "content_same": false
        },
        {
          "line": 405,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "translated_function_or_status.ok()",
          "old_line_content": "",
          "new_line_content": "    if (!translated_function_or_status.ok()) {",
          "content_same": false
        },
        {
          "line": 407,
          "old_api": null,
          "new_api": "status",
          "old_text": null,
          "new_text": "translated_function_or_status.status().ToString()",
          "old_line_content": "",
          "new_line_content": "             << translated_function_or_status.status().ToString();",
          "content_same": false
        },
        {
          "line": 409,
          "old_api": null,
          "new_api": "value",
          "old_text": null,
          "new_text": "translated_function_or_status.value()",
          "old_line_content": "  if (use_tf2xla_hlo_importer_) {",
          "new_line_content": "    translated_function = translated_function_or_status.value();",
          "content_same": false
        },
        {
          "line": 415,
          "old_api": null,
          "new_api": "failure",
          "old_text": null,
          "new_text": "failure()",
          "old_line_content": "    }",
          "new_line_content": "    return failure();",
          "content_same": false
        },
        {
          "line": 418,
          "old_api": null,
          "new_api": "replaceOp",
          "old_text": null,
          "new_text": "rewriter_.replaceOp(op_, output_values)",
          "old_line_content": "",
          "new_line_content": "  rewriter_.replaceOp(op_, output_values);",
          "content_same": false
        },
        {
          "line": 419,
          "old_api": null,
          "new_api": "success",
          "old_text": null,
          "new_text": "success()",
          "old_line_content": "  llvm::SmallVector<Value> output_values;",
          "new_line_content": "  return success();",
          "content_same": false
        },
        {
          "line": 424,
          "old_api": null,
          "new_api": "proto",
          "old_text": null,
          "new_text": "computation.proto().entry_computation_id()",
          "old_line_content": "",
          "new_line_content": "  int entry_computation = computation.proto().entry_computation_id();",
          "content_same": false
        },
        {
          "line": 428,
          "old_api": null,
          "new_api": "mutable_proto",
          "old_text": null,
          "new_text": "computation.mutable_proto()->mutable_computations()",
          "old_line_content": "",
          "new_line_content": "       *computation.mutable_proto()->mutable_computations()) {",
          "content_same": false
        },
        {
          "line": 432,
          "old_api": null,
          "new_api": "set_name",
          "old_text": null,
          "new_text": "sub_computation.set_name(renamed_computation)",
          "old_line_content": "  std::string new_entry_computation_name = \"\";",
          "new_line_content": "    sub_computation.set_name(renamed_computation);",
          "content_same": false
        },
        {
          "line": 434,
          "old_api": null,
          "new_api": "id",
          "old_text": null,
          "new_text": "sub_computation.id()",
          "old_line_content": "  for (xla::HloComputationProto& sub_computation :",
          "new_line_content": "    if (sub_computation.id() == entry_computation) {",
          "content_same": false
        },
        {
          "line": 442,
          "old_api": null,
          "new_api": "tsl::OkStatus()",
          "old_text": null,
          "new_text": "tsl::OkStatus()",
          "old_line_content": "      new_entry_computation_name = renamed_computation;",
          "new_line_content": "  return tsl::OkStatus();",
          "content_same": false
        },
        {
          "line": 456,
          "old_api": null,
          "new_api": "mutable_output",
          "old_text": null,
          "new_text": "op_context.mutable_output(i)",
          "old_line_content": "        \"Cannot compile with HloImporter because it isn't supported\");",
          "new_line_content": "    tensorflow::Tensor* output = op_context.mutable_output(i);",
          "content_same": false
        },
        {
          "line": 458,
          "old_api": null,
          "new_api": "tensorflow::XlaExpression::CastExpressionFromTensor(*output)",
          "old_text": null,
          "new_text": "tensorflow::XlaExpression::CastExpressionFromTensor(*output)",
          "old_line_content": "",
          "new_line_content": "        tensorflow::XlaExpression::CastExpressionFromTensor(*output);",
          "content_same": false
        },
        {
          "line": 459,
          "old_api": null,
          "new_api": "AsXlaOp",
          "old_text": null,
          "new_text": "expr->AsXlaOp(&xla_builder_)",
          "old_line_content": "  // XLA can only return a single value. Wrap all output op return values",
          "new_line_content": "    output_values.push_back(expr->AsXlaOp(&xla_builder_));",
          "content_same": false
        },
        {
          "line": 468,
          "old_api": null,
          "new_api": "CreateUniqueComputationNames",
          "old_text": null,
          "new_text": "CreateUniqueComputationNames(computation)",
          "old_line_content": "",
          "new_line_content": "  TF_RETURN_IF_ERROR(CreateUniqueComputationNames(computation));",
          "content_same": false
        },
        {
          "line": 476,
          "old_api": null,
          "new_api": "mutable_output",
          "old_text": null,
          "new_text": "op_context.mutable_output(i)",
          "old_line_content": "",
          "new_line_content": "    tensorflow::Tensor* output = op_context.mutable_output(i);",
          "content_same": false
        },
        {
          "line": 478,
          "old_api": null,
          "new_api": "tensorflow::XlaExpression::CastExpressionFromTensor(*output)",
          "old_text": null,
          "new_text": "tensorflow::XlaExpression::CastExpressionFromTensor(*output)",
          "old_line_content": "}",
          "new_line_content": "        tensorflow::XlaExpression::CastExpressionFromTensor(*output);",
          "content_same": false
        },
        {
          "line": 480,
          "old_api": null,
          "new_api": "kind",
          "old_text": null,
          "new_text": "expr->kind()",
          "old_line_content": "mlir::LogicalResult Tf2XlaRewriter::VerifyOpResults(",
          "new_line_content": "    if (expr->kind() != tensorflow::XlaExpression::Kind::kXlaOp &&",
          "content_same": false
        },
        {
          "line": 481,
          "old_api": null,
          "new_api": "kind",
          "old_text": null,
          "new_text": "expr->kind()",
          "old_line_content": "    tensorflow::OpKernelContext& op_context) {",
          "new_line_content": "        expr->kind() != tensorflow::XlaExpression::Kind::kConstant) {",
          "content_same": false
        },
        {
          "line": 496,
          "old_api": null,
          "new_api": "getBlocks",
          "old_text": null,
          "new_text": "translated_function.getBlocks().size()",
          "old_line_content": "}",
          "new_line_content": "  if (translated_function.getBlocks().size() != 1) {",
          "content_same": false
        },
        {
          "line": 497,
          "old_api": null,
          "new_api": "emitRemark",
          "old_text": null,
          "new_text": "op_->emitRemark()",
          "old_line_content": "",
          "new_line_content": "    return op_->emitRemark() << \"Translated function has more than one block. \"",
          "content_same": false
        },
        {
          "line": 501,
          "old_api": null,
          "new_api": "back",
          "old_text": null,
          "new_text": "llvm::dyn_cast<func::ReturnOp>(\n      translated_function.back().getTerminator())",
          "old_line_content": "mlir::LogicalResult Tf2XlaRewriter::UnpackTupleResults(",
          "new_line_content": "  func::ReturnOp xla_return_op = llvm::dyn_cast<func::ReturnOp>(",
          "content_same": false
        },
        {
          "line": 502,
          "old_api": null,
          "new_api": "back",
          "old_text": null,
          "new_text": "translated_function.back().getTerminator()",
          "old_line_content": "    mlir::func::FuncOp translated_function) {",
          "new_line_content": "      translated_function.back().getTerminator());",
          "content_same": false
        },
        {
          "line": 507,
          "old_api": null,
          "new_api": "getNumOperands",
          "old_text": null,
          "new_text": "xla_return_op->getNumOperands()",
          "old_line_content": "",
          "new_line_content": "  if (xla_return_op->getNumOperands() != 1) {",
          "content_same": false
        }
      ],
      "deletions": [
        {
          "line": 515,
          "old_api": "emitRemark",
          "new_api": null,
          "old_text": "op_->emitRemark()",
          "new_text": null,
          "old_line_content": "    return op_->emitRemark() << \"Return value has more than one op, returning\";",
          "new_line_content": "           << \"Translated Function didn't return a tuple type\";",
          "content_same": false
        },
        {
          "line": 521,
          "old_api": "emitRemark",
          "new_api": null,
          "old_text": "op_->emitRemark()",
          "new_text": null,
          "old_line_content": "    return op_->emitRemark()",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 525,
          "old_api": "getNumResults",
          "new_api": null,
          "old_text": "op_->getNumResults()",
          "new_text": null,
          "old_line_content": "  if (tuple_result->getNumOperands() != op_->getNumResults()) {",
          "new_line_content": "                        // Note: Tuple results might have been type specialized",
          "content_same": false
        },
        {
          "line": 526,
          "old_api": "emitRemark",
          "new_api": null,
          "old_text": "op_->emitRemark()",
          "new_text": null,
          "old_line_content": "    return op_->emitRemark() << \"Translated function tuple has different \"",
          "new_line_content": "                        // so we overwrite the return type with the tuple result",
          "content_same": false
        },
        {
          "line": 535,
          "old_api": "getOperandTypes",
          "new_api": null,
          "old_text": "tuple_result->getOperandTypes()",
          "new_text": null,
          "old_line_content": "                        tuple_result->getOperandTypes());",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 536,
          "old_api": "setType",
          "new_api": null,
          "old_text": "translated_function.setType(new_type)",
          "new_text": null,
          "old_line_content": "  translated_function.setType(new_type);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 538,
          "old_api": "getOperands",
          "new_api": null,
          "old_text": "tuple_result->getOperands()",
          "new_text": null,
          "old_line_content": "  xla_return_op->setOperands(tuple_result->getOperands());",
          "new_line_content": "    mlir::func::FuncOp translated_function, llvm::SmallVector<Value>& outputs) {",
          "content_same": false
        },
        {
          "line": 548,
          "old_api": "emitRemark",
          "new_api": null,
          "old_text": "op_->emitRemark()",
          "new_text": null,
          "old_line_content": "    return op_->emitRemark() << \"Translated function doesn't have the same \"",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 554,
          "old_api": "getOperands",
          "new_api": null,
          "old_text": "op_->getOperands()",
          "new_text": null,
          "old_line_content": "      op_->getLoc(), translated_function, op_->getOperands());",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 556,
          "old_api": "getNumResults",
          "new_api": null,
          "old_text": "op_->getNumResults()",
          "new_text": null,
          "old_line_content": "  for (int i = 0; i < op_->getNumResults(); i++) {",
          "new_line_content": "mlir::LogicalResult Tf2XlaRewriter::GetKernelOutputs(",
          "content_same": false
        },
        {
          "line": 557,
          "old_api": "getResult",
          "new_api": null,
          "old_text": "call_op.getResult(i)",
          "new_text": null,
          "old_line_content": "    outputs.emplace_back(call_op.getResult(i));",
          "new_line_content": "    tensorflow::OpKernelContext& op_context,",
          "content_same": false
        },
        {
          "line": 560,
          "old_api": "success",
          "new_api": null,
          "old_text": "success()",
          "new_text": null,
          "old_line_content": "  return success();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 570,
          "old_api": "InsertCallToTranslatedFunction",
          "new_api": null,
          "old_text": "InsertCallToTranslatedFunction(translated_function, outputs)",
          "new_text": null,
          "old_line_content": "    return InsertCallToTranslatedFunction(translated_function, outputs);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 573,
          "old_api": "getNumResults",
          "new_api": null,
          "old_text": "op_->getNumResults()",
          "new_text": null,
          "old_line_content": "  for (int i = 0, e = op_->getNumResults(); i < e; i++) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 574,
          "old_api": "mutable_output",
          "new_api": null,
          "old_text": "op_context.mutable_output(i)",
          "new_text": null,
          "old_line_content": "    tensorflow::Tensor* output = op_context.mutable_output(i);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 576,
          "old_api": "tensorflow::XlaExpression::CastExpressionFromTensor(*output)",
          "new_api": null,
          "old_text": "tensorflow::XlaExpression::CastExpressionFromTensor(*output)",
          "new_text": null,
          "old_line_content": "        tensorflow::XlaExpression::CastExpressionFromTensor(*output);",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 578,
          "old_api": "AsXlaOp",
          "new_api": null,
          "old_text": "expr->AsXlaOp(&hlo_builder_)",
          "new_text": null,
          "old_line_content": "    mlir::Value value = hlo_builder_.GetValue(expr->AsXlaOp(&hlo_builder_));",
          "new_line_content": "tensorflow::XlaExpression Tf2XlaRewriter::GetExprForOperand(",
          "content_same": false
        },
        {
          "line": 579,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "outputs.push_back(value)",
          "new_text": null,
          "old_line_content": "    outputs.push_back(value);",
          "new_line_content": "    Value operand, Operation* op, int64_t operand_index) {",
          "content_same": false
        },
        {
          "line": 582,
          "old_api": "success",
          "new_api": null,
          "old_text": "success()",
          "new_text": null,
          "old_line_content": "  return success();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 588,
          "old_api": "getDefiningOp",
          "new_api": null,
          "old_text": "operand.getDefiningOp()",
          "new_text": null,
          "old_line_content": "  auto defining_op = operand.getDefiningOp();",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 597,
          "old_api": "m_Constant",
          "new_api": null,
          "old_text": "m_Constant(&const_attr)",
          "new_text": null,
          "old_line_content": "  if (defining_op && matchPattern(defining_op, m_Constant(&const_attr))) {",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 600,
          "old_api": "ok",
          "new_api": null,
          "old_text": "status.ok()",
          "new_text": null,
          "old_line_content": "    if (!status.ok()) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 601,
          "old_api": "emitRemark",
          "new_api": null,
          "old_text": "op->emitRemark()",
          "new_text": null,
          "old_line_content": "      op->emitRemark() << \"skipping legalization due to failed const conversion\"",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 602,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "status.ToString()",
          "new_text": null,
          "old_line_content": "                       << status.ToString();",
          "new_line_content": "  if (!use_tf2xla_hlo_importer_) {",
          "content_same": false
        },
        {
          "line": 610,
          "old_api": "MakeXlaOp",
          "new_api": null,
          "old_text": "hlo_builder_.MakeXlaOp(operand)",
          "new_text": null,
          "old_line_content": "    auto xla_op_or = hlo_builder_.MakeXlaOp(operand);",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 611,
          "old_api": "ok",
          "new_api": null,
          "old_text": "xla_op_or.ok()",
          "new_text": null,
          "old_line_content": "    if (!xla_op_or.ok()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 612,
          "old_api": "emitRemark",
          "new_api": null,
          "old_text": "op->emitRemark()",
          "new_text": null,
          "old_line_content": "      op->emitRemark() << \"skipping legalization due to \"",
          "new_line_content": "  tensorflow::DataType dtype;",
          "content_same": false
        },
        {
          "line": 620,
          "old_api": "getType",
          "new_api": null,
          "old_text": "operand.getType()",
          "new_text": null,
          "old_line_content": "  auto status = tensorflow::ConvertToDataType(operand.getType(), &dtype);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 621,
          "old_api": "ok",
          "new_api": null,
          "old_text": "status.ok()",
          "new_text": null,
          "old_line_content": "  if (!status.ok()) {",
          "new_line_content": "}  // namespace mhlo",
          "content_same": false
        },
        {
          "line": 622,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "status.ToString()",
          "new_text": null,
          "old_line_content": "    op->emitRemark() << \"skipping legalization due to \" << status.ToString();",
          "new_line_content": "}  // namespace mlir",
          "content_same": false
        },
        {
          "line": 623,
          "old_api": "tensorflow::XlaExpression::Invalid()",
          "new_api": null,
          "old_text": "tensorflow::XlaExpression::Invalid()",
          "new_text": null,
          "old_line_content": "    return tensorflow::XlaExpression::Invalid();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 625,
          "old_api": "tensorflow::XlaExpression::XlaOp(xla_op, dtype)",
          "new_api": null,
          "old_text": "tensorflow::XlaExpression::XlaOp(xla_op, dtype)",
          "new_text": null,
          "old_line_content": "  return tensorflow::XlaExpression::XlaOp(xla_op, dtype);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 182,
          "old_api": "setVisibility",
          "new_api": null,
          "old_text": "function.setVisibility(FuncOp::Visibility::Public)",
          "new_text": null,
          "old_line_content": "    function.setVisibility(FuncOp::Visibility::Public);",
          "new_line_content": "  // XlaCompiler within the context is only used by the functional ops to",
          "content_same": false
        },
        {
          "line": 202,
          "old_api": "failure",
          "new_api": null,
          "old_text": "failure()",
          "new_text": null,
          "old_line_content": "  if (!device_mgr_) return failure();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 206,
          "old_api": "front",
          "new_api": null,
          "old_text": "device_mgr_->ListDevices().front()",
          "new_text": null,
          "old_line_content": "  device_ = device_mgr_->ListDevices().front();",
          "new_line_content": "  // Use step_id zero as we only have a single context concurrently and",
          "content_same": false
        },
        {
          "line": 218,
          "old_api": "resource_manager",
          "new_api": null,
          "old_text": "device_->resource_manager()",
          "new_text": null,
          "old_line_content": "      device_->resource_manager(),",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 224,
          "old_api": "get",
          "new_api": null,
          "old_text": "step_container_.get()",
          "new_text": null,
          "old_line_content": "  params_.step_container = step_container_.get();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 232,
          "old_api": "std::make_unique<tensorflow::FunctionLibraryDefinition>(\n      tensorflow::OpRegistry::Global(), tensorflow::FunctionDefLibrary())",
          "new_api": null,
          "old_text": "std::make_unique<tensorflow::FunctionLibraryDefinition>(\n      tensorflow::OpRegistry::Global(), tensorflow::FunctionDefLibrary())",
          "new_text": null,
          "old_line_content": "  flib_def_ = std::make_unique<tensorflow::FunctionLibraryDefinition>(",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 233,
          "old_api": "tensorflow::FunctionDefLibrary()",
          "new_api": null,
          "old_text": "tensorflow::FunctionDefLibrary()",
          "new_text": null,
          "old_line_content": "      tensorflow::OpRegistry::Global(), tensorflow::FunctionDefLibrary());",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 234,
          "old_api": "get",
          "new_api": null,
          "old_text": "std::make_unique<tensorflow::ProcessFunctionLibraryRuntime>(\n      device_mgr_.get(), tensorflow::Env::Default(), /*config=*/nullptr,\n      version_or.value(), flib_def_.get(), tensorflow::OptimizerOptions())",
          "new_text": null,
          "old_line_content": "  pflr_ = std::make_unique<tensorflow::ProcessFunctionLibraryRuntime>(",
          "new_line_content": "// Returns true if the given type is a ranked tensor type with static or",
          "content_same": false
        },
        {
          "line": 235,
          "old_api": "tensorflow::Env::Default()",
          "new_api": null,
          "old_text": "tensorflow::Env::Default()",
          "new_text": null,
          "old_line_content": "      device_mgr_.get(), tensorflow::Env::Default(), /*config=*/nullptr,",
          "new_line_content": "// bounded dimensions.",
          "content_same": false
        },
        {
          "line": 236,
          "old_api": "tensorflow::OptimizerOptions()",
          "new_api": null,
          "old_text": "tensorflow::OptimizerOptions()",
          "new_text": null,
          "old_line_content": "      version_or.value(), flib_def_.get(), tensorflow::OptimizerOptions());",
          "new_line_content": "bool IsBounded(Type ty) {",
          "content_same": false
        },
        {
          "line": 238,
          "old_api": "success",
          "new_api": null,
          "old_text": "success()",
          "new_text": null,
          "old_line_content": "  return success();",
          "new_line_content": "  if (!ranked_ty) return false;",
          "content_same": false
        },
        {
          "line": 244,
          "old_api": "ty.dyn_cast<RankedTensorType>()",
          "new_api": null,
          "old_text": "ty.dyn_cast<RankedTensorType>()",
          "new_text": null,
          "old_line_content": "  auto ranked_ty = ty.dyn_cast<RankedTensorType>();",
          "new_line_content": "  if (!encoding) return false;",
          "content_same": false
        },
        {
          "line": 250,
          "old_api": "getEncoding",
          "new_api": null,
          "old_text": "ranked_ty.getEncoding().dyn_cast_or_null<TypeExtensionsAttr>()",
          "new_text": null,
          "old_line_content": "      ranked_ty.getEncoding().dyn_cast_or_null<TypeExtensionsAttr>();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 253,
          "old_api": "getRank",
          "new_api": null,
          "old_text": "ranked_ty.getRank()",
          "new_text": null,
          "old_line_content": "  for (int i = 0; i < ranked_ty.getRank(); ++i) {",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 254,
          "old_api": "isDynamicDim",
          "new_api": null,
          "old_text": "ranked_ty.isDynamicDim(i)",
          "new_text": null,
          "old_line_content": "    if (ranked_ty.isDynamicDim(i) &&",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 255,
          "old_api": "getBounds",
          "new_api": null,
          "old_text": "encoding.getBounds()",
          "new_text": null,
          "old_line_content": "        encoding.getBounds()[i] == ShapedType::kDynamic) {",
          "new_line_content": "bool HasSymbolRefAttr(Operation* op) {",
          "content_same": false
        },
        {
          "line": 263,
          "old_api": "getAttrs",
          "new_api": null,
          "old_text": "op->getAttrs()",
          "new_text": null,
          "old_line_content": "  for (const auto& attr : op->getAttrs()) {",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 264,
          "old_api": "getValue",
          "new_api": null,
          "old_text": "attr.getValue()",
          "new_text": null,
          "old_line_content": "    Attribute attr_value = attr.getValue();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 265,
          "old_api": "attr_value.isa<SymbolRefAttr>()",
          "new_api": null,
          "old_text": "attr_value.isa<SymbolRefAttr>()",
          "new_text": null,
          "old_line_content": "    if (attr_value.isa<SymbolRefAttr>()) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 267,
          "old_api": "attr_value.dyn_cast<ArrayAttr>()",
          "new_api": null,
          "old_text": "attr_value.dyn_cast<ArrayAttr>()",
          "new_text": null,
          "old_line_content": "    } else if (auto array_attr = attr_value.dyn_cast<ArrayAttr>()) {",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 268,
          "old_api": "begin",
          "new_api": null,
          "old_text": "array_attr.begin()->isa<SymbolRefAttr>()",
          "new_text": null,
          "old_line_content": "      if (!array_attr.empty() && array_attr.begin()->isa<SymbolRefAttr>()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 283,
          "old_api": "value",
          "new_api": null,
          "old_text": "it.value()",
          "new_text": null,
          "old_line_content": "    Value operand = it.value();",
          "new_line_content": "        kind != tensorflow::XlaExpression::Kind::kConstant) {",
          "content_same": false
        },
        {
          "line": 286,
          "old_api": "GetExprForOperand",
          "new_api": null,
          "old_text": "GetExprForOperand(operand, op_, idx)",
          "new_text": null,
          "old_line_content": "    tensorflow::XlaExpression expr = GetExprForOperand(operand, op_, idx);",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 288,
          "old_api": "failure",
          "new_api": null,
          "old_text": "failure()",
          "new_text": null,
          "old_line_content": "    if (kind == tensorflow::XlaExpression::Kind::kInvalid) return failure();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 291,
          "old_api": "emitRemark",
          "new_api": null,
          "old_text": "op_->emitRemark()",
          "new_text": null,
          "old_line_content": "      return op_->emitRemark()",
          "new_line_content": "             << \"skipping legalization due to unsupported type \"",
          "content_same": false
        },
        {
          "line": 294,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "expressions.push_back(expr)",
          "new_text": null,
          "old_line_content": "    expressions.push_back(expr);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 299,
          "old_api": "getType",
          "new_api": null,
          "old_text": "operand.getType()",
          "new_text": null,
          "old_line_content": "             << operand.getType();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 304,
          "old_api": "emitRemark",
          "new_api": null,
          "old_text": "op_->emitRemark()",
          "new_text": null,
          "old_line_content": "      return op_->emitRemark()",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 308,
          "old_api": "emplace_back",
          "new_api": null,
          "old_text": "tensors.emplace_back(\n        device_->GetAllocator(tensorflow::AllocatorAttributes()), expr.dtype(),\n        shape_or.value())",
          "new_text": null,
          "old_line_content": "    tensors.emplace_back(",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 309,
          "old_api": "dtype",
          "new_api": null,
          "old_text": "expr.dtype()",
          "new_text": null,
          "old_line_content": "        device_->GetAllocator(tensorflow::AllocatorAttributes()), expr.dtype(),",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 312,
          "old_api": "back",
          "new_api": null,
          "old_text": "tensors.back()",
          "new_text": null,
          "old_line_content": "    tensorflow::Tensor& tensor = tensors.back();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 313,
          "old_api": "tensorflow::XlaExpression::AssignExpressionToTensor(expr, &tensor)",
          "new_api": null,
          "old_text": "tensorflow::XlaExpression::AssignExpressionToTensor(expr, &tensor)",
          "new_text": null,
          "old_line_content": "    tensorflow::XlaExpression::AssignExpressionToTensor(expr, &tensor);",
          "new_line_content": "LogicalResult Tf2XlaRewriter::LegalizeOp() {",
          "content_same": false
        },
        {
          "line": 321,
          "old_api": "getOperandTypes",
          "new_api": null,
          "old_text": "op_->getOperandTypes()",
          "new_text": null,
          "old_line_content": "  for (Type ty : op_->getOperandTypes()) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 322,
          "old_api": "ty.dyn_cast<ShapedType>()",
          "new_api": null,
          "old_text": "ty.dyn_cast<ShapedType>()",
          "new_text": null,
          "old_line_content": "    auto ranked_ty = ty.dyn_cast<ShapedType>();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 325,
          "old_api": "emitRemark",
          "new_api": null,
          "old_text": "op_->emitRemark()",
          "new_text": null,
          "old_line_content": "      return op_->emitRemark()",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 334,
          "old_api": "GetUniqueName",
          "new_api": null,
          "old_text": "tensorflow::ConvertTFDialectOpToNodeDef(\n      op_, name_mapper_.GetUniqueName(op_),\n      /*ignore_unregistered_attrs=*/true)",
          "new_text": null,
          "old_line_content": "  auto nodedef_or = tensorflow::ConvertTFDialectOpToNodeDef(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 337,
          "old_api": "ok",
          "new_api": null,
          "old_text": "nodedef_or.ok()",
          "new_text": null,
          "old_line_content": "  if (!nodedef_or.ok()) {",
          "new_line_content": "  std::shared_ptr<const tensorflow::NodeProperties> props;",
          "content_same": false
        },
        {
          "line": 345,
          "old_api": "value",
          "new_api": null,
          "old_text": "tensorflow::NodeProperties::CreateFromNodeDef(\n      *nodedef_or.value(),\n      params_.function_library->GetFunctionLibraryDefinition(), &props)",
          "new_text": null,
          "old_line_content": "  tsl::Status status = tensorflow::NodeProperties::CreateFromNodeDef(",
          "new_line_content": "  tensorflow::OpKernel* op_kernel_raw;",
          "content_same": false
        },
        {
          "line": 350,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "status.ToString()",
          "new_text": null,
          "old_line_content": "           << \"failed to create NodeProperties: \" << status.ToString();",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 353,
          "old_api": "CreateKernel",
          "new_api": null,
          "old_text": "params_.function_library->CreateKernel(props, &op_kernel_raw)",
          "new_text": null,
          "old_line_content": "  status = params_.function_library->CreateKernel(props, &op_kernel_raw);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 354,
          "old_api": "ok",
          "new_api": null,
          "old_text": "status.ok()",
          "new_text": null,
          "old_line_content": "  if (!status.ok()) {",
          "new_line_content": "  std::vector<int> required_constants;",
          "content_same": false
        },
        {
          "line": 356,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "status.ToString()",
          "new_text": null,
          "old_line_content": "           << \"failed to create tf2xla kernel: \" << status.ToString();",
          "new_line_content": "      *op_kernel, &required_constants);",
          "content_same": false
        },
        {
          "line": 362,
          "old_api": "tensorflow::XlaOpRegistry::CompileTimeConstantInputs(\n      *op_kernel, &required_constants)",
          "new_api": null,
          "old_text": "tensorflow::XlaOpRegistry::CompileTimeConstantInputs(\n      *op_kernel, &required_constants)",
          "new_text": null,
          "old_line_content": "  status = tensorflow::XlaOpRegistry::CompileTimeConstantInputs(",
          "new_line_content": "  llvm::SmallDenseSet<int> required_consts;",
          "content_same": false
        },
        {
          "line": 364,
          "old_api": "ok",
          "new_api": null,
          "old_text": "status.ok()",
          "new_text": null,
          "old_line_content": "  if (!status.ok()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 365,
          "old_api": "emitRemark",
          "new_api": null,
          "old_text": "op_->emitRemark()",
          "new_text": null,
          "old_line_content": "    return op_->emitRemark()",
          "new_line_content": "  // TensorValue in inputs are backed by tensors which in turn depend on",
          "content_same": false
        },
        {
          "line": 366,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "status.ToString()",
          "new_text": null,
          "old_line_content": "           << \"failed to compute required constants: \" << status.ToString();",
          "new_line_content": "  // expressions. So, pre-allocate them to the required size. Subtle note:",
          "content_same": false
        },
        {
          "line": 370,
          "old_api": "end",
          "new_api": null,
          "old_text": "required_constants.end()",
          "new_text": null,
          "old_line_content": "  required_consts.insert(required_constants.begin(), required_constants.end());",
          "new_line_content": "  std::vector<tensorflow::Tensor> tensors;",
          "content_same": false
        },
        {
          "line": 379,
          "old_api": "getNumOperands",
          "new_api": null,
          "old_text": "op_->getNumOperands()",
          "new_text": null,
          "old_line_content": "  expressions.reserve(op_->getNumOperands());",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 380,
          "old_api": "getNumOperands",
          "new_api": null,
          "old_text": "op_->getNumOperands()",
          "new_text": null,
          "old_line_content": "  tensors.reserve(op_->getNumOperands());",
          "new_line_content": "  params_.inputs = inputs;",
          "content_same": false
        },
        {
          "line": 385,
          "old_api": "failure",
          "new_api": null,
          "old_text": "failure()",
          "new_text": null,
          "old_line_content": "    return failure();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 388,
          "old_api": "get",
          "new_api": null,
          "old_text": "op_kernel.get()",
          "new_text": null,
          "old_line_content": "  params_.op_kernel = op_kernel.get();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 391,
          "old_api": "data",
          "new_api": null,
          "old_text": "output_attr.data()",
          "new_text": null,
          "old_line_content": "  params_.output_attr_array = output_attr.data();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 397,
          "old_api": "Compute",
          "new_api": null,
          "old_text": "device_->Compute(params_.op_kernel, &op_context)",
          "new_text": null,
          "old_line_content": "  device_->Compute(params_.op_kernel, &op_context);",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 400,
          "old_api": "GetCurrentStatus",
          "new_api": null,
          "old_text": "hlo_builder_.GetCurrentStatus()",
          "new_text": null,
          "old_line_content": "  status.Update(hlo_builder_.GetCurrentStatus());",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 401,
          "old_api": "ok",
          "new_api": null,
          "old_text": "status.ok()",
          "new_text": null,
          "old_line_content": "  if (!status.ok()) {",
          "new_line_content": "  FuncOp translated_function;",
          "content_same": false
        },
        {
          "line": 402,
          "old_api": "emitRemark",
          "new_api": null,
          "old_text": "op_->emitRemark()",
          "new_text": null,
          "old_line_content": "    return op_->emitRemark()",
          "new_line_content": "  if (use_tf2xla_hlo_importer_) {",
          "content_same": false
        },
        {
          "line": 403,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "status.ToString()",
          "new_text": null,
          "old_line_content": "           << \"compilation to HLO failed: \" << status.ToString();",
          "new_line_content": "    StatusOr<FuncOp> translated_function_or_status =",
          "content_same": false
        },
        {
          "line": 411,
          "old_api": "CompileWithHloImporter",
          "new_api": null,
          "old_text": "CompileWithHloImporter(op_context)",
          "new_text": null,
          "old_line_content": "        CompileWithHloImporter(op_context);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 412,
          "old_api": "ok",
          "new_api": null,
          "old_text": "translated_function_or_status.ok()",
          "new_text": null,
          "old_line_content": "    if (!translated_function_or_status.ok()) {",
          "new_line_content": "  llvm::SmallVector<Value> output_values;",
          "content_same": false
        },
        {
          "line": 416,
          "old_api": "value",
          "new_api": null,
          "old_text": "translated_function_or_status.value()",
          "new_text": null,
          "old_line_content": "    translated_function = translated_function_or_status.value();",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 420,
          "old_api": "failed",
          "new_api": null,
          "old_text": "failed(\n          GetKernelOutputs(op_context, translated_function, output_values))",
          "new_text": null,
          "old_line_content": "  if (failed(",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 421,
          "old_api": "GetKernelOutputs",
          "new_api": null,
          "old_text": "GetKernelOutputs(op_context, translated_function, output_values)",
          "new_text": null,
          "old_line_content": "          GetKernelOutputs(op_context, translated_function, output_values))) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 422,
          "old_api": "failure",
          "new_api": null,
          "old_text": "failure()",
          "new_text": null,
          "old_line_content": "    return failure();",
          "new_line_content": "tsl::Status Tf2XlaRewriter::CreateUniqueComputationNames(",
          "content_same": false
        },
        {
          "line": 425,
          "old_api": "replaceOp",
          "new_api": null,
          "old_text": "rewriter_.replaceOp(op_, output_values)",
          "new_text": null,
          "old_line_content": "  rewriter_.replaceOp(op_, output_values);",
          "new_line_content": "  std::string new_entry_computation_name = \"\";",
          "content_same": false
        },
        {
          "line": 426,
          "old_api": "success",
          "new_api": null,
          "old_text": "success()",
          "new_text": null,
          "old_line_content": "  return success();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 431,
          "old_api": "proto",
          "new_api": null,
          "old_text": "computation.proto().entry_computation_id()",
          "new_text": null,
          "old_line_content": "  int entry_computation = computation.proto().entry_computation_id();",
          "new_line_content": "        CreateUniqueTranslatedFunctionName(sub_computation.name()));",
          "content_same": false
        },
        {
          "line": 435,
          "old_api": "mutable_proto",
          "new_api": null,
          "old_text": "computation.mutable_proto()->mutable_computations()",
          "new_text": null,
          "old_line_content": "       *computation.mutable_proto()->mutable_computations()) {",
          "new_line_content": "      new_entry_computation_name = renamed_computation;",
          "content_same": false
        },
        {
          "line": 446,
          "old_api": "mutable_proto",
          "new_api": null,
          "old_text": "computation.mutable_proto()->set_entry_computation_name(\n      new_entry_computation_name)",
          "new_text": null,
          "old_line_content": "  computation.mutable_proto()->set_entry_computation_name(",
          "new_line_content": "    tensorflow::OpKernelContext& op_context) {",
          "content_same": false
        },
        {
          "line": 449,
          "old_api": "tsl::OkStatus()",
          "new_api": null,
          "old_text": "tsl::OkStatus()",
          "new_text": null,
          "old_line_content": "  return tsl::OkStatus();",
          "new_line_content": "        \"Cannot compile with HloImporter because it isn't supported\");",
          "content_same": false
        },
        {
          "line": 462,
          "old_api": "getNumResults",
          "new_api": null,
          "old_text": "op_->getNumResults()",
          "new_text": null,
          "old_line_content": "  for (int i = 0, e = op_->getNumResults(); i < e; i++) {",
          "new_line_content": "  absl::Span<const xla::XlaOp> return_values(output_values);",
          "content_same": false
        },
        {
          "line": 465,
          "old_api": "tensorflow::XlaExpression::CastExpressionFromTensor(*output)",
          "new_api": null,
          "old_text": "tensorflow::XlaExpression::CastExpressionFromTensor(*output)",
          "new_text": null,
          "old_line_content": "        tensorflow::XlaExpression::CastExpressionFromTensor(*output);",
          "new_line_content": "  TF_ASSIGN_OR_RETURN(XlaComputation computation,",
          "content_same": false
        },
        {
          "line": 466,
          "old_api": "AsXlaOp",
          "new_api": null,
          "old_text": "expr->AsXlaOp(&xla_builder_)",
          "new_text": null,
          "old_line_content": "    output_values.push_back(expr->AsXlaOp(&xla_builder_));",
          "new_line_content": "                      xla_builder_.Build(root_value,",
          "content_same": false
        },
        {
          "line": 477,
          "old_api": "ImportXlaComputation",
          "new_api": null,
          "old_text": "ImportXlaComputation(computation)",
          "new_text": null,
          "old_line_content": "  return ImportXlaComputation(computation);",
          "new_line_content": "    const tensorflow::XlaExpression* expr =",
          "content_same": false
        },
        {
          "line": 483,
          "old_api": "mutable_output",
          "new_api": null,
          "old_text": "op_context.mutable_output(i)",
          "new_text": null,
          "old_line_content": "    tensorflow::Tensor* output = op_context.mutable_output(i);",
          "new_line_content": "          \"expects XlaExpression of kind kXlaOp or kConstant in compiled \"",
          "content_same": false
        },
        {
          "line": 485,
          "old_api": "tensorflow::XlaExpression::CastExpressionFromTensor(*output)",
          "new_api": null,
          "old_text": "tensorflow::XlaExpression::CastExpressionFromTensor(*output)",
          "new_text": null,
          "old_line_content": "        tensorflow::XlaExpression::CastExpressionFromTensor(*output);",
          "new_line_content": "          i));",
          "content_same": false
        },
        {
          "line": 487,
          "old_api": "kind",
          "new_api": null,
          "old_text": "expr->kind()",
          "new_text": null,
          "old_line_content": "    if (expr->kind() != tensorflow::XlaExpression::Kind::kXlaOp &&",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 489,
          "old_api": "absl::StrCat(\n          \"expects XlaExpression of kind kXlaOp or kConstant in compiled \"\n          \"output index \",\n          i)",
          "new_api": null,
          "old_text": "absl::StrCat(\n          \"expects XlaExpression of kind kXlaOp or kConstant in compiled \"\n          \"output index \",\n          i)",
          "new_text": null,
          "old_line_content": "      return op_->emitRemark(absl::StrCat(",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 495,
          "old_api": "success",
          "new_api": null,
          "old_text": "success()",
          "new_text": null,
          "old_line_content": "  return success();",
          "new_line_content": "    mlir::func::FuncOp translated_function) {",
          "content_same": false
        },
        {
          "line": 503,
          "old_api": "getBlocks",
          "new_api": null,
          "old_text": "translated_function.getBlocks().size()",
          "new_text": null,
          "old_line_content": "  if (translated_function.getBlocks().size() != 1) {",
          "new_line_content": "  if (!xla_return_op) {",
          "content_same": false
        },
        {
          "line": 509,
          "old_api": "back",
          "new_api": null,
          "old_text": "translated_function.back().getTerminator()",
          "new_text": null,
          "old_line_content": "      translated_function.back().getTerminator());",
          "new_line_content": "  }",
          "content_same": false
        }
      ]
    },
    "api_summary": {
      "total_replacements": 78,
      "total_additions": 111,
      "total_deletions": 112,
      "total_api_changes": 301
    },
    "non_api_changes": {
      "has_non_api_changes": true,
      "evidence": {
        "total_diff_lines": 7,
        "api_related_lines": 301,
        "non_api_lines": 6,
        "non_api_line_numbers": [
          178,
          179,
          180,
          181,
          183,
          184
        ]
      }
    },
    "api_calls_before": 276,
    "api_calls_after": 275,
    "diff_info": {
      "added_lines": 0,
      "removed_lines": 7,
      "total_diff_lines": 19
    }
  }
}