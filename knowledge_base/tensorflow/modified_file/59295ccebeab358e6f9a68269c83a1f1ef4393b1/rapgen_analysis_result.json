{
  "status": "completed",
  "commit_dir": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/59295ccebeab358e6f9a68269c83a1f1ef4393b1",
  "file_info": {
    "before_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/59295ccebeab358e6f9a68269c83a1f1ef4393b1/before.cc",
    "after_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/59295ccebeab358e6f9a68269c83a1f1ef4393b1/after.cc",
    "diff_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/59295ccebeab358e6f9a68269c83a1f1ef4393b1/diff.txt"
  },
  "semgrep_analysis": {
    "is_api_change": false,
    "api_changes": {
      "replacements": [
        {
          "line": 3253,
          "old_api": "ToString",
          "new_api": "ReductionCodegenInfo",
          "old_text": "unnested_hlo->ToString()",
          "new_text": "ReductionCodegenInfo(mapping_scheme,\n                              reduction_dimensions.is_row_reduction)",
          "old_line_content": "  VLOG(10) << \"Emitting reduction to vector \" << unnested_hlo->ToString();",
          "new_line_content": "  return ReductionCodegenInfo(mapping_scheme,",
          "content_same": false
        },
        {
          "line": 3261,
          "old_api": "size",
          "new_api": "ToString",
          "old_text": "output_instructions.size()",
          "new_text": "unnested_hlo->ToString()",
          "old_line_content": "  for (int i = 0; i < output_instructions.size(); ++i) {",
          "new_line_content": "  VLOG(10) << \"Emitting reduction to vector \" << unnested_hlo->ToString();",
          "content_same": false
        },
        {
          "line": 3269,
          "old_api": "push_back",
          "new_api": "size",
          "old_text": "reduction_output_shape_indices.push_back(idx)",
          "new_text": "output_instructions.size()",
          "old_line_content": "    reduction_output_shape_indices.push_back(idx);",
          "new_line_content": "  for (int i = 0; i < output_instructions.size(); ++i) {",
          "content_same": false
        },
        {
          "line": 3270,
          "old_api": "to_apply",
          "new_api": "IsReductionFromOrToContiguousDimensions",
          "old_text": "output_instruction->to_apply()",
          "new_text": "IsReductionFromOrToContiguousDimensions(*output_instructions[i])",
          "old_line_content": "    reducers.push_back(output_instruction->to_apply());",
          "new_line_content": "    if (!IsReductionFromOrToContiguousDimensions(*output_instructions[i])) {",
          "content_same": false
        },
        {
          "line": 3277,
          "old_api": "at",
          "new_api": "push_back",
          "old_text": "reduce_instructions.at(0)",
          "new_text": "reduction_output_shape_indices.push_back(idx)",
          "old_line_content": "  const HloInstruction* first_reduce = reduce_instructions.at(0);",
          "new_line_content": "    reduction_output_shape_indices.push_back(idx);",
          "content_same": false
        },
        {
          "line": 3278,
          "old_api": "size",
          "new_api": "to_apply",
          "old_text": "output_instructions.size()",
          "new_text": "output_instruction->to_apply()",
          "old_line_content": "  if (output_instructions.size() > 1) {",
          "new_line_content": "    reducers.push_back(output_instruction->to_apply());",
          "content_same": false
        },
        {
          "line": 3281,
          "old_api": "InternalError",
          "new_api": "BuildInitializerThunk",
          "old_text": "InternalError(\"Inconsistent reduction fusion outputs\")",
          "new_text": "BuildInitializerThunk(unnested_hlo, idx)",
          "old_line_content": "      return InternalError(\"Inconsistent reduction fusion outputs\");",
          "new_line_content": "                        BuildInitializerThunk(unnested_hlo, idx));",
          "content_same": false
        },
        {
          "line": 3287,
          "old_api": "BuildKernelThunk",
          "new_api": "AreFusedReductionOutputsConsistent",
          "old_text": "BuildKernelThunk(unnested_hlo, /*implements_whole_instruction=*/false)",
          "new_text": "AreFusedReductionOutputsConsistent(output_instructions,\n                                            first_reduce)",
          "old_line_content": "      BuildKernelThunk(unnested_hlo, /*implements_whole_instruction=*/false);",
          "new_line_content": "    if (!AreFusedReductionOutputsConsistent(output_instructions,",
          "content_same": false
        },
        {
          "line": 3289,
          "old_api": "operand",
          "new_api": "InternalError",
          "old_text": "first_reduce->operand(0)->shape()",
          "new_text": "InternalError(\"Inconsistent reduction fusion outputs\")",
          "old_line_content": "  const Shape& input_shape = first_reduce->operand(0)->shape();",
          "new_line_content": "      return InternalError(\"Inconsistent reduction fusion outputs\");",
          "content_same": false
        },
        {
          "line": 3297,
          "old_api": "ComputeReductionCodegenInfo",
          "new_api": "operand",
          "old_text": "ComputeReductionCodegenInfo(unnested_hlo, first_reduce)",
          "new_text": "first_reduce->operand(0)->shape()",
          "old_line_content": "      ComputeReductionCodegenInfo(unnested_hlo, first_reduce);",
          "new_line_content": "  const Shape& input_shape = first_reduce->operand(0)->shape();",
          "content_same": false
        },
        {
          "line": 3300,
          "old_api": "GetNumberOfBlocks",
          "new_api": "has_layout",
          "old_text": "mapping_scheme.GetNumberOfBlocks()",
          "new_text": "input_shape.has_layout()",
          "old_line_content": "  LaunchDimensions launch_dimensions(mapping_scheme.GetNumberOfBlocks(),",
          "new_line_content": "  CHECK(input_shape.has_layout()) << \"LayoutAssignment or InstructionFusion \"",
          "content_same": false
        },
        {
          "line": 3302,
          "old_api": "launch_bound",
          "new_api": "ToString",
          "old_text": "GetIndexTypeForKernel(\n      unnested_hlo, launch_dimensions.launch_bound(), &b_)",
          "new_text": "first_reduce->ToString()",
          "old_line_content": "  llvm::Type* index_ty = GetIndexTypeForKernel(",
          "new_line_content": "                                  << first_reduce->ToString();",
          "content_same": false
        },
        {
          "line": 3309,
          "old_api": "EmitTileElementForReduction",
          "new_api": "GetThreadsPerBlock",
          "old_text": "EmitTileElementForReduction(unnested_hlo, input_shape,\n                                    output_instructions, index, reduction_info,\n                                    reducers, x_iter_num)",
          "new_text": "mapping_scheme.GetThreadsPerBlock()",
          "old_line_content": "        EmitTileElementForReduction(unnested_hlo, input_shape,",
          "new_line_content": "                                     mapping_scheme.GetThreadsPerBlock());",
          "content_same": false
        },
        {
          "line": 3322,
          "old_api": "EmitEpilogueForReduction",
          "new_api": "GetKernelMappingScheme",
          "old_text": "EmitEpilogueForReduction(index_ty, unnested_hlo, reduction_info,\n                           reduce_instructions, reduction_output_shape_indices,\n                           reducers, tiling_kernel_info)",
          "new_text": "EmitTilingKernel(\n      mapping_scheme, index_ty,\n      [&](const ThreadIdInfo& thread_id_info, const IrArray::Index& index,\n          const string& loop_name, llvm::Value* tile_height,\n          llvm::Value* tile_width, KernelSupportLibrary* ksl) {\n        EmitTile(reduction_info.GetKernelMappingScheme(), index, loop_name, ksl,\n                 thread_id_info, tile_height, tile_width, emit_reduction_tile);\n      })",
          "old_line_content": "  EmitEpilogueForReduction(index_ty, unnested_hlo, reduction_info,",
          "new_line_content": "  TilingKernelInfo tiling_kernel_info = EmitTilingKernel(",
          "content_same": false
        },
        {
          "line": 3327,
          "old_api": "llvm_module",
          "new_api": "GetKernelMappingScheme",
          "old_text": "ir_emitter_context_->llvm_module()",
          "new_text": "reduction_info.GetKernelMappingScheme()",
          "old_line_content": "                         ir_emitter_context_->llvm_module());",
          "new_line_content": "        EmitTile(reduction_info.GetKernelMappingScheme(), index, loop_name, ksl,",
          "content_same": false
        },
        {
          "line": 3334,
          "old_api": "Status::OK()",
          "new_api": "get",
          "old_text": "Status::OK()",
          "new_text": "kernel_thunk.get()",
          "old_line_content": "  return Status::OK();",
          "new_line_content": "  UpdateLaunchDimensions(launch_dimensions, kernel_thunk.get(),",
          "content_same": false
        },
        {
          "line": 3339,
          "old_api": "Allocations",
          "new_api": "std::move(thunks)",
          "old_text": "ir_emitter_context_->buffer_assignment().Allocations()",
          "new_text": "std::move(thunks)",
          "old_line_content": "       ir_emitter_context_->buffer_assignment().Allocations()) {",
          "new_line_content": "      absl::make_unique<SequentialThunk>(std::move(thunks), unnested_hlo);",
          "content_same": false
        },
        {
          "line": 3340,
          "old_api": "is_constant",
          "new_api": "std::move(sequential_thunk)",
          "old_text": "allocation.is_constant()",
          "new_text": "std::move(sequential_thunk)",
          "old_line_content": "    if (!allocation.is_constant()) {",
          "new_line_content": "  AddThunkToThunkSequence(std::move(sequential_thunk));",
          "content_same": false
        },
        {
          "line": 3347,
          "old_api": "size",
          "new_api": "Allocations",
          "old_text": "allocation.size()",
          "new_text": "ir_emitter_context_->buffer_assignment().Allocations()",
          "old_line_content": "        llvm::ArrayType::get(b_.getInt8Ty(), allocation.size());",
          "new_line_content": "       ir_emitter_context_->buffer_assignment().Allocations()) {",
          "content_same": false
        },
        {
          "line": 3353,
          "old_api": "VLOG",
          "new_api": "ShouldEmitLiteralInLlvmIr",
          "old_text": "VLOG(3)",
          "new_text": "ShouldEmitLiteralInLlvmIr(literal)",
          "old_line_content": "      VLOG(3) << \"Emitted initializer for constant with shape \"",
          "new_line_content": "    const bool should_emit_initializer = ShouldEmitLiteralInLlvmIr(literal);",
          "content_same": false
        },
        {
          "line": 3410,
          "old_api": "operands",
          "new_api": "ToString",
          "old_text": "slice_or_tuple->operands()",
          "new_text": "unnested_hlo->ToString()",
          "old_line_content": "    return slice_or_tuple->operands();",
          "new_line_content": "  VLOG(10) << \"Emitting slice input fusion for \" << unnested_hlo->ToString();",
          "content_same": false
        },
        {
          "line": 3417,
          "old_api": "GetGeneratorForOperandIrArrays",
          "new_api": "opcode",
          "old_text": "GetGeneratorForOperandIrArrays(unnested_hlo)",
          "new_text": "slice_or_tuple->opcode()",
          "old_line_content": "  FusedIrEmitter fused_emitter(GetGeneratorForOperandIrArrays(unnested_hlo),",
          "new_line_content": "    CHECK_EQ(slice_or_tuple->opcode(), HloOpcode::kTuple);",
          "content_same": false
        },
        {
          "line": 3427,
          "old_api": "size",
          "new_api": "fused_expression_root",
          "old_text": "slice_instructions.size()",
          "new_text": "unnested_hlo->fused_expression_root()->Accept(&fused_emitter)",
          "old_line_content": "  for (int64 i = 0; i < slice_instructions.size(); ++i) {",
          "new_line_content": "  TF_CHECK_OK(unnested_hlo->fused_expression_root()->Accept(&fused_emitter));",
          "content_same": false
        },
        {
          "line": 3435,
          "old_api": "multidim",
          "new_api": "size",
          "old_text": "index.multidim()",
          "new_text": "slice_instructions.size()",
          "old_line_content": "          index.multidim()[dim],",
          "new_line_content": "  for (int64 i = 0; i < slice_instructions.size(); ++i) {",
          "content_same": false
        },
        {
          "line": 3441,
          "old_api": "CreateAnd",
          "new_api": "slice_strides",
          "old_text": "b_.CreateAnd(larger_or_equal_than_start, smaller_than_limit)",
          "new_text": "slice->slice_strides(dim)",
          "old_line_content": "          b_.CreateAnd(larger_or_equal_than_start, smaller_than_limit);",
          "new_line_content": "      CHECK_EQ(slice->slice_strides(dim), 1);",
          "content_same": false
        },
        {
          "line": 3442,
          "old_api": "push_back",
          "new_api": "CreateICmpSGE",
          "old_text": "index_within_ranges.push_back(within_range)",
          "new_text": "b_.CreateICmpSGE(\n          index.multidim()[dim],\n          index.GetConstantWithIndexType(slice->slice_starts(dim)))",
          "old_line_content": "      index_within_ranges.push_back(within_range);",
          "new_line_content": "      auto larger_or_equal_than_start = b_.CreateICmpSGE(",
          "content_same": false
        },
        {
          "line": 3444,
          "old_api": "CreateAnd",
          "new_api": "slice_starts",
          "old_text": "b_.CreateAnd(index_within_ranges)",
          "new_text": "slice->slice_starts(dim)",
          "old_line_content": "    llvm::Value* guarding_cond = b_.CreateAnd(index_within_ranges);",
          "new_line_content": "          index.GetConstantWithIndexType(slice->slice_starts(dim)));",
          "content_same": false
        },
        {
          "line": 3447,
          "old_api": "multidim",
          "new_api": "slice_limits",
          "old_text": "index.multidim()",
          "new_text": "slice->slice_limits(dim)",
          "old_line_content": "      const std::vector<llvm::Value*>& src_multidim = index.multidim();",
          "new_line_content": "          index.GetConstantWithIndexType(slice->slice_limits(dim)));",
          "content_same": false
        },
        {
          "line": 3449,
          "old_api": "size",
          "new_api": "CreateAnd",
          "old_text": "src_multidim.size()",
          "new_text": "b_.CreateAnd(larger_or_equal_than_start, smaller_than_limit)",
          "old_line_content": "      for (size_t dim = 0; dim < src_multidim.size(); ++dim) {",
          "new_line_content": "          b_.CreateAnd(larger_or_equal_than_start, smaller_than_limit);",
          "content_same": false
        },
        {
          "line": 3452,
          "old_api": "slice_starts",
          "new_api": "CreateAnd",
          "old_text": "slice->slice_starts(dim)",
          "new_text": "b_.CreateAnd(index_within_ranges)",
          "old_line_content": "                index.GetConstantWithIndexType(slice->slice_starts(dim)));",
          "new_line_content": "    llvm::Value* guarding_cond = b_.CreateAnd(index_within_ranges);",
          "content_same": false
        },
        {
          "line": 3455,
          "old_api": "ShapeIndex",
          "new_api": "multidim",
          "old_text": "ShapeIndex()",
          "new_text": "index.multidim()",
          "old_line_content": "                                   ? ShapeIndex()",
          "new_line_content": "      const std::vector<llvm::Value*>& src_multidim = index.multidim();",
          "content_same": false
        },
        {
          "line": 3456,
          "old_api": "ShapeIndex",
          "new_api": "size",
          "old_text": "ShapeIndex({i})",
          "new_text": "src_multidim.size()",
          "old_line_content": "                                   : ShapeIndex({i});",
          "new_line_content": "      std::vector<llvm::Value*> dst_multidim(src_multidim.size());",
          "content_same": false
        },
        {
          "line": 3459,
          "old_api": "shape",
          "new_api": "GetConstantWithIndexType",
          "old_text": "slice->shape()",
          "new_text": "Sub(src_multidim[dim],\n                index.GetConstantWithIndexType(slice->slice_starts(dim)))",
          "old_line_content": "      IrArray::Index slice_dst_index(dst_multidim, slice->shape(),",
          "new_line_content": "            Sub(src_multidim[dim],",
          "content_same": false
        },
        {
          "line": 3460,
          "old_api": "GetType",
          "new_api": "slice_starts",
          "old_text": "index.GetType()",
          "new_text": "slice->slice_starts(dim)",
          "old_line_content": "                                     index.GetType());",
          "new_line_content": "                index.GetConstantWithIndexType(slice->slice_starts(dim)));",
          "content_same": false
        },
        {
          "line": 3463,
          "old_api": "CreateStore",
          "new_api": "ShapeIndex",
          "old_text": "b_.CreateStore(input_ir_values[i], dst_addr)",
          "new_text": "ShapeIndex()",
          "old_line_content": "      b_.CreateStore(input_ir_values[i], dst_addr);",
          "new_line_content": "                                   ? ShapeIndex()",
          "content_same": false
        },
        {
          "line": 3466,
          "old_api": "StrCat",
          "new_api": "GetIrArray",
          "old_text": "StrCat(\"slice\", i)",
          "new_text": "GetIrArray(*unnested_hlo, *unnested_hlo, shape_index)",
          "old_line_content": "    ksl.If(StrCat(\"slice\", i), guarding_cond, emit_slice_elem_func);",
          "new_line_content": "          GetIrArray(*unnested_hlo, *unnested_hlo, shape_index);",
          "content_same": false
        },
        {
          "line": 3480,
          "old_api": "get",
          "new_api": "constexpr",
          "old_text": "kernel_thunk.get()",
          "new_text": "constexpr",
          "old_line_content": "  UpdateLaunchDimensions(launch_dimensions, kernel_thunk.get(),",
          "new_line_content": "  constexpr int unroll_factor = 1;",
          "content_same": false
        },
        {
          "line": 3481,
          "old_api": "llvm_module",
          "new_api": "BuildKernelThunk",
          "old_text": "ir_emitter_context_->llvm_module()",
          "new_text": "BuildKernelThunk(\n      unnested_hlo, /*implements_whole_instruction=*/true, unroll_factor)",
          "old_line_content": "                         ir_emitter_context_->llvm_module());",
          "new_line_content": "  std::unique_ptr<KernelThunk> kernel_thunk = BuildKernelThunk(",
          "content_same": false
        },
        {
          "line": 3486,
          "old_api": "EmitElementForInputFusibleSlices",
          "new_api": "device_description",
          "old_text": "EmitElementForInputFusibleSlices(unnested_hlo, index)",
          "new_text": "CalculateLaunchDimensions(\n      element_shape, ir_emitter_context_->device_description(), unroll_factor)",
          "old_line_content": "            EmitElementForInputFusibleSlices(unnested_hlo, index);",
          "new_line_content": "  LaunchDimensions launch_dimensions = CalculateLaunchDimensions(",
          "content_same": false
        },
        {
          "line": 3487,
          "old_api": "Status::OK()",
          "new_api": "device_description",
          "old_text": "Status::OK()",
          "new_text": "ir_emitter_context_->device_description()",
          "old_line_content": "            return Status::OK();",
          "new_line_content": "      element_shape, ir_emitter_context_->device_description(), unroll_factor);",
          "content_same": false
        },
        {
          "line": 3492,
          "old_api": "launch_bound",
          "new_api": "EmitLoop",
          "old_text": "launch_dimensions.launch_bound()",
          "new_text": "ParallelLoopEmitter(\n          [&](const llvm_ir::IrArray::Index index) -> Status {\n            EmitElementForInputFusibleSlices(unnested_hlo, index);\n            return Status::OK();\n          },\n          element_shape, launch_dimensions, &b_)\n          .EmitLoop(IrName(unnested_hlo),\n                    GetIndexTypeForKernel(\n                        unnested_hlo, launch_dimensions.launch_bound(), &b_))",
          "old_line_content": "                        unnested_hlo, launch_dimensions.launch_bound(), &b_));",
          "new_line_content": "      ParallelLoopEmitter(",
          "content_same": false
        },
        {
          "line": 3494,
          "old_api": "std::move(kernel_thunk)",
          "new_api": "EmitElementForInputFusibleSlices",
          "old_text": "std::move(kernel_thunk)",
          "new_text": "EmitElementForInputFusibleSlices(unnested_hlo, index)",
          "old_line_content": "  thunk_sequence_->emplace_back(std::move(kernel_thunk));",
          "new_line_content": "            EmitElementForInputFusibleSlices(unnested_hlo, index);",
          "content_same": false
        }
      ],
      "additions": [
        {
          "line": 3457,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "src_multidim.size()",
          "old_line_content": "      llvm_ir::IrArray src_ir_array =",
          "new_line_content": "      for (size_t dim = 0; dim < src_multidim.size(); ++dim) {",
          "content_same": false
        },
        {
          "line": 3330,
          "old_api": null,
          "new_api": "EmitEpilogueForReduction",
          "old_text": null,
          "new_text": "EmitEpilogueForReduction(index_ty, unnested_hlo, reduction_info,\n                           reduce_instructions, reduction_output_shape_indices,\n                           reducers, tiling_kernel_info)",
          "old_line_content": "  auto sequential_thunk =",
          "new_line_content": "  EmitEpilogueForReduction(index_ty, unnested_hlo, reduction_info,",
          "content_same": false
        },
        {
          "line": 3462,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "slice_or_tuple->opcode()",
          "old_line_content": "          slice_dst_index, &b_, \"slice.dest\");",
          "new_line_content": "      ShapeIndex shape_index = (slice_or_tuple->opcode() == HloOpcode::kSlice)",
          "content_same": false
        },
        {
          "line": 3335,
          "old_api": null,
          "new_api": "llvm_module",
          "old_text": null,
          "new_text": "ir_emitter_context_->llvm_module()",
          "old_line_content": "}",
          "new_line_content": "                         ir_emitter_context_->llvm_module());",
          "content_same": false
        },
        {
          "line": 3464,
          "old_api": null,
          "new_api": "ShapeIndex",
          "old_text": null,
          "new_text": "ShapeIndex({i})",
          "old_line_content": "    };",
          "new_line_content": "                                   : ShapeIndex({i});",
          "content_same": false
        },
        {
          "line": 3337,
          "old_api": null,
          "new_api": "std::move(kernel_thunk)",
          "old_text": null,
          "new_text": "std::move(kernel_thunk)",
          "old_line_content": "Status IrEmitterUnnested::EmitConstantGlobals() {",
          "new_line_content": "  thunks.push_back(std::move(kernel_thunk));",
          "content_same": false
        },
        {
          "line": 3210,
          "old_api": null,
          "new_api": "IsUnrollingColumnReductionBeneficial",
          "old_text": null,
          "new_text": "IsUnrollingColumnReductionBeneficial(\n                   unnested_hlo, input_shape,\n                   reduction_dimensions.dimensions[2])",
          "old_line_content": "  if (indexing_order == kLinearIndexingX &&",
          "new_line_content": "    } else if (IsUnrollingColumnReductionBeneficial(",
          "content_same": false
        },
        {
          "line": 3467,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "slice->shape()",
          "old_line_content": "  }",
          "new_line_content": "      IrArray::Index slice_dst_index(dst_multidim, slice->shape(),",
          "content_same": false
        },
        {
          "line": 3468,
          "old_api": null,
          "new_api": "GetType",
          "old_text": null,
          "new_text": "index.GetType()",
          "old_line_content": "}",
          "new_line_content": "                                     index.GetType());",
          "content_same": false
        },
        {
          "line": 3469,
          "old_api": null,
          "new_api": "EmitArrayElementAddress",
          "old_text": null,
          "new_text": "src_ir_array.EmitArrayElementAddress(\n          slice_dst_index, &b_, \"slice.dest\")",
          "old_line_content": "",
          "new_line_content": "      llvm::Value* dst_addr = src_ir_array.EmitArrayElementAddress(",
          "content_same": false
        },
        {
          "line": 3342,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "    }",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 3471,
          "old_api": null,
          "new_api": "CreateStore",
          "old_text": null,
          "new_text": "b_.CreateStore(input_ir_values[i], dst_addr)",
          "old_line_content": "    HloInstruction* unnested_hlo) {",
          "new_line_content": "      b_.CreateStore(input_ir_values[i], dst_addr);",
          "content_same": false
        },
        {
          "line": 3474,
          "old_api": null,
          "new_api": "StrCat",
          "old_text": null,
          "new_text": "StrCat(\"slice\", i)",
          "old_line_content": "      unnested_hlo, /*implements_whole_instruction=*/true, unroll_factor);",
          "new_line_content": "    ksl.If(StrCat(\"slice\", i), guarding_cond, emit_slice_elem_func);",
          "content_same": false
        },
        {
          "line": 3348,
          "old_api": null,
          "new_api": "is_constant",
          "old_text": null,
          "new_text": "allocation.is_constant()",
          "old_line_content": "    llvm::Constant* initializer =",
          "new_line_content": "    if (!allocation.is_constant()) {",
          "content_same": false
        },
        {
          "line": 3352,
          "old_api": null,
          "new_api": "llvm_ir::LiteralForConstantAllocation(allocation)",
          "old_text": null,
          "new_text": "llvm_ir::LiteralForConstantAllocation(allocation)",
          "old_line_content": "    if (should_emit_initializer) {",
          "new_line_content": "    const Literal& literal = llvm_ir::LiteralForConstantAllocation(allocation);",
          "content_same": false
        },
        {
          "line": 3225,
          "old_api": null,
          "new_api": "[&] {\n    if (reduction_dimensions.is_row_reduction) {\n      return std::min(\n          kWarpSize * kWarpSize,\n          RoundUpToNearest(CeilOfRatio(reduction_dimensions.dimensions[2],\n                                       reduction_tiling[2]),\n                           kWarpSize));\n    }\n    return kWarpSize;\n  }()",
          "old_text": null,
          "new_text": "[&] {\n    if (reduction_dimensions.is_row_reduction) {\n      return std::min(\n          kWarpSize * kWarpSize,\n          RoundUpToNearest(CeilOfRatio(reduction_dimensions.dimensions[2],\n                                       reduction_tiling[2]),\n                           kWarpSize));\n    }\n    return kWarpSize;\n  }()",
          "old_line_content": "    return kWarpSize;",
          "new_line_content": "  int64 num_threads_x = [&] {",
          "content_same": false
        },
        {
          "line": 3227,
          "old_api": null,
          "new_api": "std::min(\n          kWarpSize * kWarpSize,\n          RoundUpToNearest(CeilOfRatio(reduction_dimensions.dimensions[2],\n                                       reduction_tiling[2]),\n                           kWarpSize))",
          "old_text": null,
          "new_text": "std::min(\n          kWarpSize * kWarpSize,\n          RoundUpToNearest(CeilOfRatio(reduction_dimensions.dimensions[2],\n                                       reduction_tiling[2]),\n                           kWarpSize))",
          "old_line_content": "",
          "new_line_content": "      return std::min(",
          "content_same": false
        },
        {
          "line": 3355,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "allocation.size()",
          "old_line_content": "    }",
          "new_line_content": "        llvm::ArrayType::get(b_.getInt8Ty(), allocation.size());",
          "content_same": false
        },
        {
          "line": 3229,
          "old_api": null,
          "new_api": "CeilOfRatio",
          "old_text": null,
          "new_text": "CeilOfRatio(reduction_dimensions.dimensions[2],\n                                       reduction_tiling[2])",
          "old_line_content": "",
          "new_line_content": "          RoundUpToNearest(CeilOfRatio(reduction_dimensions.dimensions[2],",
          "content_same": false
        },
        {
          "line": 3358,
          "old_api": null,
          "new_api": "llvm_ir::ConvertLiteralToIrConstant(literal, module_)",
          "old_text": null,
          "new_text": "llvm_ir::ConvertLiteralToIrConstant(literal, module_)",
          "old_line_content": "    // give them an external linkage.  Not all of their uses are visible in",
          "new_line_content": "            ? llvm_ir::ConvertLiteralToIrConstant(literal, module_)",
          "content_same": false
        },
        {
          "line": 3359,
          "old_api": null,
          "new_api": "llvm::ConstantAggregateZero::get(global_type)",
          "old_text": null,
          "new_text": "llvm::ConstantAggregateZero::get(global_type)",
          "old_line_content": "    // the LLVM IR (e.g. TupleThunk) so we can't give then a linkage that",
          "new_line_content": "            : llvm::ConstantAggregateZero::get(global_type);",
          "content_same": false
        },
        {
          "line": 3488,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "kernel_thunk.get()",
          "old_line_content": "          },",
          "new_line_content": "  UpdateLaunchDimensions(launch_dimensions, kernel_thunk.get(),",
          "content_same": false
        },
        {
          "line": 3361,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(3)",
          "old_line_content": "    // to ensure that they stick around even if they're \"unused\".",
          "new_line_content": "      VLOG(3) << \"Emitted initializer for constant with shape \"",
          "content_same": false
        },
        {
          "line": 3362,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "literal.shape()",
          "old_line_content": "    //",
          "new_line_content": "              << ShapeUtil::HumanString(literal.shape());",
          "content_same": false
        },
        {
          "line": 3489,
          "old_api": null,
          "new_api": "llvm_module",
          "old_text": null,
          "new_text": "ir_emitter_context_->llvm_module()",
          "old_line_content": "          element_shape, launch_dimensions, &b_)",
          "new_line_content": "                         ir_emitter_context_->llvm_module());",
          "content_same": false
        },
        {
          "line": 3495,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "            return Status::OK();",
          "content_same": false
        },
        {
          "line": 3498,
          "old_api": null,
          "new_api": "IrName",
          "old_text": null,
          "new_text": "IrName(unnested_hlo)",
          "old_line_content": "",
          "new_line_content": "          .EmitLoop(IrName(unnested_hlo),",
          "content_same": false
        },
        {
          "line": 3243,
          "old_api": null,
          "new_api": "MayPreventVectorization",
          "old_text": null,
          "new_text": "MayPreventVectorization(*unnested_hlo)",
          "old_line_content": "      {reduction_tiling[0], reduction_tiling[1] * num_threads_y, tile_size_x},",
          "new_line_content": "        !MayPreventVectorization(*unnested_hlo)) {",
          "content_same": false
        },
        {
          "line": 3499,
          "old_api": null,
          "new_api": "launch_bound",
          "old_text": null,
          "new_text": "GetIndexTypeForKernel(\n                        unnested_hlo, launch_dimensions.launch_bound(), &b_)",
          "old_line_content": "}  // namespace gpu",
          "new_line_content": "                    GetIndexTypeForKernel(",
          "content_same": false
        },
        {
          "line": 3373,
          "old_api": null,
          "new_api": "llvm_module",
          "old_text": null,
          "new_text": "llvm_ir::GetGlobalMemoryAddressSpace(\n        *ir_emitter_context_->llvm_module())",
          "old_line_content": "        /*AddressSpace=*/global_address_space,",
          "new_line_content": "    unsigned global_address_space = llvm_ir::GetGlobalMemoryAddressSpace(",
          "content_same": false
        },
        {
          "line": 3374,
          "old_api": null,
          "new_api": "llvm_module",
          "old_text": null,
          "new_text": "ir_emitter_context_->llvm_module()",
          "old_line_content": "        /*isExternallyInitialized=*/false);",
          "new_line_content": "        *ir_emitter_context_->llvm_module());",
          "content_same": false
        },
        {
          "line": 3500,
          "old_api": null,
          "new_api": "launch_bound",
          "old_text": null,
          "new_text": "launch_dimensions.launch_bound()",
          "old_line_content": "}  // namespace xla",
          "new_line_content": "                        unnested_hlo, launch_dimensions.launch_bound(), &b_));",
          "content_same": false
        },
        {
          "line": 3502,
          "old_api": null,
          "new_api": "std::move(kernel_thunk)",
          "old_text": null,
          "new_text": "std::move(kernel_thunk)",
          "old_line_content": "",
          "new_line_content": "  thunk_sequence_->emplace_back(std::move(kernel_thunk));",
          "content_same": false
        },
        {
          "line": 3379,
          "old_api": null,
          "new_api": "llvm_ir::ConstantBufferAllocationToGlobalName(allocation)",
          "old_text": null,
          "new_text": "llvm_ir::ConstantBufferAllocationToGlobalName(allocation)",
          "old_line_content": "",
          "new_line_content": "        llvm_ir::ConstantBufferAllocationToGlobalName(allocation),",
          "content_same": false
        },
        {
          "line": 3383,
          "old_api": null,
          "new_api": "setAlignment",
          "old_text": null,
          "new_text": "global_for_const->setAlignment(kConstantBufferAlignBytes)",
          "old_line_content": "// Emits code for slices based on the below structure. An if statement with",
          "new_line_content": "    global_for_const->setAlignment(kConstantBufferAlignBytes);",
          "content_same": false
        },
        {
          "line": 3384,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "ir_emitter_context_->llvm_module()->getGlobalList().push_back(\n        global_for_const)",
          "old_line_content": "// a guarding condition is generated for each ROOT slice.",
          "new_line_content": "    ir_emitter_context_->llvm_module()->getGlobalList().push_back(",
          "content_same": false
        },
        {
          "line": 3260,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "output_instructions.size()",
          "old_line_content": "  std::vector<std::unique_ptr<Thunk>> thunks;",
          "new_line_content": "  bool returns_tuple = output_instructions.size() > 1;",
          "content_same": false
        },
        {
          "line": 3388,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "// Compute values of slice input operands",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 3275,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "reduce_instructions.push_back(output_instruction)",
          "old_line_content": "  }",
          "new_line_content": "    reduce_instructions.push_back(output_instruction);",
          "content_same": false
        },
        {
          "line": 3276,
          "old_api": null,
          "new_api": "ShapeIndex",
          "old_text": null,
          "new_text": "ShapeIndex({})",
          "old_line_content": "",
          "new_line_content": "    ShapeIndex idx = returns_tuple ? ShapeIndex({i}) : ShapeIndex({});",
          "content_same": false
        },
        {
          "line": 3280,
          "old_api": null,
          "new_api": "TF_ASSIGN_OR_RETURN",
          "old_text": null,
          "new_text": "TF_ASSIGN_OR_RETURN(std::unique_ptr<Thunk> initializer_thunk,\n                        BuildInitializerThunk(unnested_hlo, idx))",
          "old_line_content": "                                            first_reduce)) {",
          "new_line_content": "    TF_ASSIGN_OR_RETURN(std::unique_ptr<Thunk> initializer_thunk,",
          "content_same": false
        },
        {
          "line": 3282,
          "old_api": null,
          "new_api": "std::move(initializer_thunk)",
          "old_text": null,
          "new_text": "std::move(initializer_thunk)",
          "old_line_content": "    }",
          "new_line_content": "    thunks.push_back(std::move(initializer_thunk));",
          "content_same": false
        },
        {
          "line": 3412,
          "old_api": null,
          "new_api": "fused_expression_root",
          "old_text": null,
          "new_text": "unnested_hlo->fused_expression_root()",
          "old_line_content": "",
          "new_line_content": "  HloInstruction* slice_or_tuple = unnested_hlo->fused_expression_root();",
          "content_same": false
        },
        {
          "line": 3285,
          "old_api": null,
          "new_api": "at",
          "old_text": null,
          "new_text": "reduce_instructions.at(0)",
          "old_line_content": "  // Build a kernel thunk to compute all the outputs.",
          "new_line_content": "  const HloInstruction* first_reduce = reduce_instructions.at(0);",
          "content_same": false
        },
        {
          "line": 3286,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "output_instructions.size()",
          "old_line_content": "  std::unique_ptr<KernelThunk> kernel_thunk =",
          "new_line_content": "  if (output_instructions.size() > 1) {",
          "content_same": false
        },
        {
          "line": 3413,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "() -> absl::Span<HloInstruction* const> {\n    if (slice_or_tuple->opcode() == HloOpcode::kSlice) {\n      return absl::Span<HloInstruction* const>(&slice_or_tuple, 1);\n    }\n    CHECK_EQ(slice_or_tuple->opcode(), HloOpcode::kTuple);\n    return slice_or_tuple->operands();\n  }()",
          "old_line_content": "  // Emit input operand values of slices.",
          "new_line_content": "  auto slice_instructions = [&]() -> absl::Span<HloInstruction* const> {",
          "content_same": false
        },
        {
          "line": 3414,
          "old_api": null,
          "new_api": "opcode",
          "old_text": null,
          "new_text": "slice_or_tuple->opcode()",
          "old_line_content": "  std::vector<llvm::Value*> input_ir_values;",
          "new_line_content": "    if (slice_or_tuple->opcode() == HloOpcode::kSlice) {",
          "content_same": false
        },
        {
          "line": 3415,
          "old_api": null,
          "new_api": "absl::Span<HloInstruction* const>(&slice_or_tuple, 1)",
          "old_text": null,
          "new_text": "absl::Span<HloInstruction* const>(&slice_or_tuple, 1)",
          "old_line_content": "  GpuElementalIrEmitter elem_emitter(hlo_module_config_, module_, &b_,",
          "new_line_content": "      return absl::Span<HloInstruction* const>(&slice_or_tuple, 1);",
          "content_same": false
        },
        {
          "line": 3418,
          "old_api": null,
          "new_api": "operands",
          "old_text": null,
          "new_text": "slice_or_tuple->operands()",
          "old_line_content": "                               &elem_emitter);",
          "new_line_content": "    return slice_or_tuple->operands();",
          "content_same": false
        },
        {
          "line": 3295,
          "old_api": null,
          "new_api": "BuildKernelThunk",
          "old_text": null,
          "new_text": "BuildKernelThunk(unnested_hlo, /*implements_whole_instruction=*/false)",
          "old_line_content": "",
          "new_line_content": "      BuildKernelThunk(unnested_hlo, /*implements_whole_instruction=*/false);",
          "content_same": false
        },
        {
          "line": 3424,
          "old_api": null,
          "new_api": "GetNestedComputer",
          "old_text": null,
          "new_text": "GetNestedComputer()",
          "old_line_content": "",
          "new_line_content": "                                     GetNestedComputer());",
          "content_same": false
        },
        {
          "line": 3425,
          "old_api": null,
          "new_api": "GetGeneratorForOperandIrArrays",
          "old_text": null,
          "new_text": "GetGeneratorForOperandIrArrays(unnested_hlo)",
          "old_line_content": "  // Emit for slice_instructions.",
          "new_line_content": "  FusedIrEmitter fused_emitter(GetGeneratorForOperandIrArrays(unnested_hlo),",
          "content_same": false
        },
        {
          "line": 3429,
          "old_api": null,
          "new_api": "operand",
          "old_text": null,
          "new_text": "slice->operand(0)",
          "old_line_content": "",
          "new_line_content": "    auto input_generator = fused_emitter.GetGenerator(slice->operand(0));",
          "content_same": false
        },
        {
          "line": 3430,
          "old_api": null,
          "new_api": "ValueOrDie",
          "old_text": null,
          "new_text": "input_generator(index).ValueOrDie()",
          "old_line_content": "    // guarding_cond := index >= start && index < limit, for each dim.",
          "new_line_content": "    input_ir_values.push_back(input_generator(index).ValueOrDie());",
          "content_same": false
        },
        {
          "line": 3305,
          "old_api": null,
          "new_api": "ComputeReductionCodegenInfo",
          "old_text": null,
          "new_text": "ComputeReductionCodegenInfo(unnested_hlo, first_reduce)",
          "old_line_content": "                           index_ty);",
          "new_line_content": "      ComputeReductionCodegenInfo(unnested_hlo, first_reduce);",
          "content_same": false
        },
        {
          "line": 3307,
          "old_api": null,
          "new_api": "GetKernelMappingScheme",
          "old_text": null,
          "new_text": "reduction_info.GetKernelMappingScheme()",
          "old_line_content": "      [&](const llvm_ir::IrArray::Index& index, llvm::Value* y_loc,",
          "new_line_content": "      reduction_info.GetKernelMappingScheme();",
          "content_same": false
        },
        {
          "line": 3308,
          "old_api": null,
          "new_api": "GetNumberOfBlocks",
          "old_text": null,
          "new_text": "mapping_scheme.GetNumberOfBlocks()",
          "old_line_content": "          llvm::Value* x_loc, int64 x_iter_num) {",
          "new_line_content": "  LaunchDimensions launch_dimensions(mapping_scheme.GetNumberOfBlocks(),",
          "content_same": false
        },
        {
          "line": 3310,
          "old_api": null,
          "new_api": "launch_bound",
          "old_text": null,
          "new_text": "GetIndexTypeForKernel(\n      unnested_hlo, launch_dimensions.launch_bound(), &b_)",
          "old_line_content": "                                    output_instructions, index, reduction_info,",
          "new_line_content": "  llvm::Type* index_ty = GetIndexTypeForKernel(",
          "content_same": false
        },
        {
          "line": 3311,
          "old_api": null,
          "new_api": "launch_bound",
          "old_text": null,
          "new_text": "launch_dimensions.launch_bound()",
          "old_line_content": "                                    reducers, x_iter_num);",
          "new_line_content": "      unnested_hlo, launch_dimensions.launch_bound(), &b_);",
          "content_same": false
        },
        {
          "line": 3312,
          "old_api": null,
          "new_api": "EmitPrologueForReduction",
          "old_text": null,
          "new_text": "EmitPrologueForReduction(unnested_hlo, &reduction_info, reduce_instructions,\n                           index_ty)",
          "old_line_content": "      };",
          "new_line_content": "  EmitPrologueForReduction(unnested_hlo, &reduction_info, reduce_instructions,",
          "content_same": false
        },
        {
          "line": 3440,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "slice->slice_starts().size()",
          "old_line_content": "      llvm::Value* within_range =",
          "new_line_content": "    for (size_t dim = 0; dim < slice->slice_starts().size(); ++dim) {",
          "content_same": false
        },
        {
          "line": 3443,
          "old_api": null,
          "new_api": "multidim",
          "old_text": null,
          "new_text": "index.multidim()",
          "old_line_content": "    }",
          "new_line_content": "          index.multidim()[dim],",
          "content_same": false
        },
        {
          "line": 3317,
          "old_api": null,
          "new_api": "EmitTileElementForReduction",
          "old_text": null,
          "new_text": "EmitTileElementForReduction(unnested_hlo, input_shape,\n                                    output_instructions, index, reduction_info,\n                                    reducers, x_iter_num)",
          "old_line_content": "          const string& loop_name, llvm::Value* tile_height,",
          "new_line_content": "        EmitTileElementForReduction(unnested_hlo, input_shape,",
          "content_same": false
        },
        {
          "line": 3445,
          "old_api": null,
          "new_api": "CreateICmpSLT",
          "old_text": null,
          "new_text": "b_.CreateICmpSLT(\n          index.multidim()[dim],\n          index.GetConstantWithIndexType(slice->slice_limits(dim)))",
          "old_line_content": "",
          "new_line_content": "      llvm::Value* smaller_than_limit = b_.CreateICmpSLT(",
          "content_same": false
        },
        {
          "line": 3446,
          "old_api": null,
          "new_api": "multidim",
          "old_text": null,
          "new_text": "index.multidim()",
          "old_line_content": "    auto emit_slice_elem_func = [&] {",
          "new_line_content": "          index.multidim()[dim],",
          "content_same": false
        },
        {
          "line": 3450,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "index_within_ranges.push_back(within_range)",
          "old_line_content": "        dst_multidim[dim] =",
          "new_line_content": "      index_within_ranges.push_back(within_range);",
          "content_same": false
        },
        {
          "line": 3196,
          "old_api": null,
          "new_api": "cuda_compute_capability",
          "old_text": null,
          "new_text": "ir_emitter_context_->device_description().cuda_compute_capability(&cc_major,\n                                                                    &cc_minor)",
          "old_line_content": "    if (reduction_dimensions.is_row_reduction &&",
          "new_line_content": "  ir_emitter_context_->device_description().cuda_compute_capability(&cc_major,",
          "content_same": false
        },
        {
          "line": 3199,
          "old_api": null,
          "new_api": "[&]() {\n    if (reduction_dimensions.is_row_reduction &&\n        // Only try to vectorize+coales memory access for rows of even size.\n        // For odd row sizes, every other row isn't aligned, so it can't be\n        // vectorized.\n        reduction_dimensions.dimensions[2] % 2 == 0 &&\n        // Vectorization on P100 speed up only float16 and smaller\n        // dtype. Vectorization on P100 speed up or do not hurt all\n        // dtypes.\n        ((cc_major == 6 && smallest_input_dtype_bits <= 16) || cc_major >= 7)) {\n      return kLinearStridedIndexingX;\n    } else if (IsUnrollingColumnReductionBeneficial(\n                   unnested_hlo, input_shape,\n                   reduction_dimensions.dimensions[2])) {\n      return kLinearIndexingX;\n    } else {\n      return kStridedIndexingX;\n    }\n  }()",
          "old_text": null,
          "new_text": "[&]() {\n    if (reduction_dimensions.is_row_reduction &&\n        // Only try to vectorize+coales memory access for rows of even size.\n        // For odd row sizes, every other row isn't aligned, so it can't be\n        // vectorized.\n        reduction_dimensions.dimensions[2] % 2 == 0 &&\n        // Vectorization on P100 speed up only float16 and smaller\n        // dtype. Vectorization on P100 speed up or do not hurt all\n        // dtypes.\n        ((cc_major == 6 && smallest_input_dtype_bits <= 16) || cc_major >= 7)) {\n      return kLinearStridedIndexingX;\n    } else if (IsUnrollingColumnReductionBeneficial(\n                   unnested_hlo, input_shape,\n                   reduction_dimensions.dimensions[2])) {\n      return kLinearIndexingX;\n    } else {\n      return kStridedIndexingX;\n    }\n  }()",
          "old_line_content": "        // vectorized.",
          "new_line_content": "  KernelMappingScheme::IndexingOrder indexing_order = [&]() {",
          "content_same": false
        }
      ],
      "deletions": [
        {
          "line": 3329,
          "old_api": "std::move(kernel_thunk)",
          "new_api": null,
          "old_text": "std::move(kernel_thunk)",
          "new_text": null,
          "old_line_content": "  thunks.push_back(std::move(kernel_thunk));",
          "new_line_content": "      });",
          "content_same": false
        },
        {
          "line": 3202,
          "old_api": "IsUnrollingColumnReductionBeneficial",
          "new_api": null,
          "old_text": "IsUnrollingColumnReductionBeneficial(\n                   unnested_hlo, input_shape,\n                   reduction_dimensions.dimensions[2])",
          "new_text": null,
          "old_line_content": "    } else if (IsUnrollingColumnReductionBeneficial(",
          "new_line_content": "        // For odd row sizes, every other row isn't aligned, so it can't be",
          "content_same": false
        },
        {
          "line": 3331,
          "old_api": "std::move(thunks)",
          "new_api": null,
          "old_text": "std::move(thunks)",
          "new_text": null,
          "old_line_content": "      absl::make_unique<SequentialThunk>(std::move(thunks), unnested_hlo);",
          "new_line_content": "                           reduce_instructions, reduction_output_shape_indices,",
          "content_same": false
        },
        {
          "line": 3332,
          "old_api": "std::move(sequential_thunk)",
          "new_api": null,
          "old_text": "std::move(sequential_thunk)",
          "new_text": null,
          "old_line_content": "  AddThunkToThunkSequence(std::move(sequential_thunk));",
          "new_line_content": "                           reducers, tiling_kernel_info);",
          "content_same": false
        },
        {
          "line": 3458,
          "old_api": "GetIrArray",
          "new_api": null,
          "old_text": "GetIrArray(*unnested_hlo, *unnested_hlo, shape_index)",
          "new_text": null,
          "old_line_content": "          GetIrArray(*unnested_hlo, *unnested_hlo, shape_index);",
          "new_line_content": "        dst_multidim[dim] =",
          "content_same": false
        },
        {
          "line": 3461,
          "old_api": "EmitArrayElementAddress",
          "new_api": null,
          "old_text": "src_ir_array.EmitArrayElementAddress(\n          slice_dst_index, &b_, \"slice.dest\")",
          "new_text": null,
          "old_line_content": "      llvm::Value* dst_addr = src_ir_array.EmitArrayElementAddress(",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 3344,
          "old_api": "llvm_ir::LiteralForConstantAllocation(allocation)",
          "new_api": null,
          "old_text": "llvm_ir::LiteralForConstantAllocation(allocation)",
          "new_text": null,
          "old_line_content": "    const Literal& literal = llvm_ir::LiteralForConstantAllocation(allocation);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3217,
          "old_api": "[&] {\n    if (reduction_dimensions.is_row_reduction) {\n      return std::min(\n          kWarpSize * kWarpSize,\n          RoundUpToNearest(CeilOfRatio(reduction_dimensions.dimensions[2],\n                                       reduction_tiling[2]),\n                           kWarpSize));\n    }\n    return kWarpSize;\n  }()",
          "new_api": null,
          "old_text": "[&] {\n    if (reduction_dimensions.is_row_reduction) {\n      return std::min(\n          kWarpSize * kWarpSize,\n          RoundUpToNearest(CeilOfRatio(reduction_dimensions.dimensions[2],\n                                       reduction_tiling[2]),\n                           kWarpSize));\n    }\n    return kWarpSize;\n  }()",
          "new_text": null,
          "old_line_content": "  int64 num_threads_x = [&] {",
          "new_line_content": "  }();",
          "content_same": false
        },
        {
          "line": 3345,
          "old_api": "ShouldEmitLiteralInLlvmIr",
          "new_api": null,
          "old_text": "ShouldEmitLiteralInLlvmIr(literal)",
          "new_text": null,
          "old_line_content": "    const bool should_emit_initializer = ShouldEmitLiteralInLlvmIr(literal);",
          "new_line_content": "Status IrEmitterUnnested::EmitConstantGlobals() {",
          "content_same": false
        },
        {
          "line": 3219,
          "old_api": "std::min(\n          kWarpSize * kWarpSize,\n          RoundUpToNearest(CeilOfRatio(reduction_dimensions.dimensions[2],\n                                       reduction_tiling[2]),\n                           kWarpSize))",
          "new_api": null,
          "old_text": "std::min(\n          kWarpSize * kWarpSize,\n          RoundUpToNearest(CeilOfRatio(reduction_dimensions.dimensions[2],\n                                       reduction_tiling[2]),\n                           kWarpSize))",
          "new_text": null,
          "old_line_content": "      return std::min(",
          "new_line_content": "      !reduction_dimensions.is_row_reduction) {",
          "content_same": false
        },
        {
          "line": 3472,
          "old_api": "constexpr",
          "new_api": null,
          "old_text": "constexpr",
          "new_text": null,
          "old_line_content": "  constexpr int unroll_factor = 1;",
          "new_line_content": "    };",
          "content_same": false
        },
        {
          "line": 3221,
          "old_api": "CeilOfRatio",
          "new_api": null,
          "old_text": "CeilOfRatio(reduction_dimensions.dimensions[2],\n                                       reduction_tiling[2])",
          "new_text": null,
          "old_line_content": "          RoundUpToNearest(CeilOfRatio(reduction_dimensions.dimensions[2],",
          "new_line_content": "    reduction_tiling[2] *= 2;",
          "content_same": false
        },
        {
          "line": 3350,
          "old_api": "llvm_ir::ConvertLiteralToIrConstant(literal, module_)",
          "new_api": null,
          "old_text": "llvm_ir::ConvertLiteralToIrConstant(literal, module_)",
          "new_text": null,
          "old_line_content": "            ? llvm_ir::ConvertLiteralToIrConstant(literal, module_)",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3351,
          "old_api": "llvm::ConstantAggregateZero::get(global_type)",
          "new_api": null,
          "old_text": "llvm::ConstantAggregateZero::get(global_type)",
          "new_text": null,
          "old_line_content": "            : llvm::ConstantAggregateZero::get(global_type);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3473,
          "old_api": "BuildKernelThunk",
          "new_api": null,
          "old_text": "BuildKernelThunk(\n      unnested_hlo, /*implements_whole_instruction=*/true, unroll_factor)",
          "new_text": null,
          "old_line_content": "  std::unique_ptr<KernelThunk> kernel_thunk = BuildKernelThunk(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3478,
          "old_api": "device_description",
          "new_api": null,
          "old_text": "CalculateLaunchDimensions(\n      element_shape, ir_emitter_context_->device_description(), unroll_factor)",
          "new_text": null,
          "old_line_content": "  LaunchDimensions launch_dimensions = CalculateLaunchDimensions(",
          "new_line_content": "Status IrEmitterUnnested::EmitInputFusibleNonStridedSlices(",
          "content_same": false
        },
        {
          "line": 3354,
          "old_api": "shape",
          "new_api": null,
          "old_text": "literal.shape()",
          "new_text": null,
          "old_line_content": "              << ShapeUtil::HumanString(literal.shape());",
          "new_line_content": "    llvm::ArrayType* global_type =",
          "content_same": false
        },
        {
          "line": 3479,
          "old_api": "device_description",
          "new_api": null,
          "old_text": "ir_emitter_context_->device_description()",
          "new_text": null,
          "old_line_content": "      element_shape, ir_emitter_context_->device_description(), unroll_factor);",
          "new_line_content": "    HloInstruction* unnested_hlo) {",
          "content_same": false
        },
        {
          "line": 3484,
          "old_api": "EmitLoop",
          "new_api": null,
          "old_text": "ParallelLoopEmitter(\n          [&](const llvm_ir::IrArray::Index index) -> Status {\n            EmitElementForInputFusibleSlices(unnested_hlo, index);\n            return Status::OK();\n          },\n          element_shape, launch_dimensions, &b_)\n          .EmitLoop(IrName(unnested_hlo),\n                    GetIndexTypeForKernel(\n                        unnested_hlo, launch_dimensions.launch_bound(), &b_))",
          "new_text": null,
          "old_line_content": "      ParallelLoopEmitter(",
          "new_line_content": "  TF_ASSIGN_OR_RETURN(Shape element_shape,",
          "content_same": false
        },
        {
          "line": 3490,
          "old_api": "IrName",
          "new_api": null,
          "old_text": "IrName(unnested_hlo)",
          "new_text": null,
          "old_line_content": "          .EmitLoop(IrName(unnested_hlo),",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3235,
          "old_api": "MayPreventVectorization",
          "new_api": null,
          "old_text": "MayPreventVectorization(*unnested_hlo)",
          "new_text": null,
          "old_line_content": "        !MayPreventVectorization(*unnested_hlo)) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3491,
          "old_api": "launch_bound",
          "new_api": null,
          "old_text": "GetIndexTypeForKernel(\n                        unnested_hlo, launch_dimensions.launch_bound(), &b_)",
          "new_text": null,
          "old_line_content": "                    GetIndexTypeForKernel(",
          "new_line_content": "  Status emit_status =",
          "content_same": false
        },
        {
          "line": 3365,
          "old_api": "llvm_module",
          "new_api": null,
          "old_text": "llvm_ir::GetGlobalMemoryAddressSpace(\n        *ir_emitter_context_->llvm_module())",
          "new_text": null,
          "old_line_content": "    unsigned global_address_space = llvm_ir::GetGlobalMemoryAddressSpace(",
          "new_line_content": "    // These globals will be looked up by name by GpuExecutable so we need to",
          "content_same": false
        },
        {
          "line": 3366,
          "old_api": "llvm_module",
          "new_api": null,
          "old_text": "ir_emitter_context_->llvm_module()",
          "new_text": null,
          "old_line_content": "        *ir_emitter_context_->llvm_module());",
          "new_line_content": "    // give them an external linkage.  Not all of their uses are visible in",
          "content_same": false
        },
        {
          "line": 3371,
          "old_api": "llvm_ir::ConstantBufferAllocationToGlobalName(allocation)",
          "new_api": null,
          "old_text": "llvm_ir::ConstantBufferAllocationToGlobalName(allocation)",
          "new_text": null,
          "old_line_content": "        llvm_ir::ConstantBufferAllocationToGlobalName(allocation),",
          "new_line_content": "    // We may have to be more more clever here in the future if we notice that",
          "content_same": false
        },
        {
          "line": 3245,
          "old_api": "ReductionCodegenInfo",
          "new_api": null,
          "old_text": "ReductionCodegenInfo(mapping_scheme,\n                              reduction_dimensions.is_row_reduction)",
          "new_text": null,
          "old_line_content": "  return ReductionCodegenInfo(mapping_scheme,",
          "new_line_content": "    } else {",
          "content_same": false
        },
        {
          "line": 3375,
          "old_api": "setAlignment",
          "new_api": null,
          "old_text": "global_for_const->setAlignment(kConstantBufferAlignBytes)",
          "new_text": null,
          "old_line_content": "    global_for_const->setAlignment(kConstantBufferAlignBytes);",
          "new_line_content": "    llvm::GlobalVariable* global_for_const = new llvm::GlobalVariable(",
          "content_same": false
        },
        {
          "line": 3376,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "ir_emitter_context_->llvm_module()->getGlobalList().push_back(\n        global_for_const)",
          "new_text": null,
          "old_line_content": "    ir_emitter_context_->llvm_module()->getGlobalList().push_back(",
          "new_line_content": "        global_type, /*isConstant=*/should_emit_initializer,",
          "content_same": false
        },
        {
          "line": 3252,
          "old_api": "size",
          "new_api": null,
          "old_text": "output_instructions.size()",
          "new_text": null,
          "old_line_content": "  bool returns_tuple = output_instructions.size() > 1;",
          "new_line_content": "      num_threads_y, num_threads_x, indexing_order, vector_size);",
          "content_same": false
        },
        {
          "line": 3380,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "  return Status::OK();",
          "new_line_content": "        /*TLMode=*/llvm::GlobalValue::NotThreadLocal,",
          "content_same": false
        },
        {
          "line": 3262,
          "old_api": "IsReductionFromOrToContiguousDimensions",
          "new_api": null,
          "old_text": "IsReductionFromOrToContiguousDimensions(*output_instructions[i])",
          "new_text": null,
          "old_line_content": "    if (!IsReductionFromOrToContiguousDimensions(*output_instructions[i])) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3267,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "reduce_instructions.push_back(output_instruction)",
          "new_text": null,
          "old_line_content": "    reduce_instructions.push_back(output_instruction);",
          "new_line_content": "  // Build an initializer thunk to initialize each reduction output.",
          "content_same": false
        },
        {
          "line": 3268,
          "old_api": "ShapeIndex",
          "new_api": null,
          "old_text": "ShapeIndex({})",
          "new_text": null,
          "old_line_content": "    ShapeIndex idx = returns_tuple ? ShapeIndex({i}) : ShapeIndex({});",
          "new_line_content": "  std::vector<std::unique_ptr<Thunk>> thunks;",
          "content_same": false
        },
        {
          "line": 3272,
          "old_api": "TF_ASSIGN_OR_RETURN",
          "new_api": null,
          "old_text": "TF_ASSIGN_OR_RETURN(std::unique_ptr<Thunk> initializer_thunk,\n                        BuildInitializerThunk(unnested_hlo, idx))",
          "new_text": null,
          "old_line_content": "    TF_ASSIGN_OR_RETURN(std::unique_ptr<Thunk> initializer_thunk,",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3273,
          "old_api": "BuildInitializerThunk",
          "new_api": null,
          "old_text": "BuildInitializerThunk(unnested_hlo, idx)",
          "new_text": null,
          "old_line_content": "                        BuildInitializerThunk(unnested_hlo, idx));",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3274,
          "old_api": "std::move(initializer_thunk)",
          "new_api": null,
          "old_text": "std::move(initializer_thunk)",
          "new_text": null,
          "old_line_content": "    thunks.push_back(std::move(initializer_thunk));",
          "new_line_content": "    HloInstruction* output_instruction = output_instructions[i];",
          "content_same": false
        },
        {
          "line": 3402,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "unnested_hlo->ToString()",
          "new_text": null,
          "old_line_content": "  VLOG(10) << \"Emitting slice input fusion for \" << unnested_hlo->ToString();",
          "new_line_content": "//",
          "content_same": false
        },
        {
          "line": 3404,
          "old_api": "fused_expression_root",
          "new_api": null,
          "old_text": "unnested_hlo->fused_expression_root()",
          "new_text": null,
          "old_line_content": "  HloInstruction* slice_or_tuple = unnested_hlo->fused_expression_root();",
          "new_line_content": "// if (guarding_cond1) {",
          "content_same": false
        },
        {
          "line": 3405,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "() -> absl::Span<HloInstruction* const> {\n    if (slice_or_tuple->opcode() == HloOpcode::kSlice) {\n      return absl::Span<HloInstruction* const>(&slice_or_tuple, 1);\n    }\n    CHECK_EQ(slice_or_tuple->opcode(), HloOpcode::kTuple);\n    return slice_or_tuple->operands();\n  }()",
          "new_text": null,
          "old_line_content": "  auto slice_instructions = [&]() -> absl::Span<HloInstruction* const> {",
          "new_line_content": "//   Write to output of slice1",
          "content_same": false
        },
        {
          "line": 3406,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "slice_or_tuple->opcode()",
          "new_text": null,
          "old_line_content": "    if (slice_or_tuple->opcode() == HloOpcode::kSlice) {",
          "new_line_content": "// }",
          "content_same": false
        },
        {
          "line": 3279,
          "old_api": "AreFusedReductionOutputsConsistent",
          "new_api": null,
          "old_text": "AreFusedReductionOutputsConsistent(output_instructions,\n                                            first_reduce)",
          "new_text": null,
          "old_line_content": "    if (!AreFusedReductionOutputsConsistent(output_instructions,",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3407,
          "old_api": "absl::Span<HloInstruction* const>(&slice_or_tuple, 1)",
          "new_api": null,
          "old_text": "absl::Span<HloInstruction* const>(&slice_or_tuple, 1)",
          "new_text": null,
          "old_line_content": "      return absl::Span<HloInstruction* const>(&slice_or_tuple, 1);",
          "new_line_content": "//",
          "content_same": false
        },
        {
          "line": 3409,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "slice_or_tuple->opcode()",
          "new_text": null,
          "old_line_content": "    CHECK_EQ(slice_or_tuple->opcode(), HloOpcode::kTuple);",
          "new_line_content": "    HloInstruction* unnested_hlo, const llvm_ir::IrArray::Index& index) {",
          "content_same": false
        },
        {
          "line": 3451,
          "old_api": "GetConstantWithIndexType",
          "new_api": null,
          "old_text": "Sub(src_multidim[dim],\n                index.GetConstantWithIndexType(slice->slice_starts(dim)))",
          "new_text": null,
          "old_line_content": "            Sub(src_multidim[dim],",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3416,
          "old_api": "GetNestedComputer",
          "new_api": null,
          "old_text": "GetNestedComputer()",
          "new_text": null,
          "old_line_content": "                                     GetNestedComputer());",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 3419,
          "old_api": "fused_expression_root",
          "new_api": null,
          "old_text": "unnested_hlo->fused_expression_root()->Accept(&fused_emitter)",
          "new_text": null,
          "old_line_content": "  TF_CHECK_OK(unnested_hlo->fused_expression_root()->Accept(&fused_emitter));",
          "new_line_content": "  }();",
          "content_same": false
        },
        {
          "line": 3292,
          "old_api": "has_layout",
          "new_api": null,
          "old_text": "input_shape.has_layout()",
          "new_text": null,
          "old_line_content": "  CHECK(input_shape.has_layout()) << \"LayoutAssignment or InstructionFusion \"",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3421,
          "old_api": "operand",
          "new_api": null,
          "old_text": "slice->operand(0)",
          "new_text": null,
          "old_line_content": "    auto input_generator = fused_emitter.GetGenerator(slice->operand(0));",
          "new_line_content": "  // Emit input operand values of slices.",
          "content_same": false
        },
        {
          "line": 3294,
          "old_api": "ToString",
          "new_api": null,
          "old_text": "first_reduce->ToString()",
          "new_text": null,
          "old_line_content": "                                  << first_reduce->ToString();",
          "new_line_content": "  std::unique_ptr<KernelThunk> kernel_thunk =",
          "content_same": false
        },
        {
          "line": 3422,
          "old_api": "ValueOrDie",
          "new_api": null,
          "old_text": "input_generator(index).ValueOrDie()",
          "new_text": null,
          "old_line_content": "    input_ir_values.push_back(input_generator(index).ValueOrDie());",
          "new_line_content": "  std::vector<llvm::Value*> input_ir_values;",
          "content_same": false
        },
        {
          "line": 3454,
          "old_api": "opcode",
          "new_api": null,
          "old_text": "slice_or_tuple->opcode()",
          "new_text": null,
          "old_line_content": "      ShapeIndex shape_index = (slice_or_tuple->opcode() == HloOpcode::kSlice)",
          "new_line_content": "    auto emit_slice_elem_func = [&] {",
          "content_same": false
        },
        {
          "line": 3299,
          "old_api": "GetKernelMappingScheme",
          "new_api": null,
          "old_text": "reduction_info.GetKernelMappingScheme()",
          "new_text": null,
          "old_line_content": "      reduction_info.GetKernelMappingScheme();",
          "new_line_content": "  // unnested kReduce or by InstructionFusion for fused kReduce.",
          "content_same": false
        },
        {
          "line": 3301,
          "old_api": "GetThreadsPerBlock",
          "new_api": null,
          "old_text": "mapping_scheme.GetThreadsPerBlock()",
          "new_text": null,
          "old_line_content": "                                     mapping_scheme.GetThreadsPerBlock());",
          "new_line_content": "                                     \"doesn't set the input layout of \"",
          "content_same": false
        },
        {
          "line": 3303,
          "old_api": "launch_bound",
          "new_api": null,
          "old_text": "launch_dimensions.launch_bound()",
          "new_text": null,
          "old_line_content": "      unnested_hlo, launch_dimensions.launch_bound(), &b_);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3304,
          "old_api": "EmitPrologueForReduction",
          "new_api": null,
          "old_text": "EmitPrologueForReduction(unnested_hlo, &reduction_info, reduce_instructions,\n                           index_ty)",
          "new_text": null,
          "old_line_content": "  EmitPrologueForReduction(unnested_hlo, &reduction_info, reduce_instructions,",
          "new_line_content": "  ReductionCodegenInfo reduction_info =",
          "content_same": false
        },
        {
          "line": 3432,
          "old_api": "size",
          "new_api": null,
          "old_text": "slice->slice_starts().size()",
          "new_text": null,
          "old_line_content": "    for (size_t dim = 0; dim < slice->slice_starts().size(); ++dim) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3433,
          "old_api": "slice_strides",
          "new_api": null,
          "old_text": "slice->slice_strides(dim)",
          "new_text": null,
          "old_line_content": "      CHECK_EQ(slice->slice_strides(dim), 1);",
          "new_line_content": "  // Emit for slice_instructions.",
          "content_same": false
        },
        {
          "line": 3434,
          "old_api": "CreateICmpSGE",
          "new_api": null,
          "old_text": "b_.CreateICmpSGE(\n          index.multidim()[dim],\n          index.GetConstantWithIndexType(slice->slice_starts(dim)))",
          "new_text": null,
          "old_line_content": "      auto larger_or_equal_than_start = b_.CreateICmpSGE(",
          "new_line_content": "  KernelSupportLibrary ksl(&b_, llvm_ir::UnrollMode::kDefaultUnroll);",
          "content_same": false
        },
        {
          "line": 3436,
          "old_api": "slice_starts",
          "new_api": null,
          "old_text": "slice->slice_starts(dim)",
          "new_text": null,
          "old_line_content": "          index.GetConstantWithIndexType(slice->slice_starts(dim)));",
          "new_line_content": "    HloInstruction* slice = slice_instructions[i];",
          "content_same": false
        },
        {
          "line": 3437,
          "old_api": "CreateICmpSLT",
          "new_api": null,
          "old_text": "b_.CreateICmpSLT(\n          index.multidim()[dim],\n          index.GetConstantWithIndexType(slice->slice_limits(dim)))",
          "new_text": null,
          "old_line_content": "      llvm::Value* smaller_than_limit = b_.CreateICmpSLT(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 3438,
          "old_api": "multidim",
          "new_api": null,
          "old_text": "index.multidim()",
          "new_text": null,
          "old_line_content": "          index.multidim()[dim],",
          "new_line_content": "    // guarding_cond := index >= start && index < limit, for each dim.",
          "content_same": false
        },
        {
          "line": 3439,
          "old_api": "slice_limits",
          "new_api": null,
          "old_text": "slice->slice_limits(dim)",
          "new_text": null,
          "old_line_content": "          index.GetConstantWithIndexType(slice->slice_limits(dim)));",
          "new_line_content": "    std::vector<llvm::Value*> index_within_ranges;",
          "content_same": false
        },
        {
          "line": 3314,
          "old_api": "GetKernelMappingScheme",
          "new_api": null,
          "old_text": "EmitTilingKernel(\n      mapping_scheme, index_ty,\n      [&](const ThreadIdInfo& thread_id_info, const IrArray::Index& index,\n          const string& loop_name, llvm::Value* tile_height,\n          llvm::Value* tile_width, KernelSupportLibrary* ksl) {\n        EmitTile(reduction_info.GetKernelMappingScheme(), index, loop_name, ksl,\n                 thread_id_info, tile_height, tile_width, emit_reduction_tile);\n      })",
          "new_text": null,
          "old_line_content": "  TilingKernelInfo tiling_kernel_info = EmitTilingKernel(",
          "new_line_content": "  EmitElementFunction emit_reduction_tile =",
          "content_same": false
        },
        {
          "line": 3319,
          "old_api": "GetKernelMappingScheme",
          "new_api": null,
          "old_text": "reduction_info.GetKernelMappingScheme()",
          "new_text": null,
          "old_line_content": "        EmitTile(reduction_info.GetKernelMappingScheme(), index, loop_name, ksl,",
          "new_line_content": "                                    reducers, x_iter_num);",
          "content_same": false
        },
        {
          "line": 3448,
          "old_api": "size",
          "new_api": null,
          "old_text": "src_multidim.size()",
          "new_text": null,
          "old_line_content": "      std::vector<llvm::Value*> dst_multidim(src_multidim.size());",
          "new_line_content": "      llvm::Value* within_range =",
          "content_same": false
        },
        {
          "line": 3195,
          "old_api": "[&]() {\n    if (reduction_dimensions.is_row_reduction &&\n        // Only try to vectorize+coales memory access for rows of even size.\n        // For odd row sizes, every other row isn't aligned, so it can't be\n        // vectorized.\n        reduction_dimensions.dimensions[2] % 2 == 0) {\n      return kLinearStridedIndexingX;\n    } else if (IsUnrollingColumnReductionBeneficial(\n                   unnested_hlo, input_shape,\n                   reduction_dimensions.dimensions[2])) {\n      return kLinearIndexingX;\n    } else {\n      return kStridedIndexingX;\n    }\n  }()",
          "new_api": null,
          "old_text": "[&]() {\n    if (reduction_dimensions.is_row_reduction &&\n        // Only try to vectorize+coales memory access for rows of even size.\n        // For odd row sizes, every other row isn't aligned, so it can't be\n        // vectorized.\n        reduction_dimensions.dimensions[2] % 2 == 0) {\n      return kLinearStridedIndexingX;\n    } else if (IsUnrollingColumnReductionBeneficial(\n                   unnested_hlo, input_shape,\n                   reduction_dimensions.dimensions[2])) {\n      return kLinearIndexingX;\n    } else {\n      return kStridedIndexingX;\n    }\n  }()",
          "new_text": null,
          "old_line_content": "  KernelMappingScheme::IndexingOrder indexing_order = [&]() {",
          "new_line_content": "  int cc_major = 0, cc_minor = 0;",
          "content_same": false
        },
        {
          "line": 3326,
          "old_api": "get",
          "new_api": null,
          "old_text": "kernel_thunk.get()",
          "new_text": null,
          "old_line_content": "  UpdateLaunchDimensions(launch_dimensions, kernel_thunk.get(),",
          "new_line_content": "          llvm::Value* tile_width, KernelSupportLibrary* ksl) {",
          "content_same": false
        }
      ]
    },
    "api_summary": {
      "total_replacements": 42,
      "total_additions": 68,
      "total_deletions": 67,
      "total_api_changes": 177
    },
    "non_api_changes": {
      "has_non_api_changes": true,
      "evidence": {
        "total_diff_lines": 10,
        "api_related_lines": 177,
        "non_api_lines": 8,
        "non_api_line_numbers": [
          3200,
          3204,
          3205,
          3206,
          3207,
          3208,
          3197,
          3198
        ]
      }
    },
    "api_calls_before": 1731,
    "api_calls_after": 1733,
    "diff_info": {
      "added_lines": 9,
      "removed_lines": 1,
      "total_diff_lines": 27
    }
  }
}