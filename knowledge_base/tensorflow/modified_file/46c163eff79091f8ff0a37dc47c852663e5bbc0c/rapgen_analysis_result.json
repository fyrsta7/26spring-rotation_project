{
  "status": "completed",
  "commit_dir": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/46c163eff79091f8ff0a37dc47c852663e5bbc0c",
  "file_info": {
    "before_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/46c163eff79091f8ff0a37dc47c852663e5bbc0c/before.cc",
    "after_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/46c163eff79091f8ff0a37dc47c852663e5bbc0c/after.cc",
    "diff_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/46c163eff79091f8ff0a37dc47c852663e5bbc0c/diff.txt"
  },
  "semgrep_analysis": {
    "is_api_change": false,
    "api_changes": {
      "replacements": [
        {
          "line": 48,
          "old_api": "mm_cvtsi128_si32",
          "new_api": "MM_SHUFFLE",
          "old_text": "mm_cvtsi128_si32(acc);",
          "new_text": "MM_SHUFFLE(2, 3, 0, 1))",
          "old_line_content": "  return _mm_cvtsi128_si32(acc);",
          "new_line_content": "  shuffle = _mm_shuffle_epi32(acc, _MM_SHUFFLE(2, 3, 0, 1));",
          "content_same": false
        },
        {
          "line": 80,
          "old_api": "duceInt32x4",
          "new_api": "tProdInt8x4x4",
          "old_text": "duceInt32x4(dotprod_32x4);\n",
          "new_text": "tProdInt8x4x4(vec_8x16, row_8x16));",
          "old_line_content": "      int32_t sum = ReduceInt32x4(dotprod_32x4);",
          "new_line_content": "            _mm_add_epi32(dotprod_32x4, DotProdInt8x4x4(vec_8x16, row_8x16));",
          "content_same": false
        },
        {
          "line": 99,
          "old_api": "nstexpr i",
          "new_api": "restrict__ m",
          "old_text": "nstexpr i",
          "new_text": "restrict__ m",
          "old_line_content": "  static constexpr int kBlockSize = 16;",
          "new_line_content": "    const int8_t* __restrict__ matrix, const int m_rows, const int m_cols,",
          "content_same": false
        },
        {
          "line": 109,
          "old_api": "interpret_cast<const __m128i*>(vectors + col));",
          "new_api": "m_setzero_si128",
          "old_text": "interpret_cast<const __m128i*>(vectors + col));",
          "new_text": "m_setzero_si128();\n",
          "old_line_content": "            _mm_loadu_si128(reinterpret_cast<const __m128i*>(vectors + col));",
          "new_line_content": "      __m128i row_sum_16x8 = _mm_setzero_si128();",
          "content_same": false
        },
        {
          "line": 118,
          "old_api": "_set1_epi8",
          "new_api": "ProdInt8x4x4",
          "old_text": "_set1_epi8(1), r",
          "new_text": "ProdInt8x4x4(vec_8x16, row_8x16));\n",
          "old_line_content": "        const __m128i row_16x8 = _mm_maddubs_epi16(_mm_set1_epi8(1), row_8x16);",
          "new_line_content": "            _mm_add_epi32(dotprod_32x4, DotProdInt8x4x4(vec_8x16, row_8x16));",
          "content_same": false
        },
        {
          "line": 145,
          "old_api": "ITE_DCHECK_EQ",
          "new_api": "estrict__ ve",
          "old_text": "ITE_DCHECK_EQ(m_cols % kBlockSize, 0);\n\n",
          "new_text": "estrict__ ve",
          "old_line_content": "  TFLITE_DCHECK_EQ(m_cols % kBlockSize, 0);",
          "new_line_content": "    const int m_cols, const int8_t* __restrict__ vectors,",
          "content_same": false
        },
        {
          "line": 157,
          "old_api": "_loadu_si128",
          "new_api": "_setzero_si128",
          "old_text": "_loadu_si128(\n            reinterpret_cast<const __m128i*>(vectors + col_index));\n ",
          "new_text": "_setzero_si128();\n ",
          "old_line_content": "        const __m128i vec_8x16 = _mm_loadu_si128(",
          "new_line_content": "      __m128i dotprod_32x4 = _mm_setzero_si128();",
          "content_same": false
        }
      ],
      "additions": [
        {
          "line": 128,
          "old_api": null,
          "new_api": "_set1_epi16",
          "old_text": null,
          "new_text": "_set1_epi16(1));\n",
          "old_line_content": "      for (; col < m_cols; ++col) {",
          "new_line_content": "          _mm_madd_epi16(row_sum_16x8, _mm_set1_epi16(1));",
          "content_same": false
        },
        {
          "line": 129,
          "old_api": null,
          "new_api": "uceInt32x4",
          "old_text": null,
          "new_text": "uceInt32x4(dotprod_32x4);\n ",
          "old_line_content": "        sum += row_ptr[col] * vectors[col];",
          "new_line_content": "      int32_t sum = ReduceInt32x4(dotprod_32x4);",
          "content_same": false
        },
        {
          "line": 130,
          "old_api": null,
          "new_api": "uceInt32x4",
          "old_text": null,
          "new_text": "uceInt32x4(row_sum_32x4);\n ",
          "old_line_content": "        row_sum += row_ptr[col];",
          "new_line_content": "      int32_t row_sum = ReduceInt32x4(row_sum_32x4);",
          "content_same": false
        },
        {
          "line": 144,
          "old_api": null,
          "new_api": "estrict__ ma",
          "old_text": null,
          "new_text": "estrict__ ma",
          "old_line_content": "  static const int kBlockSize = 16;",
          "new_line_content": "    const int8_t* __restrict__ matrix, const uint8_t* ledger, const int m_rows,",
          "content_same": false
        },
        {
          "line": 146,
          "old_api": null,
          "new_api": "estrict__ re",
          "old_text": null,
          "new_text": "estrict__ re",
          "old_line_content": "",
          "new_line_content": "    const float* scaling_factors, int n_batch, float* __restrict__ result,",
          "content_same": false
        },
        {
          "line": 149,
          "old_api": null,
          "new_api": "ITE_DCHECK_EQ",
          "old_text": null,
          "new_text": "ITE_DCHECK_EQ(m_cols % kBlockSize, 0);\n\n",
          "old_line_content": "    const uint8_t* ledger_ptr = ledger;",
          "new_line_content": "  TFLITE_DCHECK_EQ(m_cols % kBlockSize, 0);",
          "content_same": false
        },
        {
          "line": 161,
          "old_api": null,
          "new_api": "_loadu_si128",
          "old_text": null,
          "new_text": "_loadu_si128(\n            reinterpret_cast<const __m128i*>(vectors + col_index));\n ",
          "old_line_content": "        // dotprod += vec Â· row",
          "new_line_content": "        const __m128i vec_8x16 = _mm_loadu_si128(",
          "content_same": false
        },
        {
          "line": 162,
          "old_api": null,
          "new_api": "nterpret_cast<const __m128i*>(vectors + col_index));",
          "old_text": null,
          "new_text": "nterpret_cast<const __m128i*>(vectors + col_index));\n",
          "old_line_content": "        dotprod_32x4 =",
          "new_line_content": "            reinterpret_cast<const __m128i*>(vectors + col_index));",
          "content_same": false
        },
        {
          "line": 164,
          "old_api": null,
          "new_api": "nterpret_cast<const __m128i*>(row_ptr));",
          "old_text": null,
          "new_text": "nterpret_cast<const __m128i*>(row_ptr));\n",
          "old_line_content": "        row_ptr += kBlockSize;",
          "new_line_content": "            _mm_loadu_si128(reinterpret_cast<const __m128i*>(row_ptr));",
          "content_same": false
        },
        {
          "line": 167,
          "old_api": null,
          "new_api": "rodInt8x4x4",
          "old_text": null,
          "new_text": "rodInt8x4x4(vec_8x16, row_8x16));\n ",
          "old_line_content": "      // dot-prod value for this row.",
          "new_line_content": "            _mm_add_epi32(dotprod_32x4, DotProdInt8x4x4(vec_8x16, row_8x16));",
          "content_same": false
        },
        {
          "line": 44,
          "old_api": null,
          "new_api": "mm_unpackhi_epi64",
          "old_text": null,
          "new_text": "mm_unpackhi_epi64(acc, acc);",
          "old_line_content": "  // This second hadd could be only 64 bit, but 64 and 128 bit hadd has same",
          "new_line_content": "  __m128i shuffle = _mm_unpackhi_epi64(acc, acc);",
          "content_same": false
        },
        {
          "line": 172,
          "old_api": null,
          "new_api": "ceInt32x4",
          "old_text": null,
          "new_text": "ceInt32x4(dotprod_32x4);\n\n ",
          "old_line_content": "  }    // for batch",
          "new_line_content": "      int32_t dotprod = ReduceInt32x4(dotprod_32x4);",
          "content_same": false
        },
        {
          "line": 46,
          "old_api": null,
          "new_api": "mm_add_epi32",
          "old_text": null,
          "new_text": "mm_add_epi32(acc, shuffle);",
          "old_line_content": "  // nevertheless is an extra instruction occupying the decoder and I cache.)",
          "new_line_content": "  acc = _mm_add_epi32(acc, shuffle);",
          "content_same": false
        },
        {
          "line": 50,
          "old_api": null,
          "new_api": "mm_add_epi32",
          "old_text": null,
          "new_text": "mm_add_epi32(acc, shuffle);",
          "old_line_content": "",
          "new_line_content": "  acc = _mm_add_epi32(acc, shuffle);",
          "content_same": false
        },
        {
          "line": 52,
          "old_api": null,
          "new_api": "mm_cvtsi128_si32",
          "old_text": null,
          "new_text": "mm_cvtsi128_si32(acc);",
          "old_line_content": "",
          "new_line_content": "  return _mm_cvtsi128_si32(acc);",
          "content_same": false
        },
        {
          "line": 58,
          "old_api": null,
          "new_api": "_restrict__",
          "old_text": null,
          "new_text": "_restrict__ ",
          "old_line_content": "  for (int batch = 0; batch < n_batch; ++batch) {",
          "new_line_content": "    const int8_t* __restrict__ matrix, const int m_rows, const int m_cols,",
          "content_same": false
        },
        {
          "line": 59,
          "old_api": null,
          "new_api": "_restrict__",
          "old_text": null,
          "new_text": "_restrict__ ",
          "old_line_content": "    const float batch_scaling_factor = scaling_factors[batch];",
          "new_line_content": "    const int8_t* __restrict__ vectors, const float* scaling_factors,",
          "content_same": false
        },
        {
          "line": 60,
          "old_api": null,
          "new_api": "_restrict__",
          "old_text": null,
          "new_text": "_restrict__ ",
          "old_line_content": "    // Compute dot-product for every column.",
          "new_line_content": "    int n_batch, float* __restrict__ result, int result_stride) {",
          "content_same": false
        },
        {
          "line": 61,
          "old_api": null,
          "new_api": "onstexpr",
          "old_text": null,
          "new_text": "onstexpr ",
          "old_line_content": "    for (int row = 0; row < m_rows; ++row, result += result_stride) {",
          "new_line_content": "  static constexpr int kBlockSize = 16;",
          "content_same": false
        },
        {
          "line": 70,
          "old_api": null,
          "new_api": "mm_setzero_si128",
          "old_text": null,
          "new_text": "mm_setzero_si128();",
          "old_line_content": "        const __m128i vec_8x16 =",
          "new_line_content": "      __m128i dotprod_32x4 = _mm_setzero_si128();",
          "content_same": false
        },
        {
          "line": 75,
          "old_api": null,
          "new_api": "einterpret_cast<const __m128i*>(vectors + col))",
          "old_text": null,
          "new_text": "einterpret_cast<const __m128i*>(vectors + col))",
          "old_line_content": "        dotprod_32x4 =",
          "new_line_content": "            _mm_loadu_si128(reinterpret_cast<const __m128i*>(vectors + col));",
          "content_same": false
        },
        {
          "line": 77,
          "old_api": null,
          "new_api": "einterpret_cast<const __m128i*>(row_ptr + col))",
          "old_text": null,
          "new_text": "einterpret_cast<const __m128i*>(row_ptr + col))",
          "old_line_content": "      }  // for col",
          "new_line_content": "            _mm_loadu_si128(reinterpret_cast<const __m128i*>(row_ptr + col));",
          "content_same": false
        },
        {
          "line": 84,
          "old_api": null,
          "new_api": "duceInt32x4",
          "old_text": null,
          "new_text": "duceInt32x4(dotprod_32x4);\n",
          "old_line_content": "        sum += row_ptr[col] * vectors[col];",
          "new_line_content": "      int32_t sum = ReduceInt32x4(dotprod_32x4);",
          "content_same": false
        },
        {
          "line": 100,
          "old_api": null,
          "new_api": "restrict__ v",
          "old_text": null,
          "new_text": "restrict__ v",
          "old_line_content": "  for (int batch = 0; batch < n_batch; ++batch) {",
          "new_line_content": "    const int8_t* __restrict__ vectors, const float* scaling_factors,",
          "content_same": false
        },
        {
          "line": 101,
          "old_api": null,
          "new_api": "restrict__ r",
          "old_text": null,
          "new_text": "restrict__ r",
          "old_line_content": "    const float batch_scaling_factor = scaling_factors[batch];",
          "new_line_content": "    int n_batch, float* __restrict__ result, int result_stride,",
          "content_same": false
        },
        {
          "line": 103,
          "old_api": null,
          "new_api": "nstexpr i",
          "old_text": null,
          "new_text": "nstexpr i",
          "old_line_content": "      const int8_t* row_ptr = matrix + row * m_cols;",
          "new_line_content": "  static constexpr int kBlockSize = 16;",
          "content_same": false
        },
        {
          "line": 108,
          "old_api": null,
          "new_api": "m_setzero_si128",
          "old_text": null,
          "new_text": "m_setzero_si128();\n",
          "old_line_content": "        const __m128i vec_8x16 =",
          "new_line_content": "      __m128i dotprod_32x4 = _mm_setzero_si128();",
          "content_same": false
        },
        {
          "line": 113,
          "old_api": null,
          "new_api": "interpret_cast<const __m128i*>(vectors + col));",
          "old_text": null,
          "new_text": "interpret_cast<const __m128i*>(vectors + col));",
          "old_line_content": "        dotprod_32x4 =",
          "new_line_content": "            _mm_loadu_si128(reinterpret_cast<const __m128i*>(vectors + col));",
          "content_same": false
        },
        {
          "line": 115,
          "old_api": null,
          "new_api": "interpret_cast<const __m128i*>(row_ptr + col));",
          "old_text": null,
          "new_text": "interpret_cast<const __m128i*>(row_ptr + col));",
          "old_line_content": "",
          "new_line_content": "            _mm_loadu_si128(reinterpret_cast<const __m128i*>(row_ptr + col));",
          "content_same": false
        },
        {
          "line": 122,
          "old_api": null,
          "new_api": "_set1_epi8",
          "old_text": null,
          "new_text": "_set1_epi8(1), r",
          "old_line_content": "      // Result is 4x 32-bit values.",
          "new_line_content": "        const __m128i row_16x8 = _mm_maddubs_epi16(_mm_set1_epi8(1), row_8x16);",
          "content_same": false
        },
        {
          "line": 123,
          "old_api": null,
          "new_api": "_add_epi16",
          "old_text": null,
          "new_text": "_add_epi16(row_sum_16x8, row_16x8);\n ",
          "old_line_content": "      const __m128i row_sum_32x4 =",
          "new_line_content": "        row_sum_16x8 = _mm_add_epi16(row_sum_16x8, row_16x8);",
          "content_same": false
        }
      ],
      "deletions": [
        {
          "line": 140,
          "old_api": "estrict__ ma",
          "new_api": null,
          "old_text": "estrict__ ma",
          "new_text": null,
          "old_line_content": "    const int8_t* __restrict__ matrix, const uint8_t* ledger, const int m_rows,",
          "new_line_content": "  }  // for batch",
          "content_same": false
        },
        {
          "line": 141,
          "old_api": "estrict__ ve",
          "new_api": null,
          "old_text": "estrict__ ve",
          "new_text": null,
          "old_line_content": "    const int m_cols, const int8_t* __restrict__ vectors,",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 142,
          "old_api": "estrict__ re",
          "new_api": null,
          "old_text": "estrict__ re",
          "new_text": null,
          "old_line_content": "    const float* scaling_factors, int n_batch, float* __restrict__ result,",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 153,
          "old_api": "_setzero_si128",
          "new_api": null,
          "old_text": "_setzero_si128();\n ",
          "new_text": null,
          "old_line_content": "      __m128i dotprod_32x4 = _mm_setzero_si128();",
          "new_line_content": "    const uint8_t* ledger_ptr = ledger;",
          "content_same": false
        },
        {
          "line": 158,
          "old_api": "nterpret_cast<const __m128i*>(vectors + col_index));",
          "new_api": null,
          "old_text": "nterpret_cast<const __m128i*>(vectors + col_index));\n",
          "new_text": null,
          "old_line_content": "            reinterpret_cast<const __m128i*>(vectors + col_index));",
          "new_line_content": "      int num_nonzero_blocks = *ledger_ptr++;",
          "content_same": false
        },
        {
          "line": 160,
          "old_api": "nterpret_cast<const __m128i*>(row_ptr));",
          "new_api": null,
          "old_text": "nterpret_cast<const __m128i*>(row_ptr));\n",
          "new_text": null,
          "old_line_content": "            _mm_loadu_si128(reinterpret_cast<const __m128i*>(row_ptr));",
          "new_line_content": "        const int col_index = *ledger_ptr++ * kBlockSize;",
          "content_same": false
        },
        {
          "line": 163,
          "old_api": "rodInt8x4x4",
          "new_api": null,
          "old_text": "rodInt8x4x4(vec_8x16, row_8x16));\n ",
          "new_text": null,
          "old_line_content": "            _mm_add_epi32(dotprod_32x4, DotProdInt8x4x4(vec_8x16, row_8x16));",
          "new_line_content": "        const __m128i row_8x16 =",
          "content_same": false
        },
        {
          "line": 168,
          "old_api": "ceInt32x4",
          "new_api": null,
          "old_text": "ceInt32x4(dotprod_32x4);\n\n ",
          "new_text": null,
          "old_line_content": "      int32_t dotprod = ReduceInt32x4(dotprod_32x4);",
          "new_line_content": "        row_ptr += kBlockSize;",
          "content_same": false
        },
        {
          "line": 43,
          "old_api": "mm_hadd_epi32",
          "new_api": null,
          "old_text": "mm_hadd_epi32(acc, acc);",
          "new_text": null,
          "old_line_content": "  acc = _mm_hadd_epi32(acc, acc);",
          "new_line_content": "  // Shuffle to contain high half of acc (both in high and low halfs).",
          "content_same": false
        },
        {
          "line": 47,
          "old_api": "mm_hadd_epi32",
          "new_api": null,
          "old_text": "mm_hadd_epi32(acc, acc);",
          "new_text": null,
          "old_line_content": "  acc = _mm_hadd_epi32(acc, acc);",
          "new_line_content": "  // Shuffle the two elements in low half (ignore high half).",
          "content_same": false
        },
        {
          "line": 54,
          "old_api": "_restrict__",
          "new_api": null,
          "old_text": "_restrict__ ",
          "new_text": null,
          "old_line_content": "    const int8_t* __restrict__ matrix, const int m_rows, const int m_cols,",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 55,
          "old_api": "_restrict__",
          "new_api": null,
          "old_text": "_restrict__ ",
          "new_text": null,
          "old_line_content": "    const int8_t* __restrict__ vectors, const float* scaling_factors,",
          "new_line_content": "}  // namespace",
          "content_same": false
        },
        {
          "line": 56,
          "old_api": "_restrict__",
          "new_api": null,
          "old_text": "_restrict__ ",
          "new_text": null,
          "old_line_content": "    int n_batch, float* __restrict__ result, int result_stride) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 57,
          "old_api": "onstexpr",
          "new_api": null,
          "old_text": "onstexpr ",
          "new_text": null,
          "old_line_content": "  static constexpr int kBlockSize = 16;",
          "new_line_content": "void SseMatrixBatchVectorMultiplyAccumulate(",
          "content_same": false
        },
        {
          "line": 66,
          "old_api": "mm_setzero_si128",
          "new_api": null,
          "old_text": "mm_setzero_si128();",
          "new_text": null,
          "old_line_content": "      __m128i dotprod_32x4 = _mm_setzero_si128();",
          "new_line_content": "      // Get the address of the first element of the row.",
          "content_same": false
        },
        {
          "line": 71,
          "old_api": "einterpret_cast<const __m128i*>(vectors + col))",
          "new_api": null,
          "old_text": "einterpret_cast<const __m128i*>(vectors + col))",
          "new_text": null,
          "old_line_content": "            _mm_loadu_si128(reinterpret_cast<const __m128i*>(vectors + col));",
          "new_line_content": "      // For every block of kBlockSize 8-bit elements.",
          "content_same": false
        },
        {
          "line": 73,
          "old_api": "einterpret_cast<const __m128i*>(row_ptr + col))",
          "new_api": null,
          "old_text": "einterpret_cast<const __m128i*>(row_ptr + col))",
          "new_text": null,
          "old_line_content": "            _mm_loadu_si128(reinterpret_cast<const __m128i*>(row_ptr + col));",
          "new_line_content": "      for (; col < (m_cols & ~(kBlockSize - 1)); col += kBlockSize) {",
          "content_same": false
        },
        {
          "line": 76,
          "old_api": "tProdInt8x4x4",
          "new_api": null,
          "old_text": "tProdInt8x4x4(vec_8x16, row_8x16));",
          "new_text": null,
          "old_line_content": "            _mm_add_epi32(dotprod_32x4, DotProdInt8x4x4(vec_8x16, row_8x16));",
          "new_line_content": "        const __m128i row_8x16 =",
          "content_same": false
        },
        {
          "line": 95,
          "old_api": "restrict__ m",
          "new_api": null,
          "old_text": "restrict__ m",
          "new_text": null,
          "old_line_content": "    const int8_t* __restrict__ matrix, const int m_rows, const int m_cols,",
          "new_line_content": "  }  // for batch",
          "content_same": false
        },
        {
          "line": 96,
          "old_api": "restrict__ v",
          "new_api": null,
          "old_text": "restrict__ v",
          "new_text": null,
          "old_line_content": "    const int8_t* __restrict__ vectors, const float* scaling_factors,",
          "new_line_content": "}",
          "content_same": false
        },
        {
          "line": 97,
          "old_api": "restrict__ r",
          "new_api": null,
          "old_text": "restrict__ r",
          "new_text": null,
          "old_line_content": "    int n_batch, float* __restrict__ result, int result_stride,",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 104,
          "old_api": "m_setzero_si128",
          "new_api": null,
          "old_text": "m_setzero_si128();\n",
          "new_text": null,
          "old_line_content": "      __m128i dotprod_32x4 = _mm_setzero_si128();",
          "new_line_content": "  for (int batch = 0; batch < n_batch; ++batch) {",
          "content_same": false
        },
        {
          "line": 105,
          "old_api": "m_setzero_si128",
          "new_api": null,
          "old_text": "m_setzero_si128();\n",
          "new_text": null,
          "old_line_content": "      __m128i row_sum_16x8 = _mm_setzero_si128();",
          "new_line_content": "    const float batch_scaling_factor = scaling_factors[batch];",
          "content_same": false
        },
        {
          "line": 111,
          "old_api": "interpret_cast<const __m128i*>(row_ptr + col));",
          "new_api": null,
          "old_text": "interpret_cast<const __m128i*>(row_ptr + col));",
          "new_text": null,
          "old_line_content": "            _mm_loadu_si128(reinterpret_cast<const __m128i*>(row_ptr + col));",
          "new_line_content": "      for (; col < (m_cols & ~(kBlockSize - 1)); col += kBlockSize) {",
          "content_same": false
        },
        {
          "line": 114,
          "old_api": "ProdInt8x4x4",
          "new_api": null,
          "old_text": "ProdInt8x4x4(vec_8x16, row_8x16));\n",
          "new_text": null,
          "old_line_content": "            _mm_add_epi32(dotprod_32x4, DotProdInt8x4x4(vec_8x16, row_8x16));",
          "new_line_content": "        const __m128i row_8x16 =",
          "content_same": false
        },
        {
          "line": 119,
          "old_api": "_add_epi16",
          "new_api": null,
          "old_text": "_add_epi16(row_sum_16x8, row_16x8);\n ",
          "new_text": null,
          "old_line_content": "        row_sum_16x8 = _mm_add_epi16(row_sum_16x8, row_16x8);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 124,
          "old_api": "_set1_epi16",
          "new_api": null,
          "old_text": "_set1_epi16(1));\n",
          "new_text": null,
          "old_line_content": "          _mm_madd_epi16(row_sum_16x8, _mm_set1_epi16(1));",
          "new_line_content": "      }  // for col",
          "content_same": false
        },
        {
          "line": 125,
          "old_api": "uceInt32x4",
          "new_api": null,
          "old_text": "uceInt32x4(dotprod_32x4);\n ",
          "new_text": null,
          "old_line_content": "      int32_t sum = ReduceInt32x4(dotprod_32x4);",
          "new_line_content": "      // Pairwise add 8x 16-bit values; equivalently, multipy-add with 1.",
          "content_same": false
        },
        {
          "line": 126,
          "old_api": "uceInt32x4",
          "new_api": null,
          "old_text": "uceInt32x4(row_sum_32x4);\n ",
          "new_text": null,
          "old_line_content": "      int32_t row_sum = ReduceInt32x4(row_sum_32x4);",
          "new_line_content": "      // Result is 4x 32-bit values.",
          "content_same": false
        }
      ]
    },
    "api_summary": {
      "total_replacements": 7,
      "total_additions": 31,
      "total_deletions": 29,
      "total_api_changes": 67
    },
    "non_api_changes": {
      "has_non_api_changes": true,
      "evidence": {
        "total_diff_lines": 9,
        "api_related_lines": 67,
        "non_api_lines": 3,
        "non_api_line_numbers": [
          49,
          51,
          45
        ]
      }
    },
    "api_calls_before": 51,
    "api_calls_after": 54,
    "diff_info": {
      "added_lines": 9,
      "removed_lines": 5,
      "total_diff_lines": 26
    }
  }
}