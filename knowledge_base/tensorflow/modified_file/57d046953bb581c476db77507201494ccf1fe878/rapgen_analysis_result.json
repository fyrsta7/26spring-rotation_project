{
  "status": "completed",
  "commit_dir": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/57d046953bb581c476db77507201494ccf1fe878",
  "file_info": {
    "before_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/57d046953bb581c476db77507201494ccf1fe878/before.cc",
    "after_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/57d046953bb581c476db77507201494ccf1fe878/after.cc",
    "diff_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/57d046953bb581c476db77507201494ccf1fe878/diff.txt"
  },
  "semgrep_analysis": {
    "is_api_change": true,
    "api_changes": {
      "replacements": [
        {
          "line": 70,
          "old_api": "builder",
          "new_api": "push_back",
          "old_text": "ctx->builder()",
          "new_text": "dynamic_dims.push_back(\n        xla::ConstantR0<int32>(ctx->builder(), num_elements))",
          "old_line_content": "        xla::ConstantR0<int32>(ctx->builder(), num_elements));",
          "new_line_content": "    dynamic_dims.push_back(",
          "content_same": false
        },
        {
          "line": 75,
          "old_api": "xla::Reshape(dynamic_dim_size, {})",
          "new_api": "Input",
          "old_text": "xla::Reshape(dynamic_dim_size, {})",
          "new_text": "ctx->Input(0)",
          "old_line_content": "      dynamic_dim_size = xla::Reshape(dynamic_dim_size, {});",
          "new_line_content": "      auto dynamic_dim_size = xla::Slice(ctx->Input(0), {dim}, {dim + 1}, {1});",
          "content_same": false
        },
        {
          "line": 76,
          "old_api": "xla::ConvertElementType(dynamic_dim_size, xla::S32)",
          "new_api": "xla::Reshape(dynamic_dim_size, {})",
          "old_text": "xla::ConvertElementType(dynamic_dim_size, xla::S32)",
          "new_text": "xla::Reshape(dynamic_dim_size, {})",
          "old_line_content": "      dynamic_dim_size = xla::ConvertElementType(dynamic_dim_size, xla::S32);",
          "new_line_content": "      dynamic_dim_size = xla::Reshape(dynamic_dim_size, {});",
          "content_same": false
        },
        {
          "line": 77,
          "old_api": "push_back",
          "new_api": "xla::ConvertElementType(dynamic_dim_size, xla::S32)",
          "old_text": "dynamic_dims.push_back(dynamic_dim_size)",
          "new_text": "xla::ConvertElementType(dynamic_dim_size, xla::S32)",
          "old_line_content": "      dynamic_dims.push_back(dynamic_dim_size);",
          "new_line_content": "      dynamic_dim_size = xla::ConvertElementType(dynamic_dim_size, xla::S32);",
          "content_same": false
        },
        {
          "line": 80,
          "old_api": "builder",
          "new_api": "push_back",
          "old_text": "ctx->builder()",
          "new_text": "dynamic_dims.push_back(\n          xla::ConstantR0<int32>(ctx->builder(), dynamic_sizes[dim]))",
          "old_line_content": "          xla::ConstantR0<int32>(ctx->builder(), dynamic_sizes[dim]));",
          "new_line_content": "      dynamic_dims.push_back(",
          "content_same": false
        },
        {
          "line": 114,
          "old_api": "status",
          "new_api": "builder",
          "old_text": "is_compile_time_constant_or.status()",
          "new_text": "input.builder()->IsConstant(input)",
          "old_line_content": "  TF_RETURN_IF_ERROR(is_compile_time_constant_or.status());",
          "new_line_content": "  auto is_compile_time_constant_or = input.builder()->IsConstant(input);",
          "content_same": false
        },
        {
          "line": 124,
          "old_api": "IsFullyDefined",
          "new_api": "ConstantInputAsPartialShape",
          "old_text": "partial_shape.IsFullyDefined()",
          "new_text": "ctx->ConstantInputAsPartialShape(0, &partial_shape)",
          "old_line_content": "  if (!partial_shape.IsFullyDefined()) {",
          "new_line_content": "  TF_RETURN_IF_ERROR(ctx->ConstantInputAsPartialShape(0, &partial_shape));",
          "content_same": false
        },
        {
          "line": 137,
          "old_api": "GetAttr",
          "new_api": "explicit",
          "old_text": "ctx->GetAttr(\"element_dtype\", &dtype_)",
          "new_text": "explicit",
          "old_line_content": "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &dtype_));",
          "new_line_content": "  explicit TensorListReserveOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {",
          "content_same": false
        },
        {
          "line": 153,
          "old_api": "OP_REQUIRES",
          "new_api": "ResolveInputDynamismIntoPred",
          "old_text": "OP_REQUIRES(\n        ctx, num_elements >= 0,\n        errors::InvalidArgument(\n            \"XLA compilation requires a fixed tensor list size. Set the number \"\n            \"of elements. This could also happen if you're using a TensorArray \"\n            \"in a while loop that does not have its maximum_iteration set, you \"\n            \"can fix this by setting maximum_iteration to a suitable value.\"))",
          "new_text": "ctx->ResolveInputDynamismIntoPred(1, &num_element_is_dynamic)",
          "old_line_content": "    OP_REQUIRES(",
          "new_line_content": "        ctx, ctx->ResolveInputDynamismIntoPred(1, &num_element_is_dynamic));",
          "content_same": false
        },
        {
          "line": 170,
          "old_api": "TryGetElementShapeFromInput",
          "new_api": "OP_REQUIRES_OK",
          "old_text": "TryGetElementShapeFromInput(ctx, element_shape_handle, type,\n                                               &got_shape, &element_shape)",
          "new_text": "OP_REQUIRES_OK(ctx,\n                   TryGetElementShapeFromInput(ctx, element_shape_handle, type,\n                                               &got_shape, &element_shape))",
          "old_line_content": "                   TryGetElementShapeFromInput(ctx, element_shape_handle, type,",
          "new_line_content": "    OP_REQUIRES_OK(ctx,",
          "content_same": false
        },
        {
          "line": 183,
          "old_api": "builder",
          "new_api": "ValueOrDie",
          "old_text": "ctx->builder()",
          "new_text": "CreateZerosTensorListWithShape(\n                              ctx->builder(), list_shape,\n                              list_dynamic_dims_or.ValueOrDie(), &new_list)",
          "old_line_content": "                              ctx->builder(), list_shape,",
          "new_line_content": "      OP_REQUIRES_OK(ctx, CreateZerosTensorListWithShape(",
          "content_same": false
        },
        {
          "line": 184,
          "old_api": "ValueOrDie",
          "new_api": "builder",
          "old_text": "list_dynamic_dims_or.ValueOrDie()",
          "new_text": "ctx->builder()",
          "old_line_content": "                              list_dynamic_dims_or.ValueOrDie(), &new_list));",
          "new_line_content": "                              ctx->builder(), list_shape,",
          "content_same": false
        },
        {
          "line": 196,
          "old_api": "Input",
          "new_api": "builder",
          "old_text": "ctx->Input(1)",
          "new_text": "BuildUninitializedTensorList(\n        ctx->builder(), num_elements, num_element_is_dynamic, ctx->Input(1))",
          "old_line_content": "        ctx->builder(), num_elements, num_element_is_dynamic, ctx->Input(1));",
          "new_line_content": "    xla::XlaOp result = BuildUninitializedTensorList(",
          "content_same": false
        },
        {
          "line": 197,
          "old_api": "SetTensorListOutput",
          "new_api": "Input",
          "old_text": "ctx->SetTensorListOutput(0, result)",
          "new_text": "ctx->Input(1)",
          "old_line_content": "    ctx->SetTensorListOutput(0, result);",
          "new_line_content": "        ctx->builder(), num_elements, num_element_is_dynamic, ctx->Input(1));",
          "content_same": false
        },
        {
          "line": 214,
          "old_api": "GetAttr",
          "new_api": "explicit",
          "old_text": "ctx->GetAttr(\"element_dtype\", &dtype_)",
          "new_text": "explicit",
          "old_line_content": "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &dtype_));",
          "new_line_content": "  explicit EmptyTensorListOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {",
          "content_same": false
        },
        {
          "line": 225,
          "old_api": "OP_REQUIRES",
          "new_api": "ResolveInputDynamismIntoPred",
          "old_text": "OP_REQUIRES(ctx, max_num_elements >= 0,\n                errors::InvalidArgument(\n                    \"XLA compilation requires a fixed tensor list size. Set \"\n                    \"the max number of elements. This could also happen if \"\n                    \"you're using a TensorArray in a while loop that does not \"\n                    \"have its maximum_iteration set, you can fix this by \"\n                    \"setting maximum_iteration to a suitable value.\"))",
          "new_text": "ctx->ResolveInputDynamismIntoPred(1, &num_element_is_dynamic)",
          "old_line_content": "    OP_REQUIRES(ctx, max_num_elements >= 0,",
          "new_line_content": "        ctx, ctx->ResolveInputDynamismIntoPred(1, &num_element_is_dynamic));",
          "content_same": false
        },
        {
          "line": 226,
          "old_api": "errors::InvalidArgument(\n                    \"XLA compilation requires a fixed tensor list size. Set \"\n                    \"the max number of elements. This could also happen if \"\n                    \"you're using a TensorArray in a while loop that does not \"\n                    \"have its maximum_iteration set, you can fix this by \"\n                    \"setting maximum_iteration to a suitable value.\")",
          "new_api": "OP_REQUIRES",
          "old_text": "errors::InvalidArgument(\n                    \"XLA compilation requires a fixed tensor list size. Set \"\n                    \"the max number of elements. This could also happen if \"\n                    \"you're using a TensorArray in a while loop that does not \"\n                    \"have its maximum_iteration set, you can fix this by \"\n                    \"setting maximum_iteration to a suitable value.\")",
          "new_text": "OP_REQUIRES(ctx, max_num_elements >= 0,\n                errors::InvalidArgument(\n                    \"XLA compilation requires a fixed tensor list size. Set \"\n                    \"the max number of elements. This could also happen if \"\n                    \"you're using a TensorArray in a while loop that does not \"\n                    \"have its maximum_iteration set, you can fix this by \"\n                    \"setting maximum_iteration to a suitable value.\"))",
          "old_line_content": "                errors::InvalidArgument(",
          "new_line_content": "    OP_REQUIRES(ctx, max_num_elements >= 0,",
          "content_same": false
        },
        {
          "line": 244,
          "old_api": "TryGetElementShapeFromInput",
          "new_api": "OP_REQUIRES_OK",
          "old_text": "TryGetElementShapeFromInput(ctx, element_shape_handle, type,\n                                           &got_shape, &element_shape)",
          "new_text": "OP_REQUIRES_OK(\n          ctx, TryGetElementShapeFromInput(ctx, element_shape_handle, type,\n                                           &got_shape, &element_shape))",
          "old_line_content": "          ctx, TryGetElementShapeFromInput(ctx, element_shape_handle, type,",
          "new_line_content": "      OP_REQUIRES_OK(",
          "content_same": false
        },
        {
          "line": 258,
          "old_api": "builder",
          "new_api": "ValueOrDie",
          "old_text": "ctx->builder()",
          "new_text": "CreateZerosTensorListWithShape(\n                                ctx->builder(), list_shape,\n                                list_dynamic_dims_or.ValueOrDie(), &result)",
          "old_line_content": "                                ctx->builder(), list_shape,",
          "new_line_content": "        OP_REQUIRES_OK(ctx, CreateZerosTensorListWithShape(",
          "content_same": false
        },
        {
          "line": 259,
          "old_api": "ValueOrDie",
          "new_api": "builder",
          "old_text": "list_dynamic_dims_or.ValueOrDie()",
          "new_text": "ctx->builder()",
          "old_line_content": "                                list_dynamic_dims_or.ValueOrDie(), &result));",
          "new_line_content": "                                ctx->builder(), list_shape,",
          "content_same": false
        },
        {
          "line": 270,
          "old_api": "Input",
          "new_api": "builder",
          "old_text": "ctx->Input(1)",
          "new_text": "ctx->builder()",
          "old_line_content": "                                     num_element_is_dynamic, ctx->Input(1));",
          "new_line_content": "        BuildUninitializedTensorList(ctx->builder(), max_num_elements,",
          "content_same": false
        },
        {
          "line": 271,
          "old_api": "SetTensorListOutput",
          "new_api": "Input",
          "old_text": "ctx->SetTensorListOutput(0, result)",
          "new_text": "ctx->Input(1)",
          "old_line_content": "    ctx->SetTensorListOutput(0, result);",
          "new_line_content": "                                     num_element_is_dynamic, ctx->Input(1));",
          "content_same": false
        },
        {
          "line": 298,
          "old_api": "OP_REQUIRES",
          "new_api": "Input",
          "old_text": "OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"))",
          "new_text": "ctx->Input(0)",
          "old_line_content": "    OP_REQUIRES(ctx, is_initialized,",
          "new_line_content": "                   (IsTensorListInitialized(ctx->Input(0), &is_initialized)));",
          "content_same": false
        },
        {
          "line": 299,
          "old_api": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "new_api": "OP_REQUIRES",
          "old_text": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "new_text": "OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"))",
          "old_line_content": "                errors::InvalidArgument(\"TensorList is not initialized\"));",
          "new_line_content": "    OP_REQUIRES(ctx, is_initialized,",
          "content_same": false
        },
        {
          "line": 304,
          "old_api": "OP_REQUIRES",
          "new_api": "Input",
          "old_text": "OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListElementShape.\"))",
          "new_text": "ctx->Input(0)",
          "old_line_content": "    OP_REQUIRES(ctx, !is_nested,",
          "new_line_content": "    OP_REQUIRES_OK(ctx, IsNestedTensorList(ctx->Input(0), &is_nested));",
          "content_same": false
        },
        {
          "line": 305,
          "old_api": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListElementShape.\")",
          "new_api": "OP_REQUIRES",
          "old_text": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListElementShape.\")",
          "new_text": "OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListElementShape.\"))",
          "old_line_content": "                errors::Unimplemented(\"Only non-nested TensorList is supported \"",
          "new_line_content": "    OP_REQUIRES(ctx, !is_nested,",
          "content_same": false
        },
        {
          "line": 313,
          "old_api": "DeleteDimension",
          "new_api": "Input",
          "old_text": "list_shape.DeleteDimension(0)",
          "new_text": "ctx->Input(0)",
          "old_line_content": "    list_shape.DeleteDimension(0);",
          "new_line_content": "    OP_REQUIRES_OK(ctx, GetTensorListBufferShape(ctx->Input(0), &list_shape));",
          "content_same": false
        },
        {
          "line": 322,
          "old_api": "size",
          "new_api": "dimensions",
          "old_text": "dimensions.size()",
          "new_text": "list_shape.dimensions()",
          "old_line_content": "        size.reserve(dimensions.size());",
          "new_line_content": "        const auto& dimensions = list_shape.dimensions();",
          "content_same": false
        },
        {
          "line": 331,
          "old_api": "errors::InvalidArgument(\"Unsupported shape type requested\")",
          "new_api": "CtxFailure",
          "old_text": "errors::InvalidArgument(\"Unsupported shape type requested\")",
          "new_text": "ctx->CtxFailure(\n            errors::InvalidArgument(\"Unsupported shape type requested\"))",
          "old_line_content": "            errors::InvalidArgument(\"Unsupported shape type requested\"));",
          "new_line_content": "        ctx->CtxFailure(",
          "content_same": false
        },
        {
          "line": 348,
          "old_api": "GetAttr",
          "new_api": "explicit",
          "old_text": "ctx->GetAttr(\"element_dtype\", &dtype_)",
          "new_text": "explicit",
          "old_line_content": "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &dtype_));",
          "new_line_content": "  explicit TensorListGetItemOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {",
          "content_same": false
        },
        {
          "line": 356,
          "old_api": "OP_REQUIRES",
          "new_api": "Input",
          "old_text": "OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"))",
          "new_text": "ctx->Input(0)",
          "old_line_content": "    OP_REQUIRES(ctx, is_initialized,",
          "new_line_content": "                   (IsTensorListInitialized(ctx->Input(0), &is_initialized)));",
          "content_same": false
        },
        {
          "line": 357,
          "old_api": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "new_api": "OP_REQUIRES",
          "old_text": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "new_text": "OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"))",
          "old_line_content": "                errors::InvalidArgument(\"TensorList is not initialized\"));",
          "new_line_content": "    OP_REQUIRES(ctx, is_initialized,",
          "content_same": false
        },
        {
          "line": 362,
          "old_api": "OP_REQUIRES",
          "new_api": "Input",
          "old_text": "OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGetItem.\"))",
          "new_text": "ctx->Input(0)",
          "old_line_content": "    OP_REQUIRES(ctx, !is_nested,",
          "new_line_content": "    OP_REQUIRES_OK(ctx, IsNestedTensorList(ctx->Input(0), &is_nested));",
          "content_same": false
        },
        {
          "line": 363,
          "old_api": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGetItem.\")",
          "new_api": "OP_REQUIRES",
          "old_text": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGetItem.\")",
          "new_text": "OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGetItem.\"))",
          "old_line_content": "                errors::Unimplemented(\"Only non-nested TensorList is supported \"",
          "new_line_content": "    OP_REQUIRES(ctx, !is_nested,",
          "content_same": false
        },
        {
          "line": 386,
          "old_api": "GetAttr",
          "new_api": "explicit",
          "old_text": "ctx->GetAttr(\"element_dtype\", &dtype_)",
          "new_text": "explicit",
          "old_line_content": "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &dtype_));",
          "new_line_content": "  explicit TensorListGatherOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {",
          "content_same": false
        },
        {
          "line": 394,
          "old_api": "OP_REQUIRES",
          "new_api": "Input",
          "old_text": "OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"))",
          "new_text": "ctx->Input(0)",
          "old_line_content": "    OP_REQUIRES(ctx, is_initialized,",
          "new_line_content": "                   (IsTensorListInitialized(ctx->Input(0), &is_initialized)));",
          "content_same": false
        },
        {
          "line": 395,
          "old_api": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "new_api": "OP_REQUIRES",
          "old_text": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "new_text": "OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"))",
          "old_line_content": "                errors::InvalidArgument(\"TensorList is not initialized\"));",
          "new_line_content": "    OP_REQUIRES(ctx, is_initialized,",
          "content_same": false
        },
        {
          "line": 400,
          "old_api": "OP_REQUIRES",
          "new_api": "Input",
          "old_text": "OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGather.\"))",
          "new_text": "ctx->Input(0)",
          "old_line_content": "    OP_REQUIRES(ctx, !is_nested,",
          "new_line_content": "    OP_REQUIRES_OK(ctx, IsNestedTensorList(ctx->Input(0), &is_nested));",
          "content_same": false
        },
        {
          "line": 401,
          "old_api": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGather.\")",
          "new_api": "OP_REQUIRES",
          "old_text": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGather.\")",
          "new_text": "OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGather.\"))",
          "old_line_content": "                errors::Unimplemented(\"Only non-nested TensorList is supported \"",
          "new_line_content": "    OP_REQUIRES(ctx, !is_nested,",
          "content_same": false
        },
        {
          "line": 407,
          "old_api": "dims",
          "new_api": "InputShape",
          "old_text": "indices_shape.dims()",
          "new_text": "ctx->InputShape(1)",
          "old_line_content": "    OP_REQUIRES(ctx, indices_shape.dims() == 1,",
          "new_line_content": "    const TensorShape indices_shape = ctx->InputShape(1);",
          "content_same": false
        },
        {
          "line": 408,
          "old_api": "errors::InvalidArgument(\"indices must be rank 1\")",
          "new_api": "dims",
          "old_text": "errors::InvalidArgument(\"indices must be rank 1\")",
          "new_text": "indices_shape.dims()",
          "old_line_content": "                errors::InvalidArgument(\"indices must be rank 1\"));",
          "new_line_content": "    OP_REQUIRES(ctx, indices_shape.dims() == 1,",
          "content_same": false
        },
        {
          "line": 425,
          "old_api": "SetOutput",
          "new_api": "builder",
          "old_text": "ctx->SetOutput(0, result)",
          "new_text": "ctx->builder()",
          "old_line_content": "    ctx->SetOutput(0, result);",
          "new_line_content": "                       ctx->builder(), &result));",
          "content_same": false
        },
        {
          "line": 445,
          "old_api": "OP_REQUIRES",
          "new_api": "Input",
          "old_text": "OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"))",
          "new_text": "ctx->Input(0)",
          "old_line_content": "    OP_REQUIRES(ctx, is_initialized,",
          "new_line_content": "                   (IsTensorListInitialized(ctx->Input(0), &is_initialized)));",
          "content_same": false
        },
        {
          "line": 446,
          "old_api": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "new_api": "OP_REQUIRES",
          "old_text": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "new_text": "OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"))",
          "old_line_content": "                errors::InvalidArgument(\"TensorList is not initialized\"));",
          "new_line_content": "    OP_REQUIRES(ctx, is_initialized,",
          "content_same": false
        },
        {
          "line": 451,
          "old_api": "OP_REQUIRES",
          "new_api": "Input",
          "old_text": "OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGetItem.\"))",
          "new_text": "ctx->Input(0)",
          "old_line_content": "    OP_REQUIRES(ctx, !is_nested,",
          "new_line_content": "    OP_REQUIRES_OK(ctx, IsNestedTensorList(ctx->Input(0), &is_nested));",
          "content_same": false
        },
        {
          "line": 452,
          "old_api": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGetItem.\")",
          "new_api": "OP_REQUIRES",
          "old_text": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGetItem.\")",
          "new_text": "OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGetItem.\"))",
          "old_line_content": "                errors::Unimplemented(\"Only non-nested TensorList is supported \"",
          "new_line_content": "    OP_REQUIRES(ctx, !is_nested,",
          "content_same": false
        },
        {
          "line": 457,
          "old_api": "SetOutput",
          "new_api": "Input",
          "old_text": "ctx->SetOutput(0, buffer)",
          "new_text": "ctx->Input(0)",
          "old_line_content": "    ctx->SetOutput(0, buffer);",
          "new_line_content": "    OP_REQUIRES_OK(ctx, GetTensorListBuffer(ctx->Input(0), &buffer));",
          "content_same": false
        },
        {
          "line": 476,
          "old_api": "OP_REQUIRES",
          "new_api": "IsTensorListInitialized",
          "old_text": "OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"))",
          "new_text": "IsTensorListInitialized(input, &is_initialized)",
          "old_line_content": "    OP_REQUIRES(ctx, is_initialized,",
          "new_line_content": "    OP_REQUIRES_OK(ctx, (IsTensorListInitialized(input, &is_initialized)));",
          "content_same": false
        },
        {
          "line": 477,
          "old_api": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "new_api": "OP_REQUIRES",
          "old_text": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "new_text": "OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"))",
          "old_line_content": "                errors::InvalidArgument(\"TensorList is not initialized\"));",
          "new_line_content": "    OP_REQUIRES(ctx, is_initialized,",
          "content_same": false
        },
        {
          "line": 482,
          "old_api": "OP_REQUIRES",
          "new_api": "IsNestedTensorList",
          "old_text": "OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListConcat.\"))",
          "new_text": "IsNestedTensorList(input, &is_nested)",
          "old_line_content": "    OP_REQUIRES(ctx, !is_nested,",
          "new_line_content": "    OP_REQUIRES_OK(ctx, IsNestedTensorList(input, &is_nested));",
          "content_same": false
        },
        {
          "line": 483,
          "old_api": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListConcat.\")",
          "new_api": "OP_REQUIRES",
          "old_text": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListConcat.\")",
          "new_text": "OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListConcat.\"))",
          "old_line_content": "                errors::Unimplemented(\"Only non-nested TensorList is supported \"",
          "new_line_content": "    OP_REQUIRES(ctx, !is_nested,",
          "content_same": false
        },
        {
          "line": 490,
          "old_api": "GetShape",
          "new_api": "builder",
          "old_text": "b->GetShape(buffer)",
          "new_text": "input.builder()",
          "old_line_content": "    auto shape_or = b->GetShape(buffer);",
          "new_line_content": "    xla::XlaBuilder* b = input.builder();",
          "content_same": false
        },
        {
          "line": 491,
          "old_api": "status",
          "new_api": "GetShape",
          "old_text": "shape_or.status()",
          "new_text": "b->GetShape(buffer)",
          "old_line_content": "    OP_REQUIRES_OK(ctx, shape_or.status());",
          "new_line_content": "    auto shape_or = b->GetShape(buffer);",
          "content_same": false
        },
        {
          "line": 492,
          "old_api": "ConsumeValueOrDie",
          "new_api": "status",
          "old_text": "shape_or.ConsumeValueOrDie()",
          "new_text": "shape_or.status()",
          "old_line_content": "    xla::Shape element_shape = shape_or.ConsumeValueOrDie();",
          "new_line_content": "    OP_REQUIRES_OK(ctx, shape_or.status());",
          "content_same": false
        },
        {
          "line": 495,
          "old_api": "size",
          "new_api": "dimensions",
          "old_text": "OP_REQUIRES(\n        ctx, element_dims.size() > 1,\n        errors::Unimplemented(\"TensorList of scalars is not supported\"))",
          "new_text": "element_shape.dimensions()",
          "old_line_content": "    OP_REQUIRES(",
          "new_line_content": "        xla::SpanToVector(element_shape.dimensions());",
          "content_same": false
        },
        {
          "line": 497,
          "old_api": "errors::Unimplemented(\"TensorList of scalars is not supported\")",
          "new_api": "size",
          "old_text": "errors::Unimplemented(\"TensorList of scalars is not supported\")",
          "new_text": "element_dims.size()",
          "old_line_content": "        errors::Unimplemented(\"TensorList of scalars is not supported\"));",
          "new_line_content": "        ctx, element_dims.size() > 1,",
          "content_same": false
        },
        {
          "line": 504,
          "old_api": "push_back",
          "new_api": "size",
          "old_text": "new_dims.push_back(element_dims[i])",
          "new_text": "element_dims.size()",
          "old_line_content": "      new_dims.push_back(element_dims[i]);",
          "new_line_content": "    for (int i = 2; i < element_dims.size(); i++) {",
          "content_same": false
        },
        {
          "line": 508,
          "old_api": "SetOutput",
          "new_api": "xla::Reshape(buffer, new_dims)",
          "old_text": "ctx->SetOutput(0, out)",
          "new_text": "xla::Reshape(buffer, new_dims)",
          "old_line_content": "    ctx->SetOutput(0, out);",
          "new_line_content": "    xla::XlaOp out = xla::Reshape(buffer, new_dims);",
          "content_same": false
        },
        {
          "line": 512,
          "old_api": "SetOutput",
          "new_api": "xla::ConstantR1(b, num_elements, tensor_lengths)",
          "old_text": "ctx->SetOutput(1, lengths)",
          "new_text": "xla::ConstantR1(b, num_elements, tensor_lengths)",
          "old_line_content": "    ctx->SetOutput(1, lengths);",
          "new_line_content": "    xla::XlaOp lengths = xla::ConstantR1(b, num_elements, tensor_lengths);",
          "content_same": false
        },
        {
          "line": 524,
          "old_api": "GetAttr",
          "new_api": "explicit",
          "old_text": "ctx->GetAttr(\"element_dtype\", &dtype_)",
          "new_text": "explicit",
          "old_line_content": "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &dtype_));",
          "new_line_content": "  explicit TensorListSplitOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {",
          "content_same": false
        },
        {
          "line": 536,
          "old_api": "GetShape",
          "new_api": "builder",
          "old_text": "b->GetShape(input_tensor)",
          "new_text": "input_tensor.builder()",
          "old_line_content": "    auto shape_or = b->GetShape(input_tensor);",
          "new_line_content": "    xla::XlaBuilder* b = input_tensor.builder();",
          "content_same": false
        },
        {
          "line": 537,
          "old_api": "status",
          "new_api": "GetShape",
          "old_text": "shape_or.status()",
          "new_text": "b->GetShape(input_tensor)",
          "old_line_content": "    OP_REQUIRES_OK(ctx, shape_or.status());",
          "new_line_content": "    auto shape_or = b->GetShape(input_tensor);",
          "content_same": false
        },
        {
          "line": 538,
          "old_api": "ConsumeValueOrDie",
          "new_api": "status",
          "old_text": "shape_or.ConsumeValueOrDie()",
          "new_text": "shape_or.status()",
          "old_line_content": "    xla::Shape element_shape = shape_or.ConsumeValueOrDie();",
          "new_line_content": "    OP_REQUIRES_OK(ctx, shape_or.status());",
          "content_same": false
        },
        {
          "line": 541,
          "old_api": "empty",
          "new_api": "dimensions",
          "old_text": "OP_REQUIRES(\n        ctx, !element_dims.empty(),\n        errors::Unimplemented(\"Element dimensions have to be non-empty\"))",
          "new_text": "element_shape.dimensions()",
          "old_line_content": "    OP_REQUIRES(",
          "new_line_content": "        xla::SpanToVector(element_shape.dimensions());",
          "content_same": false
        },
        {
          "line": 543,
          "old_api": "errors::Unimplemented(\"Element dimensions have to be non-empty\")",
          "new_api": "empty",
          "old_text": "errors::Unimplemented(\"Element dimensions have to be non-empty\")",
          "new_text": "element_dims.empty()",
          "old_line_content": "        errors::Unimplemented(\"Element dimensions have to be non-empty\"));",
          "new_line_content": "        ctx, !element_dims.empty(),",
          "content_same": false
        },
        {
          "line": 547,
          "old_api": "empty",
          "new_api": "ConstantInputAsIntVector",
          "old_text": "lengths.empty()",
          "new_text": "ctx->ConstantInputAsIntVector(2, &lengths)",
          "old_line_content": "    OP_REQUIRES(ctx, !lengths.empty(),",
          "new_line_content": "    OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntVector(2, &lengths));",
          "content_same": false
        },
        {
          "line": 548,
          "old_api": "errors::Unimplemented(\"Length has to be non-empty\")",
          "new_api": "empty",
          "old_text": "errors::Unimplemented(\"Length has to be non-empty\")",
          "new_text": "lengths.empty()",
          "old_line_content": "                errors::Unimplemented(\"Length has to be non-empty\"));",
          "new_line_content": "    OP_REQUIRES(ctx, !lengths.empty(),",
          "content_same": false
        },
        {
          "line": 552,
          "old_api": "errors::Unimplemented(\"All lengths have to be the same\")",
          "new_api": "OP_REQUIRES",
          "old_text": "errors::Unimplemented(\"All lengths have to be the same\")",
          "new_text": "OP_REQUIRES(ctx, len == length,\n                  errors::Unimplemented(\"All lengths have to be the same\"))",
          "old_line_content": "                  errors::Unimplemented(\"All lengths have to be the same\"));",
          "new_line_content": "      OP_REQUIRES(ctx, len == length,",
          "content_same": false
        },
        {
          "line": 559,
          "old_api": "push_back",
          "new_api": "size",
          "old_text": "new_dims.push_back(element_dims[i])",
          "new_text": "element_dims.size()",
          "old_line_content": "      new_dims.push_back(element_dims[i]);",
          "new_line_content": "    for (int i = 1; i < element_dims.size(); i++) {",
          "content_same": false
        },
        {
          "line": 566,
          "old_api": "SetTensorListOutput",
          "new_api": "ExecuteTensorListFromTensor",
          "old_text": "ctx->SetTensorListOutput(0, result)",
          "new_text": "ExecuteTensorListFromTensor(length, reshaped, &result)",
          "old_line_content": "    ctx->SetTensorListOutput(0, result);",
          "new_line_content": "    OP_REQUIRES_OK(ctx, ExecuteTensorListFromTensor(length, reshaped, &result));",
          "content_same": false
        },
        {
          "line": 587,
          "old_api": "dim_size",
          "new_api": "InputShape",
          "old_text": "tensor_shape.dim_size(0)",
          "new_text": "ctx->InputShape(0)",
          "old_line_content": "    int num_elements = tensor_shape.dim_size(0);",
          "new_line_content": "    const TensorShape& tensor_shape = ctx->InputShape(0);",
          "content_same": false
        },
        {
          "line": 588,
          "old_api": "Input",
          "new_api": "dim_size",
          "old_text": "ctx->Input(0)",
          "new_text": "tensor_shape.dim_size(0)",
          "old_line_content": "    const xla::XlaOp tensor = ctx->Input(0);",
          "new_line_content": "    int num_elements = tensor_shape.dim_size(0);",
          "content_same": false
        },
        {
          "line": 591,
          "old_api": "ExecuteTensorListFromTensor",
          "new_api": "OP_REQUIRES_OK",
          "old_text": "ExecuteTensorListFromTensor(num_elements, tensor, &result)",
          "new_text": "OP_REQUIRES_OK(ctx,\n                   ExecuteTensorListFromTensor(num_elements, tensor, &result))",
          "old_line_content": "                   ExecuteTensorListFromTensor(num_elements, tensor, &result));",
          "new_line_content": "    OP_REQUIRES_OK(ctx,",
          "content_same": false
        },
        {
          "line": 592,
          "old_api": "builder",
          "new_api": "ExecuteTensorListFromTensor",
          "old_text": "ctx->builder()->GetShape(result)",
          "new_text": "ExecuteTensorListFromTensor(num_elements, tensor, &result)",
          "old_line_content": "    auto list_shape_or = ctx->builder()->GetShape(result);",
          "new_line_content": "                   ExecuteTensorListFromTensor(num_elements, tensor, &result));",
          "content_same": false
        },
        {
          "line": 593,
          "old_api": "SetTensorListOutput",
          "new_api": "builder",
          "old_text": "ctx->SetTensorListOutput(0, result)",
          "new_text": "ctx->builder()->GetShape(result)",
          "old_line_content": "    ctx->SetTensorListOutput(0, result);",
          "new_line_content": "    auto list_shape_or = ctx->builder()->GetShape(result);",
          "content_same": false
        },
        {
          "line": 620,
          "old_api": "OP_REQUIRES",
          "new_api": "IsNestedTensorList",
          "old_text": "OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListSetItem.\"))",
          "new_text": "IsNestedTensorList(initialized_list, &is_nested)",
          "old_line_content": "    OP_REQUIRES(ctx, !is_nested,",
          "new_line_content": "    OP_REQUIRES_OK(ctx, IsNestedTensorList(initialized_list, &is_nested));",
          "content_same": false
        },
        {
          "line": 621,
          "old_api": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListSetItem.\")",
          "new_api": "OP_REQUIRES",
          "old_text": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListSetItem.\")",
          "new_text": "OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListSetItem.\"))",
          "old_line_content": "                errors::Unimplemented(\"Only non-nested TensorList is supported \"",
          "new_line_content": "    OP_REQUIRES(ctx, !is_nested,",
          "content_same": false
        },
        {
          "line": 644,
          "old_api": "IsTensorListInput",
          "new_api": "Input",
          "old_text": "IsTensorListInput(ctx, 1)",
          "new_text": "ctx->Input(1)",
          "old_line_content": "    bool element_is_tensor_list = IsTensorListInput(ctx, 1);",
          "new_line_content": "    xla::XlaOp element = ctx->Input(1);",
          "content_same": false
        },
        {
          "line": 647,
          "old_api": "GetInitializedTensorListForElement",
          "new_api": "OP_REQUIRES_OK",
          "old_text": "GetInitializedTensorListForElement(\n                 list, element, element_is_tensor_list, &initialized_list)",
          "new_text": "OP_REQUIRES_OK(\n        ctx, GetInitializedTensorListForElement(\n                 list, element, element_is_tensor_list, &initialized_list))",
          "old_line_content": "        ctx, GetInitializedTensorListForElement(",
          "new_line_content": "    OP_REQUIRES_OK(",
          "content_same": false
        },
        {
          "line": 652,
          "old_api": "ExecuteTensorListPushBack",
          "new_api": "OP_REQUIRES_OK",
          "old_text": "ExecuteTensorListPushBack(initialized_list, element,\n                                             element_is_tensor_list, &result)",
          "new_text": "OP_REQUIRES_OK(ctx,\n                   ExecuteTensorListPushBack(initialized_list, element,\n                                             element_is_tensor_list, &result))",
          "old_line_content": "                   ExecuteTensorListPushBack(initialized_list, element,",
          "new_line_content": "    OP_REQUIRES_OK(ctx,",
          "content_same": false
        },
        {
          "line": 674,
          "old_api": "OP_REQUIRES",
          "new_api": "Input",
          "old_text": "OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"))",
          "new_text": "ctx->Input(0)",
          "old_line_content": "    OP_REQUIRES(ctx, is_initialized,",
          "new_line_content": "                   (IsTensorListInitialized(ctx->Input(0), &is_initialized)));",
          "content_same": false
        },
        {
          "line": 675,
          "old_api": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "new_api": "OP_REQUIRES",
          "old_text": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "new_text": "OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"))",
          "old_line_content": "                errors::InvalidArgument(\"TensorList is not initialized\"));",
          "new_line_content": "    OP_REQUIRES(ctx, is_initialized,",
          "content_same": false
        },
        {
          "line": 681,
          "old_api": "ExecuteTensorListPopBack",
          "new_api": "OP_REQUIRES_OK",
          "old_text": "ExecuteTensorListPopBack(list, &list_result, &element_result,\n                                            &element_is_tensor_list)",
          "new_text": "OP_REQUIRES_OK(ctx,\n                   ExecuteTensorListPopBack(list, &list_result, &element_result,\n                                            &element_is_tensor_list))",
          "old_line_content": "                   ExecuteTensorListPopBack(list, &list_result, &element_result,",
          "new_line_content": "    OP_REQUIRES_OK(ctx,",
          "content_same": false
        }
      ],
      "additions": [
        {
          "line": 513,
          "old_api": null,
          "new_api": "SetOutput",
          "old_text": null,
          "new_text": "ctx->SetOutput(1, lengths)",
          "old_line_content": "  }",
          "new_line_content": "    ctx->SetOutput(1, lengths);",
          "content_same": false
        },
        {
          "line": 520,
          "old_api": null,
          "new_api": "Name",
          "old_text": null,
          "new_text": "Name(\"TensorListConcatV2\")",
          "old_line_content": "",
          "new_line_content": "REGISTER_XLA_OP(Name(\"TensorListConcatV2\"), TensorListConcatOp);",
          "content_same": false
        },
        {
          "line": 525,
          "old_api": null,
          "new_api": "GetAttr",
          "old_text": null,
          "new_text": "ctx->GetAttr(\"element_dtype\", &dtype_)",
          "old_line_content": "    // Only non-nested TensorList is supported for now.",
          "new_line_content": "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &dtype_));",
          "content_same": false
        },
        {
          "line": 527,
          "old_api": null,
          "new_api": "OP_REQUIRES",
          "old_text": null,
          "new_text": "OP_REQUIRES(\n        ctx, dtype_ != DT_VARIANT,\n        errors::Unimplemented(\n            \"Only non-nested TensorList is supported for TensorListReserve.\"))",
          "old_line_content": "        ctx, dtype_ != DT_VARIANT,",
          "new_line_content": "    OP_REQUIRES(",
          "content_same": false
        },
        {
          "line": 529,
          "old_api": null,
          "new_api": "errors::Unimplemented(\n            \"Only non-nested TensorList is supported for TensorListReserve.\")",
          "old_text": null,
          "new_text": "errors::Unimplemented(\n            \"Only non-nested TensorList is supported for TensorListReserve.\")",
          "old_line_content": "            \"Only non-nested TensorList is supported for TensorListReserve.\"));",
          "new_line_content": "        errors::Unimplemented(",
          "content_same": false
        },
        {
          "line": 534,
          "old_api": null,
          "new_api": "Input",
          "old_text": null,
          "new_text": "ctx->Input(0)",
          "old_line_content": "",
          "new_line_content": "    xla::XlaOp input_tensor = ctx->Input(0);",
          "content_same": false
        },
        {
          "line": 539,
          "old_api": null,
          "new_api": "ConsumeValueOrDie",
          "old_text": null,
          "new_text": "shape_or.ConsumeValueOrDie()",
          "old_line_content": "    std::vector<int64_t> element_dims =",
          "new_line_content": "    xla::Shape element_shape = shape_or.ConsumeValueOrDie();",
          "content_same": false
        },
        {
          "line": 544,
          "old_api": null,
          "new_api": "errors::Unimplemented(\"Element dimensions have to be non-empty\")",
          "old_text": null,
          "new_text": "errors::Unimplemented(\"Element dimensions have to be non-empty\")",
          "old_line_content": "",
          "new_line_content": "        errors::Unimplemented(\"Element dimensions have to be non-empty\"));",
          "content_same": false
        },
        {
          "line": 549,
          "old_api": null,
          "new_api": "errors::Unimplemented(\"Length has to be non-empty\")",
          "old_text": null,
          "new_text": "errors::Unimplemented(\"Length has to be non-empty\")",
          "old_line_content": "    int64_t length = lengths[0];",
          "new_line_content": "                errors::Unimplemented(\"Length has to be non-empty\"));",
          "content_same": false
        },
        {
          "line": 553,
          "old_api": null,
          "new_api": "errors::Unimplemented(\"All lengths have to be the same\")",
          "old_text": null,
          "new_text": "errors::Unimplemented(\"All lengths have to be the same\")",
          "old_line_content": "    }",
          "new_line_content": "                  errors::Unimplemented(\"All lengths have to be the same\"));",
          "content_same": false
        },
        {
          "line": 555,
          "old_api": null,
          "new_api": "OP_REQUIRES",
          "old_text": null,
          "new_text": "OP_REQUIRES(\n        ctx, element_dims[0] % length == 0,\n        errors::Unimplemented(\"Buffer size has to be a multiple of length\"))",
          "old_line_content": "        ctx, element_dims[0] % length == 0,",
          "new_line_content": "    OP_REQUIRES(",
          "content_same": false
        },
        {
          "line": 557,
          "old_api": null,
          "new_api": "errors::Unimplemented(\"Buffer size has to be a multiple of length\")",
          "old_text": null,
          "new_text": "errors::Unimplemented(\"Buffer size has to be a multiple of length\")",
          "old_line_content": "    std::vector<int64_t> new_dims = {element_dims[0] / length, length};",
          "new_line_content": "        errors::Unimplemented(\"Buffer size has to be a multiple of length\"));",
          "content_same": false
        },
        {
          "line": 560,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "new_dims.push_back(element_dims[i])",
          "old_line_content": "    }",
          "new_line_content": "      new_dims.push_back(element_dims[i]);",
          "content_same": false
        },
        {
          "line": 563,
          "old_api": null,
          "new_api": "xla::Reshape(input_tensor, new_dims)",
          "old_text": null,
          "new_text": "xla::Reshape(input_tensor, new_dims)",
          "old_line_content": "",
          "new_line_content": "    xla::XlaOp reshaped = xla::Reshape(input_tensor, new_dims);",
          "content_same": false
        },
        {
          "line": 567,
          "old_api": null,
          "new_api": "SetTensorListOutput",
          "old_text": null,
          "new_text": "ctx->SetTensorListOutput(0, result)",
          "old_line_content": "  }",
          "new_line_content": "    ctx->SetTensorListOutput(0, result);",
          "content_same": false
        },
        {
          "line": 576,
          "old_api": null,
          "new_api": "CompileTimeConstantInput",
          "old_text": null,
          "new_text": "Name(\"TensorListSplit\")\n                    .CompileTimeConstantInput(\"element_shape\")\n                    .CompileTimeConstantInput(\"lengths\")",
          "old_line_content": "                    .CompileTimeConstantInput(\"element_shape\")",
          "new_line_content": "REGISTER_XLA_OP(Name(\"TensorListSplit\")",
          "content_same": false
        },
        {
          "line": 66,
          "old_api": null,
          "new_api": "dimensions_size",
          "old_text": null,
          "new_text": "element_shape.dimensions_size()",
          "old_line_content": "  if (leading_dim_is_dynamic) {",
          "new_line_content": "  dynamic_dims.reserve(1 + element_shape.dimensions_size());",
          "content_same": false
        },
        {
          "line": 68,
          "old_api": null,
          "new_api": "Input",
          "old_text": null,
          "new_text": "ctx->Input(1)",
          "old_line_content": "  } else {",
          "new_line_content": "    dynamic_dims.push_back(ctx->Input(1));",
          "content_same": false
        },
        {
          "line": 71,
          "old_api": null,
          "new_api": "builder",
          "old_text": null,
          "new_text": "ctx->builder()",
          "old_line_content": "  }",
          "new_line_content": "        xla::ConstantR0<int32>(ctx->builder(), num_elements));",
          "content_same": false
        },
        {
          "line": 583,
          "old_api": null,
          "new_api": "explicit",
          "old_text": null,
          "new_text": "explicit",
          "old_line_content": "      : XlaOpKernel(ctx) {}",
          "new_line_content": "  explicit TensorListFromTensorOp(OpKernelConstruction* ctx)",
          "content_same": false
        },
        {
          "line": 73,
          "old_api": null,
          "new_api": "dimensions_size",
          "old_text": null,
          "new_text": "element_shape.dimensions_size()",
          "old_line_content": "    if (dims_are_dynamic[dim]) {",
          "new_line_content": "  for (int64_t dim = 0; dim < element_shape.dimensions_size(); ++dim) {",
          "content_same": false
        },
        {
          "line": 589,
          "old_api": null,
          "new_api": "Input",
          "old_text": null,
          "new_text": "ctx->Input(0)",
          "old_line_content": "    xla::XlaOp result;",
          "new_line_content": "    const xla::XlaOp tensor = ctx->Input(0);",
          "content_same": false
        },
        {
          "line": 78,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "dynamic_dims.push_back(dynamic_dim_size)",
          "old_line_content": "    } else {",
          "new_line_content": "      dynamic_dims.push_back(dynamic_dim_size);",
          "content_same": false
        },
        {
          "line": 81,
          "old_api": null,
          "new_api": "builder",
          "old_text": null,
          "new_text": "ctx->builder()",
          "old_line_content": "    }",
          "new_line_content": "          xla::ConstantR0<int32>(ctx->builder(), dynamic_sizes[dim]));",
          "content_same": false
        },
        {
          "line": 594,
          "old_api": null,
          "new_api": "SetTensorListOutput",
          "old_text": null,
          "new_text": "ctx->SetTensorListOutput(0, result)",
          "old_line_content": "  }",
          "new_line_content": "    ctx->SetTensorListOutput(0, result);",
          "content_same": false
        },
        {
          "line": 84,
          "old_api": null,
          "new_api": "std::move(dynamic_dims)",
          "old_text": null,
          "new_text": "std::move(dynamic_dims)",
          "old_line_content": "  return list_dynamic_dims;",
          "new_line_content": "  list_dynamic_dims.push_back(std::move(dynamic_dims));",
          "content_same": false
        },
        {
          "line": 90,
          "old_api": null,
          "new_api": "explicit",
          "old_text": null,
          "new_text": "explicit",
          "old_line_content": "",
          "new_line_content": "  explicit TensorListLengthOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}",
          "content_same": false
        },
        {
          "line": 602,
          "old_api": null,
          "new_api": "CompileTimeConstantInput",
          "old_text": null,
          "new_text": "Name(\"TensorListFromTensor\").CompileTimeConstantInput(\"element_shape\")",
          "old_line_content": "    TensorListFromTensorOp);",
          "new_line_content": "    Name(\"TensorListFromTensor\").CompileTimeConstantInput(\"element_shape\"),",
          "content_same": false
        },
        {
          "line": 607,
          "old_api": null,
          "new_api": "explicit",
          "old_text": null,
          "new_text": "explicit",
          "old_line_content": "",
          "new_line_content": "  explicit TensorListSetItemOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}",
          "content_same": false
        },
        {
          "line": 96,
          "old_api": null,
          "new_api": "Input",
          "old_text": null,
          "new_text": "ctx->Input(0)",
          "old_line_content": "                                                   &leading_dim_is_dynamic,",
          "new_line_content": "    OP_REQUIRES_OK(ctx, GetLeadingDimForTensorList(ctx->Input(0), &leading_dim,",
          "content_same": false
        },
        {
          "line": 99,
          "old_api": null,
          "new_api": "SetOutput",
          "old_text": null,
          "new_text": "ctx->SetOutput(0, leading_dim_size)",
          "old_line_content": "  }",
          "new_line_content": "    ctx->SetOutput(0, leading_dim_size);",
          "content_same": false
        },
        {
          "line": 612,
          "old_api": null,
          "new_api": "Input",
          "old_text": null,
          "new_text": "ctx->Input(2)",
          "old_line_content": "    xla::XlaOp initialized_list;",
          "new_line_content": "    xla::XlaOp element = ctx->Input(2);",
          "content_same": false
        },
        {
          "line": 614,
          "old_api": null,
          "new_api": "GetInitializedTensorListForElement",
          "old_text": null,
          "new_text": "GetInitializedTensorListForElement(\n                            list, element, /*element_is_tensor_list=*/false,\n                            &initialized_list)",
          "old_line_content": "                            list, element, /*element_is_tensor_list=*/false,",
          "new_line_content": "    OP_REQUIRES_OK(ctx, GetInitializedTensorListForElement(",
          "content_same": false
        },
        {
          "line": 106,
          "old_api": null,
          "new_api": "IsMetadataOp",
          "old_text": null,
          "new_text": "Name(\"TensorListLength\").IsMetadataOp()",
          "old_line_content": "",
          "new_line_content": "REGISTER_XLA_OP(Name(\"TensorListLength\").IsMetadataOp(), TensorListLengthOp);",
          "content_same": false
        },
        {
          "line": 622,
          "old_api": null,
          "new_api": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListSetItem.\")",
          "old_text": null,
          "new_text": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListSetItem.\")",
          "old_line_content": "                                      \"for TensorListSetItem.\"));",
          "new_line_content": "                errors::Unimplemented(\"Only non-nested TensorList is supported \"",
          "content_same": false
        },
        {
          "line": 626,
          "old_api": null,
          "new_api": "ExecuteTensorListSetItem",
          "old_text": null,
          "new_text": "ExecuteTensorListSetItem(initialized_list, index,\n                                                 element, &result)",
          "old_line_content": "                                                 element, &result));",
          "new_line_content": "    OP_REQUIRES_OK(ctx, ExecuteTensorListSetItem(initialized_list, index,",
          "content_same": false
        },
        {
          "line": 115,
          "old_api": null,
          "new_api": "status",
          "old_text": null,
          "new_text": "is_compile_time_constant_or.status()",
          "old_line_content": "",
          "new_line_content": "  TF_RETURN_IF_ERROR(is_compile_time_constant_or.status());",
          "content_same": false
        },
        {
          "line": 117,
          "old_api": null,
          "new_api": "ValueOrDie",
          "old_text": null,
          "new_text": "is_compile_time_constant_or.ValueOrDie()",
          "old_line_content": "  if (!is_compile_time_constant) {",
          "new_line_content": "  bool is_compile_time_constant = is_compile_time_constant_or.ValueOrDie();",
          "content_same": false
        },
        {
          "line": 629,
          "old_api": null,
          "new_api": "SetTensorListOutput",
          "old_text": null,
          "new_text": "ctx->SetTensorListOutput(0, result)",
          "old_line_content": "  }",
          "new_line_content": "    ctx->SetTensorListOutput(0, result);",
          "content_same": false
        },
        {
          "line": 120,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "  }",
          "new_line_content": "    return Status::OK();",
          "content_same": false
        },
        {
          "line": 636,
          "old_api": null,
          "new_api": "Name",
          "old_text": null,
          "new_text": "Name(\"TensorListSetItem\")",
          "old_line_content": "",
          "new_line_content": "REGISTER_XLA_OP(Name(\"TensorListSetItem\"), TensorListSetItemOp);",
          "content_same": false
        },
        {
          "line": 125,
          "old_api": null,
          "new_api": "IsFullyDefined",
          "old_text": null,
          "new_text": "partial_shape.IsFullyDefined()",
          "old_line_content": "    *got_shape = false;",
          "new_line_content": "  if (!partial_shape.IsFullyDefined()) {",
          "content_same": false
        },
        {
          "line": 127,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "  }",
          "new_line_content": "    return Status::OK();",
          "content_same": false
        },
        {
          "line": 640,
          "old_api": null,
          "new_api": "explicit",
          "old_text": null,
          "new_text": "explicit",
          "old_line_content": "",
          "new_line_content": "  explicit TensorListPushBackOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}",
          "content_same": false
        },
        {
          "line": 130,
          "old_api": null,
          "new_api": "dim_sizes",
          "old_text": null,
          "new_text": "partial_shape.dim_sizes()",
          "old_line_content": "  *got_shape = true;",
          "new_line_content": "  *shape = xla::ShapeUtil::MakeShape(dtype, partial_shape.dim_sizes());",
          "content_same": false
        },
        {
          "line": 132,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "}",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 645,
          "old_api": null,
          "new_api": "IsTensorListInput",
          "old_text": null,
          "new_text": "IsTensorListInput(ctx, 1)",
          "old_line_content": "    xla::XlaOp initialized_list;",
          "new_line_content": "    bool element_is_tensor_list = IsTensorListInput(ctx, 1);",
          "content_same": false
        },
        {
          "line": 648,
          "old_api": null,
          "new_api": "GetInitializedTensorListForElement",
          "old_text": null,
          "new_text": "GetInitializedTensorListForElement(\n                 list, element, element_is_tensor_list, &initialized_list)",
          "old_line_content": "                 list, element, element_is_tensor_list, &initialized_list));",
          "new_line_content": "        ctx, GetInitializedTensorListForElement(",
          "content_same": false
        },
        {
          "line": 138,
          "old_api": null,
          "new_api": "GetAttr",
          "old_text": null,
          "new_text": "ctx->GetAttr(\"element_dtype\", &dtype_)",
          "old_line_content": "    // Only non-nested TensorList is supported for now.",
          "new_line_content": "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &dtype_));",
          "content_same": false
        },
        {
          "line": 140,
          "old_api": null,
          "new_api": "OP_REQUIRES",
          "old_text": null,
          "new_text": "OP_REQUIRES(\n        ctx, dtype_ != DT_VARIANT,\n        errors::Unimplemented(\n            \"Only non-nested TensorList is supported for TensorListReserve.\"))",
          "old_line_content": "        ctx, dtype_ != DT_VARIANT,",
          "new_line_content": "    OP_REQUIRES(",
          "content_same": false
        },
        {
          "line": 653,
          "old_api": null,
          "new_api": "ExecuteTensorListPushBack",
          "old_text": null,
          "new_text": "ExecuteTensorListPushBack(initialized_list, element,\n                                             element_is_tensor_list, &result)",
          "old_line_content": "                                             element_is_tensor_list, &result));",
          "new_line_content": "                   ExecuteTensorListPushBack(initialized_list, element,",
          "content_same": false
        },
        {
          "line": 142,
          "old_api": null,
          "new_api": "errors::Unimplemented(\n            \"Only non-nested TensorList is supported for TensorListReserve.\")",
          "old_text": null,
          "new_text": "errors::Unimplemented(\n            \"Only non-nested TensorList is supported for TensorListReserve.\")",
          "old_line_content": "            \"Only non-nested TensorList is supported for TensorListReserve.\"));",
          "new_line_content": "        errors::Unimplemented(",
          "content_same": false
        },
        {
          "line": 656,
          "old_api": null,
          "new_api": "SetTensorListOutput",
          "old_text": null,
          "new_text": "ctx->SetTensorListOutput(0, result)",
          "old_line_content": "  }",
          "new_line_content": "    ctx->SetTensorListOutput(0, result);",
          "content_same": false
        },
        {
          "line": 149,
          "old_api": null,
          "new_api": "ConstantInputAsIntScalar",
          "old_text": null,
          "new_text": "ctx->ConstantInputAsIntScalar(\n                       1, &num_elements, xla::ValueInferenceMode::kUpperBound)",
          "old_line_content": "                       1, &num_elements, xla::ValueInferenceMode::kUpperBound));",
          "new_line_content": "                   ctx->ConstantInputAsIntScalar(",
          "content_same": false
        },
        {
          "line": 663,
          "old_api": null,
          "new_api": "AllowVariantTypes",
          "old_text": null,
          "new_text": "Name(\"TensorListPushBack\").AllowVariantTypes()",
          "old_line_content": "                TensorListPushBackOp);",
          "new_line_content": "REGISTER_XLA_OP(Name(\"TensorListPushBack\").AllowVariantTypes(),",
          "content_same": false
        },
        {
          "line": 154,
          "old_api": null,
          "new_api": "OP_REQUIRES",
          "old_text": null,
          "new_text": "OP_REQUIRES(\n        ctx, num_elements >= 0,\n        errors::InvalidArgument(\n            \"XLA compilation requires a fixed tensor list size. Set the number \"\n            \"of elements. This could also happen if you're using a TensorArray \"\n            \"in a while loop that does not have its maximum_iteration set, you \"\n            \"can fix this by setting maximum_iteration to a suitable value.\"))",
          "old_line_content": "        ctx, num_elements >= 0,",
          "new_line_content": "    OP_REQUIRES(",
          "content_same": false
        },
        {
          "line": 156,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\n            \"XLA compilation requires a fixed tensor list size. Set the number \"\n            \"of elements. This could also happen if you're using a TensorArray \"\n            \"in a while loop that does not have its maximum_iteration set, you \"\n            \"can fix this by setting maximum_iteration to a suitable value.\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\n            \"XLA compilation requires a fixed tensor list size. Set the number \"\n            \"of elements. This could also happen if you're using a TensorArray \"\n            \"in a while loop that does not have its maximum_iteration set, you \"\n            \"can fix this by setting maximum_iteration to a suitable value.\")",
          "old_line_content": "            \"XLA compilation requires a fixed tensor list size. Set the number \"",
          "new_line_content": "        errors::InvalidArgument(",
          "content_same": false
        },
        {
          "line": 668,
          "old_api": null,
          "new_api": "explicit",
          "old_text": null,
          "new_text": "explicit",
          "old_line_content": "",
          "new_line_content": "  explicit TensorListPopBackOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}",
          "content_same": false
        },
        {
          "line": 676,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "old_line_content": "",
          "new_line_content": "                errors::InvalidArgument(\"TensorList is not initialized\"));",
          "content_same": false
        },
        {
          "line": 165,
          "old_api": null,
          "new_api": "Input",
          "old_text": null,
          "new_text": "ctx->Input(0)",
          "old_line_content": "    xla::PrimitiveType type;",
          "new_line_content": "    xla::XlaOp element_shape_handle = ctx->Input(0);",
          "content_same": false
        },
        {
          "line": 678,
          "old_api": null,
          "new_api": "Input",
          "old_text": null,
          "new_text": "ctx->Input(0)",
          "old_line_content": "    xla::XlaOp list_result, element_result;",
          "new_line_content": "    xla::XlaOp list = ctx->Input(0);",
          "content_same": false
        },
        {
          "line": 167,
          "old_api": null,
          "new_api": "DataTypeToPrimitiveType",
          "old_text": null,
          "new_text": "DataTypeToPrimitiveType(dtype_, &type)",
          "old_line_content": "    bool got_shape;",
          "new_line_content": "    OP_REQUIRES_OK(ctx, DataTypeToPrimitiveType(dtype_, &type));",
          "content_same": false
        },
        {
          "line": 682,
          "old_api": null,
          "new_api": "ExecuteTensorListPopBack",
          "old_text": null,
          "new_text": "ExecuteTensorListPopBack(list, &list_result, &element_result,\n                                            &element_is_tensor_list)",
          "old_line_content": "                                            &element_is_tensor_list));",
          "new_line_content": "                   ExecuteTensorListPopBack(list, &list_result, &element_result,",
          "content_same": false
        },
        {
          "line": 171,
          "old_api": null,
          "new_api": "TryGetElementShapeFromInput",
          "old_text": null,
          "new_text": "TryGetElementShapeFromInput(ctx, element_shape_handle, type,\n                                               &got_shape, &element_shape)",
          "old_line_content": "                                               &got_shape, &element_shape));",
          "new_line_content": "                   TryGetElementShapeFromInput(ctx, element_shape_handle, type,",
          "content_same": false
        },
        {
          "line": 685,
          "old_api": null,
          "new_api": "SetTensorListOutput",
          "old_text": null,
          "new_text": "ctx->SetTensorListOutput(0, list_result)",
          "old_line_content": "    if (element_is_tensor_list) {",
          "new_line_content": "    ctx->SetTensorListOutput(0, list_result);",
          "content_same": false
        },
        {
          "line": 175,
          "old_api": null,
          "new_api": "GetTensorListShapeFromElementShape",
          "old_text": null,
          "new_text": "GetTensorListShapeFromElementShape(\n                              element_shape, num_elements,\n                              num_element_is_dynamic, &list_shape)",
          "old_line_content": "                              element_shape, num_elements,",
          "new_line_content": "      OP_REQUIRES_OK(ctx, GetTensorListShapeFromElementShape(",
          "content_same": false
        },
        {
          "line": 687,
          "old_api": null,
          "new_api": "SetTensorListOutput",
          "old_text": null,
          "new_text": "ctx->SetTensorListOutput(1, element_result)",
          "old_line_content": "    } else {",
          "new_line_content": "      ctx->SetTensorListOutput(1, element_result);",
          "content_same": false
        },
        {
          "line": 689,
          "old_api": null,
          "new_api": "SetOutput",
          "old_text": null,
          "new_text": "ctx->SetOutput(1, element_result)",
          "old_line_content": "    }",
          "new_line_content": "      ctx->SetOutput(1, element_result);",
          "content_same": false
        },
        {
          "line": 179,
          "old_api": null,
          "new_api": "GetTensorListDynamicDims",
          "old_text": null,
          "new_text": "GetTensorListDynamicDims(\n          ctx, element_shape, list_shape, num_elements)",
          "old_line_content": "          ctx, element_shape, list_shape, num_elements);",
          "new_line_content": "      auto list_dynamic_dims_or = GetTensorListDynamicDims(",
          "content_same": false
        },
        {
          "line": 181,
          "old_api": null,
          "new_api": "status",
          "old_text": null,
          "new_text": "list_dynamic_dims_or.status()",
          "old_line_content": "      xla::XlaOp new_list;",
          "new_line_content": "      OP_REQUIRES_OK(ctx, list_dynamic_dims_or.status());",
          "content_same": false
        },
        {
          "line": 185,
          "old_api": null,
          "new_api": "ValueOrDie",
          "old_text": null,
          "new_text": "list_dynamic_dims_or.ValueOrDie()",
          "old_line_content": "      xla::XlaOp result;",
          "new_line_content": "                              list_dynamic_dims_or.ValueOrDie(), &new_list));",
          "content_same": false
        },
        {
          "line": 187,
          "old_api": null,
          "new_api": "builder",
          "old_text": null,
          "new_text": "OP_REQUIRES_OK(\n          ctx,\n          SetTensorListPushIndex(\n              new_list, xla::ConstantR0<int32>(ctx->builder(), num_elements),\n              &result))",
          "old_line_content": "          ctx,",
          "new_line_content": "      OP_REQUIRES_OK(",
          "content_same": false
        },
        {
          "line": 699,
          "old_api": null,
          "new_api": "AllowVariantTypes",
          "old_text": null,
          "new_text": "Name(\"TensorListPopBack\").AllowVariantTypes()",
          "old_line_content": "                TensorListPopBackOp);",
          "new_line_content": "REGISTER_XLA_OP(Name(\"TensorListPopBack\").AllowVariantTypes(),",
          "content_same": false
        },
        {
          "line": 190,
          "old_api": null,
          "new_api": "builder",
          "old_text": null,
          "new_text": "ctx->builder()",
          "old_line_content": "              &result));",
          "new_line_content": "              new_list, xla::ConstantR0<int32>(ctx->builder(), num_elements),",
          "content_same": false
        },
        {
          "line": 192,
          "old_api": null,
          "new_api": "SetTensorListOutput",
          "old_text": null,
          "new_text": "ctx->SetTensorListOutput(0, result)",
          "old_line_content": "      return;",
          "new_line_content": "      ctx->SetTensorListOutput(0, result);",
          "content_same": false
        },
        {
          "line": 198,
          "old_api": null,
          "new_api": "SetTensorListOutput",
          "old_text": null,
          "new_text": "ctx->SetTensorListOutput(0, result)",
          "old_line_content": "  }",
          "new_line_content": "    ctx->SetTensorListOutput(0, result);",
          "content_same": false
        },
        {
          "line": 207,
          "old_api": null,
          "new_api": "CompileTimeConstantInput",
          "old_text": null,
          "new_text": "Name(\"TensorListReserve\")\n                    .CompileTimeConstantInput(\"element_shape\")\n                    .CompileTimeConstantInput(\"num_elements\")",
          "old_line_content": "                    .CompileTimeConstantInput(\"element_shape\")",
          "new_line_content": "REGISTER_XLA_OP(Name(\"TensorListReserve\")",
          "content_same": false
        },
        {
          "line": 215,
          "old_api": null,
          "new_api": "GetAttr",
          "old_text": null,
          "new_text": "ctx->GetAttr(\"element_dtype\", &dtype_)",
          "old_line_content": "  }",
          "new_line_content": "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &dtype_));",
          "content_same": false
        },
        {
          "line": 221,
          "old_api": null,
          "new_api": "ConstantInputAsIntScalar",
          "old_text": null,
          "new_text": "ctx->ConstantInputAsIntScalar(\n                 1, &max_num_elements, xla::ValueInferenceMode::kUpperBound)",
          "old_line_content": "                 1, &max_num_elements, xla::ValueInferenceMode::kUpperBound));",
          "new_line_content": "        ctx, ctx->ConstantInputAsIntScalar(",
          "content_same": false
        },
        {
          "line": 227,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\n                    \"XLA compilation requires a fixed tensor list size. Set \"\n                    \"the max number of elements. This could also happen if \"\n                    \"you're using a TensorArray in a while loop that does not \"\n                    \"have its maximum_iteration set, you can fix this by \"\n                    \"setting maximum_iteration to a suitable value.\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\n                    \"XLA compilation requires a fixed tensor list size. Set \"\n                    \"the max number of elements. This could also happen if \"\n                    \"you're using a TensorArray in a while loop that does not \"\n                    \"have its maximum_iteration set, you can fix this by \"\n                    \"setting maximum_iteration to a suitable value.\")",
          "old_line_content": "                    \"XLA compilation requires a fixed tensor list size. Set \"",
          "new_line_content": "                errors::InvalidArgument(",
          "content_same": false
        },
        {
          "line": 239,
          "old_api": null,
          "new_api": "Input",
          "old_text": null,
          "new_text": "ctx->Input(0)",
          "old_line_content": "      xla::PrimitiveType type;",
          "new_line_content": "      xla::XlaOp element_shape_handle = ctx->Input(0);",
          "content_same": false
        },
        {
          "line": 241,
          "old_api": null,
          "new_api": "DataTypeToPrimitiveType",
          "old_text": null,
          "new_text": "DataTypeToPrimitiveType(dtype_, &type)",
          "old_line_content": "      bool got_shape;",
          "new_line_content": "      OP_REQUIRES_OK(ctx, DataTypeToPrimitiveType(dtype_, &type));",
          "content_same": false
        },
        {
          "line": 245,
          "old_api": null,
          "new_api": "TryGetElementShapeFromInput",
          "old_text": null,
          "new_text": "TryGetElementShapeFromInput(ctx, element_shape_handle, type,\n                                           &got_shape, &element_shape)",
          "old_line_content": "                                           &got_shape, &element_shape));",
          "new_line_content": "          ctx, TryGetElementShapeFromInput(ctx, element_shape_handle, type,",
          "content_same": false
        },
        {
          "line": 249,
          "old_api": null,
          "new_api": "GetTensorListShapeFromElementShape",
          "old_text": null,
          "new_text": "GetTensorListShapeFromElementShape(\n                                element_shape, max_num_elements,\n                                num_element_is_dynamic, &list_shape)",
          "old_line_content": "                                element_shape, max_num_elements,",
          "new_line_content": "        OP_REQUIRES_OK(ctx, GetTensorListShapeFromElementShape(",
          "content_same": false
        },
        {
          "line": 253,
          "old_api": null,
          "new_api": "GetTensorListDynamicDims",
          "old_text": null,
          "new_text": "GetTensorListDynamicDims(\n            ctx, element_shape, list_shape, max_num_elements)",
          "old_line_content": "            ctx, element_shape, list_shape, max_num_elements);",
          "new_line_content": "        auto list_dynamic_dims_or = GetTensorListDynamicDims(",
          "content_same": false
        },
        {
          "line": 255,
          "old_api": null,
          "new_api": "status",
          "old_text": null,
          "new_text": "list_dynamic_dims_or.status()",
          "old_line_content": "",
          "new_line_content": "        OP_REQUIRES_OK(ctx, list_dynamic_dims_or.status());",
          "content_same": false
        },
        {
          "line": 260,
          "old_api": null,
          "new_api": "ValueOrDie",
          "old_text": null,
          "new_text": "list_dynamic_dims_or.ValueOrDie()",
          "old_line_content": "",
          "new_line_content": "                                list_dynamic_dims_or.ValueOrDie(), &result));",
          "content_same": false
        },
        {
          "line": 262,
          "old_api": null,
          "new_api": "SetTensorListOutput",
          "old_text": null,
          "new_text": "ctx->SetTensorListOutput(0, result)",
          "old_line_content": "        return;",
          "new_line_content": "        ctx->SetTensorListOutput(0, result);",
          "content_same": false
        },
        {
          "line": 272,
          "old_api": null,
          "new_api": "SetTensorListOutput",
          "old_text": null,
          "new_text": "ctx->SetTensorListOutput(0, result)",
          "old_line_content": "  }",
          "new_line_content": "    ctx->SetTensorListOutput(0, result);",
          "content_same": false
        },
        {
          "line": 281,
          "old_api": null,
          "new_api": "CompileTimeConstantInput",
          "old_text": null,
          "new_text": "Name(\"EmptyTensorList\")\n                    .CompileTimeConstantInput(\"element_shape\")\n                    .CompileTimeConstantInput(\"max_num_elements\")\n                    .AllowVariantTypes()",
          "old_line_content": "                    .CompileTimeConstantInput(\"element_shape\")",
          "new_line_content": "REGISTER_XLA_OP(Name(\"EmptyTensorList\")",
          "content_same": false
        },
        {
          "line": 289,
          "old_api": null,
          "new_api": "explicit",
          "old_text": null,
          "new_text": "explicit",
          "old_line_content": "      : XlaOpKernel(ctx) {",
          "new_line_content": "  explicit TensorListElementShapeOp(OpKernelConstruction* ctx)",
          "content_same": false
        },
        {
          "line": 291,
          "old_api": null,
          "new_api": "GetAttr",
          "old_text": null,
          "new_text": "ctx->GetAttr(\"shape_type\", &shape_type_)",
          "old_line_content": "  }",
          "new_line_content": "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"shape_type\", &shape_type_));",
          "content_same": false
        },
        {
          "line": 300,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "old_line_content": "",
          "new_line_content": "                errors::InvalidArgument(\"TensorList is not initialized\"));",
          "content_same": false
        },
        {
          "line": 306,
          "old_api": null,
          "new_api": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListElementShape.\")",
          "old_text": null,
          "new_text": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListElementShape.\")",
          "old_line_content": "                                      \"for TensorListElementShape.\"));",
          "new_line_content": "                errors::Unimplemented(\"Only non-nested TensorList is supported \"",
          "content_same": false
        },
        {
          "line": 311,
          "old_api": null,
          "new_api": "builder",
          "old_text": null,
          "new_text": "ctx->builder()",
          "old_line_content": "    xla::Shape list_shape;",
          "new_line_content": "    xla::XlaBuilder* b = ctx->builder();",
          "content_same": false
        },
        {
          "line": 314,
          "old_api": null,
          "new_api": "DeleteDimension",
          "old_text": null,
          "new_text": "list_shape.DeleteDimension(0)",
          "old_line_content": "",
          "new_line_content": "    list_shape.DeleteDimension(0);",
          "content_same": false
        },
        {
          "line": 318,
          "old_api": null,
          "new_api": "dimensions",
          "old_text": null,
          "new_text": "list_shape.dimensions()",
          "old_line_content": "        break;",
          "new_line_content": "        ctx->SetOutput(0, xla::ConstantR1<int64_t>(b, list_shape.dimensions()));",
          "content_same": false
        },
        {
          "line": 323,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "dimensions.size()",
          "old_line_content": "        for (int64_t s : dimensions) {",
          "new_line_content": "        size.reserve(dimensions.size());",
          "content_same": false
        },
        {
          "line": 325,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "size.push_back(s)",
          "old_line_content": "        }",
          "new_line_content": "          size.push_back(s);",
          "content_same": false
        },
        {
          "line": 327,
          "old_api": null,
          "new_api": "xla::ConstantR1<int32>(b, size)",
          "old_text": null,
          "new_text": "xla::ConstantR1<int32>(b, size)",
          "old_line_content": "        break;",
          "new_line_content": "        ctx->SetOutput(0, xla::ConstantR1<int32>(b, size));",
          "content_same": false
        },
        {
          "line": 332,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\"Unsupported shape type requested\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\"Unsupported shape type requested\")",
          "old_line_content": "        return;",
          "new_line_content": "            errors::InvalidArgument(\"Unsupported shape type requested\"));",
          "content_same": false
        },
        {
          "line": 343,
          "old_api": null,
          "new_api": "IsMetadataOp",
          "old_text": null,
          "new_text": "Name(\"TensorListElementShape\").IsMetadataOp()",
          "old_line_content": "                TensorListElementShapeOp);",
          "new_line_content": "REGISTER_XLA_OP(Name(\"TensorListElementShape\").IsMetadataOp(),",
          "content_same": false
        },
        {
          "line": 349,
          "old_api": null,
          "new_api": "GetAttr",
          "old_text": null,
          "new_text": "ctx->GetAttr(\"element_dtype\", &dtype_)",
          "old_line_content": "  }",
          "new_line_content": "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &dtype_));",
          "content_same": false
        },
        {
          "line": 358,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "old_line_content": "",
          "new_line_content": "                errors::InvalidArgument(\"TensorList is not initialized\"));",
          "content_same": false
        },
        {
          "line": 364,
          "old_api": null,
          "new_api": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGetItem.\")",
          "old_text": null,
          "new_text": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGetItem.\")",
          "old_line_content": "                                      \"for TensorListGetItem.\"));",
          "new_line_content": "                errors::Unimplemented(\"Only non-nested TensorList is supported \"",
          "content_same": false
        },
        {
          "line": 368,
          "old_api": null,
          "new_api": "Input",
          "old_text": null,
          "new_text": "ctx->Input(1)",
          "old_line_content": "",
          "new_line_content": "    xla::XlaOp index = ctx->Input(1);",
          "content_same": false
        },
        {
          "line": 371,
          "old_api": null,
          "new_api": "ExecuteTensorListGetItem",
          "old_text": null,
          "new_text": "ExecuteTensorListGetItem(list, index, &result)",
          "old_line_content": "",
          "new_line_content": "    OP_REQUIRES_OK(ctx, ExecuteTensorListGetItem(list, index, &result));",
          "content_same": false
        },
        {
          "line": 373,
          "old_api": null,
          "new_api": "SetOutput",
          "old_text": null,
          "new_text": "ctx->SetOutput(0, result)",
          "old_line_content": "  }",
          "new_line_content": "    ctx->SetOutput(0, result);",
          "content_same": false
        },
        {
          "line": 382,
          "old_api": null,
          "new_api": "Name",
          "old_text": null,
          "new_text": "Name(\"TensorListGetItem\")",
          "old_line_content": "",
          "new_line_content": "REGISTER_XLA_OP(Name(\"TensorListGetItem\"), TensorListGetItemOp);",
          "content_same": false
        },
        {
          "line": 387,
          "old_api": null,
          "new_api": "GetAttr",
          "old_text": null,
          "new_text": "ctx->GetAttr(\"element_dtype\", &dtype_)",
          "old_line_content": "  }",
          "new_line_content": "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &dtype_));",
          "content_same": false
        },
        {
          "line": 396,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "old_line_content": "",
          "new_line_content": "                errors::InvalidArgument(\"TensorList is not initialized\"));",
          "content_same": false
        },
        {
          "line": 402,
          "old_api": null,
          "new_api": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGather.\")",
          "old_text": null,
          "new_text": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGather.\")",
          "old_line_content": "                                      \"for TensorListGather.\"));",
          "new_line_content": "                errors::Unimplemented(\"Only non-nested TensorList is supported \"",
          "content_same": false
        },
        {
          "line": 405,
          "old_api": null,
          "new_api": "input_type",
          "old_text": null,
          "new_text": "ctx->input_type(1)",
          "old_line_content": "",
          "new_line_content": "    DataType indices_type = ctx->input_type(1);",
          "content_same": false
        },
        {
          "line": 409,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\"indices must be rank 1\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\"indices must be rank 1\")",
          "old_line_content": "",
          "new_line_content": "                errors::InvalidArgument(\"indices must be rank 1\"));",
          "content_same": false
        },
        {
          "line": 412,
          "old_api": null,
          "new_api": "Input",
          "old_text": null,
          "new_text": "ctx->Input(1)",
          "old_line_content": "",
          "new_line_content": "    xla::XlaOp indices = ctx->Input(1);",
          "content_same": false
        },
        {
          "line": 415,
          "old_api": null,
          "new_api": "GetTensorListBuffer",
          "old_text": null,
          "new_text": "GetTensorListBuffer(list, &buffer)",
          "old_line_content": "    xla::Shape buffer_xla_shape;",
          "new_line_content": "    OP_REQUIRES_OK(ctx, GetTensorListBuffer(list, &buffer));",
          "content_same": false
        },
        {
          "line": 417,
          "old_api": null,
          "new_api": "GetTensorListBufferShape",
          "old_text": null,
          "new_text": "GetTensorListBufferShape(list, &buffer_xla_shape)",
          "old_line_content": "    TensorShape buffer_shape;",
          "new_line_content": "    OP_REQUIRES_OK(ctx, GetTensorListBufferShape(list, &buffer_xla_shape));",
          "content_same": false
        },
        {
          "line": 419,
          "old_api": null,
          "new_api": "XLAShapeToTensorShape",
          "old_text": null,
          "new_text": "XLAShapeToTensorShape(buffer_xla_shape, &buffer_shape)",
          "old_line_content": "",
          "new_line_content": "    OP_REQUIRES_OK(ctx, XLAShapeToTensorShape(buffer_xla_shape, &buffer_shape));",
          "content_same": false
        },
        {
          "line": 423,
          "old_api": null,
          "new_api": "builder",
          "old_text": null,
          "new_text": "XlaGather(buffer, buffer_shape, indices, indices_shape, /*axis=*/0,\n                       /*indices_are_nd=*/false, dtype_, indices_type,\n                       ctx->builder(), &result)",
          "old_line_content": "                       /*indices_are_nd=*/false, dtype_, indices_type,",
          "new_line_content": "        ctx, XlaGather(buffer, buffer_shape, indices, indices_shape, /*axis=*/0,",
          "content_same": false
        },
        {
          "line": 426,
          "old_api": null,
          "new_api": "SetOutput",
          "old_text": null,
          "new_text": "ctx->SetOutput(0, result)",
          "old_line_content": "  }",
          "new_line_content": "    ctx->SetOutput(0, result);",
          "content_same": false
        },
        {
          "line": 435,
          "old_api": null,
          "new_api": "Name",
          "old_text": null,
          "new_text": "Name(\"TensorListGather\")",
          "old_line_content": "",
          "new_line_content": "REGISTER_XLA_OP(Name(\"TensorListGather\"), TensorListGatherOp);",
          "content_same": false
        },
        {
          "line": 439,
          "old_api": null,
          "new_api": "explicit",
          "old_text": null,
          "new_text": "explicit",
          "old_line_content": "",
          "new_line_content": "  explicit TensorListStackOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}",
          "content_same": false
        },
        {
          "line": 447,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "old_line_content": "",
          "new_line_content": "                errors::InvalidArgument(\"TensorList is not initialized\"));",
          "content_same": false
        },
        {
          "line": 453,
          "old_api": null,
          "new_api": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGetItem.\")",
          "old_text": null,
          "new_text": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGetItem.\")",
          "old_line_content": "                                      \"for TensorListGetItem.\"));",
          "new_line_content": "                errors::Unimplemented(\"Only non-nested TensorList is supported \"",
          "content_same": false
        },
        {
          "line": 458,
          "old_api": null,
          "new_api": "SetOutput",
          "old_text": null,
          "new_text": "ctx->SetOutput(0, buffer)",
          "old_line_content": "  }",
          "new_line_content": "    ctx->SetOutput(0, buffer);",
          "content_same": false
        },
        {
          "line": 465,
          "old_api": null,
          "new_api": "Name",
          "old_text": null,
          "new_text": "Name(\"TensorListStack\")",
          "old_line_content": "",
          "new_line_content": "REGISTER_XLA_OP(Name(\"TensorListStack\"), TensorListStackOp);",
          "content_same": false
        },
        {
          "line": 469,
          "old_api": null,
          "new_api": "explicit",
          "old_text": null,
          "new_text": "explicit",
          "old_line_content": "",
          "new_line_content": "  explicit TensorListConcatOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}",
          "content_same": false
        },
        {
          "line": 472,
          "old_api": null,
          "new_api": "Input",
          "old_text": null,
          "new_text": "ctx->Input(0)",
          "old_line_content": "",
          "new_line_content": "    xla::XlaOp input = ctx->Input(0);",
          "content_same": false
        },
        {
          "line": 478,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\"TensorList is not initialized\")",
          "old_line_content": "",
          "new_line_content": "                errors::InvalidArgument(\"TensorList is not initialized\"));",
          "content_same": false
        },
        {
          "line": 484,
          "old_api": null,
          "new_api": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListConcat.\")",
          "old_text": null,
          "new_text": "errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListConcat.\")",
          "old_line_content": "                                      \"for TensorListConcat.\"));",
          "new_line_content": "                errors::Unimplemented(\"Only non-nested TensorList is supported \"",
          "content_same": false
        },
        {
          "line": 488,
          "old_api": null,
          "new_api": "GetTensorListBuffer",
          "old_text": null,
          "new_text": "GetTensorListBuffer(input, &buffer)",
          "old_line_content": "",
          "new_line_content": "    OP_REQUIRES_OK(ctx, GetTensorListBuffer(input, &buffer));",
          "content_same": false
        },
        {
          "line": 493,
          "old_api": null,
          "new_api": "ConsumeValueOrDie",
          "old_text": null,
          "new_text": "shape_or.ConsumeValueOrDie()",
          "old_line_content": "    std::vector<int64_t> element_dims =",
          "new_line_content": "    xla::Shape element_shape = shape_or.ConsumeValueOrDie();",
          "content_same": false
        },
        {
          "line": 498,
          "old_api": null,
          "new_api": "errors::Unimplemented(\"TensorList of scalars is not supported\")",
          "old_text": null,
          "new_text": "errors::Unimplemented(\"TensorList of scalars is not supported\")",
          "old_line_content": "    int64_t num_elements = element_dims[0];",
          "new_line_content": "        errors::Unimplemented(\"TensorList of scalars is not supported\"));",
          "content_same": false
        },
        {
          "line": 505,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "new_dims.push_back(element_dims[i])",
          "old_line_content": "    }",
          "new_line_content": "      new_dims.push_back(element_dims[i]);",
          "content_same": false
        },
        {
          "line": 509,
          "old_api": null,
          "new_api": "SetOutput",
          "old_text": null,
          "new_text": "ctx->SetOutput(0, out)",
          "old_line_content": "",
          "new_line_content": "    ctx->SetOutput(0, out);",
          "content_same": false
        }
      ],
      "deletions": [
        {
          "line": 519,
          "old_api": "Name",
          "new_api": null,
          "old_text": "Name(\"TensorListConcatV2\")",
          "new_text": null,
          "old_line_content": "REGISTER_XLA_OP(Name(\"TensorListConcatV2\"), TensorListConcatOp);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 523,
          "old_api": "explicit",
          "new_api": null,
          "old_text": "explicit",
          "new_text": null,
          "old_line_content": "  explicit TensorListSplitOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {",
          "new_line_content": " public:",
          "content_same": false
        },
        {
          "line": 526,
          "old_api": "OP_REQUIRES",
          "new_api": null,
          "old_text": "OP_REQUIRES(\n        ctx, dtype_ != DT_VARIANT,\n        errors::Unimplemented(\n            \"Only non-nested TensorList is supported for TensorListReserve.\"))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES(",
          "new_line_content": "    // Only non-nested TensorList is supported for now.",
          "content_same": false
        },
        {
          "line": 528,
          "old_api": "errors::Unimplemented(\n            \"Only non-nested TensorList is supported for TensorListReserve.\")",
          "new_api": null,
          "old_text": "errors::Unimplemented(\n            \"Only non-nested TensorList is supported for TensorListReserve.\")",
          "new_text": null,
          "old_line_content": "        errors::Unimplemented(",
          "new_line_content": "        ctx, dtype_ != DT_VARIANT,",
          "content_same": false
        },
        {
          "line": 533,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "    xla::XlaOp input_tensor = ctx->Input(0);",
          "new_line_content": "  void Compile(XlaOpKernelContext* ctx) override {",
          "content_same": false
        },
        {
          "line": 535,
          "old_api": "builder",
          "new_api": null,
          "old_text": "input_tensor.builder()",
          "new_text": null,
          "old_line_content": "    xla::XlaBuilder* b = input_tensor.builder();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 540,
          "old_api": "dimensions",
          "new_api": null,
          "old_text": "element_shape.dimensions()",
          "new_text": null,
          "old_line_content": "        xla::SpanToVector(element_shape.dimensions());",
          "new_line_content": "    std::vector<int64_t> element_dims =",
          "content_same": false
        },
        {
          "line": 546,
          "old_api": "ConstantInputAsIntVector",
          "new_api": null,
          "old_text": "ctx->ConstantInputAsIntVector(2, &lengths)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntVector(2, &lengths));",
          "new_line_content": "    std::vector<int64_t> lengths;",
          "content_same": false
        },
        {
          "line": 551,
          "old_api": "OP_REQUIRES",
          "new_api": null,
          "old_text": "OP_REQUIRES(ctx, len == length,\n                  errors::Unimplemented(\"All lengths have to be the same\"))",
          "new_text": null,
          "old_line_content": "      OP_REQUIRES(ctx, len == length,",
          "new_line_content": "    for (int64_t len : lengths) {",
          "content_same": false
        },
        {
          "line": 554,
          "old_api": "OP_REQUIRES",
          "new_api": null,
          "old_text": "OP_REQUIRES(\n        ctx, element_dims[0] % length == 0,\n        errors::Unimplemented(\"Buffer size has to be a multiple of length\"))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES(",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 556,
          "old_api": "errors::Unimplemented(\"Buffer size has to be a multiple of length\")",
          "new_api": null,
          "old_text": "errors::Unimplemented(\"Buffer size has to be a multiple of length\")",
          "new_text": null,
          "old_line_content": "        errors::Unimplemented(\"Buffer size has to be a multiple of length\"));",
          "new_line_content": "        ctx, element_dims[0] % length == 0,",
          "content_same": false
        },
        {
          "line": 558,
          "old_api": "size",
          "new_api": null,
          "old_text": "element_dims.size()",
          "new_text": null,
          "old_line_content": "    for (int i = 1; i < element_dims.size(); i++) {",
          "new_line_content": "    std::vector<int64_t> new_dims = {element_dims[0] / length, length};",
          "content_same": false
        },
        {
          "line": 562,
          "old_api": "xla::Reshape(input_tensor, new_dims)",
          "new_api": null,
          "old_text": "xla::Reshape(input_tensor, new_dims)",
          "new_text": null,
          "old_line_content": "    xla::XlaOp reshaped = xla::Reshape(input_tensor, new_dims);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 565,
          "old_api": "ExecuteTensorListFromTensor",
          "new_api": null,
          "old_text": "ExecuteTensorListFromTensor(length, reshaped, &result)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, ExecuteTensorListFromTensor(length, reshaped, &result));",
          "new_line_content": "    xla::XlaOp result;",
          "content_same": false
        },
        {
          "line": 575,
          "old_api": "CompileTimeConstantInput",
          "new_api": null,
          "old_text": "Name(\"TensorListSplit\")\n                    .CompileTimeConstantInput(\"element_shape\")\n                    .CompileTimeConstantInput(\"lengths\")",
          "new_text": null,
          "old_line_content": "REGISTER_XLA_OP(Name(\"TensorListSplit\")",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 67,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(1)",
          "new_text": null,
          "old_line_content": "    dynamic_dims.push_back(ctx->Input(1));",
          "new_line_content": "  if (leading_dim_is_dynamic) {",
          "content_same": false
        },
        {
          "line": 69,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "dynamic_dims.push_back(\n        xla::ConstantR0<int32>(ctx->builder(), num_elements))",
          "new_text": null,
          "old_line_content": "    dynamic_dims.push_back(",
          "new_line_content": "  } else {",
          "content_same": false
        },
        {
          "line": 582,
          "old_api": "explicit",
          "new_api": null,
          "old_text": "explicit",
          "new_text": null,
          "old_line_content": "  explicit TensorListFromTensorOp(OpKernelConstruction* ctx)",
          "new_line_content": " public:",
          "content_same": false
        },
        {
          "line": 72,
          "old_api": "dimensions_size",
          "new_api": null,
          "old_text": "element_shape.dimensions_size()",
          "new_text": null,
          "old_line_content": "  for (int64_t dim = 0; dim < element_shape.dimensions_size(); ++dim) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 74,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "      auto dynamic_dim_size = xla::Slice(ctx->Input(0), {dim}, {dim + 1}, {1});",
          "new_line_content": "    if (dims_are_dynamic[dim]) {",
          "content_same": false
        },
        {
          "line": 586,
          "old_api": "InputShape",
          "new_api": null,
          "old_text": "ctx->InputShape(0)",
          "new_text": null,
          "old_line_content": "    const TensorShape& tensor_shape = ctx->InputShape(0);",
          "new_line_content": "  void Compile(XlaOpKernelContext* ctx) override {",
          "content_same": false
        },
        {
          "line": 590,
          "old_api": "OP_REQUIRES_OK",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(ctx,\n                   ExecuteTensorListFromTensor(num_elements, tensor, &result))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx,",
          "new_line_content": "    xla::XlaOp result;",
          "content_same": false
        },
        {
          "line": 79,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "dynamic_dims.push_back(\n          xla::ConstantR0<int32>(ctx->builder(), dynamic_sizes[dim]))",
          "new_text": null,
          "old_line_content": "      dynamic_dims.push_back(",
          "new_line_content": "    } else {",
          "content_same": false
        },
        {
          "line": 83,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "list_dynamic_dims.push_back(dynamic_dims)",
          "new_text": null,
          "old_line_content": "  list_dynamic_dims.push_back(dynamic_dims);",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 600,
          "old_api": "CompileTimeConstantInput",
          "new_api": null,
          "old_text": "REGISTER_XLA_OP(\n    Name(\"TensorListFromTensor\").CompileTimeConstantInput(\"element_shape\"),\n    TensorListFromTensorOp)",
          "new_text": null,
          "old_line_content": "REGISTER_XLA_OP(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 89,
          "old_api": "explicit",
          "new_api": null,
          "old_text": "explicit",
          "new_text": null,
          "old_line_content": "  explicit TensorListLengthOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}",
          "new_line_content": " public:",
          "content_same": false
        },
        {
          "line": 606,
          "old_api": "explicit",
          "new_api": null,
          "old_text": "explicit",
          "new_text": null,
          "old_line_content": "  explicit TensorListSetItemOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}",
          "new_line_content": " public:",
          "content_same": false
        },
        {
          "line": 95,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, GetLeadingDimForTensorList(ctx->Input(0), &leading_dim,",
          "new_line_content": "    bool leading_dim_is_dynamic;",
          "content_same": false
        },
        {
          "line": 609,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "    xla::XlaOp list = ctx->Input(0);",
          "new_line_content": "  void Compile(XlaOpKernelContext* ctx) override {",
          "content_same": false
        },
        {
          "line": 98,
          "old_api": "SetOutput",
          "new_api": null,
          "old_text": "ctx->SetOutput(0, leading_dim_size)",
          "new_text": null,
          "old_line_content": "    ctx->SetOutput(0, leading_dim_size);",
          "new_line_content": "                                                   &leading_dim_size));",
          "content_same": false
        },
        {
          "line": 613,
          "old_api": "GetInitializedTensorListForElement",
          "new_api": null,
          "old_text": "GetInitializedTensorListForElement(\n                            list, element, /*element_is_tensor_list=*/false,\n                            &initialized_list)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, GetInitializedTensorListForElement(",
          "new_line_content": "    xla::XlaOp initialized_list;",
          "content_same": false
        },
        {
          "line": 105,
          "old_api": "IsMetadataOp",
          "new_api": null,
          "old_text": "Name(\"TensorListLength\").IsMetadataOp()",
          "new_text": null,
          "old_line_content": "REGISTER_XLA_OP(Name(\"TensorListLength\").IsMetadataOp(), TensorListLengthOp);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 619,
          "old_api": "IsNestedTensorList",
          "new_api": null,
          "old_text": "IsNestedTensorList(initialized_list, &is_nested)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, IsNestedTensorList(initialized_list, &is_nested));",
          "new_line_content": "    bool is_nested;",
          "content_same": false
        },
        {
          "line": 113,
          "old_api": "builder",
          "new_api": null,
          "old_text": "input.builder()->IsConstant(input)",
          "new_text": null,
          "old_line_content": "  auto is_compile_time_constant_or = input.builder()->IsConstant(input);",
          "new_line_content": "                                   xla::Shape* shape) {",
          "content_same": false
        },
        {
          "line": 625,
          "old_api": "ExecuteTensorListSetItem",
          "new_api": null,
          "old_text": "ExecuteTensorListSetItem(initialized_list, index,\n                                                 element, &result)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, ExecuteTensorListSetItem(initialized_list, index,",
          "new_line_content": "    xla::XlaOp result;",
          "content_same": false
        },
        {
          "line": 116,
          "old_api": "ValueOrDie",
          "new_api": null,
          "old_text": "is_compile_time_constant_or.ValueOrDie()",
          "new_text": null,
          "old_line_content": "  bool is_compile_time_constant = is_compile_time_constant_or.ValueOrDie();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 628,
          "old_api": "SetTensorListOutput",
          "new_api": null,
          "old_text": "ctx->SetTensorListOutput(0, result)",
          "new_text": null,
          "old_line_content": "    ctx->SetTensorListOutput(0, result);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 119,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "    return Status::OK();",
          "new_line_content": "    *got_shape = false;",
          "content_same": false
        },
        {
          "line": 635,
          "old_api": "Name",
          "new_api": null,
          "old_text": "Name(\"TensorListSetItem\")",
          "new_text": null,
          "old_line_content": "REGISTER_XLA_OP(Name(\"TensorListSetItem\"), TensorListSetItemOp);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 123,
          "old_api": "ConstantInputAsPartialShape",
          "new_api": null,
          "old_text": "ctx->ConstantInputAsPartialShape(0, &partial_shape)",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(ctx->ConstantInputAsPartialShape(0, &partial_shape));",
          "new_line_content": "  PartialTensorShape partial_shape;",
          "content_same": false
        },
        {
          "line": 126,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "    return Status::OK();",
          "new_line_content": "    *got_shape = false;",
          "content_same": false
        },
        {
          "line": 639,
          "old_api": "explicit",
          "new_api": null,
          "old_text": "explicit",
          "new_text": null,
          "old_line_content": "  explicit TensorListPushBackOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}",
          "new_line_content": " public:",
          "content_same": false
        },
        {
          "line": 129,
          "old_api": "dim_sizes",
          "new_api": null,
          "old_text": "partial_shape.dim_sizes()",
          "new_text": null,
          "old_line_content": "  *shape = xla::ShapeUtil::MakeShape(dtype, partial_shape.dim_sizes());",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 642,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "    xla::XlaOp list = ctx->Input(0);",
          "new_line_content": "  void Compile(XlaOpKernelContext* ctx) override {",
          "content_same": false
        },
        {
          "line": 131,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "  return Status::OK();",
          "new_line_content": "  *got_shape = true;",
          "content_same": false
        },
        {
          "line": 646,
          "old_api": "OP_REQUIRES_OK",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(\n        ctx, GetInitializedTensorListForElement(\n                 list, element, element_is_tensor_list, &initialized_list))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(",
          "new_line_content": "    xla::XlaOp initialized_list;",
          "content_same": false
        },
        {
          "line": 136,
          "old_api": "explicit",
          "new_api": null,
          "old_text": "explicit",
          "new_text": null,
          "old_line_content": "  explicit TensorListReserveOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {",
          "new_line_content": " public:",
          "content_same": false
        },
        {
          "line": 139,
          "old_api": "OP_REQUIRES",
          "new_api": null,
          "old_text": "OP_REQUIRES(\n        ctx, dtype_ != DT_VARIANT,\n        errors::Unimplemented(\n            \"Only non-nested TensorList is supported for TensorListReserve.\"))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES(",
          "new_line_content": "    // Only non-nested TensorList is supported for now.",
          "content_same": false
        },
        {
          "line": 651,
          "old_api": "OP_REQUIRES_OK",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(ctx,\n                   ExecuteTensorListPushBack(initialized_list, element,\n                                             element_is_tensor_list, &result))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx,",
          "new_line_content": "    xla::XlaOp result;",
          "content_same": false
        },
        {
          "line": 141,
          "old_api": "errors::Unimplemented(\n            \"Only non-nested TensorList is supported for TensorListReserve.\")",
          "new_api": null,
          "old_text": "errors::Unimplemented(\n            \"Only non-nested TensorList is supported for TensorListReserve.\")",
          "new_text": null,
          "old_line_content": "        errors::Unimplemented(",
          "new_line_content": "        ctx, dtype_ != DT_VARIANT,",
          "content_same": false
        },
        {
          "line": 655,
          "old_api": "SetTensorListOutput",
          "new_api": null,
          "old_text": "ctx->SetTensorListOutput(0, result)",
          "new_text": null,
          "old_line_content": "    ctx->SetTensorListOutput(0, result);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 147,
          "old_api": "ConstantInputAsIntScalar",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(ctx,\n                   ctx->ConstantInputAsIntScalar(\n                       1, &num_elements, xla::ValueInferenceMode::kUpperBound))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx,",
          "new_line_content": "    int64_t num_elements;",
          "content_same": false
        },
        {
          "line": 662,
          "old_api": "AllowVariantTypes",
          "new_api": null,
          "old_text": "Name(\"TensorListPushBack\").AllowVariantTypes()",
          "new_text": null,
          "old_line_content": "REGISTER_XLA_OP(Name(\"TensorListPushBack\").AllowVariantTypes(),",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 151,
          "old_api": "ResolveInputDynamismIntoPred",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(\n        ctx, ctx->ResolveInputDynamismIntoPred(1, &num_element_is_dynamic))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(",
          "new_line_content": "    bool num_element_is_dynamic;",
          "content_same": false
        },
        {
          "line": 155,
          "old_api": "errors::InvalidArgument(\n            \"XLA compilation requires a fixed tensor list size. Set the number \"\n            \"of elements. This could also happen if you're using a TensorArray \"\n            \"in a while loop that does not have its maximum_iteration set, you \"\n            \"can fix this by setting maximum_iteration to a suitable value.\")",
          "new_api": null,
          "old_text": "errors::InvalidArgument(\n            \"XLA compilation requires a fixed tensor list size. Set the number \"\n            \"of elements. This could also happen if you're using a TensorArray \"\n            \"in a while loop that does not have its maximum_iteration set, you \"\n            \"can fix this by setting maximum_iteration to a suitable value.\")",
          "new_text": null,
          "old_line_content": "        errors::InvalidArgument(",
          "new_line_content": "        ctx, num_elements >= 0,",
          "content_same": false
        },
        {
          "line": 667,
          "old_api": "explicit",
          "new_api": null,
          "old_text": "explicit",
          "new_text": null,
          "old_line_content": "  explicit TensorListPopBackOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}",
          "new_line_content": " public:",
          "content_same": false
        },
        {
          "line": 672,
          "old_api": "Input",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(ctx,\n                   (IsTensorListInitialized(ctx->Input(0), &is_initialized)))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx,",
          "new_line_content": "    bool is_initialized;",
          "content_same": false
        },
        {
          "line": 164,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "    xla::XlaOp element_shape_handle = ctx->Input(0);",
          "new_line_content": "    // uninitialized TensorList.",
          "content_same": false
        },
        {
          "line": 677,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "    xla::XlaOp list = ctx->Input(0);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 166,
          "old_api": "DataTypeToPrimitiveType",
          "new_api": null,
          "old_text": "DataTypeToPrimitiveType(dtype_, &type)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, DataTypeToPrimitiveType(dtype_, &type));",
          "new_line_content": "    xla::PrimitiveType type;",
          "content_same": false
        },
        {
          "line": 680,
          "old_api": "OP_REQUIRES_OK",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(ctx,\n                   ExecuteTensorListPopBack(list, &list_result, &element_result,\n                                            &element_is_tensor_list))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx,",
          "new_line_content": "    bool element_is_tensor_list;",
          "content_same": false
        },
        {
          "line": 169,
          "old_api": "OP_REQUIRES_OK",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(ctx,\n                   TryGetElementShapeFromInput(ctx, element_shape_handle, type,\n                                               &got_shape, &element_shape))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx,",
          "new_line_content": "    xla::Shape element_shape;",
          "content_same": false
        },
        {
          "line": 684,
          "old_api": "SetTensorListOutput",
          "new_api": null,
          "old_text": "ctx->SetTensorListOutput(0, list_result)",
          "new_text": null,
          "old_line_content": "    ctx->SetTensorListOutput(0, list_result);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 174,
          "old_api": "GetTensorListShapeFromElementShape",
          "new_api": null,
          "old_text": "GetTensorListShapeFromElementShape(\n                              element_shape, num_elements,\n                              num_element_is_dynamic, &list_shape)",
          "new_text": null,
          "old_line_content": "      OP_REQUIRES_OK(ctx, GetTensorListShapeFromElementShape(",
          "new_line_content": "      xla::Shape list_shape;",
          "content_same": false
        },
        {
          "line": 686,
          "old_api": "SetTensorListOutput",
          "new_api": null,
          "old_text": "ctx->SetTensorListOutput(1, element_result)",
          "new_text": null,
          "old_line_content": "      ctx->SetTensorListOutput(1, element_result);",
          "new_line_content": "    if (element_is_tensor_list) {",
          "content_same": false
        },
        {
          "line": 688,
          "old_api": "SetOutput",
          "new_api": null,
          "old_text": "ctx->SetOutput(1, element_result)",
          "new_text": null,
          "old_line_content": "      ctx->SetOutput(1, element_result);",
          "new_line_content": "    } else {",
          "content_same": false
        },
        {
          "line": 178,
          "old_api": "GetTensorListDynamicDims",
          "new_api": null,
          "old_text": "GetTensorListDynamicDims(\n          ctx, element_shape, list_shape, num_elements)",
          "new_text": null,
          "old_line_content": "      auto list_dynamic_dims_or = GetTensorListDynamicDims(",
          "new_line_content": "      // Set up dynamic dimension sizes to create the zero tensor.",
          "content_same": false
        },
        {
          "line": 180,
          "old_api": "status",
          "new_api": null,
          "old_text": "list_dynamic_dims_or.status()",
          "new_text": null,
          "old_line_content": "      OP_REQUIRES_OK(ctx, list_dynamic_dims_or.status());",
          "new_line_content": "          ctx, element_shape, list_shape, num_elements);",
          "content_same": false
        },
        {
          "line": 182,
          "old_api": "ValueOrDie",
          "new_api": null,
          "old_text": "CreateZerosTensorListWithShape(\n                              ctx->builder(), list_shape,\n                              list_dynamic_dims_or.ValueOrDie(), &new_list)",
          "new_text": null,
          "old_line_content": "      OP_REQUIRES_OK(ctx, CreateZerosTensorListWithShape(",
          "new_line_content": "      xla::XlaOp new_list;",
          "content_same": false
        },
        {
          "line": 186,
          "old_api": "builder",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(\n          ctx,\n          SetTensorListPushIndex(\n              new_list, xla::ConstantR0<int32>(ctx->builder(), num_elements),\n              &result))",
          "new_text": null,
          "old_line_content": "      OP_REQUIRES_OK(",
          "new_line_content": "      xla::XlaOp result;",
          "content_same": false
        },
        {
          "line": 698,
          "old_api": "AllowVariantTypes",
          "new_api": null,
          "old_text": "Name(\"TensorListPopBack\").AllowVariantTypes()",
          "new_text": null,
          "old_line_content": "REGISTER_XLA_OP(Name(\"TensorListPopBack\").AllowVariantTypes(),",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 188,
          "old_api": "builder",
          "new_api": null,
          "old_text": "SetTensorListPushIndex(\n              new_list, xla::ConstantR0<int32>(ctx->builder(), num_elements),\n              &result)",
          "new_text": null,
          "old_line_content": "          SetTensorListPushIndex(",
          "new_line_content": "          ctx,",
          "content_same": false
        },
        {
          "line": 191,
          "old_api": "SetTensorListOutput",
          "new_api": null,
          "old_text": "ctx->SetTensorListOutput(0, result)",
          "new_text": null,
          "old_line_content": "      ctx->SetTensorListOutput(0, result);",
          "new_line_content": "              &result));",
          "content_same": false
        },
        {
          "line": 195,
          "old_api": "builder",
          "new_api": null,
          "old_text": "BuildUninitializedTensorList(\n        ctx->builder(), num_elements, num_element_is_dynamic, ctx->Input(1))",
          "new_text": null,
          "old_line_content": "    xla::XlaOp result = BuildUninitializedTensorList(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 206,
          "old_api": "CompileTimeConstantInput",
          "new_api": null,
          "old_text": "Name(\"TensorListReserve\")\n                    .CompileTimeConstantInput(\"element_shape\")\n                    .CompileTimeConstantInput(\"num_elements\")",
          "new_text": null,
          "old_line_content": "REGISTER_XLA_OP(Name(\"TensorListReserve\")",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 213,
          "old_api": "explicit",
          "new_api": null,
          "old_text": "explicit",
          "new_text": null,
          "old_line_content": "  explicit EmptyTensorListOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {",
          "new_line_content": " public:",
          "content_same": false
        },
        {
          "line": 219,
          "old_api": "ConstantInputAsIntScalar",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(\n        ctx, ctx->ConstantInputAsIntScalar(\n                 1, &max_num_elements, xla::ValueInferenceMode::kUpperBound))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(",
          "new_line_content": "    int64_t max_num_elements;",
          "content_same": false
        },
        {
          "line": 223,
          "old_api": "ResolveInputDynamismIntoPred",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(\n        ctx, ctx->ResolveInputDynamismIntoPred(1, &num_element_is_dynamic))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(",
          "new_line_content": "    bool num_element_is_dynamic;",
          "content_same": false
        },
        {
          "line": 238,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "      xla::XlaOp element_shape_handle = ctx->Input(0);",
          "new_line_content": "      // create an uninitialized TensorList.",
          "content_same": false
        },
        {
          "line": 240,
          "old_api": "DataTypeToPrimitiveType",
          "new_api": null,
          "old_text": "DataTypeToPrimitiveType(dtype_, &type)",
          "new_text": null,
          "old_line_content": "      OP_REQUIRES_OK(ctx, DataTypeToPrimitiveType(dtype_, &type));",
          "new_line_content": "      xla::PrimitiveType type;",
          "content_same": false
        },
        {
          "line": 243,
          "old_api": "OP_REQUIRES_OK",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(\n          ctx, TryGetElementShapeFromInput(ctx, element_shape_handle, type,\n                                           &got_shape, &element_shape))",
          "new_text": null,
          "old_line_content": "      OP_REQUIRES_OK(",
          "new_line_content": "      xla::Shape element_shape;",
          "content_same": false
        },
        {
          "line": 248,
          "old_api": "GetTensorListShapeFromElementShape",
          "new_api": null,
          "old_text": "GetTensorListShapeFromElementShape(\n                                element_shape, max_num_elements,\n                                num_element_is_dynamic, &list_shape)",
          "new_text": null,
          "old_line_content": "        OP_REQUIRES_OK(ctx, GetTensorListShapeFromElementShape(",
          "new_line_content": "        xla::Shape list_shape;",
          "content_same": false
        },
        {
          "line": 252,
          "old_api": "GetTensorListDynamicDims",
          "new_api": null,
          "old_text": "GetTensorListDynamicDims(\n            ctx, element_shape, list_shape, max_num_elements)",
          "new_text": null,
          "old_line_content": "        auto list_dynamic_dims_or = GetTensorListDynamicDims(",
          "new_line_content": "        // Set up dynamic dimension sizes to create the zero tensor.",
          "content_same": false
        },
        {
          "line": 254,
          "old_api": "status",
          "new_api": null,
          "old_text": "list_dynamic_dims_or.status()",
          "new_text": null,
          "old_line_content": "        OP_REQUIRES_OK(ctx, list_dynamic_dims_or.status());",
          "new_line_content": "            ctx, element_shape, list_shape, max_num_elements);",
          "content_same": false
        },
        {
          "line": 257,
          "old_api": "ValueOrDie",
          "new_api": null,
          "old_text": "CreateZerosTensorListWithShape(\n                                ctx->builder(), list_shape,\n                                list_dynamic_dims_or.ValueOrDie(), &result)",
          "new_text": null,
          "old_line_content": "        OP_REQUIRES_OK(ctx, CreateZerosTensorListWithShape(",
          "new_line_content": "        xla::XlaOp result;",
          "content_same": false
        },
        {
          "line": 261,
          "old_api": "SetTensorListOutput",
          "new_api": null,
          "old_text": "ctx->SetTensorListOutput(0, result)",
          "new_text": null,
          "old_line_content": "        ctx->SetTensorListOutput(0, result);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 269,
          "old_api": "builder",
          "new_api": null,
          "old_text": "ctx->builder()",
          "new_text": null,
          "old_line_content": "        BuildUninitializedTensorList(ctx->builder(), max_num_elements,",
          "new_line_content": "    xla::XlaOp result =",
          "content_same": false
        },
        {
          "line": 280,
          "old_api": "CompileTimeConstantInput",
          "new_api": null,
          "old_text": "Name(\"EmptyTensorList\")\n                    .CompileTimeConstantInput(\"element_shape\")\n                    .CompileTimeConstantInput(\"max_num_elements\")\n                    .AllowVariantTypes()",
          "new_text": null,
          "old_line_content": "REGISTER_XLA_OP(Name(\"EmptyTensorList\")",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 288,
          "old_api": "explicit",
          "new_api": null,
          "old_text": "explicit",
          "new_text": null,
          "old_line_content": "  explicit TensorListElementShapeOp(OpKernelConstruction* ctx)",
          "new_line_content": " public:",
          "content_same": false
        },
        {
          "line": 290,
          "old_api": "GetAttr",
          "new_api": null,
          "old_text": "ctx->GetAttr(\"shape_type\", &shape_type_)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"shape_type\", &shape_type_));",
          "new_line_content": "      : XlaOpKernel(ctx) {",
          "content_same": false
        },
        {
          "line": 296,
          "old_api": "Input",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(ctx,\n                   (IsTensorListInitialized(ctx->Input(0), &is_initialized)))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx,",
          "new_line_content": "    bool is_initialized;",
          "content_same": false
        },
        {
          "line": 303,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, IsNestedTensorList(ctx->Input(0), &is_nested));",
          "new_line_content": "    bool is_nested;",
          "content_same": false
        },
        {
          "line": 310,
          "old_api": "builder",
          "new_api": null,
          "old_text": "ctx->builder()",
          "new_text": null,
          "old_line_content": "    xla::XlaBuilder* b = ctx->builder();",
          "new_line_content": "    // the first dimension.",
          "content_same": false
        },
        {
          "line": 312,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, GetTensorListBufferShape(ctx->Input(0), &list_shape));",
          "new_line_content": "    xla::Shape list_shape;",
          "content_same": false
        },
        {
          "line": 317,
          "old_api": "dimensions",
          "new_api": null,
          "old_text": "list_shape.dimensions()",
          "new_text": null,
          "old_line_content": "        ctx->SetOutput(0, xla::ConstantR1<int64_t>(b, list_shape.dimensions()));",
          "new_line_content": "      case DT_INT64:",
          "content_same": false
        },
        {
          "line": 321,
          "old_api": "dimensions",
          "new_api": null,
          "old_text": "list_shape.dimensions()",
          "new_text": null,
          "old_line_content": "        const auto& dimensions = list_shape.dimensions();",
          "new_line_content": "        std::vector<int32> size;",
          "content_same": false
        },
        {
          "line": 324,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "size.push_back(s)",
          "new_text": null,
          "old_line_content": "          size.push_back(s);",
          "new_line_content": "        for (int64_t s : dimensions) {",
          "content_same": false
        },
        {
          "line": 326,
          "old_api": "xla::ConstantR1<int32>(b, size)",
          "new_api": null,
          "old_text": "xla::ConstantR1<int32>(b, size)",
          "new_text": null,
          "old_line_content": "        ctx->SetOutput(0, xla::ConstantR1<int32>(b, size));",
          "new_line_content": "        }",
          "content_same": false
        },
        {
          "line": 330,
          "old_api": "CtxFailure",
          "new_api": null,
          "old_text": "ctx->CtxFailure(\n            errors::InvalidArgument(\"Unsupported shape type requested\"))",
          "new_text": null,
          "old_line_content": "        ctx->CtxFailure(",
          "new_line_content": "      default:",
          "content_same": false
        },
        {
          "line": 342,
          "old_api": "IsMetadataOp",
          "new_api": null,
          "old_text": "Name(\"TensorListElementShape\").IsMetadataOp()",
          "new_text": null,
          "old_line_content": "REGISTER_XLA_OP(Name(\"TensorListElementShape\").IsMetadataOp(),",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 347,
          "old_api": "explicit",
          "new_api": null,
          "old_text": "explicit",
          "new_text": null,
          "old_line_content": "  explicit TensorListGetItemOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {",
          "new_line_content": " public:",
          "content_same": false
        },
        {
          "line": 354,
          "old_api": "Input",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(ctx,\n                   (IsTensorListInitialized(ctx->Input(0), &is_initialized)))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx,",
          "new_line_content": "    bool is_initialized;",
          "content_same": false
        },
        {
          "line": 361,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, IsNestedTensorList(ctx->Input(0), &is_nested));",
          "new_line_content": "    bool is_nested;",
          "content_same": false
        },
        {
          "line": 366,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "    xla::XlaOp list = ctx->Input(0);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 370,
          "old_api": "ExecuteTensorListGetItem",
          "new_api": null,
          "old_text": "ExecuteTensorListGetItem(list, index, &result)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, ExecuteTensorListGetItem(list, index, &result));",
          "new_line_content": "    xla::XlaOp result;",
          "content_same": false
        },
        {
          "line": 372,
          "old_api": "SetOutput",
          "new_api": null,
          "old_text": "ctx->SetOutput(0, result)",
          "new_text": null,
          "old_line_content": "    ctx->SetOutput(0, result);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 381,
          "old_api": "Name",
          "new_api": null,
          "old_text": "Name(\"TensorListGetItem\")",
          "new_text": null,
          "old_line_content": "REGISTER_XLA_OP(Name(\"TensorListGetItem\"), TensorListGetItemOp);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 385,
          "old_api": "explicit",
          "new_api": null,
          "old_text": "explicit",
          "new_text": null,
          "old_line_content": "  explicit TensorListGatherOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {",
          "new_line_content": " public:",
          "content_same": false
        },
        {
          "line": 392,
          "old_api": "Input",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(ctx,\n                   (IsTensorListInitialized(ctx->Input(0), &is_initialized)))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx,",
          "new_line_content": "    bool is_initialized;",
          "content_same": false
        },
        {
          "line": 399,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, IsNestedTensorList(ctx->Input(0), &is_nested));",
          "new_line_content": "    bool is_nested;",
          "content_same": false
        },
        {
          "line": 404,
          "old_api": "input_type",
          "new_api": null,
          "old_text": "ctx->input_type(1)",
          "new_text": null,
          "old_line_content": "    DataType indices_type = ctx->input_type(1);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 406,
          "old_api": "InputShape",
          "new_api": null,
          "old_text": "ctx->InputShape(1)",
          "new_text": null,
          "old_line_content": "    const TensorShape indices_shape = ctx->InputShape(1);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 410,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "    xla::XlaOp list = ctx->Input(0);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 414,
          "old_api": "GetTensorListBuffer",
          "new_api": null,
          "old_text": "GetTensorListBuffer(list, &buffer)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, GetTensorListBuffer(list, &buffer));",
          "new_line_content": "    xla::XlaOp buffer;",
          "content_same": false
        },
        {
          "line": 416,
          "old_api": "GetTensorListBufferShape",
          "new_api": null,
          "old_text": "GetTensorListBufferShape(list, &buffer_xla_shape)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, GetTensorListBufferShape(list, &buffer_xla_shape));",
          "new_line_content": "    xla::Shape buffer_xla_shape;",
          "content_same": false
        },
        {
          "line": 418,
          "old_api": "XLAShapeToTensorShape",
          "new_api": null,
          "old_text": "XLAShapeToTensorShape(buffer_xla_shape, &buffer_shape)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, XLAShapeToTensorShape(buffer_xla_shape, &buffer_shape));",
          "new_line_content": "    TensorShape buffer_shape;",
          "content_same": false
        },
        {
          "line": 421,
          "old_api": "builder",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(\n        ctx, XlaGather(buffer, buffer_shape, indices, indices_shape, /*axis=*/0,\n                       /*indices_are_nd=*/false, dtype_, indices_type,\n                       ctx->builder(), &result))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(",
          "new_line_content": "    xla::XlaOp result;",
          "content_same": false
        },
        {
          "line": 424,
          "old_api": "builder",
          "new_api": null,
          "old_text": "ctx->builder()",
          "new_text": null,
          "old_line_content": "                       ctx->builder(), &result));",
          "new_line_content": "                       /*indices_are_nd=*/false, dtype_, indices_type,",
          "content_same": false
        },
        {
          "line": 434,
          "old_api": "Name",
          "new_api": null,
          "old_text": "Name(\"TensorListGather\")",
          "new_text": null,
          "old_line_content": "REGISTER_XLA_OP(Name(\"TensorListGather\"), TensorListGatherOp);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 438,
          "old_api": "explicit",
          "new_api": null,
          "old_text": "explicit",
          "new_text": null,
          "old_line_content": "  explicit TensorListStackOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}",
          "new_line_content": " public:",
          "content_same": false
        },
        {
          "line": 443,
          "old_api": "Input",
          "new_api": null,
          "old_text": "OP_REQUIRES_OK(ctx,\n                   (IsTensorListInitialized(ctx->Input(0), &is_initialized)))",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx,",
          "new_line_content": "    bool is_initialized;",
          "content_same": false
        },
        {
          "line": 450,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, IsNestedTensorList(ctx->Input(0), &is_nested));",
          "new_line_content": "    bool is_nested;",
          "content_same": false
        },
        {
          "line": 456,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, GetTensorListBuffer(ctx->Input(0), &buffer));",
          "new_line_content": "    xla::XlaOp buffer;",
          "content_same": false
        },
        {
          "line": 464,
          "old_api": "Name",
          "new_api": null,
          "old_text": "Name(\"TensorListStack\")",
          "new_text": null,
          "old_line_content": "REGISTER_XLA_OP(Name(\"TensorListStack\"), TensorListStackOp);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 468,
          "old_api": "explicit",
          "new_api": null,
          "old_text": "explicit",
          "new_text": null,
          "old_line_content": "  explicit TensorListConcatOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}",
          "new_line_content": " public:",
          "content_same": false
        },
        {
          "line": 471,
          "old_api": "Input",
          "new_api": null,
          "old_text": "ctx->Input(0)",
          "new_text": null,
          "old_line_content": "    xla::XlaOp input = ctx->Input(0);",
          "new_line_content": "  void Compile(XlaOpKernelContext* ctx) override {",
          "content_same": false
        },
        {
          "line": 475,
          "old_api": "IsTensorListInitialized",
          "new_api": null,
          "old_text": "IsTensorListInitialized(input, &is_initialized)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, (IsTensorListInitialized(input, &is_initialized)));",
          "new_line_content": "    bool is_initialized;",
          "content_same": false
        },
        {
          "line": 481,
          "old_api": "IsNestedTensorList",
          "new_api": null,
          "old_text": "IsNestedTensorList(input, &is_nested)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, IsNestedTensorList(input, &is_nested));",
          "new_line_content": "    bool is_nested;",
          "content_same": false
        },
        {
          "line": 487,
          "old_api": "GetTensorListBuffer",
          "new_api": null,
          "old_text": "GetTensorListBuffer(input, &buffer)",
          "new_text": null,
          "old_line_content": "    OP_REQUIRES_OK(ctx, GetTensorListBuffer(input, &buffer));",
          "new_line_content": "    xla::XlaOp buffer;",
          "content_same": false
        },
        {
          "line": 489,
          "old_api": "builder",
          "new_api": null,
          "old_text": "input.builder()",
          "new_text": null,
          "old_line_content": "    xla::XlaBuilder* b = input.builder();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 494,
          "old_api": "dimensions",
          "new_api": null,
          "old_text": "element_shape.dimensions()",
          "new_text": null,
          "old_line_content": "        xla::SpanToVector(element_shape.dimensions());",
          "new_line_content": "    std::vector<int64_t> element_dims =",
          "content_same": false
        },
        {
          "line": 503,
          "old_api": "size",
          "new_api": null,
          "old_text": "element_dims.size()",
          "new_text": null,
          "old_line_content": "    for (int i = 2; i < element_dims.size(); i++) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 507,
          "old_api": "xla::Reshape(buffer, new_dims)",
          "new_api": null,
          "old_text": "xla::Reshape(buffer, new_dims)",
          "new_text": null,
          "old_line_content": "    xla::XlaOp out = xla::Reshape(buffer, new_dims);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 511,
          "old_api": "xla::ConstantR1(b, num_elements, tensor_lengths)",
          "new_api": null,
          "old_text": "xla::ConstantR1(b, num_elements, tensor_lengths)",
          "new_text": null,
          "old_line_content": "    xla::XlaOp lengths = xla::ConstantR1(b, num_elements, tensor_lengths);",
          "new_line_content": "    // Second output is a tensor of lengths of returned tensors.",
          "content_same": false
        }
      ]
    },
    "api_summary": {
      "total_replacements": 83,
      "total_additions": 135,
      "total_deletions": 134,
      "total_api_changes": 352
    },
    "non_api_changes": {
      "has_non_api_changes": false,
      "evidence": {
        "total_diff_lines": 3,
        "api_related_lines": 352,
        "non_api_lines": 0,
        "non_api_line_numbers": []
      }
    },
    "api_calls_before": 333,
    "api_calls_after": 336,
    "diff_info": {
      "added_lines": 2,
      "removed_lines": 1,
      "total_diff_lines": 22
    }
  }
}