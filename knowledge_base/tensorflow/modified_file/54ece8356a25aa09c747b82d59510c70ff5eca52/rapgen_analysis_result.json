{
  "status": "completed",
  "commit_dir": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/54ece8356a25aa09c747b82d59510c70ff5eca52",
  "file_info": {
    "before_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/54ece8356a25aa09c747b82d59510c70ff5eca52/before.cc",
    "after_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/54ece8356a25aa09c747b82d59510c70ff5eca52/after.cc",
    "diff_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/54ece8356a25aa09c747b82d59510c70ff5eca52/diff.txt"
  },
  "semgrep_analysis": {
    "is_api_change": false,
    "api_changes": {
      "replacements": [
        {
          "line": 460,
          "old_api": "swap",
          "new_api": "Extend",
          "old_text": "execution_state_.swap(state)",
          "new_text": "execution_state_->Extend(graph, &state)",
          "old_line_content": "    execution_state_.swap(state);",
          "new_line_content": "    TF_RETURN_IF_ERROR(execution_state_->Extend(graph, &state));",
          "content_same": false
        },
        {
          "line": 462,
          "old_api": "Status::OK()",
          "new_api": "library",
          "old_text": "Status::OK()",
          "new_text": "graph.library()",
          "old_line_content": "  return Status::OK();",
          "new_line_content": "    TF_RETURN_IF_ERROR(flib_def_->AddLibrary(graph.library()));",
          "content_same": false
        },
        {
          "line": 480,
          "old_api": "feed",
          "new_api": "run_options",
          "old_text": "callable_options.feed().begin()",
          "new_text": "DebuggerStateRegistry::CreateState(\n      callable_options.run_options().debug_options(), debugger_state)",
          "old_line_content": "  std::vector<string> input_names(callable_options.feed().begin(),",
          "new_line_content": "  TF_RETURN_IF_ERROR(DebuggerStateRegistry::CreateState(",
          "content_same": false
        },
        {
          "line": 481,
          "old_api": "feed",
          "new_api": "run_options",
          "old_text": "callable_options.feed().end()",
          "new_text": "callable_options.run_options().debug_options()",
          "old_line_content": "                                  callable_options.feed().end());",
          "new_line_content": "      callable_options.run_options().debug_options(), debugger_state));",
          "content_same": false
        },
        {
          "line": 482,
          "old_api": "fetch",
          "new_api": "feed",
          "old_text": "callable_options.fetch().begin()",
          "new_text": "callable_options.feed().begin()",
          "old_line_content": "  std::vector<string> output_names(callable_options.fetch().begin(),",
          "new_line_content": "  std::vector<string> input_names(callable_options.feed().begin(),",
          "content_same": false
        },
        {
          "line": 483,
          "old_api": "fetch",
          "new_api": "feed",
          "old_text": "callable_options.fetch().end()",
          "new_text": "callable_options.feed().end()",
          "old_line_content": "                                   callable_options.fetch().end());",
          "new_line_content": "                                  callable_options.feed().end());",
          "content_same": false
        },
        {
          "line": 484,
          "old_api": "target",
          "new_api": "fetch",
          "old_text": "callable_options.target().begin()",
          "new_text": "callable_options.fetch().begin()",
          "old_line_content": "  std::vector<string> target_names(callable_options.target().begin(),",
          "new_line_content": "  std::vector<string> output_names(callable_options.fetch().begin(),",
          "content_same": false
        },
        {
          "line": 485,
          "old_api": "target",
          "new_api": "fetch",
          "old_text": "callable_options.target().end()",
          "new_text": "callable_options.fetch().end()",
          "old_line_content": "                                   callable_options.target().end());",
          "new_line_content": "                                   callable_options.fetch().end());",
          "content_same": false
        },
        {
          "line": 487,
          "old_api": "get",
          "new_api": "target",
          "old_text": "debugger_state->get()->PublishDebugMetadata(\n      global_step, session_run_index, executor_step_index, input_names,\n      output_names, target_names)",
          "new_text": "callable_options.target().end()",
          "old_line_content": "  TF_RETURN_IF_ERROR(debugger_state->get()->PublishDebugMetadata(",
          "new_line_content": "                                   callable_options.target().end());",
          "content_same": false
        },
        {
          "line": 499,
          "old_api": "DecorateGraph",
          "new_api": "DebugGraphDecoratorRegistry::CreateDecorator(debug_options, &decorator)",
          "old_text": "decorator->DecorateGraph(graph, device)",
          "new_text": "DebugGraphDecoratorRegistry::CreateDecorator(debug_options, &decorator)",
          "old_line_content": "  TF_RETURN_IF_ERROR(decorator->DecorateGraph(graph, device));",
          "new_line_content": "      DebugGraphDecoratorRegistry::CreateDecorator(debug_options, &decorator));",
          "content_same": false
        },
        {
          "line": 501,
          "old_api": "Status::OK()",
          "new_api": "DecorateGraph",
          "old_text": "Status::OK()",
          "new_text": "decorator->DecorateGraph(graph, device)",
          "old_line_content": "  return Status::OK();",
          "new_line_content": "  TF_RETURN_IF_ERROR(decorator->DecorateGraph(graph, device));",
          "content_same": false
        },
        {
          "line": 511,
          "old_api": "fetch_add",
          "new_api": "NowMicros",
          "old_text": "executors_and_keys->step_count.fetch_add(1)",
          "new_text": "options_.env->NowMicros()",
          "old_line_content": "      executors_and_keys->step_count.fetch_add(1);",
          "new_line_content": "  const uint64 start_time_usecs = options_.env->NowMicros();",
          "content_same": false
        },
        {
          "line": 513,
          "old_api": "size",
          "new_api": "fetch_add",
          "old_text": "executors_and_keys->items.size()",
          "new_text": "executors_and_keys->step_count.fetch_add(1)",
          "old_line_content": "  const size_t num_executors = executors_and_keys->items.size();",
          "new_line_content": "      executors_and_keys->step_count.fetch_add(1);",
          "content_same": false
        },
        {
          "line": 522,
          "old_api": "version",
          "new_api": "experimental",
          "old_text": "model_metadata.version()",
          "new_text": "options_.config.experimental().session_metadata()",
          "old_line_content": "                                            model_metadata.version());",
          "new_line_content": "              options_.config.experimental().session_metadata();",
          "content_same": false
        },
        {
          "line": 523,
          "old_api": "profiler::TraceMeEncode(\"SessionRun\",\n                                         {{\"id\", step_id},\n                                          {\"_r\", 1} /*root_event*/,\n                                          {\"model_id\", model_id}})",
          "new_api": "name",
          "old_text": "profiler::TraceMeEncode(\"SessionRun\",\n                                         {{\"id\", step_id},\n                                          {\"_r\", 1} /*root_event*/,\n                                          {\"model_id\", model_id}})",
          "new_text": "model_metadata.name()",
          "old_line_content": "          return profiler::TraceMeEncode(\"SessionRun\",",
          "new_line_content": "          string model_id = strings::StrCat(model_metadata.name(), \":\",",
          "content_same": false
        },
        {
          "line": 563,
          "old_api": "MaybeCreateNcclCommunicator",
          "new_api": "get",
          "old_text": "MaybeCreateNcclCommunicator(options_.config)",
          "new_text": "CreateProdLocalCollectiveExecutorMgr(\n          options_.config, device_mgr_.get(),\n          MaybeCreateNcclCommunicator(options_.config))",
          "old_line_content": "          MaybeCreateNcclCommunicator(options_.config));",
          "new_line_content": "      collective_executor_mgr_ = CreateProdLocalCollectiveExecutorMgr(",
          "content_same": false
        },
        {
          "line": 565,
          "old_api": "reset",
          "new_api": "MaybeCreateNcclCommunicator",
          "old_text": "run_state.collective_executor.reset(new CollectiveExecutor::Handle(\n        collective_executor_mgr_->FindOrCreate(step_id), true /*inherit_ref*/))",
          "new_text": "MaybeCreateNcclCommunicator(options_.config)",
          "old_line_content": "    run_state.collective_executor.reset(new CollectiveExecutor::Handle(",
          "new_line_content": "          MaybeCreateNcclCommunicator(options_.config));",
          "content_same": false
        },
        {
          "line": 589,
          "old_api": "get",
          "new_api": "absl::make_unique<thread::ThreadPool>(\n        threadpool_options.inter_op_threadpool)",
          "old_text": "threadpool_wrapper.get()",
          "new_text": "absl::make_unique<thread::ThreadPool>(\n        threadpool_options.inter_op_threadpool)",
          "old_line_content": "    pool = threadpool_wrapper.get();",
          "new_line_content": "    threadpool_wrapper = absl::make_unique<thread::ThreadPool>(",
          "content_same": false
        },
        {
          "line": 591,
          "old_api": "inter_op_thread_pool",
          "new_api": "get",
          "old_text": "run_options.inter_op_thread_pool()",
          "new_text": "threadpool_wrapper.get()",
          "old_line_content": "    if (run_options.inter_op_thread_pool() < -1 ||",
          "new_line_content": "    pool = threadpool_wrapper.get();",
          "content_same": false
        },
        {
          "line": 593,
          "old_api": "size",
          "new_api": "inter_op_thread_pool",
          "old_text": "thread_pools_.size()",
          "new_text": "run_options.inter_op_thread_pool()",
          "old_line_content": "            static_cast<int32>(thread_pools_.size())) {",
          "new_line_content": "    if (run_options.inter_op_thread_pool() < -1 ||",
          "content_same": false
        },
        {
          "line": 595,
          "old_api": "inter_op_thread_pool",
          "new_api": "size",
          "old_text": "run_options.inter_op_thread_pool()",
          "new_text": "thread_pools_.size()",
          "old_line_content": "                                     run_options.inter_op_thread_pool());",
          "new_line_content": "            static_cast<int32>(thread_pools_.size())) {",
          "content_same": false
        },
        {
          "line": 612,
          "old_api": "VLOG",
          "new_api": "ShouldUseRunHandlerPool",
          "old_text": "VLOG(1)",
          "new_text": "ShouldUseRunHandlerPool(run_options)",
          "old_line_content": "    VLOG(1) << \"Using RunHandler to scheduler inter-op closures.\";",
          "new_line_content": "  if (ShouldUseRunHandlerPool(run_options) &&",
          "content_same": false
        },
        {
          "line": 617,
          "old_api": "errors::DeadlineExceeded(\n          \"Could not obtain RunHandler for request after waiting for \",\n          call_timeout, \"ms.\")",
          "new_api": "experimental",
          "old_text": "errors::DeadlineExceeded(\n          \"Could not obtain RunHandler for request after waiting for \",\n          call_timeout, \"ms.\")",
          "new_text": "run_options.experimental().run_handler_pool_options()",
          "old_line_content": "      return errors::DeadlineExceeded(",
          "new_line_content": "        run_options.experimental().run_handler_pool_options());",
          "content_same": false
        },
        {
          "line": 682,
          "old_api": "mutable_step_stats",
          "new_api": "report_tensor_allocations_upon_oom",
          "old_text": "run_metadata->mutable_step_stats()",
          "new_text": "run_options.report_tensor_allocations_upon_oom()",
          "old_line_content": "        new StepStatsCollector(run_metadata->mutable_step_stats()));",
          "new_line_content": "      run_options.report_tensor_allocations_upon_oom()) {",
          "content_same": false
        },
        {
          "line": 683,
          "old_api": "get",
          "new_api": "reset",
          "old_text": "run_state.collector.get()",
          "new_text": "run_state.collector.reset(\n        new StepStatsCollector(run_metadata->mutable_step_stats()))",
          "old_line_content": "    args.stats_collector = run_state.collector.get();",
          "new_line_content": "    run_state.collector.reset(",
          "content_same": false
        },
        {
          "line": 746,
          "old_api": "Notify",
          "new_api": "Update",
          "old_text": "executors_done.Notify()",
          "new_text": "run_state.status.Update(ret)",
          "old_line_content": "                              executors_done.Notify();",
          "new_line_content": "                                run_state.status.Update(ret);",
          "content_same": false
        },
        {
          "line": 776,
          "old_api": "fetch",
          "new_api": "empty",
          "old_text": "executors_and_keys->callable_options.fetch().begin()",
          "new_text": "run_state.tensor_store.empty()",
          "old_line_content": "        {executors_and_keys->callable_options.fetch().begin(),",
          "new_line_content": "  if (!run_state.tensor_store.empty()) {",
          "content_same": false
        },
        {
          "line": 777,
          "old_api": "fetch",
          "new_api": "SaveTensors",
          "old_text": "executors_and_keys->callable_options.fetch().end()",
          "new_text": "run_state.tensor_store.SaveTensors(\n        {executors_and_keys->callable_options.fetch().begin(),\n         executors_and_keys->callable_options.fetch().end()},\n        &session_state_)",
          "old_line_content": "         executors_and_keys->callable_options.fetch().end()},",
          "new_line_content": "    TF_RETURN_IF_ERROR(run_state.tensor_store.SaveTensors(",
          "content_same": false
        },
        {
          "line": 802,
          "old_api": "AddToCostGraphDef",
          "new_api": "mutable_cost_graph",
          "old_text": "TF_RETURN_IF_ERROR(\n          cost_model_manager_.AddToCostGraphDef(item.graph.get(), cost_graph))",
          "new_text": "run_metadata->mutable_cost_graph()",
          "old_line_content": "      TF_RETURN_IF_ERROR(",
          "new_line_content": "    CostGraphDef* cost_graph = run_metadata->mutable_cost_graph();",
          "content_same": false
        },
        {
          "line": 825,
          "old_api": "Status::OK()",
          "new_api": "NowMicros",
          "old_text": "Status::OK()",
          "new_text": "options_.env->NowMicros()",
          "old_line_content": "  return Status::OK();",
          "new_line_content": "  metrics::UpdateGraphExecTime(options_.env->NowMicros() - start_time_usecs);",
          "content_same": false
        },
        {
          "line": 847,
          "old_api": "GetCell",
          "new_api": "CheckNotClosed",
          "old_text": "direct_session_runs->GetCell()->IncrementBy(1)",
          "new_text": "CheckNotClosed()",
          "old_line_content": "  direct_session_runs->GetCell()->IncrementBy(1);",
          "new_line_content": "  TF_RETURN_IF_ERROR(CheckNotClosed());",
          "content_same": false
        },
        {
          "line": 857,
          "old_api": "metrics::RecordGraphInputTensors(input_size)",
          "new_api": "AllocatedBytes",
          "old_text": "metrics::RecordGraphInputTensors(input_size)",
          "new_text": "it.second.AllocatedBytes()",
          "old_line_content": "  metrics::RecordGraphInputTensors(input_size);",
          "new_line_content": "    input_size += it.second.AllocatedBytes();",
          "content_same": false
        },
        {
          "line": 863,
          "old_api": "experimental",
          "new_api": "debug_options",
          "old_text": "run_options.experimental().collective_graph_key()",
          "new_text": "run_options.debug_options()",
          "old_line_content": "      run_options.experimental().collective_graph_key();",
          "new_line_content": "  RunStateArgs run_state_args(run_options.debug_options());",
          "content_same": false
        },
        {
          "line": 865,
          "old_api": "GetOrCreateExecutors",
          "new_api": "experimental",
          "old_text": "GetOrCreateExecutors(input_tensor_names, output_names,\n                                          target_nodes, &executors_and_keys,\n                                          &run_state_args)",
          "new_text": "run_options.experimental().collective_graph_key()",
          "old_line_content": "  TF_RETURN_IF_ERROR(GetOrCreateExecutors(input_tensor_names, output_names,",
          "new_line_content": "      run_options.experimental().collective_graph_key();",
          "content_same": false
        },
        {
          "line": 879,
          "old_api": "dtype",
          "new_api": "size",
          "old_text": "it.second.dtype()",
          "new_text": "inputs.size()",
          "old_line_content": "    if (it.second.dtype() == DT_RESOURCE) {",
          "new_line_content": "  gtl::InlinedVector<Tensor, 4> feed_args(inputs.size());",
          "content_same": false
        },
        {
          "line": 881,
          "old_api": "TF_RETURN_IF_ERROR",
          "new_api": "dtype",
          "old_text": "TF_RETURN_IF_ERROR(\n          ResourceHandleToInputTensor(it.second, &tensor_from_handle))",
          "new_text": "it.second.dtype()",
          "old_line_content": "      TF_RETURN_IF_ERROR(",
          "new_line_content": "    if (it.second.dtype() == DT_RESOURCE) {",
          "content_same": false
        },
        {
          "line": 891,
          "old_api": "error_message",
          "new_api": "SetArgs",
          "old_text": "s.error_message()",
          "new_text": "call_frame.SetArgs(feed_args)",
          "old_line_content": "    return errors::InvalidArgument(s.error_message());",
          "new_line_content": "  const Status s = call_frame.SetArgs(feed_args);",
          "content_same": false
        },
        {
          "line": 892,
          "old_api": "ok",
          "new_api": "errors::IsInternal(s)",
          "old_text": "s.ok()",
          "new_text": "errors::IsInternal(s)",
          "old_line_content": "  } else if (!s.ok()) {",
          "new_line_content": "  if (errors::IsInternal(s)) {",
          "content_same": false
        },
        {
          "line": 898,
          "old_api": "LogMemory::IsEnabled()",
          "new_api": "fetch_add",
          "old_text": "LogMemory::IsEnabled()",
          "new_text": "step_id_counter_.fetch_add(1)",
          "old_line_content": "  if (LogMemory::IsEnabled()) {",
          "new_line_content": "  const int64_t step_id = step_id_counter_.fetch_add(1);",
          "content_same": false
        },
        {
          "line": 911,
          "old_api": "errors::IsInternal(s)",
          "new_api": "ConsumeRetvals",
          "old_text": "errors::IsInternal(s)",
          "new_text": "call_frame.ConsumeRetvals(\n        &sorted_outputs, /* allow_dead_tensors = */ false)",
          "old_line_content": "    if (errors::IsInternal(s)) {",
          "new_line_content": "    const Status s = call_frame.ConsumeRetvals(",
          "content_same": false
        },
        {
          "line": 913,
          "old_api": "ok",
          "new_api": "errors::IsInternal(s)",
          "old_text": "s.ok()",
          "new_text": "errors::IsInternal(s)",
          "old_line_content": "    } else if (!s.ok()) {",
          "new_line_content": "    if (errors::IsInternal(s)) {",
          "content_same": false
        },
        {
          "line": 924,
          "old_api": "push_back",
          "new_api": "size",
          "old_text": "first_indices.push_back(\n            std::find(output_names.begin(), output_names.end(), name) -\n            output_names.begin())",
          "new_text": "output_names.size()",
          "old_line_content": "        first_indices.push_back(",
          "new_line_content": "      first_indices.reserve(output_names.size());",
          "content_same": false
        },
        {
          "line": 926,
          "old_api": "begin",
          "new_api": "push_back",
          "old_text": "output_names.begin()",
          "new_text": "first_indices.push_back(\n            std::find(output_names.begin(), output_names.end(), name) -\n            output_names.begin())",
          "old_line_content": "            output_names.begin());",
          "new_line_content": "        first_indices.push_back(",
          "content_same": false
        },
        {
          "line": 931,
          "old_api": "size",
          "new_api": "clear",
          "old_text": "sorted_outputs.size()",
          "new_text": "outputs->clear()",
          "old_line_content": "    outputs->reserve(sorted_outputs.size());",
          "new_line_content": "    outputs->clear();",
          "content_same": false
        },
        {
          "line": 934,
          "old_api": "empty",
          "new_api": "size",
          "old_text": "first_indices.empty()",
          "new_text": "output_names.size()",
          "old_line_content": "      if (first_indices.empty() || first_indices[i] == i) {",
          "new_line_content": "    for (int i = 0; i < output_names.size(); ++i) {",
          "content_same": false
        },
        {
          "line": 936,
          "old_api": "std::move(sorted_outputs[executors_and_keys\n                                         ->output_name_to_index[output_name]])",
          "new_api": "empty",
          "old_text": "std::move(sorted_outputs[executors_and_keys\n                                         ->output_name_to_index[output_name]])",
          "new_text": "first_indices.empty()",
          "old_line_content": "            std::move(sorted_outputs[executors_and_keys",
          "new_line_content": "      if (first_indices.empty() || first_indices[i] == i) {",
          "content_same": false
        },
        {
          "line": 941,
          "old_api": "AllocatedBytes",
          "new_api": "push_back",
          "old_text": "outputs->back().AllocatedBytes()",
          "new_text": "outputs->push_back((*outputs)[first_indices[i]])",
          "old_line_content": "      output_size += outputs->back().AllocatedBytes();",
          "new_line_content": "        outputs->push_back((*outputs)[first_indices[i]]);",
          "content_same": false
        },
        {
          "line": 943,
          "old_api": "metrics::RecordGraphOutputTensors(output_size)",
          "new_api": "AllocatedBytes",
          "old_text": "metrics::RecordGraphOutputTensors(output_size)",
          "new_text": "outputs->back().AllocatedBytes()",
          "old_line_content": "    metrics::RecordGraphOutputTensors(output_size);",
          "new_line_content": "      output_size += outputs->back().AllocatedBytes();",
          "content_same": false
        },
        {
          "line": 979,
          "old_api": "std::unique_ptr<PartialRunState>(run_state)",
          "new_api": "emplace",
          "old_text": "std::unique_ptr<PartialRunState>(run_state)",
          "new_text": "partial_runs_\n             .emplace(run_state_args.handle,\n                      std::unique_ptr<PartialRunState>(run_state))",
          "old_line_content": "                      std::unique_ptr<PartialRunState>(run_state))",
          "new_line_content": "    if (!partial_runs_",
          "content_same": false
        },
        {
          "line": 981,
          "old_api": "errors::Internal(\"The handle '\", run_state_args.handle,\n                              \"' created for this partial run is not unique.\")",
          "new_api": "std::unique_ptr<PartialRunState>(run_state)",
          "old_text": "errors::Internal(\"The handle '\", run_state_args.handle,\n                              \"' created for this partial run is not unique.\")",
          "new_text": "std::unique_ptr<PartialRunState>(run_state)",
          "old_line_content": "      return errors::Internal(\"The handle '\", run_state_args.handle,",
          "new_line_content": "                      std::unique_ptr<PartialRunState>(run_state))",
          "content_same": false
        },
        {
          "line": 989,
          "old_api": "get",
          "new_api": "size",
          "old_text": "run_state->rendez.get()",
          "new_text": "executors_and_keys->items.size()",
          "old_line_content": "      num_executors, run_state->rendez.get(), [run_state](const Status& ret) {",
          "new_line_content": "  const size_t num_executors = executors_and_keys->items.size();",
          "content_same": false
        },
        {
          "line": 992,
          "old_api": "Update",
          "new_api": "ok",
          "old_text": "run_state->status.Update(ret)",
          "new_text": "ret.ok()",
          "old_line_content": "          run_state->status.Update(ret);",
          "new_line_content": "        if (!ret.ok()) {",
          "content_same": false
        },
        {
          "line": 994,
          "old_api": "Notify",
          "new_api": "Update",
          "old_text": "run_state->executors_done.Notify()",
          "new_text": "run_state->status.Update(ret)",
          "old_line_content": "        run_state->executors_done.Notify();",
          "new_line_content": "          run_state->status.Update(ret);",
          "content_same": false
        },
        {
          "line": 1017,
          "old_api": "get",
          "new_api": "graph_options",
          "old_text": "run_state->collector.get()",
          "new_text": "options_.config.graph_options().build_cost_model()",
          "old_line_content": "    args.stats_collector = run_state->collector.get();",
          "new_line_content": "  if (options_.config.graph_options().build_cost_model()) {",
          "content_same": false
        },
        {
          "line": 1041,
          "old_api": "errors::InvalidArgument(\n          \"Must run 'setup' before performing partial runs!\")",
          "new_api": "find",
          "old_text": "errors::InvalidArgument(\n          \"Must run 'setup' before performing partial runs!\")",
          "new_text": "executors_.find(key)",
          "old_line_content": "      return errors::InvalidArgument(",
          "new_line_content": "    auto exc_it = executors_.find(key);",
          "content_same": false
        },
        {
          "line": 1046,
          "old_api": "find",
          "new_api": "get",
          "old_text": "partial_runs_.find(handle)",
          "new_text": "exc_it->second.get()",
          "old_line_content": "    auto prun_it = partial_runs_.find(handle);",
          "new_line_content": "    executors_and_keys = exc_it->second.get();",
          "content_same": false
        },
        {
          "line": 1048,
          "old_api": "errors::InvalidArgument(\n          \"Must run 'setup' before performing partial runs!\")",
          "new_api": "find",
          "old_text": "errors::InvalidArgument(\n          \"Must run 'setup' before performing partial runs!\")",
          "new_text": "partial_runs_.find(handle)",
          "old_line_content": "      return errors::InvalidArgument(",
          "new_line_content": "    auto prun_it = partial_runs_.find(handle);",
          "content_same": false
        },
        {
          "line": 1057,
          "old_api": "errors::InvalidArgument(\n            \"The feed \", input.first,\n            \" was not specified in partial_run_setup.\")",
          "new_api": "find",
          "old_text": "errors::InvalidArgument(\n            \"The feed \", input.first,\n            \" was not specified in partial_run_setup.\")",
          "new_text": "run_state->pending_inputs.find(input.first)",
          "old_line_content": "        return errors::InvalidArgument(",
          "new_line_content": "      auto it = run_state->pending_inputs.find(input.first);",
          "content_same": false
        },
        {
          "line": 1069,
          "old_api": "errors::InvalidArgument(\n            \"The fetch \", output, \" was not specified in partial_run_setup.\")",
          "new_api": "find",
          "old_text": "errors::InvalidArgument(\n            \"The fetch \", output, \" was not specified in partial_run_setup.\")",
          "new_text": "run_state->pending_outputs.find(output)",
          "old_line_content": "        return errors::InvalidArgument(",
          "new_line_content": "      auto it = run_state->pending_outputs.find(output);",
          "content_same": false
        },
        {
          "line": 1122,
          "old_api": "erase",
          "new_api": "WaitForNotification",
          "old_text": "partial_runs_.erase(handle)",
          "new_text": "WaitForNotification(&run_state->executors_done, run_state,\n                          cancellation_manager_, operation_timeout_in_ms_)",
          "old_line_content": "      partial_runs_.erase(handle);",
          "new_line_content": "      WaitForNotification(&run_state->executors_done, run_state,",
          "content_same": false
        },
        {
          "line": 1140,
          "old_api": "container",
          "new_api": "resource_tensor.scalar<ResourceHandle>()()",
          "old_text": "resource_handle.container()",
          "new_text": "resource_tensor.scalar<ResourceHandle>()()",
          "old_line_content": "  if (resource_handle.container() ==",
          "new_line_content": "      resource_tensor.scalar<ResourceHandle>()();",
          "content_same": false
        },
        {
          "line": 1142,
          "old_api": "name",
          "new_api": "container",
          "old_text": "resource_handle.name()",
          "new_text": "resource_handle.container()",
          "old_line_content": "    return session_state_.GetTensor(resource_handle.name(), retrieved_tensor);",
          "new_line_content": "  if (resource_handle.container() ==",
          "content_same": false
        },
        {
          "line": 1144,
          "old_api": "hash_code",
          "new_api": "name",
          "old_text": "strings::StrCat(\n        \"Invalid resource type hash code: \", resource_handle.hash_code(),\n        \"(name: \", resource_handle.name(),\n        \" type: \", resource_handle.maybe_type_name(),\n        \"). Perhaps a resource tensor was being provided as a feed? That is \"\n        \"not currently allowed. Please file an issue at \"\n        \"https://github.com/tensorflow/tensorflow/issues/new, ideally with a \"\n        \"short code snippet that leads to this error message.\")",
          "new_text": "resource_handle.name()",
          "old_line_content": "    return errors::InvalidArgument(strings::StrCat(",
          "new_line_content": "    return session_state_.GetTensor(resource_handle.name(), retrieved_tensor);",
          "content_same": false
        },
        {
          "line": 1146,
          "old_api": "name",
          "new_api": "hash_code",
          "old_text": "resource_handle.name()",
          "new_text": "strings::StrCat(\n        \"Invalid resource type hash code: \", resource_handle.hash_code(),\n        \"(name: \", resource_handle.name(),\n        \" type: \", resource_handle.maybe_type_name(),\n        \"). Perhaps a resource tensor was being provided as a feed? That is \"\n        \"not currently allowed. Please file an issue at \"\n        \"https://github.com/tensorflow/tensorflow/issues/new, ideally with a \"\n        \"short code snippet that leads to this error message.\")",
          "old_line_content": "        \"(name: \", resource_handle.name(),",
          "new_line_content": "    return errors::InvalidArgument(strings::StrCat(",
          "content_same": false
        },
        {
          "line": 1147,
          "old_api": "maybe_type_name",
          "new_api": "hash_code",
          "old_text": "resource_handle.maybe_type_name()",
          "new_text": "resource_handle.hash_code()",
          "old_line_content": "        \" type: \", resource_handle.maybe_type_name(),",
          "new_line_content": "        \"Invalid resource type hash code: \", resource_handle.hash_code(),",
          "content_same": false
        },
        {
          "line": 1166,
          "old_api": "errors::Internal(\"'\", input.first, \"' is not a pre-defined feed.\")",
          "new_api": "find",
          "old_text": "errors::Internal(\"'\", input.first, \"' is not a pre-defined feed.\")",
          "new_text": "executors_and_keys->input_name_to_rendezvous_key.find(input.first)",
          "old_line_content": "      return errors::Internal(\"'\", input.first, \"' is not a pre-defined feed.\");",
          "new_line_content": "        executors_and_keys->input_name_to_rendezvous_key.find(input.first);",
          "content_same": false
        },
        {
          "line": 1172,
          "old_api": "StartAbort",
          "new_api": "Rendezvous::ParseKey(input_key, &parsed)",
          "old_text": "rendez->StartAbort(s)",
          "new_text": "Rendezvous::ParseKey(input_key, &parsed)",
          "old_line_content": "      rendez->StartAbort(s);",
          "new_line_content": "    s = Rendezvous::ParseKey(input_key, &parsed);",
          "content_same": false
        },
        {
          "line": 1178,
          "old_api": "ResourceHandleToInputTensor",
          "new_api": "dtype",
          "old_text": "ResourceHandleToInputTensor(input.second, &tensor_from_handle)",
          "new_text": "input.second.dtype()",
          "old_line_content": "      s = ResourceHandleToInputTensor(input.second, &tensor_from_handle);",
          "new_line_content": "    if (input.second.dtype() == DT_RESOURCE) {",
          "content_same": false
        },
        {
          "line": 1180,
          "old_api": "Rendezvous::Args()",
          "new_api": "ResourceHandleToInputTensor",
          "old_text": "Rendezvous::Args()",
          "new_text": "ResourceHandleToInputTensor(input.second, &tensor_from_handle)",
          "old_line_content": "        s = rendez->Send(parsed, Rendezvous::Args(), tensor_from_handle, false);",
          "new_line_content": "      s = ResourceHandleToInputTensor(input.second, &tensor_from_handle);",
          "content_same": false
        },
        {
          "line": 1211,
          "old_api": "errors::Internal(\"'\", output_name,\n                              \"' is not a pre-defined fetch.\")",
          "new_api": "find",
          "old_text": "errors::Internal(\"'\", output_name,\n                              \"' is not a pre-defined fetch.\")",
          "new_text": "executors_and_keys->output_name_to_rendezvous_key.find(output_name)",
          "old_line_content": "      return errors::Internal(\"'\", output_name,",
          "new_line_content": "        executors_and_keys->output_name_to_rendezvous_key.find(output_name);",
          "content_same": false
        },
        {
          "line": 1221,
          "old_api": "Rendezvous::Args()",
          "new_api": "ok",
          "old_text": "Rendezvous::Args()",
          "new_text": "s.ok()",
          "old_line_content": "      s = run_state->rendez->Recv(parsed, Rendezvous::Args(), &output_tensor,",
          "new_line_content": "    if (s.ok()) {",
          "content_same": false
        },
        {
          "line": 1223,
          "old_api": "ok",
          "new_api": "Rendezvous::Args()",
          "old_text": "s.ok()",
          "new_text": "Rendezvous::Args()",
          "old_line_content": "      if (is_dead && s.ok()) {",
          "new_line_content": "      s = run_state->rendez->Recv(parsed, Rendezvous::Args(), &output_tensor,",
          "content_same": false
        },
        {
          "line": 1230,
          "old_api": "clear",
          "new_api": "ok",
          "old_text": "outputs->clear()",
          "new_text": "s.ok()",
          "old_line_content": "      outputs->clear();",
          "new_line_content": "    if (!s.ok()) {",
          "content_same": false
        },
        {
          "line": 1255,
          "old_api": "end",
          "new_api": "ParseTensorName",
          "old_text": "name_to_node->end()",
          "new_text": "ParseTensorName(input.first)",
          "old_line_content": "      if (it == name_to_node->end()) {",
          "new_line_content": "      TensorId id(ParseTensorName(input.first));",
          "content_same": false
        },
        {
          "line": 1256,
          "old_api": "errors::NotFound(\"Feed \", input.first, \": not found\")",
          "new_api": "find",
          "old_text": "errors::NotFound(\"Feed \", input.first, \": not found\")",
          "new_text": "name_to_node->find(id.first)",
          "old_line_content": "        return errors::NotFound(\"Feed \", input.first, \": not found\");",
          "new_line_content": "      auto it = name_to_node->find(id.first);",
          "content_same": false
        },
        {
          "line": 1258,
          "old_api": "insert",
          "new_api": "errors::NotFound(\"Feed \", input.first, \": not found\")",
          "old_text": "pending_feeds.insert(id)",
          "new_text": "errors::NotFound(\"Feed \", input.first, \": not found\")",
          "old_line_content": "      pending_feeds.insert(id);",
          "new_line_content": "        return errors::NotFound(\"Feed \", input.first, \": not found\");",
          "content_same": false
        },
        {
          "line": 1272,
          "old_api": "errors::NotFound(\"Fetch \", fetch, \": not found\")",
          "new_api": "find",
          "old_text": "errors::NotFound(\"Fetch \", fetch, \": not found\")",
          "new_text": "name_to_node->find(id.first)",
          "old_line_content": "      return errors::NotFound(\"Fetch \", fetch, \": not found\");",
          "new_line_content": "    auto it = name_to_node->find(id.first);",
          "content_same": false
        },
        {
          "line": 1274,
          "old_api": "push_back",
          "new_api": "errors::NotFound(\"Fetch \", fetch, \": not found\")",
          "old_text": "stack.push_back(it->second)",
          "new_text": "errors::NotFound(\"Fetch \", fetch, \": not found\")",
          "old_line_content": "    stack.push_back(it->second);",
          "new_line_content": "      return errors::NotFound(\"Fetch \", fetch, \": not found\");",
          "content_same": false
        },
        {
          "line": 1280,
          "old_api": "back",
          "new_api": "num_node_ids",
          "old_text": "stack.back()",
          "new_text": "graph->num_node_ids()",
          "old_line_content": "    const Node* n = stack.back();",
          "new_line_content": "  std::vector<bool> visited(graph->num_node_ids(), false);",
          "content_same": false
        },
        {
          "line": 1281,
          "old_api": "pop_back",
          "new_api": "empty",
          "old_text": "stack.pop_back()",
          "new_text": "stack.empty()",
          "old_line_content": "    stack.pop_back();",
          "new_line_content": "  while (!stack.empty()) {",
          "content_same": false
        },
        {
          "line": 1283,
          "old_api": "in_edges",
          "new_api": "pop_back",
          "old_text": "n->in_edges()",
          "new_text": "stack.pop_back()",
          "old_line_content": "    for (const Edge* in_edge : n->in_edges()) {",
          "new_line_content": "    stack.pop_back();",
          "content_same": false
        },
        {
          "line": 1285,
          "old_api": "src_output",
          "new_api": "in_edges",
          "old_text": "in_edge->src_output()",
          "new_text": "n->in_edges()",
          "old_line_content": "      if (pending_feeds.count({in_node->name(), in_edge->src_output()}) > 0) {",
          "new_line_content": "    for (const Edge* in_edge : n->in_edges()) {",
          "content_same": false
        },
        {
          "line": 1286,
          "old_api": "name",
          "new_api": "src",
          "old_text": "in_node->name()",
          "new_text": "in_edge->src()",
          "old_line_content": "        return errors::InvalidArgument(\"Fetch \", in_node->name(), \":\",",
          "new_line_content": "      const Node* in_node = in_edge->src();",
          "content_same": false
        },
        {
          "line": 1293,
          "old_api": "push_back",
          "new_api": "id",
          "old_text": "stack.push_back(in_node)",
          "new_text": "in_node->id()",
          "old_line_content": "        stack.push_back(in_node);",
          "new_line_content": "      if (!visited[in_node->id()]) {",
          "content_same": false
        },
        {
          "line": 1330,
          "old_api": "feed",
          "new_api": "std::move(run_state_args->graph)",
          "old_text": "callable_options.feed()",
          "new_text": "std::move(run_state_args->graph)",
          "old_line_content": "    for (const string& input : callable_options.feed()) {",
          "new_line_content": "    ek->graph = std::move(run_state_args->graph);",
          "content_same": false
        },
        {
          "line": 1332,
          "old_api": "emplace",
          "new_api": "feed",
          "old_text": "names.emplace(id.first)",
          "new_text": "callable_options.feed()",
          "old_line_content": "      names.emplace(id.first);",
          "new_line_content": "    for (const string& input : callable_options.feed()) {",
          "content_same": false
        },
        {
          "line": 1334,
          "old_api": "fetch",
          "new_api": "emplace",
          "old_text": "callable_options.fetch()",
          "new_text": "names.emplace(id.first)",
          "old_line_content": "    for (const string& output : callable_options.fetch()) {",
          "new_line_content": "      names.emplace(id.first);",
          "content_same": false
        },
        {
          "line": 1336,
          "old_api": "emplace",
          "new_api": "fetch",
          "old_text": "names.emplace(id.first)",
          "new_text": "callable_options.fetch()",
          "old_line_content": "      names.emplace(id.first);",
          "new_line_content": "    for (const string& output : callable_options.fetch()) {",
          "content_same": false
        },
        {
          "line": 1338,
          "old_api": "nodes",
          "new_api": "emplace",
          "old_text": "ek->graph->nodes()",
          "new_text": "names.emplace(id.first)",
          "old_line_content": "    for (Node* n : ek->graph->nodes()) {",
          "new_line_content": "      names.emplace(id.first);",
          "content_same": false
        },
        {
          "line": 1340,
          "old_api": "name",
          "new_api": "nodes",
          "old_text": "n->name()",
          "new_text": "ek->graph->nodes()",
          "old_line_content": "        ek->name_to_node.insert({n->name(), n});",
          "new_line_content": "    for (Node* n : ek->graph->nodes()) {",
          "content_same": false
        },
        {
          "line": 1346,
          "old_api": "graph_options",
          "new_api": "size",
          "old_text": "options_.config.graph_options().optimizer_options()",
          "new_text": "graphs.size()",
          "old_line_content": "      options_.config.graph_options().optimizer_options();",
          "new_line_content": "  ek->items.reserve(graphs.size());",
          "content_same": false
        },
        {
          "line": 1348,
          "old_api": "begin",
          "new_api": "graph_options",
          "old_text": "graphs.begin()->second->versions().producer()",
          "new_text": "options_.config.graph_options().optimizer_options()",
          "old_line_content": "  int graph_def_version = graphs.begin()->second->versions().producer();",
          "new_line_content": "      options_.config.graph_options().optimizer_options();",
          "content_same": false
        },
        {
          "line": 1354,
          "old_api": "reset",
          "new_api": "experimental",
          "old_text": "func_info->proc_flr.reset(new ProcessFunctionLibraryRuntime(\n      device_mgr_.get(), options_.env, &options_.config, graph_def_version,\n      func_info->flib_def.get(), optimizer_opts, thread_pools_[0].first,\n      /*parent=*/nullptr, session_metadata,\n      Rendezvous::Factory{\n          [](const int64_t, const DeviceMgr* device_mgr, Rendezvous** r) {\n            *r = new IntraProcessRendezvous(device_mgr);\n            return Status::OK();\n          }}))",
          "new_text": "options_.config.experimental().session_metadata()",
          "old_line_content": "  func_info->proc_flr.reset(new ProcessFunctionLibraryRuntime(",
          "new_line_content": "          ? &options_.config.experimental().session_metadata()",
          "content_same": false
        },
        {
          "line": 1356,
          "old_api": "get",
          "new_api": "reset",
          "old_text": "func_info->flib_def.get()",
          "new_text": "func_info->proc_flr.reset(new ProcessFunctionLibraryRuntime(\n      device_mgr_.get(), options_.env, &options_.config, graph_def_version,\n      func_info->flib_def.get(), optimizer_opts, thread_pools_[0].first,\n      /*parent=*/nullptr, session_metadata,\n      Rendezvous::Factory{\n          [](const int64_t, const DeviceMgr* device_mgr, Rendezvous** r) {\n            *r = new IntraProcessRendezvous(device_mgr);\n            return Status::OK();\n          }}))",
          "old_line_content": "      func_info->flib_def.get(), optimizer_opts, thread_pools_[0].first,",
          "new_line_content": "  func_info->proc_flr.reset(new ProcessFunctionLibraryRuntime(",
          "content_same": false
        },
        {
          "line": 1372,
          "old_api": "size",
          "new_api": "LookupDevice",
          "old_text": "ek->items.size()",
          "new_text": "device_mgr_->LookupDevice(partition_name, &device)",
          "old_line_content": "    ek->items.resize(ek->items.size() + 1);",
          "new_line_content": "    TF_RETURN_IF_ERROR(device_mgr_->LookupDevice(partition_name, &device));",
          "content_same": false
        },
        {
          "line": 1374,
          "old_api": "GetFLR",
          "new_api": "size",
          "old_text": "func_info->proc_flr->GetFLR(partition_name)",
          "new_text": "ek->items.size()",
          "old_line_content": "    auto lib = func_info->proc_flr->GetFLR(partition_name);",
          "new_line_content": "    ek->items.resize(ek->items.size() + 1);",
          "content_same": false
        },
        {
          "line": 1376,
          "old_api": "errors::Internal(\"Could not find device: \", partition_name)",
          "new_api": "GetFLR",
          "old_text": "errors::Internal(\"Could not find device: \", partition_name)",
          "new_text": "func_info->proc_flr->GetFLR(partition_name)",
          "old_line_content": "      return errors::Internal(\"Could not find device: \", partition_name);",
          "new_line_content": "    auto lib = func_info->proc_flr->GetFLR(partition_name);",
          "content_same": false
        },
        {
          "line": 1416,
          "old_api": "get",
          "new_api": "run_options",
          "old_text": "DecorateAndPublishGraphForDebug(\n          debug_options, partition_graph.get(), params.device)",
          "new_text": "options.callable_options.run_options().debug_options()",
          "old_line_content": "      TF_RETURN_IF_ERROR(DecorateAndPublishGraphForDebug(",
          "new_line_content": "        options.callable_options.run_options().debug_options();",
          "content_same": false
        },
        {
          "line": 1417,
          "old_api": "get",
          "new_api": "debug_tensor_watch_opts",
          "old_text": "partition_graph.get()",
          "new_text": "debug_options.debug_tensor_watch_opts().empty()",
          "old_line_content": "          debug_options, partition_graph.get(), params.device));",
          "new_line_content": "    if (!debug_options.debug_tensor_watch_opts().empty()) {",
          "content_same": false
        },
        {
          "line": 1422,
          "old_api": "get",
          "new_api": "device_type",
          "old_text": "partition_graph.get()",
          "new_text": "device->device_type()",
          "old_line_content": "                                         partition_graph.get()));",
          "new_line_content": "    TF_RETURN_IF_ERROR(EnsureMemoryTypes(DeviceType(device->device_type()),",
          "content_same": false
        },
        {
          "line": 1428,
          "old_api": "NewExecutor",
          "new_api": "experimental",
          "old_text": "NewExecutor(executor_type, params, *partition_graph, &item->executor)",
          "new_text": "options_.config.experimental().executor_type()",
          "old_line_content": "        NewExecutor(executor_type, params, *partition_graph, &item->executor));",
          "new_line_content": "    auto executor_type = options_.config.experimental().executor_type();",
          "content_same": false
        },
        {
          "line": 1429,
          "old_api": "experimental",
          "new_api": "TF_RETURN_IF_ERROR",
          "old_text": "options_.config.experimental().disable_output_partition_graphs()",
          "new_text": "TF_RETURN_IF_ERROR(\n        NewExecutor(executor_type, params, *partition_graph, &item->executor))",
          "old_line_content": "    if (!options_.config.experimental().disable_output_partition_graphs() ||",
          "new_line_content": "    TF_RETURN_IF_ERROR(",
          "content_same": false
        },
        {
          "line": 1430,
          "old_api": "graph_options",
          "new_api": "NewExecutor",
          "old_text": "options_.config.graph_options().build_cost_model()",
          "new_text": "NewExecutor(executor_type, params, *partition_graph, &item->executor)",
          "old_line_content": "        options_.config.graph_options().build_cost_model() > 0) {",
          "new_line_content": "        NewExecutor(executor_type, params, *partition_graph, &item->executor));",
          "content_same": false
        },
        {
          "line": 1431,
          "old_api": "std::move(partition_graph)",
          "new_api": "experimental",
          "old_text": "std::move(partition_graph)",
          "new_text": "options_.config.experimental().disable_output_partition_graphs()",
          "old_line_content": "      item->graph = std::move(partition_graph);",
          "new_line_content": "    if (!options_.config.experimental().disable_output_partition_graphs() ||",
          "content_same": false
        },
        {
          "line": 1457,
          "old_api": "client_device",
          "new_api": "feed",
          "old_text": "GetRendezvousKey(\n          input, device_set_.client_device()->attributes(), FrameAndIter(0, 0))",
          "new_text": "callable_options.feed().size()",
          "old_line_content": "      ek->input_name_to_rendezvous_key[input] = GetRendezvousKey(",
          "new_line_content": "    for (int i = 0; i < callable_options.feed().size(); ++i) {",
          "content_same": false
        },
        {
          "line": 1458,
          "old_api": "FrameAndIter",
          "new_api": "feed",
          "old_text": "FrameAndIter(0, 0)",
          "new_text": "callable_options.feed(i)",
          "old_line_content": "          input, device_set_.client_device()->attributes(), FrameAndIter(0, 0));",
          "new_line_content": "      const string& input = callable_options.feed(i);",
          "content_same": false
        },
        {
          "line": 1460,
          "old_api": "fetch",
          "new_api": "FrameAndIter",
          "old_text": "callable_options.fetch().size()",
          "new_text": "FrameAndIter(0, 0)",
          "old_line_content": "    for (int i = 0; i < callable_options.fetch().size(); ++i) {",
          "new_line_content": "          input, device_set_.client_device()->attributes(), FrameAndIter(0, 0));",
          "content_same": false
        },
        {
          "line": 1463,
          "old_api": "client_device",
          "new_api": "fetch",
          "old_text": "device_set_.client_device()->attributes()",
          "new_text": "callable_options.fetch(i)",
          "old_line_content": "          GetRendezvousKey(output, device_set_.client_device()->attributes(),",
          "new_line_content": "      const string& output = callable_options.fetch(i);",
          "content_same": false
        },
        {
          "line": 1470,
          "old_api": "Status::OK()",
          "new_api": "std::move(ek)",
          "old_text": "Status::OK()",
          "new_text": "std::move(ek)",
          "old_line_content": "  return Status::OK();",
          "new_line_content": "  *out_executors_and_keys = std::move(ek);",
          "content_same": false
        },
        {
          "line": 1491,
          "old_api": "absl::StrJoin(target_nodes, \",\")",
          "new_api": "strings::StrCat(\n      absl::StrJoin(inputs, \",\"), \"->\", absl::StrJoin(outputs, \",\"), \"/\",\n      absl::StrJoin(target_nodes, \",\"), \"/\", run_state_args->is_partial_run,\n      \"/\", debug_tensor_watches_summary)",
          "old_text": "absl::StrJoin(target_nodes, \",\")",
          "new_text": "strings::StrCat(\n      absl::StrJoin(inputs, \",\"), \"->\", absl::StrJoin(outputs, \",\"), \"/\",\n      absl::StrJoin(target_nodes, \",\"), \"/\", run_state_args->is_partial_run,\n      \"/\", debug_tensor_watches_summary)",
          "old_line_content": "      absl::StrJoin(target_nodes, \",\"), \"/\", run_state_args->is_partial_run,",
          "new_line_content": "  const string key = strings::StrCat(",
          "content_same": false
        },
        {
          "line": 1504,
          "old_api": "get",
          "new_api": "find",
          "old_text": "it->second.get()",
          "new_text": "executors_.find(key)",
          "old_line_content": "      *executors_and_keys = it->second.get();",
          "new_line_content": "    auto it = executors_.find(key);",
          "content_same": false
        },
        {
          "line": 1505,
          "old_api": "Status::OK()",
          "new_api": "end",
          "old_text": "Status::OK()",
          "new_text": "executors_.end()",
          "old_line_content": "      return Status::OK();",
          "new_line_content": "    if (it != executors_.end()) {",
          "content_same": false
        },
        {
          "line": 1522,
          "old_api": "strings::StrCat(\n      absl::StrJoin(inputs_sorted, \",\"), \"->\",\n      absl::StrJoin(outputs_sorted, \",\"), \"/\", absl::StrJoin(tn_sorted, \",\"),\n      \"/\", run_state_args->is_partial_run, \"/\", debug_tensor_watches_summary)",
          "new_api": "end",
          "old_text": "strings::StrCat(\n      absl::StrJoin(inputs_sorted, \",\"), \"->\",\n      absl::StrJoin(outputs_sorted, \",\"), \"/\", absl::StrJoin(tn_sorted, \",\"),\n      \"/\", run_state_args->is_partial_run, \"/\", debug_tensor_watches_summary)",
          "new_text": "tn_sorted.end()",
          "old_line_content": "  const string sorted_key = strings::StrCat(",
          "new_line_content": "  std::sort(tn_sorted.begin(), tn_sorted.end());",
          "content_same": false
        },
        {
          "line": 1524,
          "old_api": "absl::StrJoin(tn_sorted, \",\")",
          "new_api": "strings::StrCat(\n      absl::StrJoin(inputs_sorted, \",\"), \"->\",\n      absl::StrJoin(outputs_sorted, \",\"), \"/\", absl::StrJoin(tn_sorted, \",\"),\n      \"/\", run_state_args->is_partial_run, \"/\", debug_tensor_watches_summary)",
          "old_text": "absl::StrJoin(tn_sorted, \",\")",
          "new_text": "strings::StrCat(\n      absl::StrJoin(inputs_sorted, \",\"), \"->\",\n      absl::StrJoin(outputs_sorted, \",\"), \"/\", absl::StrJoin(tn_sorted, \",\"),\n      \"/\", run_state_args->is_partial_run, \"/\", debug_tensor_watches_summary)",
          "old_line_content": "      absl::StrJoin(outputs_sorted, \",\"), \"/\", absl::StrJoin(tn_sorted, \",\"),",
          "new_line_content": "  const string sorted_key = strings::StrCat(",
          "content_same": false
        },
        {
          "line": 1537,
          "old_api": "get",
          "new_api": "find",
          "old_text": "it->second.get()",
          "new_text": "executors_.find(sorted_key)",
          "old_line_content": "      *executors_and_keys = it->second.get();",
          "new_line_content": "    auto it = executors_.find(sorted_key);",
          "content_same": false
        },
        {
          "line": 1538,
          "old_api": "Status::OK()",
          "new_api": "end",
          "old_text": "Status::OK()",
          "new_text": "executors_.end()",
          "old_line_content": "      return Status::OK();",
          "new_line_content": "    if (it != executors_.end()) {",
          "content_same": false
        },
        {
          "line": 1548,
          "old_api": "add_feed",
          "new_api": "size",
          "old_text": "callable_options.add_feed(input)",
          "new_text": "inputs_sorted.size()",
          "old_line_content": "    callable_options.add_feed(input);",
          "new_line_content": "  callable_options.mutable_feed()->Reserve(inputs_sorted.size());",
          "content_same": false
        },
        {
          "line": 1550,
          "old_api": "size",
          "new_api": "add_feed",
          "old_text": "outputs_sorted.size()",
          "new_text": "callable_options.add_feed(input)",
          "old_line_content": "  callable_options.mutable_fetch()->Reserve(outputs_sorted.size());",
          "new_line_content": "    callable_options.add_feed(input);",
          "content_same": false
        },
        {
          "line": 1552,
          "old_api": "add_fetch",
          "new_api": "size",
          "old_text": "callable_options.add_fetch(output)",
          "new_text": "outputs_sorted.size()",
          "old_line_content": "    callable_options.add_fetch(output);",
          "new_line_content": "  callable_options.mutable_fetch()->Reserve(outputs_sorted.size());",
          "content_same": false
        },
        {
          "line": 1554,
          "old_api": "size",
          "new_api": "add_fetch",
          "old_text": "tn_sorted.size()",
          "new_text": "callable_options.add_fetch(output)",
          "old_line_content": "  callable_options.mutable_target()->Reserve(tn_sorted.size());",
          "new_line_content": "    callable_options.add_fetch(output);",
          "content_same": false
        },
        {
          "line": 1556,
          "old_api": "add_target",
          "new_api": "size",
          "old_text": "callable_options.add_target(target)",
          "new_text": "tn_sorted.size()",
          "old_line_content": "    callable_options.add_target(target);",
          "new_line_content": "  callable_options.mutable_target()->Reserve(tn_sorted.size());",
          "content_same": false
        },
        {
          "line": 1558,
          "old_api": "mutable_run_options",
          "new_api": "add_target",
          "old_text": "callable_options.mutable_run_options()->mutable_debug_options()",
          "new_text": "callable_options.add_target(target)",
          "old_line_content": "  *callable_options.mutable_run_options()->mutable_debug_options() =",
          "new_line_content": "    callable_options.add_target(target);",
          "content_same": false
        },
        {
          "line": 1576,
          "old_api": "std::move(func_info)",
          "new_api": "std::move(ek)",
          "old_text": "std::move(func_info)",
          "new_text": "std::move(ek)",
          "old_line_content": "    functions_.push_back(std::move(func_info));",
          "new_line_content": "      sorted_key, std::shared_ptr<ExecutorsAndKeys>(std::move(ek)));",
          "content_same": false
        },
        {
          "line": 1584,
          "old_api": "Status::OK()",
          "new_api": "get",
          "old_text": "Status::OK()",
          "new_text": "insert_result.first->second.get()",
          "old_line_content": "  return Status::OK();",
          "new_line_content": "  *executors_and_keys = insert_result.first->second.get();",
          "content_same": false
        },
        {
          "line": 1618,
          "old_api": "BuildGraph",
          "new_api": "get",
          "old_text": "execution_state->BuildGraph(subgraph_options, &client_graph)",
          "new_text": "execution_state_.get()",
          "old_line_content": "        execution_state->BuildGraph(subgraph_options, &client_graph));",
          "new_line_content": "    execution_state = execution_state_.get();",
          "content_same": false
        },
        {
          "line": 1628,
          "old_api": "size",
          "new_api": "feed_size",
          "old_text": "client_graph->feed_types.size()",
          "new_text": "subgraph_options.callable_options.feed_size()",
          "old_line_content": "        client_graph->feed_types.size());",
          "new_line_content": "        subgraph_options.callable_options.feed_size(),",
          "content_same": false
        },
        {
          "line": 1630,
          "old_api": "fetch_size",
          "new_api": "size",
          "old_text": "subgraph_options.callable_options.fetch_size()",
          "new_text": "client_graph->feed_types.size()",
          "old_line_content": "  if (subgraph_options.callable_options.fetch_size() !=",
          "new_line_content": "        client_graph->feed_types.size());",
          "content_same": false
        },
        {
          "line": 1636,
          "old_api": "size",
          "new_api": "fetch_size",
          "old_text": "client_graph->fetch_types.size()",
          "new_text": "subgraph_options.callable_options.fetch_size()",
          "old_line_content": "        client_graph->fetch_types.size());",
          "new_line_content": "        subgraph_options.callable_options.fetch_size(),",
          "content_same": false
        },
        {
          "line": 1648,
          "old_api": "std::make_pair(node_name, placement)",
          "new_api": "find",
          "old_text": "std::make_pair(node_name, placement)",
          "new_text": "stateful_placements_.find(node_name)",
          "old_line_content": "      stateful_placements_.insert(std::make_pair(node_name, placement));",
          "new_line_content": "    auto iter = stateful_placements_.find(node_name);",
          "content_same": false
        },
        {
          "line": 1650,
          "old_api": "errors::Internal(\n          \"Stateful placement mismatch. \"\n          \"Current assignment of \",\n          node_name, \" to \", iter->second, \" does not match \", placement)",
          "new_api": "std::make_pair(node_name, placement)",
          "old_text": "errors::Internal(\n          \"Stateful placement mismatch. \"\n          \"Current assignment of \",\n          node_name, \" to \", iter->second, \" does not match \", placement)",
          "new_text": "std::make_pair(node_name, placement)",
          "old_line_content": "      return errors::Internal(",
          "new_line_content": "      stateful_placements_.insert(std::make_pair(node_name, placement));",
          "content_same": false
        },
        {
          "line": 1696,
          "old_api": "errors::InvalidArgument(\n          \"Creating a partition for \", local_partition_name,\n          \" which doesn't exist in the list of available devices. Available \"\n          \"devices: \",\n          absl::StrJoin(device_names, \",\"))",
          "new_api": "end",
          "old_text": "errors::InvalidArgument(\n          \"Creating a partition for \", local_partition_name,\n          \" which doesn't exist in the list of available devices. Available \"\n          \"devices: \",\n          absl::StrJoin(device_names, \",\"))",
          "new_text": "device_names.end()",
          "old_line_content": "      return errors::InvalidArgument(",
          "new_line_content": "    if (std::count(device_names.begin(), device_names.end(),",
          "content_same": false
        },
        {
          "line": 1714,
          "old_api": "std::move(device_graph)",
          "new_api": "get",
          "old_text": "std::move(device_graph)",
          "new_text": "ConvertGraphDefToGraph(\n        device_opts, std::move(partition.second), device_graph.get())",
          "old_line_content": "    outputs->emplace(partition.first, std::move(device_graph));",
          "new_line_content": "    TF_RETURN_IF_ERROR(ConvertGraphDefToGraph(",
          "content_same": false
        },
        {
          "line": 1721,
          "old_api": "RunGrouping",
          "new_api": "get",
          "old_text": "OptimizationPassRegistry::Global()->RunGrouping(\n      OptimizationPassRegistry::POST_PARTITIONING, optimization_options)",
          "new_text": "client_graph->flib_def.get()",
          "old_line_content": "  TF_RETURN_IF_ERROR(OptimizationPassRegistry::Global()->RunGrouping(",
          "new_line_content": "  optimization_options.flib_def = client_graph->flib_def.get();",
          "content_same": false
        },
        {
          "line": 1736,
          "old_api": "MaybeRewriteGraph",
          "new_api": "LookupDevice",
          "old_text": "d->MaybeRewriteGraph(graph)",
          "new_text": "device_mgr_->LookupDevice(partition_name, &d)",
          "old_line_content": "    s = d->MaybeRewriteGraph(graph);",
          "new_line_content": "    s = device_mgr_->LookupDevice(partition_name, &d);",
          "content_same": false
        },
        {
          "line": 1743,
          "old_api": "std::swap(*output_types, client_graph->fetch_types)",
          "new_api": "std::move(client_graph->flib_def)",
          "old_text": "std::swap(*output_types, client_graph->fetch_types)",
          "new_text": "std::move(client_graph->flib_def)",
          "old_line_content": "  std::swap(*output_types, client_graph->fetch_types);",
          "new_line_content": "  *flib_def = std::move(client_graph->flib_def);",
          "content_same": false
        },
        {
          "line": 1752,
          "old_api": "attributes",
          "new_api": "size",
          "old_text": "d->attributes()",
          "new_text": "devices_.size()",
          "old_line_content": "    const DeviceAttributes& attrs = d->attributes();",
          "new_line_content": "  response->reserve(devices_.size());",
          "content_same": false
        },
        {
          "line": 1755,
          "old_api": "::tensorflow::Status::OK()",
          "new_api": "emplace_back",
          "old_text": "::tensorflow::Status::OK()",
          "new_text": "response->emplace_back(attrs)",
          "old_line_content": "  return ::tensorflow::Status::OK();",
          "new_line_content": "    response->emplace_back(attrs);",
          "content_same": false
        },
        {
          "line": 1827,
          "old_api": "StartCancel",
          "new_api": "Update",
          "old_text": "cm->StartCancel()",
          "new_text": "run_state->status.Update(status)",
          "old_line_content": "    cm->StartCancel();",
          "new_line_content": "      run_state->status.Update(status);",
          "content_same": false
        },
        {
          "line": 1842,
          "old_api": "Status",
          "new_api": "WaitForNotificationWithTimeout",
          "old_text": "Status(error::DEADLINE_EXCEEDED,\n                    \"Timed out waiting for notification\")",
          "new_text": "WaitForNotificationWithTimeout(notification, timeout_in_us)",
          "old_line_content": "      return Status(error::DEADLINE_EXCEEDED,",
          "new_line_content": "        WaitForNotificationWithTimeout(notification, timeout_in_us);",
          "content_same": false
        },
        {
          "line": 1848,
          "old_api": "Status::OK()",
          "new_api": "WaitForNotification",
          "old_text": "Status::OK()",
          "new_text": "notification->WaitForNotification()",
          "old_line_content": "  return Status::OK();",
          "new_line_content": "    notification->WaitForNotification();",
          "content_same": false
        },
        {
          "line": 1860,
          "old_api": "CreateExecutors",
          "new_api": "run_options",
          "old_text": "CreateExecutors(callable_options, &ek, &func_info, &run_state_args)",
          "new_text": "callable_options.run_options().debug_options()",
          "old_line_content": "      CreateExecutors(callable_options, &ek, &func_info, &run_state_args));",
          "new_line_content": "  RunStateArgs run_state_args(callable_options.run_options().debug_options());",
          "content_same": false
        },
        {
          "line": 1866,
          "old_api": "Status::OK()",
          "new_api": "std::move(func_info)",
          "old_text": "Status::OK()",
          "new_text": "std::move(func_info)",
          "old_line_content": "  return Status::OK();",
          "new_line_content": "    callables_[*out_handle] = {std::move(ek), std::move(func_info)};",
          "content_same": false
        },
        {
          "line": 1924,
          "old_api": "GetCell",
          "new_api": "CheckNotClosed",
          "old_text": "direct_session_runs->GetCell()->IncrementBy(1)",
          "new_text": "CheckNotClosed()",
          "old_line_content": "  direct_session_runs->GetCell()->IncrementBy(1);",
          "new_line_content": "  TF_RETURN_IF_ERROR(CheckNotClosed());",
          "content_same": false
        },
        {
          "line": 1958,
          "old_api": "errors::InvalidArgument(\n        \"`fetch_tensors` must be provided when the callable has one or more \"\n        \"outputs.\")",
          "new_api": "size",
          "old_text": "errors::InvalidArgument(\n        \"`fetch_tensors` must be provided when the callable has one or more \"\n        \"outputs.\")",
          "new_text": "executors_and_keys->output_types.size()",
          "old_line_content": "    return errors::InvalidArgument(",
          "new_line_content": "    fetch_tensors->resize(executors_and_keys->output_types.size());",
          "content_same": false
        },
        {
          "line": 1969,
          "old_api": "metrics::RecordGraphInputTensors(input_size)",
          "new_api": "dtype",
          "old_text": "metrics::RecordGraphInputTensors(input_size)",
          "new_text": "tensor.dtype()",
          "old_line_content": "  metrics::RecordGraphInputTensors(input_size);",
          "new_line_content": "    any_resource_feeds = any_resource_feeds || tensor.dtype() == DT_RESOURCE;",
          "content_same": false
        },
        {
          "line": 1976,
          "old_api": "size",
          "new_api": "TF_PREDICT_FALSE",
          "old_text": "feed_tensors.size()",
          "new_text": "TF_PREDICT_FALSE(any_resource_feeds)",
          "old_line_content": "    converted_feed_tensors->reserve(feed_tensors.size());",
          "new_line_content": "  if (TF_PREDICT_FALSE(any_resource_feeds)) {",
          "content_same": false
        },
        {
          "line": 1978,
          "old_api": "dtype",
          "new_api": "size",
          "old_text": "t.dtype()",
          "new_text": "feed_tensors.size()",
          "old_line_content": "      if (t.dtype() == DT_RESOURCE) {",
          "new_line_content": "    converted_feed_tensors->reserve(feed_tensors.size());",
          "content_same": false
        },
        {
          "line": 1980,
          "old_api": "back",
          "new_api": "dtype",
          "old_text": "converted_feed_tensors->back()",
          "new_text": "t.dtype()",
          "old_line_content": "        Tensor* tensor_from_handle = &converted_feed_tensors->back();",
          "new_line_content": "      if (t.dtype() == DT_RESOURCE) {",
          "content_same": false
        },
        {
          "line": 1981,
          "old_api": "ResourceHandleToInputTensor",
          "new_api": "emplace_back",
          "old_text": "ResourceHandleToInputTensor(t, tensor_from_handle)",
          "new_text": "converted_feed_tensors->emplace_back()",
          "old_line_content": "        TF_RETURN_IF_ERROR(ResourceHandleToInputTensor(t, tensor_from_handle));",
          "new_line_content": "        converted_feed_tensors->emplace_back();",
          "content_same": false
        },
        {
          "line": 1983,
          "old_api": "emplace_back",
          "new_api": "ResourceHandleToInputTensor",
          "old_text": "converted_feed_tensors->emplace_back(t)",
          "new_text": "ResourceHandleToInputTensor(t, tensor_from_handle)",
          "old_line_content": "        converted_feed_tensors->emplace_back(t);",
          "new_line_content": "        TF_RETURN_IF_ERROR(ResourceHandleToInputTensor(t, tensor_from_handle));",
          "content_same": false
        },
        {
          "line": 2002,
          "old_api": "get",
          "new_api": "run_options",
          "old_text": "executors_and_keys.get()",
          "new_text": "RunInternal(\n      step_id, executors_and_keys->callable_options.run_options(), &call_frame,\n      executors_and_keys.get(), run_metadata, threadpool_options)",
          "old_line_content": "      executors_and_keys.get(), run_metadata, threadpool_options));",
          "new_line_content": "  TF_RETURN_IF_ERROR(RunInternal(",
          "content_same": false
        },
        {
          "line": 2009,
          "old_api": "metrics::RecordGraphOutputTensors(output_size)",
          "new_api": "AllocatedBytes",
          "old_text": "metrics::RecordGraphOutputTensors(output_size)",
          "new_text": "tensor.AllocatedBytes()",
          "old_line_content": "    metrics::RecordGraphOutputTensors(output_size);",
          "new_line_content": "      output_size += tensor.AllocatedBytes();",
          "content_same": false
        },
        {
          "line": 2020,
          "old_api": "erase",
          "new_api": "errors::InvalidArgument(\"No such callable handle: \", handle)",
          "old_text": "callables_.erase(handle)",
          "new_text": "errors::InvalidArgument(\"No such callable handle: \", handle)",
          "old_line_content": "  callables_.erase(handle);",
          "new_line_content": "    return errors::InvalidArgument(\"No such callable handle: \", handle);",
          "content_same": false
        },
        {
          "line": 2032,
          "old_api": "reset",
          "new_api": "errors::FailedPrecondition(\"Session not yet created.\")",
          "old_text": "execution_state_.reset()",
          "new_text": "errors::FailedPrecondition(\"Session not yet created.\")",
          "old_line_content": "  execution_state_.reset();",
          "new_line_content": "    return errors::FailedPrecondition(\"Session not yet created.\");",
          "content_same": false
        },
        {
          "line": 2035,
          "old_api": "Status::OK()",
          "new_api": "reset",
          "old_text": "Status::OK()",
          "new_text": "flib_def_.reset()",
          "old_line_content": "  return Status::OK();",
          "new_line_content": "  flib_def_.reset();",
          "content_same": false
        }
      ],
      "additions": [
        {
          "line": 447,
          "old_api": null,
          "new_api": "GraphExecutionState::MakeForBaseGraph(\n        std::move(graph), options, &execution_state_)",
          "old_text": null,
          "new_text": "GraphExecutionState::MakeForBaseGraph(\n        std::move(graph), options, &execution_state_)",
          "old_line_content": "    GraphExecutionStateOptions options;",
          "new_line_content": "    TF_RETURN_IF_ERROR(GraphExecutionState::MakeForBaseGraph(",
          "content_same": false
        },
        {
          "line": 448,
          "old_api": null,
          "new_api": "std::move(graph)",
          "old_text": null,
          "new_text": "std::move(graph)",
          "old_line_content": "    options.device_set = &device_set_;",
          "new_line_content": "        std::move(graph), options, &execution_state_));",
          "content_same": false
        },
        {
          "line": 453,
          "old_api": null,
          "new_api": "reset",
          "old_text": null,
          "new_text": "flib_def_.reset(\n        new FunctionLibraryDefinition(execution_state_->flib_def()))",
          "old_line_content": "    graph_created_ = true;",
          "new_line_content": "    flib_def_.reset(",
          "content_same": false
        },
        {
          "line": 454,
          "old_api": null,
          "new_api": "flib_def",
          "old_text": null,
          "new_text": "execution_state_->flib_def()",
          "old_line_content": "  } else {",
          "new_line_content": "        new FunctionLibraryDefinition(execution_state_->flib_def()));",
          "content_same": false
        },
        {
          "line": 461,
          "old_api": null,
          "new_api": "swap",
          "old_text": null,
          "new_text": "execution_state_.swap(state)",
          "old_line_content": "  }",
          "new_line_content": "    execution_state_.swap(state);",
          "content_same": false
        },
        {
          "line": 464,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 472,
          "old_api": null,
          "new_api": "RunOptions",
          "old_text": null,
          "new_text": "RunOptions()",
          "old_line_content": "}",
          "new_line_content": "  return Run(RunOptions(), inputs, output_names, target_nodes, outputs,",
          "content_same": false
        },
        {
          "line": 486,
          "old_api": null,
          "new_api": "target",
          "old_text": null,
          "new_text": "callable_options.target().begin()",
          "old_line_content": "",
          "new_line_content": "  std::vector<string> target_names(callable_options.target().begin(),",
          "content_same": false
        },
        {
          "line": 489,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "debugger_state->get()->PublishDebugMetadata(\n      global_step, session_run_index, executor_step_index, input_names,\n      output_names, target_names)",
          "old_line_content": "      output_names, target_names));",
          "new_line_content": "  TF_RETURN_IF_ERROR(debugger_state->get()->PublishDebugMetadata(",
          "content_same": false
        },
        {
          "line": 492,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 498,
          "old_api": null,
          "new_api": "TF_RETURN_IF_ERROR",
          "old_text": null,
          "new_text": "TF_RETURN_IF_ERROR(\n      DebugGraphDecoratorRegistry::CreateDecorator(debug_options, &decorator))",
          "old_line_content": "",
          "new_line_content": "  TF_RETURN_IF_ERROR(",
          "content_same": false
        },
        {
          "line": 502,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "device->name()",
          "old_line_content": "}",
          "new_line_content": "  TF_RETURN_IF_ERROR(decorator->PublishGraph(*graph, device->name()));",
          "content_same": false
        },
        {
          "line": 503,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 515,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "executors_and_keys->items.size()",
          "old_line_content": "  profiler::TraceMeProducer activity(",
          "new_line_content": "  const size_t num_executors = executors_and_keys->items.size();",
          "content_same": false
        },
        {
          "line": 524,
          "old_api": null,
          "new_api": "version",
          "old_text": null,
          "new_text": "model_metadata.version()",
          "old_line_content": "                                         {{\"id\", step_id},",
          "new_line_content": "                                            model_metadata.version());",
          "content_same": false
        },
        {
          "line": 525,
          "old_api": null,
          "new_api": "profiler::TraceMeEncode(\"SessionRun\",\n                                         {{\"id\", step_id},\n                                          {\"_r\", 1} /*root_event*/,\n                                          {\"model_id\", model_id}})",
          "old_text": null,
          "new_text": "profiler::TraceMeEncode(\"SessionRun\",\n                                         {{\"id\", step_id},\n                                          {\"_r\", 1} /*root_event*/,\n                                          {\"model_id\", model_id}})",
          "old_line_content": "                                          {\"_r\", 1} /*root_event*/,",
          "new_line_content": "          return profiler::TraceMeEncode(\"SessionRun\",",
          "content_same": false
        },
        {
          "line": 530,
          "old_api": null,
          "new_api": "profiler::TraceMeEncode(\n              \"SessionRun\", {{\"id\", step_id}, {\"_r\", 1} /*root_event*/})",
          "old_text": null,
          "new_text": "profiler::TraceMeEncode(\n              \"SessionRun\", {{\"id\", step_id}, {\"_r\", 1} /*root_event*/})",
          "old_line_content": "        }",
          "new_line_content": "          return profiler::TraceMeEncode(",
          "content_same": false
        },
        {
          "line": 540,
          "old_api": null,
          "new_api": "debug_options",
          "old_text": null,
          "new_text": "CreateDebuggerState(executors_and_keys->callable_options,\n                            run_options.debug_options().global_step(), step_id,\n                            executor_step_count, &debugger_state)",
          "old_line_content": "                            executor_step_count, &debugger_state));",
          "new_line_content": "        CreateDebuggerState(executors_and_keys->callable_options,",
          "content_same": false
        },
        {
          "line": 541,
          "old_api": null,
          "new_api": "debug_options",
          "old_text": null,
          "new_text": "run_options.debug_options().global_step()",
          "old_line_content": "  }",
          "new_line_content": "                            run_options.debug_options().global_step(), step_id,",
          "content_same": false
        },
        {
          "line": 549,
          "old_api": null,
          "new_api": "experimental",
          "old_text": null,
          "new_text": "run_options.experimental().collective_graph_key()",
          "old_line_content": "      // If a collective_graph_key was specified in run_options, ensure that it",
          "new_line_content": "    if (run_options.experimental().collective_graph_key() !=",
          "content_same": false
        },
        {
          "line": 557,
          "old_api": null,
          "new_api": "experimental",
          "old_text": null,
          "new_text": "run_options.experimental().collective_graph_key()",
          "old_line_content": "            executors_and_keys->collective_graph_key);",
          "new_line_content": "            run_options.experimental().collective_graph_key(),",
          "content_same": false
        },
        {
          "line": 564,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "device_mgr_.get()",
          "old_line_content": "    }",
          "new_line_content": "          options_.config, device_mgr_.get(),",
          "content_same": false
        },
        {
          "line": 567,
          "old_api": null,
          "new_api": "reset",
          "old_text": null,
          "new_text": "run_state.collective_executor.reset(new CollectiveExecutor::Handle(\n        collective_executor_mgr_->FindOrCreate(step_id), true /*inherit_ref*/))",
          "old_line_content": "  }",
          "new_line_content": "    run_state.collective_executor.reset(new CollectiveExecutor::Handle(",
          "content_same": false
        },
        {
          "line": 568,
          "old_api": null,
          "new_api": "FindOrCreate",
          "old_text": null,
          "new_text": "collective_executor_mgr_->FindOrCreate(step_id)",
          "old_line_content": "#endif",
          "new_line_content": "        collective_executor_mgr_->FindOrCreate(step_id), true /*inherit_ref*/));",
          "content_same": false
        },
        {
          "line": 577,
          "old_api": null,
          "new_api": "inter_op_thread_pool",
          "old_text": null,
          "new_text": "run_options.inter_op_thread_pool()",
          "old_line_content": "  if (inline_execution_requested) {",
          "new_line_content": "      run_in_caller_thread_ || run_options.inter_op_thread_pool() == -1;",
          "content_same": false
        },
        {
          "line": 582,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "executors_and_keys->items.size()",
          "old_line_content": "    } else {",
          "new_line_content": "    if (executors_and_keys->items.size() > 1) {",
          "content_same": false
        },
        {
          "line": 585,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(1)",
          "old_line_content": "    }",
          "new_line_content": "      VLOG(1) << \"Executing Session::Run() synchronously!\";",
          "content_same": false
        },
        {
          "line": 596,
          "old_api": null,
          "new_api": "inter_op_thread_pool",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\"Invalid inter_op_thread_pool: \",\n                                     run_options.inter_op_thread_pool())",
          "old_line_content": "    }",
          "new_line_content": "      return errors::InvalidArgument(\"Invalid inter_op_thread_pool: \",",
          "content_same": false
        },
        {
          "line": 597,
          "old_api": null,
          "new_api": "inter_op_thread_pool",
          "old_text": null,
          "new_text": "run_options.inter_op_thread_pool()",
          "old_line_content": "",
          "new_line_content": "                                     run_options.inter_op_thread_pool());",
          "content_same": false
        },
        {
          "line": 600,
          "old_api": null,
          "new_api": "inter_op_thread_pool",
          "old_text": null,
          "new_text": "run_options.inter_op_thread_pool()",
          "old_line_content": "",
          "new_line_content": "    pool = thread_pools_[run_options.inter_op_thread_pool()].first;",
          "content_same": false
        },
        {
          "line": 603,
          "old_api": null,
          "new_api": "timeout_in_ms",
          "old_text": null,
          "new_text": "run_options.timeout_in_ms()",
          "old_line_content": "                                   : operation_timeout_in_ms_;",
          "new_line_content": "  const int64_t call_timeout = run_options.timeout_in_ms() > 0",
          "content_same": false
        },
        {
          "line": 604,
          "old_api": null,
          "new_api": "timeout_in_ms",
          "old_text": null,
          "new_text": "run_options.timeout_in_ms()",
          "old_line_content": "  absl::optional<absl::Time> deadline;",
          "new_line_content": "                                   ? run_options.timeout_in_ms()",
          "content_same": false
        },
        {
          "line": 608,
          "old_api": null,
          "new_api": "absl::Milliseconds(call_timeout)",
          "old_text": null,
          "new_text": "absl::Milliseconds(call_timeout)",
          "old_line_content": "",
          "new_line_content": "    deadline = absl::Now() + absl::Milliseconds(call_timeout);",
          "content_same": false
        },
        {
          "line": 614,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(1)",
          "old_line_content": "        step_id, call_timeout,",
          "new_line_content": "    VLOG(1) << \"Using RunHandler to scheduler inter-op closures.\";",
          "content_same": false
        },
        {
          "line": 619,
          "old_api": null,
          "new_api": "errors::DeadlineExceeded(\n          \"Could not obtain RunHandler for request after waiting for \",\n          call_timeout, \"ms.\")",
          "old_text": null,
          "new_text": "errors::DeadlineExceeded(\n          \"Could not obtain RunHandler for request after waiting for \",\n          call_timeout, \"ms.\")",
          "old_line_content": "          call_timeout, \"ms.\");",
          "new_line_content": "      return errors::DeadlineExceeded(",
          "content_same": false
        },
        {
          "line": 624,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "handler.get()",
          "old_line_content": "  Executor::Args::Runner default_runner = nullptr;",
          "new_line_content": "  auto* handler_ptr = handler.get();",
          "content_same": false
        },
        {
          "line": 629,
          "old_api": null,
          "new_api": "c",
          "old_text": null,
          "new_text": "c()",
          "old_line_content": "    default_runner = [handler_ptr](Executor::Args::Closure c) {",
          "new_line_content": "    default_runner = [](const Executor::Args::Closure& c) { c(); };",
          "content_same": false
        },
        {
          "line": 632,
          "old_api": null,
          "new_api": "std::move(c)",
          "old_text": null,
          "new_text": "std::move(c)",
          "old_line_content": "  } else {",
          "new_line_content": "      handler_ptr->ScheduleInterOpClosure(std::move(c));",
          "content_same": false
        },
        {
          "line": 636,
          "old_api": null,
          "new_api": "std::move(c)",
          "old_text": null,
          "new_text": "std::move(c)",
          "old_line_content": "  }",
          "new_line_content": "      pool->Schedule(std::move(c));",
          "content_same": false
        },
        {
          "line": 649,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "executors_and_keys->items.size()",
          "old_line_content": "  Executor::Args args;",
          "new_line_content": "      executors_and_keys->items.size() == 1 && call_timeout == 0;",
          "content_same": false
        },
        {
          "line": 655,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "run_state.collective_executor->get()",
          "old_line_content": "  args.session_state = &session_state_;",
          "new_line_content": "      (run_state.collective_executor ? run_state.collective_executor->get()",
          "content_same": false
        },
        {
          "line": 667,
          "old_api": null,
          "new_api": "trace_level",
          "old_text": null,
          "new_text": "run_options.trace_level()",
          "old_line_content": "  bool update_cost_model = false;",
          "new_line_content": "  const bool do_trace = (run_options.trace_level() > RunOptions::NO_TRACE);",
          "content_same": false
        },
        {
          "line": 674,
          "old_api": null,
          "new_api": "graph_options",
          "old_text": null,
          "new_text": "options_.config.graph_options().build_cost_model_after()",
          "old_line_content": "    if (measure_step_count >= 0) {",
          "new_line_content": "        options_.config.graph_options().build_cost_model_after();",
          "content_same": false
        },
        {
          "line": 684,
          "old_api": null,
          "new_api": "mutable_step_stats",
          "old_text": null,
          "new_text": "run_metadata->mutable_step_stats()",
          "old_line_content": "  }",
          "new_line_content": "        new StepStatsCollector(run_metadata->mutable_step_stats()));",
          "content_same": false
        },
        {
          "line": 685,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "run_state.collector.get()",
          "old_line_content": "",
          "new_line_content": "    args.stats_collector = run_state.collector.get();",
          "content_same": false
        },
        {
          "line": 689,
          "old_api": null,
          "new_api": "trace_level",
          "old_text": null,
          "new_text": "run_options.trace_level()",
          "old_line_content": "  }",
          "new_line_content": "  if (run_options.trace_level() >= RunOptions::HARDWARE_TRACE) {",
          "content_same": false
        },
        {
          "line": 690,
          "old_api": null,
          "new_api": "DeviceProfilerSession::Create()",
          "old_text": null,
          "new_text": "DeviceProfilerSession::Create()",
          "old_line_content": "",
          "new_line_content": "    device_profiler_session = DeviceProfilerSession::Create();",
          "content_same": false
        },
        {
          "line": 696,
          "old_api": null,
          "new_api": "IsCancelled",
          "old_text": null,
          "new_text": "step_cancellation_manager.IsCancelled()",
          "old_line_content": "  }",
          "new_line_content": "  if (step_cancellation_manager.IsCancelled()) {",
          "content_same": false
        },
        {
          "line": 697,
          "old_api": null,
          "new_api": "errors::Cancelled(\"Run call was cancelled\")",
          "old_text": null,
          "new_text": "errors::Cancelled(\"Run call was cancelled\")",
          "old_line_content": "  args.cancellation_manager = &step_cancellation_manager;",
          "new_line_content": "    return errors::Cancelled(\"Run call was cancelled\");",
          "content_same": false
        },
        {
          "line": 711,
          "old_api": null,
          "new_api": "tensorflow_device_thread_pool",
          "old_text": null,
          "new_text": "item.device->tensorflow_device_thread_pool()",
          "old_line_content": "        // specific thread pool(s).",
          "new_line_content": "            item.device->tensorflow_device_thread_pool();",
          "content_same": false
        },
        {
          "line": 718,
          "old_api": null,
          "new_api": "std::move(c)",
          "old_text": null,
          "new_text": "std::move(c)",
          "old_line_content": "        }",
          "new_line_content": "            device_thread_pool->Schedule(std::move(c));",
          "content_same": false
        },
        {
          "line": 723,
          "old_api": null,
          "new_api": "AsIntraThreadPoolInterface",
          "old_text": null,
          "new_text": "handler->AsIntraThreadPoolInterface()",
          "old_line_content": "      };",
          "new_line_content": "              handler->AsIntraThreadPoolInterface();",
          "content_same": false
        },
        {
          "line": 728,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "device_mgr_.get()",
          "old_line_content": "",
          "new_line_content": "    PrivateIntraProcessRendezvous rendezvous(device_mgr_.get());",
          "content_same": false
        },
        {
          "line": 732,
          "old_api": null,
          "new_api": "set_threadpool_args_for_item",
          "old_text": null,
          "new_text": "set_threadpool_args_for_item(item, &args)",
          "old_line_content": "  } else {",
          "new_line_content": "    set_threadpool_args_for_item(item, &args);",
          "content_same": false
        },
        {
          "line": 733,
          "old_api": null,
          "new_api": "Run",
          "old_text": null,
          "new_text": "item.executor->Run(args)",
          "old_line_content": "    core::RefCountPtr<RefCountedIntraProcessRendezvous> rendezvous(",
          "new_line_content": "    run_status = item.executor->Run(args);",
          "content_same": false
        },
        {
          "line": 736,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "device_mgr_.get()",
          "old_line_content": "",
          "new_line_content": "        new RefCountedIntraProcessRendezvous(device_mgr_.get()));",
          "content_same": false
        },
        {
          "line": 737,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "rendezvous.get()",
          "old_line_content": "    // `barrier` will delete itself after the final executor finishes.",
          "new_line_content": "    args.rendezvous = rendezvous.get();",
          "content_same": false
        },
        {
          "line": 742,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "rendezvous.get()",
          "old_line_content": "                              {",
          "new_line_content": "        new ExecutorBarrier(num_executors, rendezvous.get(),",
          "content_same": false
        },
        {
          "line": 748,
          "old_api": null,
          "new_api": "Notify",
          "old_text": null,
          "new_text": "executors_done.Notify()",
          "old_line_content": "",
          "new_line_content": "                              executors_done.Notify();",
          "content_same": false
        },
        {
          "line": 752,
          "old_api": null,
          "new_api": "set_threadpool_args_for_item",
          "old_text": null,
          "new_text": "set_threadpool_args_for_item(item, &args)",
          "old_line_content": "    }",
          "new_line_content": "      set_threadpool_args_for_item(item, &args);",
          "content_same": false
        },
        {
          "line": 753,
          "old_api": null,
          "new_api": "Get",
          "old_text": null,
          "new_text": "barrier->Get()",
          "old_line_content": "",
          "new_line_content": "      item.executor->RunAsync(args, barrier->Get());",
          "content_same": false
        },
        {
          "line": 756,
          "old_api": null,
          "new_api": "WaitForNotification",
          "old_text": null,
          "new_text": "WaitForNotification(&executors_done, &run_state, &step_cancellation_manager,\n                        call_timeout)",
          "old_line_content": "    {",
          "new_line_content": "    WaitForNotification(&executors_done, &run_state, &step_cancellation_manager,",
          "content_same": false
        },
        {
          "line": 764,
          "old_api": null,
          "new_api": "IsCancelled",
          "old_text": null,
          "new_text": "step_cancellation_manager.IsCancelled()",
          "old_line_content": "  }",
          "new_line_content": "  if (step_cancellation_manager.IsCancelled()) {",
          "content_same": false
        },
        {
          "line": 765,
          "old_api": null,
          "new_api": "errors::Cancelled(\"Run call was cancelled\")",
          "old_text": null,
          "new_text": "errors::Cancelled(\"Run call was cancelled\")",
          "old_line_content": "",
          "new_line_content": "    run_status.Update(errors::Cancelled(\"Run call was cancelled\"));",
          "content_same": false
        },
        {
          "line": 769,
          "old_api": null,
          "new_api": "CollectData",
          "old_text": null,
          "new_text": "device_profiler_session->CollectData(\n        run_metadata->mutable_step_stats())",
          "old_line_content": "  }",
          "new_line_content": "    TF_RETURN_IF_ERROR(device_profiler_session->CollectData(",
          "content_same": false
        },
        {
          "line": 770,
          "old_api": null,
          "new_api": "mutable_step_stats",
          "old_text": null,
          "new_text": "run_metadata->mutable_step_stats()",
          "old_line_content": "",
          "new_line_content": "        run_metadata->mutable_step_stats()));",
          "content_same": false
        },
        {
          "line": 773,
          "old_api": null,
          "new_api": "TF_RETURN_IF_ERROR",
          "old_text": null,
          "new_text": "TF_RETURN_IF_ERROR(run_status)",
          "old_line_content": "  // Save the output tensors of this run we choose to keep.",
          "new_line_content": "  TF_RETURN_IF_ERROR(run_status);",
          "content_same": false
        },
        {
          "line": 778,
          "old_api": null,
          "new_api": "fetch",
          "old_text": null,
          "new_text": "executors_and_keys->callable_options.fetch().begin()",
          "old_line_content": "        &session_state_));",
          "new_line_content": "        {executors_and_keys->callable_options.fetch().begin(),",
          "content_same": false
        },
        {
          "line": 779,
          "old_api": null,
          "new_api": "fetch",
          "old_text": null,
          "new_text": "executors_and_keys->callable_options.fetch().end()",
          "old_line_content": "  }",
          "new_line_content": "         executors_and_keys->callable_options.fetch().end()},",
          "content_same": false
        },
        {
          "line": 784,
          "old_api": null,
          "new_api": "Finalize",
          "old_text": null,
          "new_text": "run_state.collector->Finalize()",
          "old_line_content": "",
          "new_line_content": "    run_state.collector->Finalize();",
          "content_same": false
        },
        {
          "line": 793,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "partition.graph.get()",
          "old_line_content": "      device_to_graph[device] = graph;",
          "new_line_content": "      const Graph* graph = partition.graph.get();",
          "content_same": false
        },
        {
          "line": 794,
          "old_api": null,
          "new_api": "device",
          "old_text": null,
          "new_text": "partition.flib->device()->name()",
          "old_line_content": "    }",
          "new_line_content": "      const string& device = partition.flib->device()->name();",
          "content_same": false
        },
        {
          "line": 799,
          "old_api": null,
          "new_api": "BuildCostModel",
          "old_text": null,
          "new_text": "run_state.collector->BuildCostModel(&cost_model_manager_, device_to_graph)",
          "old_line_content": "    // annotate stats onto cost graph.",
          "new_line_content": "    run_state.collector->BuildCostModel(&cost_model_manager_, device_to_graph);",
          "content_same": false
        },
        {
          "line": 804,
          "old_api": null,
          "new_api": "AddToCostGraphDef",
          "old_text": null,
          "new_text": "TF_RETURN_IF_ERROR(\n          cost_model_manager_.AddToCostGraphDef(item.graph.get(), cost_graph))",
          "old_line_content": "    }",
          "new_line_content": "      TF_RETURN_IF_ERROR(",
          "content_same": false
        },
        {
          "line": 805,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "item.graph.get()",
          "old_line_content": "  }",
          "new_line_content": "          cost_model_manager_.AddToCostGraphDef(item.graph.get(), cost_graph));",
          "content_same": false
        },
        {
          "line": 811,
          "old_api": null,
          "new_api": "experimental",
          "old_text": null,
          "new_text": "options_.config.experimental().disable_output_partition_graphs()",
          "old_line_content": "          \"RunOptions.output_partition_graphs() is not supported when \"",
          "new_line_content": "    if (options_.config.experimental().disable_output_partition_graphs()) {",
          "content_same": false
        },
        {
          "line": 812,
          "old_api": null,
          "new_api": "output_partition_graphs",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\n          \"RunOptions.output_partition_graphs() is not supported when \"\n          \"disable_output_partition_graphs is true.\")",
          "old_line_content": "          \"disable_output_partition_graphs is true.\");",
          "new_line_content": "      return errors::InvalidArgument(",
          "content_same": false
        },
        {
          "line": 817,
          "old_api": null,
          "new_api": "mutable_partition_graphs",
          "old_text": null,
          "new_text": "run_metadata->mutable_partition_graphs()",
          "old_line_content": "           executors_and_keys->items) {",
          "new_line_content": "          run_metadata->mutable_partition_graphs();",
          "content_same": false
        },
        {
          "line": 820,
          "old_api": null,
          "new_api": "Add",
          "old_text": null,
          "new_text": "partition_graph_defs->Add()",
          "old_line_content": "      }",
          "new_line_content": "        GraphDef* partition_graph_def = partition_graph_defs->Add();",
          "content_same": false
        },
        {
          "line": 821,
          "old_api": null,
          "new_api": "ToGraphDef",
          "old_text": null,
          "new_text": "exec_and_lib.graph->ToGraphDef(partition_graph_def)",
          "old_line_content": "    }",
          "new_line_content": "        exec_and_lib.graph->ToGraphDef(partition_graph_def);",
          "content_same": false
        },
        {
          "line": 827,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 836,
          "old_api": null,
          "new_api": "Run",
          "old_text": null,
          "new_text": "Run(run_options, inputs, output_names, target_nodes, outputs,\n             run_metadata, thread::ThreadPoolOptions())",
          "old_line_content": "}",
          "new_line_content": "  return Run(run_options, inputs, output_names, target_nodes, outputs,",
          "content_same": false
        },
        {
          "line": 837,
          "old_api": null,
          "new_api": "thread::ThreadPoolOptions()",
          "old_text": null,
          "new_text": "thread::ThreadPoolOptions()",
          "old_line_content": "",
          "new_line_content": "             run_metadata, thread::ThreadPoolOptions());",
          "content_same": false
        },
        {
          "line": 848,
          "old_api": null,
          "new_api": "CheckGraphCreated",
          "old_text": null,
          "new_text": "CheckGraphCreated(\"Run()\")",
          "old_line_content": "",
          "new_line_content": "  TF_RETURN_IF_ERROR(CheckGraphCreated(\"Run()\"));",
          "content_same": false
        },
        {
          "line": 849,
          "old_api": null,
          "new_api": "GetCell",
          "old_text": null,
          "new_text": "direct_session_runs->GetCell()->IncrementBy(1)",
          "old_line_content": "  // Extract the inputs names for this run of the session.",
          "new_line_content": "  direct_session_runs->GetCell()->IncrementBy(1);",
          "content_same": false
        },
        {
          "line": 853,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "inputs.size()",
          "old_line_content": "  for (const auto& it : inputs) {",
          "new_line_content": "  input_tensor_names.reserve(inputs.size());",
          "content_same": false
        },
        {
          "line": 856,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "input_tensor_names.push_back(it.first)",
          "old_line_content": "  }",
          "new_line_content": "    input_tensor_names.push_back(it.first);",
          "content_same": false
        },
        {
          "line": 859,
          "old_api": null,
          "new_api": "metrics::RecordGraphInputTensors(input_size)",
          "old_text": null,
          "new_text": "metrics::RecordGraphInputTensors(input_size)",
          "old_line_content": "  // Check if we already have an executor for these arguments.",
          "new_line_content": "  metrics::RecordGraphInputTensors(input_size);",
          "content_same": false
        },
        {
          "line": 867,
          "old_api": null,
          "new_api": "GetOrCreateExecutors",
          "old_text": null,
          "new_text": "GetOrCreateExecutors(input_tensor_names, output_names,\n                                          target_nodes, &executors_and_keys,\n                                          &run_state_args)",
          "old_line_content": "                                          &run_state_args));",
          "new_line_content": "  TF_RETURN_IF_ERROR(GetOrCreateExecutors(input_tensor_names, output_names,",
          "content_same": false
        },
        {
          "line": 883,
          "old_api": null,
          "new_api": "TF_RETURN_IF_ERROR",
          "old_text": null,
          "new_text": "TF_RETURN_IF_ERROR(\n          ResourceHandleToInputTensor(it.second, &tensor_from_handle))",
          "old_line_content": "      feed_args[executors_and_keys->input_name_to_index[it.first]] =",
          "new_line_content": "      TF_RETURN_IF_ERROR(",
          "content_same": false
        },
        {
          "line": 884,
          "old_api": null,
          "new_api": "ResourceHandleToInputTensor",
          "old_text": null,
          "new_text": "ResourceHandleToInputTensor(it.second, &tensor_from_handle)",
          "old_line_content": "          tensor_from_handle;",
          "new_line_content": "          ResourceHandleToInputTensor(it.second, &tensor_from_handle));",
          "content_same": false
        },
        {
          "line": 893,
          "old_api": null,
          "new_api": "error_message",
          "old_text": null,
          "new_text": "s.error_message()",
          "old_line_content": "    return s;",
          "new_line_content": "    return errors::InvalidArgument(s.error_message());",
          "content_same": false
        },
        {
          "line": 894,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "s.ok()",
          "old_line_content": "  }",
          "new_line_content": "  } else if (!s.ok()) {",
          "content_same": false
        },
        {
          "line": 900,
          "old_api": null,
          "new_api": "LogMemory::IsEnabled()",
          "old_text": null,
          "new_text": "LogMemory::IsEnabled()",
          "old_line_content": "  }",
          "new_line_content": "  if (LogMemory::IsEnabled()) {",
          "content_same": false
        },
        {
          "line": 901,
          "old_api": null,
          "new_api": "LogMemory::RecordStep(step_id, run_state_args.handle)",
          "old_text": null,
          "new_text": "LogMemory::RecordStep(step_id, run_state_args.handle)",
          "old_line_content": "",
          "new_line_content": "    LogMemory::RecordStep(step_id, run_state_args.handle);",
          "content_same": false
        },
        {
          "line": 904,
          "old_api": null,
          "new_api": "RunInternal",
          "old_text": null,
          "new_text": "RunInternal(step_id, run_options, &call_frame,\n                                 executors_and_keys, run_metadata,\n                                 threadpool_options)",
          "old_line_content": "                                 threadpool_options));",
          "new_line_content": "  TF_RETURN_IF_ERROR(RunInternal(step_id, run_options, &call_frame,",
          "content_same": false
        },
        {
          "line": 914,
          "old_api": null,
          "new_api": "error_message",
          "old_text": null,
          "new_text": "s.error_message()",
          "old_line_content": "      return s;",
          "new_line_content": "      return errors::InvalidArgument(s.error_message());",
          "content_same": false
        },
        {
          "line": 915,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "s.ok()",
          "old_line_content": "    }",
          "new_line_content": "    } else if (!s.ok()) {",
          "content_same": false
        },
        {
          "line": 919,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "executors_and_keys->output_name_to_index.size()",
          "old_line_content": "    // output_names[i] == output_names[j].",
          "new_line_content": "        output_names.size() == executors_and_keys->output_name_to_index.size();",
          "content_same": false
        },
        {
          "line": 927,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "output_names.end()",
          "old_line_content": "      }",
          "new_line_content": "            std::find(output_names.begin(), output_names.end(), name) -",
          "content_same": false
        },
        {
          "line": 928,
          "old_api": null,
          "new_api": "begin",
          "old_text": null,
          "new_text": "output_names.begin()",
          "old_line_content": "    }",
          "new_line_content": "            output_names.begin());",
          "content_same": false
        },
        {
          "line": 933,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "sorted_outputs.size()",
          "old_line_content": "      const string& output_name = output_names[i];",
          "new_line_content": "    outputs->reserve(sorted_outputs.size());",
          "content_same": false
        },
        {
          "line": 937,
          "old_api": null,
          "new_api": "emplace_back",
          "old_text": null,
          "new_text": "outputs->emplace_back(\n            std::move(sorted_outputs[executors_and_keys\n                                         ->output_name_to_index[output_name]]))",
          "old_line_content": "                                         ->output_name_to_index[output_name]]));",
          "new_line_content": "        outputs->emplace_back(",
          "content_same": false
        },
        {
          "line": 938,
          "old_api": null,
          "new_api": "std::move(sorted_outputs[executors_and_keys\n                                         ->output_name_to_index[output_name]])",
          "old_text": null,
          "new_text": "std::move(sorted_outputs[executors_and_keys\n                                         ->output_name_to_index[output_name]])",
          "old_line_content": "      } else {",
          "new_line_content": "            std::move(sorted_outputs[executors_and_keys",
          "content_same": false
        },
        {
          "line": 945,
          "old_api": null,
          "new_api": "metrics::RecordGraphOutputTensors(output_size)",
          "old_text": null,
          "new_text": "metrics::RecordGraphOutputTensors(output_size)",
          "old_line_content": "",
          "new_line_content": "    metrics::RecordGraphOutputTensors(output_size);",
          "content_same": false
        },
        {
          "line": 948,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 955,
          "old_api": null,
          "new_api": "CheckNotClosed",
          "old_text": null,
          "new_text": "CheckNotClosed()",
          "old_line_content": "",
          "new_line_content": "  TF_RETURN_IF_ERROR(CheckNotClosed());",
          "content_same": false
        },
        {
          "line": 956,
          "old_api": null,
          "new_api": "CheckGraphCreated",
          "old_text": null,
          "new_text": "CheckGraphCreated(\"PRunSetup()\")",
          "old_line_content": "  // RunOptions is not available in PRunSetup, so use thread pool 0.",
          "new_line_content": "  TF_RETURN_IF_ERROR(CheckGraphCreated(\"PRunSetup()\"));",
          "content_same": false
        },
        {
          "line": 967,
          "old_api": null,
          "new_api": "GetOrCreateExecutors",
          "old_text": null,
          "new_text": "GetOrCreateExecutors(input_names, output_names,\n                                          target_nodes, &executors_and_keys,\n                                          &run_state_args)",
          "old_line_content": "                                          &run_state_args));",
          "new_line_content": "  TF_RETURN_IF_ERROR(GetOrCreateExecutors(input_names, output_names,",
          "content_same": false
        },
        {
          "line": 973,
          "old_api": null,
          "new_api": "fetch_add",
          "old_text": null,
          "new_text": "step_id_counter_.fetch_add(1)",
          "old_line_content": "      new PartialRunState(input_names, output_names, args.step_id, &devices_);",
          "new_line_content": "  args.step_id = step_id_counter_.fetch_add(1);",
          "content_same": false
        },
        {
          "line": 976,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "device_mgr_.get()",
          "old_line_content": "    mutex_lock l(executor_lock_);",
          "new_line_content": "  run_state->rendez.reset(new IntraProcessRendezvous(device_mgr_.get()));",
          "content_same": false
        },
        {
          "line": 983,
          "old_api": null,
          "new_api": "errors::Internal(\"The handle '\", run_state_args.handle,\n                              \"' created for this partial run is not unique.\")",
          "old_text": null,
          "new_text": "errors::Internal(\"The handle '\", run_state_args.handle,\n                              \"' created for this partial run is not unique.\")",
          "old_line_content": "    }",
          "new_line_content": "      return errors::Internal(\"The handle '\", run_state_args.handle,",
          "content_same": false
        },
        {
          "line": 991,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "run_state->rendez.get()",
          "old_line_content": "          mutex_lock l(run_state->mu);",
          "new_line_content": "      num_executors, run_state->rendez.get(), [run_state](const Status& ret) {",
          "content_same": false
        },
        {
          "line": 996,
          "old_api": null,
          "new_api": "Notify",
          "old_text": null,
          "new_text": "run_state->executors_done.Notify()",
          "old_line_content": "",
          "new_line_content": "        run_state->executors_done.Notify();",
          "content_same": false
        },
        {
          "line": 999,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "run_state->rendez.get()",
          "old_line_content": "  // Note that Collectives are not supported in partial runs",
          "new_line_content": "  args.rendezvous = run_state->rendez.get();",
          "content_same": false
        },
        {
          "line": 1006,
          "old_api": null,
          "new_api": "std::move(c)",
          "old_text": null,
          "new_text": "std::move(c)",
          "old_line_content": "  args.session_state = &session_state_;",
          "new_line_content": "    pool->Schedule(std::move(c));",
          "content_same": false
        },
        {
          "line": 1012,
          "old_api": null,
          "new_api": "LogMemory::IsEnabled()",
          "old_text": null,
          "new_text": "LogMemory::IsEnabled()",
          "old_line_content": "  }",
          "new_line_content": "  if (LogMemory::IsEnabled()) {",
          "content_same": false
        },
        {
          "line": 1013,
          "old_api": null,
          "new_api": "LogMemory::RecordStep(args.step_id, run_state_args.handle)",
          "old_text": null,
          "new_text": "LogMemory::RecordStep(args.step_id, run_state_args.handle)",
          "old_line_content": "  args.sync_on_finish = sync_on_finish_;",
          "new_line_content": "    LogMemory::RecordStep(args.step_id, run_state_args.handle);",
          "content_same": false
        },
        {
          "line": 1018,
          "old_api": null,
          "new_api": "reset",
          "old_text": null,
          "new_text": "run_state->collector.reset(new StepStatsCollector(nullptr))",
          "old_line_content": "  }",
          "new_line_content": "    run_state->collector.reset(new StepStatsCollector(nullptr));",
          "content_same": false
        },
        {
          "line": 1019,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "run_state->collector.get()",
          "old_line_content": "",
          "new_line_content": "    args.stats_collector = run_state->collector.get();",
          "content_same": false
        },
        {
          "line": 1023,
          "old_api": null,
          "new_api": "Get",
          "old_text": null,
          "new_text": "barrier->Get()",
          "old_line_content": "",
          "new_line_content": "    item.executor->RunAsync(args, barrier->Get());",
          "content_same": false
        },
        {
          "line": 1027,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 1033,
          "old_api": null,
          "new_api": "CheckNotClosed",
          "old_text": null,
          "new_text": "CheckNotClosed()",
          "old_line_content": "  const string& key = parts[0];",
          "new_line_content": "  TF_RETURN_IF_ERROR(CheckNotClosed());",
          "content_same": false
        },
        {
          "line": 1034,
          "old_api": null,
          "new_api": "str_util::Split(handle, ';')",
          "old_text": null,
          "new_text": "str_util::Split(handle, ';')",
          "old_line_content": "  // Get the executors for this partial run.",
          "new_line_content": "  std::vector<string> parts = str_util::Split(handle, ';');",
          "content_same": false
        },
        {
          "line": 1042,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "executors_.end()",
          "old_line_content": "          \"Must run 'setup' before performing partial runs!\");",
          "new_line_content": "    if (exc_it == executors_.end()) {",
          "content_same": false
        },
        {
          "line": 1043,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\n          \"Must run 'setup' before performing partial runs!\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\n          \"Must run 'setup' before performing partial runs!\")",
          "old_line_content": "    }",
          "new_line_content": "      return errors::InvalidArgument(",
          "content_same": false
        },
        {
          "line": 1049,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "partial_runs_.end()",
          "old_line_content": "          \"Must run 'setup' before performing partial runs!\");",
          "new_line_content": "    if (prun_it == partial_runs_.end()) {",
          "content_same": false
        },
        {
          "line": 1050,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\n          \"Must run 'setup' before performing partial runs!\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\n          \"Must run 'setup' before performing partial runs!\")",
          "old_line_content": "    }",
          "new_line_content": "      return errors::InvalidArgument(",
          "content_same": false
        },
        {
          "line": 1053,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "prun_it->second.get()",
          "old_line_content": "    // Make sure that this is a new set of feeds that are still pending.",
          "new_line_content": "    run_state = prun_it->second.get();",
          "content_same": false
        },
        {
          "line": 1058,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "run_state->pending_inputs.end()",
          "old_line_content": "            \"The feed \", input.first,",
          "new_line_content": "      if (it == run_state->pending_inputs.end()) {",
          "content_same": false
        },
        {
          "line": 1059,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\n            \"The feed \", input.first,\n            \" was not specified in partial_run_setup.\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\n            \"The feed \", input.first,\n            \" was not specified in partial_run_setup.\")",
          "old_line_content": "            \" was not specified in partial_run_setup.\");",
          "new_line_content": "        return errors::InvalidArgument(",
          "content_same": false
        },
        {
          "line": 1063,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\"The feed \", input.first,\n                                       \" has already been fed.\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\"The feed \", input.first,\n                                       \" has already been fed.\")",
          "old_line_content": "      }",
          "new_line_content": "        return errors::InvalidArgument(\"The feed \", input.first,",
          "content_same": false
        },
        {
          "line": 1070,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "run_state->pending_outputs.end()",
          "old_line_content": "            \"The fetch \", output, \" was not specified in partial_run_setup.\");",
          "new_line_content": "      if (it == run_state->pending_outputs.end()) {",
          "content_same": false
        },
        {
          "line": 1071,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\n            \"The fetch \", output, \" was not specified in partial_run_setup.\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\n            \"The fetch \", output, \" was not specified in partial_run_setup.\")",
          "old_line_content": "      } else if (it->second) {",
          "new_line_content": "        return errors::InvalidArgument(",
          "content_same": false
        },
        {
          "line": 1074,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\"The fetch \", output,\n                                       \" has already been fetched.\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\"The fetch \", output,\n                                       \" has already been fetched.\")",
          "old_line_content": "      }",
          "new_line_content": "        return errors::InvalidArgument(\"The fetch \", output,",
          "content_same": false
        },
        {
          "line": 1082,
          "old_api": null,
          "new_api": "TF_RETURN_IF_ERROR",
          "old_text": null,
          "new_text": "TF_RETURN_IF_ERROR(\n      CheckFetch(inputs, output_names, executors_and_keys, run_state))",
          "old_line_content": "",
          "new_line_content": "  TF_RETURN_IF_ERROR(",
          "content_same": false
        },
        {
          "line": 1083,
          "old_api": null,
          "new_api": "CheckFetch",
          "old_text": null,
          "new_text": "CheckFetch(inputs, output_names, executors_and_keys, run_state)",
          "old_line_content": "  // Send inputs.",
          "new_line_content": "      CheckFetch(inputs, output_names, executors_and_keys, run_state));",
          "content_same": false
        },
        {
          "line": 1087,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "run_state->rendez.get()",
          "old_line_content": "  // Receive outputs.",
          "new_line_content": "      SendPRunInputs(inputs, executors_and_keys, run_state->rendez.get());",
          "content_same": false
        },
        {
          "line": 1090,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "s.ok()",
          "old_line_content": "  }",
          "new_line_content": "  if (s.ok()) {",
          "content_same": false
        },
        {
          "line": 1091,
          "old_api": null,
          "new_api": "RecvPRunOutputs",
          "old_text": null,
          "new_text": "RecvPRunOutputs(output_names, executors_and_keys, run_state, outputs)",
          "old_line_content": "",
          "new_line_content": "    s = RecvPRunOutputs(output_names, executors_and_keys, run_state, outputs);",
          "content_same": false
        },
        {
          "line": 1095,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "s.ok()",
          "old_line_content": "  }",
          "new_line_content": "  if (s.ok()) {",
          "content_same": false
        },
        {
          "line": 1096,
          "old_api": null,
          "new_api": "SaveTensors",
          "old_text": null,
          "new_text": "run_state->tensor_store.SaveTensors(output_names, &session_state_)",
          "old_line_content": "",
          "new_line_content": "    s = run_state->tensor_store.SaveTensors(output_names, &session_state_);",
          "content_same": false
        },
        {
          "line": 1103,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "s.ok()",
          "old_line_content": "        mutex_lock l(run_state->mu);",
          "new_line_content": "    if (s.ok()) {",
          "content_same": false
        },
        {
          "line": 1106,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "run_state->status.ok()",
          "old_line_content": "                       << run_state->status;",
          "new_line_content": "        if (!run_state->status.ok()) {",
          "content_same": false
        },
        {
          "line": 1107,
          "old_api": null,
          "new_api": "LOG",
          "old_text": null,
          "new_text": "LOG(WARNING)",
          "old_line_content": "        }",
          "new_line_content": "          LOG(WARNING) << \"An error unrelated to this prun has been detected. \"",
          "content_same": false
        },
        {
          "line": 1112,
          "old_api": null,
          "new_api": "find",
          "old_text": null,
          "new_text": "run_state->pending_inputs.find(input.first)",
          "old_line_content": "      }",
          "new_line_content": "        auto it = run_state->pending_inputs.find(input.first);",
          "content_same": false
        },
        {
          "line": 1116,
          "old_api": null,
          "new_api": "find",
          "old_text": null,
          "new_text": "run_state->pending_outputs.find(name)",
          "old_line_content": "      }",
          "new_line_content": "        auto it = run_state->pending_outputs.find(name);",
          "content_same": false
        },
        {
          "line": 1119,
          "old_api": null,
          "new_api": "PendingDone",
          "old_text": null,
          "new_text": "run_state->PendingDone()",
          "old_line_content": "    if (done) {",
          "new_line_content": "      done = run_state->PendingDone();",
          "content_same": false
        },
        {
          "line": 1124,
          "old_api": null,
          "new_api": "erase",
          "old_text": null,
          "new_text": "partial_runs_.erase(handle)",
          "old_line_content": "  }",
          "new_line_content": "      partial_runs_.erase(handle);",
          "content_same": false
        },
        {
          "line": 1133,
          "old_api": null,
          "new_api": "dtype",
          "old_text": null,
          "new_text": "resource_tensor.dtype()",
          "old_line_content": "        \"ResourceHandleToInputTensor() received non-DT_RESOURCE Tensor: \",",
          "new_line_content": "  if (resource_tensor.dtype() != DT_RESOURCE) {",
          "content_same": false
        },
        {
          "line": 1136,
          "old_api": null,
          "new_api": "dtype",
          "old_text": null,
          "new_text": "resource_tensor.dtype()",
          "old_line_content": "",
          "new_line_content": "        resource_tensor.dtype()));",
          "content_same": false
        },
        {
          "line": 1148,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "resource_handle.name()",
          "old_line_content": "        \"). Perhaps a resource tensor was being provided as a feed? That is \"",
          "new_line_content": "        \"(name: \", resource_handle.name(),",
          "content_same": false
        },
        {
          "line": 1149,
          "old_api": null,
          "new_api": "maybe_type_name",
          "old_text": null,
          "new_text": "resource_handle.maybe_type_name()",
          "old_line_content": "        \"not currently allowed. Please file an issue at \"",
          "new_line_content": "        \" type: \", resource_handle.maybe_type_name(),",
          "content_same": false
        },
        {
          "line": 1167,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "executors_and_keys->input_name_to_rendezvous_key.end()",
          "old_line_content": "    }",
          "new_line_content": "    if (it == executors_and_keys->input_name_to_rendezvous_key.end()) {",
          "content_same": false
        },
        {
          "line": 1168,
          "old_api": null,
          "new_api": "errors::Internal(\"'\", input.first, \"' is not a pre-defined feed.\")",
          "old_text": null,
          "new_text": "errors::Internal(\"'\", input.first, \"' is not a pre-defined feed.\")",
          "old_line_content": "    const string& input_key = it->second;",
          "new_line_content": "      return errors::Internal(\"'\", input.first, \"' is not a pre-defined feed.\");",
          "content_same": false
        },
        {
          "line": 1173,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "s.ok()",
          "old_line_content": "      return s;",
          "new_line_content": "    if (!s.ok()) {",
          "content_same": false
        },
        {
          "line": 1174,
          "old_api": null,
          "new_api": "StartAbort",
          "old_text": null,
          "new_text": "rendez->StartAbort(s)",
          "old_line_content": "    }",
          "new_line_content": "      rendez->StartAbort(s);",
          "content_same": false
        },
        {
          "line": 1181,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "s.ok()",
          "old_line_content": "      }",
          "new_line_content": "      if (s.ok()) {",
          "content_same": false
        },
        {
          "line": 1182,
          "old_api": null,
          "new_api": "Rendezvous::Args()",
          "old_text": null,
          "new_text": "Rendezvous::Args()",
          "old_line_content": "    } else {",
          "new_line_content": "        s = rendez->Send(parsed, Rendezvous::Args(), tensor_from_handle, false);",
          "content_same": false
        },
        {
          "line": 1185,
          "old_api": null,
          "new_api": "Rendezvous::Args()",
          "old_text": null,
          "new_text": "Rendezvous::Args()",
          "old_line_content": "",
          "new_line_content": "      s = rendez->Send(parsed, Rendezvous::Args(), input.second, false);",
          "content_same": false
        },
        {
          "line": 1188,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "s.ok()",
          "old_line_content": "      return s;",
          "new_line_content": "    if (!s.ok()) {",
          "content_same": false
        },
        {
          "line": 1189,
          "old_api": null,
          "new_api": "StartAbort",
          "old_text": null,
          "new_text": "rendez->StartAbort(s)",
          "old_line_content": "    }",
          "new_line_content": "      rendez->StartAbort(s);",
          "content_same": false
        },
        {
          "line": 1193,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 1201,
          "old_api": null,
          "new_api": "empty",
          "old_text": null,
          "new_text": "output_names.empty()",
          "old_line_content": "  }",
          "new_line_content": "  if (!output_names.empty()) {",
          "content_same": false
        },
        {
          "line": 1202,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "output_names.size()",
          "old_line_content": "",
          "new_line_content": "    outputs->resize(output_names.size());",
          "content_same": false
        },
        {
          "line": 1207,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "output_names.size()",
          "old_line_content": "    const string& output_name = output_names[output_offset];",
          "new_line_content": "  for (size_t output_offset = 0; output_offset < output_names.size();",
          "content_same": false
        },
        {
          "line": 1212,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "executors_and_keys->output_name_to_rendezvous_key.end()",
          "old_line_content": "                              \"' is not a pre-defined fetch.\");",
          "new_line_content": "    if (it == executors_and_keys->output_name_to_rendezvous_key.end()) {",
          "content_same": false
        },
        {
          "line": 1213,
          "old_api": null,
          "new_api": "errors::Internal(\"'\", output_name,\n                              \"' is not a pre-defined fetch.\")",
          "old_text": null,
          "new_text": "errors::Internal(\"'\", output_name,\n                              \"' is not a pre-defined fetch.\")",
          "old_line_content": "    }",
          "new_line_content": "      return errors::Internal(\"'\", output_name,",
          "content_same": false
        },
        {
          "line": 1220,
          "old_api": null,
          "new_api": "Rendezvous::ParseKey(output_key, &parsed)",
          "old_text": null,
          "new_text": "Rendezvous::ParseKey(output_key, &parsed)",
          "old_line_content": "      // Fetch data from the Rendezvous.",
          "new_line_content": "    s = Rendezvous::ParseKey(output_key, &parsed);",
          "content_same": false
        },
        {
          "line": 1225,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "s.ok()",
          "old_line_content": "                                    \" was not valid.\");",
          "new_line_content": "      if (is_dead && s.ok()) {",
          "content_same": false
        },
        {
          "line": 1226,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\"The tensor returned for \", output_name,\n                                    \" was not valid.\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\"The tensor returned for \", output_name,\n                                    \" was not valid.\")",
          "old_line_content": "      }",
          "new_line_content": "        s = errors::InvalidArgument(\"The tensor returned for \", output_name,",
          "content_same": false
        },
        {
          "line": 1231,
          "old_api": null,
          "new_api": "StartAbort",
          "old_text": null,
          "new_text": "run_state->rendez->StartAbort(s)",
          "old_line_content": "      return s;",
          "new_line_content": "      run_state->rendez->StartAbort(s);",
          "content_same": false
        },
        {
          "line": 1232,
          "old_api": null,
          "new_api": "clear",
          "old_text": null,
          "new_text": "outputs->clear()",
          "old_line_content": "    }",
          "new_line_content": "      outputs->clear();",
          "content_same": false
        },
        {
          "line": 1238,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 1245,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "executors_and_keys->graph.get()",
          "old_line_content": "",
          "new_line_content": "  const Graph* graph = executors_and_keys->graph.get();",
          "content_same": false
        },
        {
          "line": 1257,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "name_to_node->end()",
          "old_line_content": "      }",
          "new_line_content": "      if (it == name_to_node->end()) {",
          "content_same": false
        },
        {
          "line": 1260,
          "old_api": null,
          "new_api": "insert",
          "old_text": null,
          "new_text": "pending_feeds.insert(id)",
          "old_line_content": "  }",
          "new_line_content": "      pending_feeds.insert(id);",
          "content_same": false
        },
        {
          "line": 1264,
          "old_api": null,
          "new_api": "ParseTensorName",
          "old_text": null,
          "new_text": "ParseTensorName(it.first)",
          "old_line_content": "  }",
          "new_line_content": "    TensorId id(ParseTensorName(it.first));",
          "content_same": false
        },
        {
          "line": 1265,
          "old_api": null,
          "new_api": "erase",
          "old_text": null,
          "new_text": "pending_feeds.erase(id)",
          "old_line_content": "",
          "new_line_content": "    pending_feeds.erase(id);",
          "content_same": false
        },
        {
          "line": 1273,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "name_to_node->end()",
          "old_line_content": "    }",
          "new_line_content": "    if (it == name_to_node->end()) {",
          "content_same": false
        },
        {
          "line": 1276,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "stack.push_back(it->second)",
          "old_line_content": "",
          "new_line_content": "    stack.push_back(it->second);",
          "content_same": false
        },
        {
          "line": 1282,
          "old_api": null,
          "new_api": "back",
          "old_text": null,
          "new_text": "stack.back()",
          "old_line_content": "",
          "new_line_content": "    const Node* n = stack.back();",
          "content_same": false
        },
        {
          "line": 1288,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "in_node->name()",
          "old_line_content": "                                       \" can't be computed from the feeds\"",
          "new_line_content": "        return errors::InvalidArgument(\"Fetch \", in_node->name(), \":\",",
          "content_same": false
        },
        {
          "line": 1289,
          "old_api": null,
          "new_api": "src_output",
          "old_text": null,
          "new_text": "in_edge->src_output()",
          "old_line_content": "                                       \" that have been fed so far.\");",
          "new_line_content": "                                       in_edge->src_output(),",
          "content_same": false
        },
        {
          "line": 1294,
          "old_api": null,
          "new_api": "id",
          "old_text": null,
          "new_text": "in_node->id()",
          "old_line_content": "      }",
          "new_line_content": "        visited[in_node->id()] = true;",
          "content_same": false
        },
        {
          "line": 1295,
          "old_api": null,
          "new_api": "push_back",
          "old_text": null,
          "new_text": "stack.push_back(in_node)",
          "old_line_content": "    }",
          "new_line_content": "        stack.push_back(in_node);",
          "content_same": false
        },
        {
          "line": 1299,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 1311,
          "old_api": null,
          "new_api": "run_options",
          "old_text": null,
          "new_text": "callable_options.run_options().experimental().collective_graph_key()",
          "old_line_content": "          .collective_deterministic_sequential_execution()) {",
          "new_line_content": "      callable_options.run_options().experimental().collective_graph_key();",
          "content_same": false
        },
        {
          "line": 1312,
          "old_api": null,
          "new_api": "experimental",
          "old_text": null,
          "new_text": "options_.config.experimental()\n          .collective_deterministic_sequential_execution()",
          "old_line_content": "    options.collective_order = GraphCollectiveOrder::kEdges;",
          "new_line_content": "  if (options_.config.experimental()",
          "content_same": false
        },
        {
          "line": 1315,
          "old_api": null,
          "new_api": "experimental",
          "old_text": null,
          "new_text": "options_.config.experimental().collective_nccl()",
          "old_line_content": "  }",
          "new_line_content": "  } else if (options_.config.experimental().collective_nccl()) {",
          "content_same": false
        },
        {
          "line": 1325,
          "old_api": null,
          "new_api": "CreateGraphs",
          "old_text": null,
          "new_text": "CreateGraphs(\n      options, &graphs, &func_info->flib_def, run_state_args, &ek->input_types,\n      &ek->output_types, &ek->collective_graph_key)",
          "old_line_content": "      &ek->output_types, &ek->collective_graph_key));",
          "new_line_content": "  TF_RETURN_IF_ERROR(CreateGraphs(",
          "content_same": false
        },
        {
          "line": 1341,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "n->name()",
          "old_line_content": "      }",
          "new_line_content": "      if (names.count(n->name()) > 0) {",
          "content_same": false
        },
        {
          "line": 1342,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "n->name()",
          "old_line_content": "    }",
          "new_line_content": "        ek->name_to_node.insert({n->name(), n});",
          "content_same": false
        },
        {
          "line": 1350,
          "old_api": null,
          "new_api": "begin",
          "old_text": null,
          "new_text": "graphs.begin()->second->versions().producer()",
          "old_line_content": "  const auto* session_metadata =",
          "new_line_content": "  int graph_def_version = graphs.begin()->second->versions().producer();",
          "content_same": false
        },
        {
          "line": 1353,
          "old_api": null,
          "new_api": "experimental",
          "old_text": null,
          "new_text": "options_.config.experimental().has_session_metadata()",
          "old_line_content": "          : nullptr;",
          "new_line_content": "      options_.config.experimental().has_session_metadata()",
          "content_same": false
        },
        {
          "line": 1357,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "device_mgr_.get()",
          "old_line_content": "      /*parent=*/nullptr, session_metadata,",
          "new_line_content": "      device_mgr_.get(), options_.env, &options_.config, graph_def_version,",
          "content_same": false
        },
        {
          "line": 1358,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "func_info->flib_def.get()",
          "old_line_content": "      Rendezvous::Factory{",
          "new_line_content": "      func_info->flib_def.get(), optimizer_opts, thread_pools_[0].first,",
          "content_same": false
        },
        {
          "line": 1363,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "            return Status::OK();",
          "content_same": false
        },
        {
          "line": 1367,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "graphs.end()",
          "old_line_content": "    std::unique_ptr<Graph>& partition_graph = iter->second;",
          "new_line_content": "  for (auto iter = graphs.begin(); iter != graphs.end(); ++iter) {",
          "content_same": false
        },
        {
          "line": 1375,
          "old_api": null,
          "new_api": "back",
          "old_text": null,
          "new_text": "ek->items.back()",
          "old_line_content": "    if (lib == nullptr) {",
          "new_line_content": "    auto* item = &(ek->items.back());",
          "content_same": false
        },
        {
          "line": 1378,
          "old_api": null,
          "new_api": "errors::Internal(\"Could not find device: \", partition_name)",
          "old_text": null,
          "new_text": "errors::Internal(\"Could not find device: \", partition_name)",
          "old_line_content": "    item->flib = lib;",
          "new_line_content": "      return errors::Internal(\"Could not find device: \", partition_name);",
          "content_same": false
        },
        {
          "line": 1386,
          "old_api": null,
          "new_api": "op_segment",
          "old_text": null,
          "new_text": "device->op_segment()",
          "old_line_content": "        [this, lib, opseg](const std::shared_ptr<const NodeProperties>& props,",
          "new_line_content": "    auto opseg = device->op_segment();",
          "content_same": false
        },
        {
          "line": 1394,
          "old_api": null,
          "new_api": "op",
          "old_text": null,
          "new_text": "props->node_def.op()",
          "old_line_content": "          }",
          "new_line_content": "          if (!OpSegment::ShouldOwnKernel(lib, props->node_def.op())) {",
          "content_same": false
        },
        {
          "line": 1395,
          "old_api": null,
          "new_api": "CreateKernel",
          "old_text": null,
          "new_text": "lib->CreateKernel(props, kernel)",
          "old_line_content": "          auto create_fn = [lib, &props](OpKernel** kernel) {",
          "new_line_content": "            return lib->CreateKernel(props, kernel);",
          "content_same": false
        },
        {
          "line": 1398,
          "old_api": null,
          "new_api": "CreateKernel",
          "old_text": null,
          "new_text": "lib->CreateKernel(props, kernel)",
          "old_line_content": "          // Kernels created for subgraph nodes need to be cached.  On",
          "new_line_content": "            return lib->CreateKernel(props, kernel);",
          "content_same": false
        },
        {
          "line": 1403,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "props->node_def.name()",
          "old_line_content": "        };",
          "new_line_content": "          return opseg->FindOrCreate(session_handle_, props->node_def.name(),",
          "content_same": false
        },
        {
          "line": 1407,
          "old_api": null,
          "new_api": "type_string",
          "old_text": null,
          "new_text": "kernel->type_string()",
          "old_line_content": "    };",
          "new_line_content": "      if (kernel && !OpSegment::ShouldOwnKernel(lib, kernel->type_string()))",
          "content_same": false
        },
        {
          "line": 1411,
          "old_api": null,
          "new_api": "Optimize",
          "old_text": null,
          "new_text": "optimizer.Optimize(lib, options_.env, device, &partition_graph,\n                       GraphOptimizer::Options())",
          "old_line_content": "",
          "new_line_content": "    optimizer.Optimize(lib, options_.env, device, &partition_graph,",
          "content_same": false
        },
        {
          "line": 1412,
          "old_api": null,
          "new_api": "GraphOptimizer::Options()",
          "old_text": null,
          "new_text": "GraphOptimizer::Options()",
          "old_line_content": "    // TensorFlow Debugger (tfdbg) inserts debug nodes in the graph.",
          "new_line_content": "                       GraphOptimizer::Options());",
          "content_same": false
        },
        {
          "line": 1418,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "DecorateAndPublishGraphForDebug(\n          debug_options, partition_graph.get(), params.device)",
          "old_line_content": "    }",
          "new_line_content": "      TF_RETURN_IF_ERROR(DecorateAndPublishGraphForDebug(",
          "content_same": false
        },
        {
          "line": 1419,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "partition_graph.get()",
          "old_line_content": "",
          "new_line_content": "          debug_options, partition_graph.get(), params.device));",
          "content_same": false
        },
        {
          "line": 1423,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "device->name()",
          "old_line_content": "",
          "new_line_content": "                                         device->name(),",
          "content_same": false
        },
        {
          "line": 1424,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "partition_graph.get()",
          "old_line_content": "    item->executor = nullptr;",
          "new_line_content": "                                         partition_graph.get()));",
          "content_same": false
        },
        {
          "line": 1432,
          "old_api": null,
          "new_api": "graph_options",
          "old_text": null,
          "new_text": "options_.config.graph_options().build_cost_model()",
          "old_line_content": "    }",
          "new_line_content": "        options_.config.graph_options().build_cost_model() > 0) {",
          "content_same": false
        },
        {
          "line": 1433,
          "old_api": null,
          "new_api": "std::move(partition_graph)",
          "old_text": null,
          "new_text": "std::move(partition_graph)",
          "old_line_content": "  }",
          "new_line_content": "      item->graph = std::move(partition_graph);",
          "content_same": false
        },
        {
          "line": 1443,
          "old_api": null,
          "new_api": "feed",
          "old_text": null,
          "new_text": "callable_options.feed().size()",
          "old_line_content": "      ek->input_name_to_index[input] = i;",
          "new_line_content": "    for (int i = 0; i < callable_options.feed().size(); ++i) {",
          "content_same": false
        },
        {
          "line": 1444,
          "old_api": null,
          "new_api": "feed",
          "old_text": null,
          "new_text": "callable_options.feed(i)",
          "old_line_content": "    }",
          "new_line_content": "      const string& input = callable_options.feed(i);",
          "content_same": false
        },
        {
          "line": 1447,
          "old_api": null,
          "new_api": "fetch",
          "old_text": null,
          "new_text": "callable_options.fetch().size()",
          "old_line_content": "      ek->output_name_to_index[output] = i;",
          "new_line_content": "    for (int i = 0; i < callable_options.fetch().size(); ++i) {",
          "content_same": false
        },
        {
          "line": 1448,
          "old_api": null,
          "new_api": "fetch",
          "old_text": null,
          "new_text": "callable_options.fetch(i)",
          "old_line_content": "    }",
          "new_line_content": "      const string& output = callable_options.fetch(i);",
          "content_same": false
        },
        {
          "line": 1459,
          "old_api": null,
          "new_api": "client_device",
          "old_text": null,
          "new_text": "GetRendezvousKey(\n          input, device_set_.client_device()->attributes(), FrameAndIter(0, 0))",
          "old_line_content": "    }",
          "new_line_content": "      ek->input_name_to_rendezvous_key[input] = GetRendezvousKey(",
          "content_same": false
        },
        {
          "line": 1462,
          "old_api": null,
          "new_api": "fetch",
          "old_text": null,
          "new_text": "callable_options.fetch().size()",
          "old_line_content": "      ek->output_name_to_rendezvous_key[output] =",
          "new_line_content": "    for (int i = 0; i < callable_options.fetch().size(); ++i) {",
          "content_same": false
        },
        {
          "line": 1465,
          "old_api": null,
          "new_api": "client_device",
          "old_text": null,
          "new_text": "device_set_.client_device()->attributes()",
          "old_line_content": "    }",
          "new_line_content": "          GetRendezvousKey(output, device_set_.client_device()->attributes(),",
          "content_same": false
        },
        {
          "line": 1466,
          "old_api": null,
          "new_api": "FrameAndIter",
          "old_text": null,
          "new_text": "FrameAndIter(0, 0)",
          "old_line_content": "  }",
          "new_line_content": "                           FrameAndIter(0, 0));",
          "content_same": false
        },
        {
          "line": 1471,
          "old_api": null,
          "new_api": "std::move(func_info)",
          "old_text": null,
          "new_text": "std::move(func_info)",
          "old_line_content": "}",
          "new_line_content": "  *out_func_info = std::move(func_info);",
          "content_same": false
        },
        {
          "line": 1472,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 1480,
          "old_api": null,
          "new_api": "LogMemory::IsEnabled()",
          "old_text": null,
          "new_text": "LogMemory::IsEnabled()",
          "old_line_content": "  }",
          "new_line_content": "  if (LogMemory::IsEnabled() || run_state_args->is_partial_run) {",
          "content_same": false
        },
        {
          "line": 1481,
          "old_api": null,
          "new_api": "fetch_add",
          "old_text": null,
          "new_text": "handle_name_counter_.fetch_add(1)",
          "old_line_content": "",
          "new_line_content": "    handle_name_counter_value = handle_name_counter_.fetch_add(1);",
          "content_same": false
        },
        {
          "line": 1486,
          "old_api": null,
          "new_api": "debug_tensor_watch_opts",
          "old_text": null,
          "new_text": "SummarizeDebugTensorWatches(\n        run_state_args->debug_options.debug_tensor_watch_opts())",
          "old_line_content": "  }",
          "new_line_content": "    debug_tensor_watches_summary = SummarizeDebugTensorWatches(",
          "content_same": false
        },
        {
          "line": 1487,
          "old_api": null,
          "new_api": "debug_tensor_watch_opts",
          "old_text": null,
          "new_text": "run_state_args->debug_options.debug_tensor_watch_opts()",
          "old_line_content": "",
          "new_line_content": "        run_state_args->debug_options.debug_tensor_watch_opts());",
          "content_same": false
        },
        {
          "line": 1492,
          "old_api": null,
          "new_api": "absl::StrJoin(outputs, \",\")",
          "old_text": null,
          "new_text": "absl::StrJoin(outputs, \",\")",
          "old_line_content": "      \"/\", debug_tensor_watches_summary);",
          "new_line_content": "      absl::StrJoin(inputs, \",\"), \"->\", absl::StrJoin(outputs, \",\"), \"/\",",
          "content_same": false
        },
        {
          "line": 1493,
          "old_api": null,
          "new_api": "absl::StrJoin(target_nodes, \",\")",
          "old_text": null,
          "new_text": "absl::StrJoin(target_nodes, \",\")",
          "old_line_content": "  // Set the handle, if it's needed to log memory or for partial run.",
          "new_line_content": "      absl::StrJoin(target_nodes, \",\"), \"/\", run_state_args->is_partial_run,",
          "content_same": false
        },
        {
          "line": 1498,
          "old_api": null,
          "new_api": "strings::StrCat(key, \";\", handle_name_counter_value)",
          "old_text": null,
          "new_text": "strings::StrCat(key, \";\", handle_name_counter_value)",
          "old_line_content": "",
          "new_line_content": "        strings::StrCat(key, \";\", handle_name_counter_value);",
          "content_same": false
        },
        {
          "line": 1506,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "it->second.get()",
          "old_line_content": "    }",
          "new_line_content": "      *executors_and_keys = it->second.get();",
          "content_same": false
        },
        {
          "line": 1507,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "  }",
          "new_line_content": "      return Status::OK();",
          "content_same": false
        },
        {
          "line": 1521,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "target_nodes.end()",
          "old_line_content": "",
          "new_line_content": "  std::vector<string> tn_sorted(target_nodes.begin(), target_nodes.end());",
          "content_same": false
        },
        {
          "line": 1525,
          "old_api": null,
          "new_api": "absl::StrJoin(inputs_sorted, \",\")",
          "old_text": null,
          "new_text": "absl::StrJoin(inputs_sorted, \",\")",
          "old_line_content": "      \"/\", run_state_args->is_partial_run, \"/\", debug_tensor_watches_summary);",
          "new_line_content": "      absl::StrJoin(inputs_sorted, \",\"), \"->\",",
          "content_same": false
        },
        {
          "line": 1526,
          "old_api": null,
          "new_api": "absl::StrJoin(tn_sorted, \",\")",
          "old_text": null,
          "new_text": "absl::StrJoin(tn_sorted, \",\")",
          "old_line_content": "  // Set the handle, if its needed to log memory or for partial run.",
          "new_line_content": "      absl::StrJoin(outputs_sorted, \",\"), \"/\", absl::StrJoin(tn_sorted, \",\"),",
          "content_same": false
        },
        {
          "line": 1531,
          "old_api": null,
          "new_api": "strings::StrCat(sorted_key, \";\", handle_name_counter_value)",
          "old_text": null,
          "new_text": "strings::StrCat(sorted_key, \";\", handle_name_counter_value)",
          "old_line_content": "",
          "new_line_content": "        strings::StrCat(sorted_key, \";\", handle_name_counter_value);",
          "content_same": false
        },
        {
          "line": 1539,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "it->second.get()",
          "old_line_content": "    }",
          "new_line_content": "      *executors_and_keys = it->second.get();",
          "content_same": false
        },
        {
          "line": 1540,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "  }",
          "new_line_content": "      return Status::OK();",
          "content_same": false
        },
        {
          "line": 1562,
          "old_api": null,
          "new_api": "mutable_run_options",
          "old_text": null,
          "new_text": "callable_options.mutable_run_options()\n      ->mutable_experimental()\n      ->set_collective_graph_key(run_state_args->collective_graph_key)",
          "old_line_content": "      ->set_collective_graph_key(run_state_args->collective_graph_key);",
          "new_line_content": "  callable_options.mutable_run_options()",
          "content_same": false
        },
        {
          "line": 1567,
          "old_api": null,
          "new_api": "TF_RETURN_IF_ERROR",
          "old_text": null,
          "new_text": "TF_RETURN_IF_ERROR(\n      CreateExecutors(callable_options, &ek, &func_info, run_state_args))",
          "old_line_content": "",
          "new_line_content": "  TF_RETURN_IF_ERROR(",
          "content_same": false
        },
        {
          "line": 1568,
          "old_api": null,
          "new_api": "CreateExecutors",
          "old_text": null,
          "new_text": "CreateExecutors(callable_options, &ek, &func_info, run_state_args)",
          "old_line_content": "  // Reacquire the lock, try to insert into the map.",
          "new_line_content": "      CreateExecutors(callable_options, &ek, &func_info, run_state_args));",
          "content_same": false
        },
        {
          "line": 1575,
          "old_api": null,
          "new_api": "emplace",
          "old_text": null,
          "new_text": "executors_.emplace(\n      sorted_key, std::shared_ptr<ExecutorsAndKeys>(std::move(ek)))",
          "old_line_content": "  if (insert_result.second) {",
          "new_line_content": "  auto insert_result = executors_.emplace(",
          "content_same": false
        },
        {
          "line": 1578,
          "old_api": null,
          "new_api": "std::move(func_info)",
          "old_text": null,
          "new_text": "std::move(func_info)",
          "old_line_content": "",
          "new_line_content": "    functions_.push_back(std::move(func_info));",
          "content_same": false
        },
        {
          "line": 1583,
          "old_api": null,
          "new_api": "emplace",
          "old_text": null,
          "new_text": "executors_.emplace(key, insert_result.first->second)",
          "old_line_content": "",
          "new_line_content": "  executors_.emplace(key, insert_result.first->second);",
          "content_same": false
        },
        {
          "line": 1586,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 1597,
          "old_api": null,
          "new_api": "errors::FailedPrecondition(\"Session has been finalized.\")",
          "old_text": null,
          "new_text": "errors::FailedPrecondition(\"Session has been finalized.\")",
          "old_line_content": "",
          "new_line_content": "    return errors::FailedPrecondition(\"Session has been finalized.\");",
          "content_same": false
        },
        {
          "line": 1604,
          "old_api": null,
          "new_api": "graph_options",
          "old_text": null,
          "new_text": "options_.config.graph_options().place_pruned_graph()",
          "old_line_content": "    // new GraphExecutionState for every new unseen graph,",
          "new_line_content": "  if (options_.config.graph_options().place_pruned_graph()) {",
          "content_same": false
        },
        {
          "line": 1613,
          "old_api": null,
          "new_api": "GraphExecutionState::MakeForPrunedGraph(\n        *execution_state_, prune_options, subgraph_options,\n        &temp_exec_state_holder, &client_graph)",
          "old_text": null,
          "new_text": "GraphExecutionState::MakeForPrunedGraph(\n        *execution_state_, prune_options, subgraph_options,\n        &temp_exec_state_holder, &client_graph)",
          "old_line_content": "        &temp_exec_state_holder, &client_graph));",
          "new_line_content": "    TF_RETURN_IF_ERROR(GraphExecutionState::MakeForPrunedGraph(",
          "content_same": false
        },
        {
          "line": 1619,
          "old_api": null,
          "new_api": "BuildGraph",
          "old_text": null,
          "new_text": "TF_RETURN_IF_ERROR(\n        execution_state->BuildGraph(subgraph_options, &client_graph))",
          "old_line_content": "  }",
          "new_line_content": "    TF_RETURN_IF_ERROR(",
          "content_same": false
        },
        {
          "line": 1620,
          "old_api": null,
          "new_api": "BuildGraph",
          "old_text": null,
          "new_text": "execution_state->BuildGraph(subgraph_options, &client_graph)",
          "old_line_content": "  *collective_graph_key = client_graph->collective_graph_key;",
          "new_line_content": "        execution_state->BuildGraph(subgraph_options, &client_graph));",
          "content_same": false
        },
        {
          "line": 1625,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "client_graph->feed_types.size()",
          "old_line_content": "        \"Graph pruning failed: requested number of feed endpoints = \",",
          "new_line_content": "      client_graph->feed_types.size()) {",
          "content_same": false
        },
        {
          "line": 1633,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "client_graph->fetch_types.size()",
          "old_line_content": "        \"Graph pruning failed: requested number of fetch endpoints = \",",
          "new_line_content": "      client_graph->fetch_types.size()) {",
          "content_same": false
        },
        {
          "line": 1638,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "client_graph->fetch_types.size()",
          "old_line_content": "",
          "new_line_content": "        client_graph->fetch_types.size());",
          "content_same": false
        },
        {
          "line": 1641,
          "old_api": null,
          "new_api": "GetStatefulPlacements",
          "old_text": null,
          "new_text": "execution_state->GetStatefulPlacements()",
          "old_line_content": "  // placements.  If there are any mismatches for a node,",
          "new_line_content": "  auto current_stateful_placements = execution_state->GetStatefulPlacements();",
          "content_same": false
        },
        {
          "line": 1649,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "stateful_placements_.end()",
          "old_line_content": "    } else if (iter->second != placement) {",
          "new_line_content": "    if (iter == stateful_placements_.end()) {",
          "content_same": false
        },
        {
          "line": 1652,
          "old_api": null,
          "new_api": "errors::Internal(\n          \"Stateful placement mismatch. \"\n          \"Current assignment of \",\n          node_name, \" to \", iter->second, \" does not match \", placement)",
          "old_text": null,
          "new_text": "errors::Internal(\n          \"Stateful placement mismatch. \"\n          \"Current assignment of \",\n          node_name, \" to \", iter->second, \" does not match \", placement)",
          "old_line_content": "          \"Current assignment of \",",
          "new_line_content": "      return errors::Internal(",
          "content_same": false
        },
        {
          "line": 1659,
          "old_api": null,
          "new_api": "GetStatefulPlacements",
          "old_text": null,
          "new_text": "execution_state->GetStatefulPlacements()",
          "old_line_content": "  // Remember the graph in run state if this is a partial run.",
          "new_line_content": "  stateful_placements_ = execution_state->GetStatefulPlacements();",
          "content_same": false
        },
        {
          "line": 1663,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "flib_def_.get()",
          "old_line_content": "  }",
          "new_line_content": "    run_state_args->graph.reset(new Graph(flib_def_.get()));",
          "content_same": false
        },
        {
          "line": 1664,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "run_state_args->graph.get()",
          "old_line_content": "",
          "new_line_content": "    CopyGraph(*execution_state->full_graph(), run_state_args->graph.get());",
          "content_same": false
        },
        {
          "line": 1670,
          "old_api": null,
          "new_api": "assigned_device_name",
          "old_text": null,
          "new_text": "node->assigned_device_name()",
          "old_line_content": "  popts.new_name = [this](const string& prefix) {",
          "new_line_content": "    return node->assigned_device_name();",
          "content_same": false
        },
        {
          "line": 1673,
          "old_api": null,
          "new_api": "fetch_add",
          "old_text": null,
          "new_text": "edge_name_counter_.fetch_add(1)",
          "old_line_content": "  popts.get_incarnation = [](const string& name) {",
          "new_line_content": "    return strings::StrCat(prefix, \"/_\", edge_name_counter_.fetch_add(1));",
          "content_same": false
        },
        {
          "line": 1680,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "flib_def->get()",
          "old_line_content": "",
          "new_line_content": "  popts.flib_def = flib_def->get();",
          "content_same": false
        },
        {
          "line": 1684,
          "old_api": null,
          "new_api": "Partition",
          "old_text": null,
          "new_text": "Partition(popts, &client_graph->graph, &partitions)",
          "old_line_content": "  std::vector<string> device_names;",
          "new_line_content": "  TF_RETURN_IF_ERROR(Partition(popts, &client_graph->graph, &partitions));",
          "content_same": false
        },
        {
          "line": 1689,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "device->name()",
          "old_line_content": "",
          "new_line_content": "    device_names.push_back(DeviceNameUtils::LocalName(device->name()));",
          "content_same": false
        },
        {
          "line": 1695,
          "old_api": null,
          "new_api": "DeviceNameUtils::LocalName(partition.first)",
          "old_text": null,
          "new_text": "DeviceNameUtils::LocalName(partition.first)",
          "old_line_content": "                   local_partition_name) == 0) {",
          "new_line_content": "        DeviceNameUtils::LocalName(partition.first);",
          "content_same": false
        },
        {
          "line": 1698,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\n          \"Creating a partition for \", local_partition_name,\n          \" which doesn't exist in the list of available devices. Available \"\n          \"devices: \",\n          absl::StrJoin(device_names, \",\"))",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\n          \"Creating a partition for \", local_partition_name,\n          \" which doesn't exist in the list of available devices. Available \"\n          \"devices: \",\n          absl::StrJoin(device_names, \",\"))",
          "old_line_content": "          \" which doesn't exist in the list of available devices. Available \"",
          "new_line_content": "      return errors::InvalidArgument(",
          "content_same": false
        },
        {
          "line": 1702,
          "old_api": null,
          "new_api": "absl::StrJoin(device_names, \",\")",
          "old_text": null,
          "new_text": "absl::StrJoin(device_names, \",\")",
          "old_line_content": "  }",
          "new_line_content": "          absl::StrJoin(device_names, \",\"));",
          "content_same": false
        },
        {
          "line": 1708,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "client_graph->flib_def.get()",
          "old_line_content": "    GraphConstructorOptions device_opts;",
          "new_line_content": "        new Graph(client_graph->flib_def.get()));",
          "content_same": false
        },
        {
          "line": 1709,
          "old_api": null,
          "new_api": "SetConstructionContext",
          "old_text": null,
          "new_text": "device_graph->SetConstructionContext(ConstructionContext::kDirectSession)",
          "old_line_content": "    // There are internal operations (e.g., send/recv) that we now allow.",
          "new_line_content": "    device_graph->SetConstructionContext(ConstructionContext::kDirectSession);",
          "content_same": false
        },
        {
          "line": 1715,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "device_graph.get()",
          "old_line_content": "  }",
          "new_line_content": "        device_opts, std::move(partition.second), device_graph.get()));",
          "content_same": false
        },
        {
          "line": 1716,
          "old_api": null,
          "new_api": "std::move(device_graph)",
          "old_text": null,
          "new_text": "std::move(device_graph)",
          "old_line_content": "",
          "new_line_content": "    outputs->emplace(partition.first, std::move(device_graph));",
          "content_same": false
        },
        {
          "line": 1723,
          "old_api": null,
          "new_api": "RunGrouping",
          "old_text": null,
          "new_text": "OptimizationPassRegistry::Global()->RunGrouping(\n      OptimizationPassRegistry::POST_PARTITIONING, optimization_options)",
          "old_line_content": "",
          "new_line_content": "  TF_RETURN_IF_ERROR(OptimizationPassRegistry::Global()->RunGrouping(",
          "content_same": false
        },
        {
          "line": 1731,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "graph->get()",
          "old_line_content": "",
          "new_line_content": "    VLOG(2) << \"Created \" << DebugString(graph->get()) << \" for \"",
          "content_same": false
        },
        {
          "line": 1738,
          "old_api": null,
          "new_api": "MaybeRewriteGraph",
          "old_text": null,
          "new_text": "d->MaybeRewriteGraph(graph)",
          "old_line_content": "      break;",
          "new_line_content": "    s = d->MaybeRewriteGraph(graph);",
          "content_same": false
        },
        {
          "line": 1739,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "s.ok()",
          "old_line_content": "    }",
          "new_line_content": "    if (!s.ok()) {",
          "content_same": false
        },
        {
          "line": 1744,
          "old_api": null,
          "new_api": "std::swap(*input_types, client_graph->feed_types)",
          "old_text": null,
          "new_text": "std::swap(*input_types, client_graph->feed_types)",
          "old_line_content": "  return s;",
          "new_line_content": "  std::swap(*input_types, client_graph->feed_types);",
          "content_same": false
        },
        {
          "line": 1745,
          "old_api": null,
          "new_api": "std::swap(*output_types, client_graph->fetch_types)",
          "old_text": null,
          "new_text": "std::swap(*output_types, client_graph->fetch_types)",
          "old_line_content": "}",
          "new_line_content": "  std::swap(*output_types, client_graph->fetch_types);",
          "content_same": false
        },
        {
          "line": 1751,
          "old_api": null,
          "new_api": "clear",
          "old_text": null,
          "new_text": "response->clear()",
          "old_line_content": "  for (Device* d : devices_) {",
          "new_line_content": "  response->clear();",
          "content_same": false
        },
        {
          "line": 1754,
          "old_api": null,
          "new_api": "attributes",
          "old_text": null,
          "new_text": "d->attributes()",
          "old_line_content": "  }",
          "new_line_content": "    const DeviceAttributes& attrs = d->attributes();",
          "content_same": false
        },
        {
          "line": 1757,
          "old_api": null,
          "new_api": "::tensorflow::Status::OK()",
          "old_text": null,
          "new_text": "::tensorflow::Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return ::tensorflow::Status::OK();",
          "content_same": false
        },
        {
          "line": 1762,
          "old_api": null,
          "new_api": "ClearContainers",
          "old_text": null,
          "new_text": "device_mgr_->ClearContainers(containers)",
          "old_line_content": "}",
          "new_line_content": "  device_mgr_->ClearContainers(containers);",
          "content_same": false
        },
        {
          "line": 1763,
          "old_api": null,
          "new_api": "::tensorflow::Status::OK()",
          "old_text": null,
          "new_text": "::tensorflow::Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return ::tensorflow::Status::OK();",
          "content_same": false
        },
        {
          "line": 1767,
          "old_api": null,
          "new_api": "StartCancel",
          "old_text": null,
          "new_text": "cancellation_manager_->StartCancel()",
          "old_line_content": "    mutex_lock l(closed_lock_);",
          "new_line_content": "  cancellation_manager_->StartCancel();",
          "content_same": false
        },
        {
          "line": 1770,
          "old_api": null,
          "new_api": "::tensorflow::Status::OK()",
          "old_text": null,
          "new_text": "::tensorflow::Status::OK()",
          "old_line_content": "  }",
          "new_line_content": "    if (closed_) return ::tensorflow::Status::OK();",
          "content_same": false
        },
        {
          "line": 1773,
          "old_api": null,
          "new_api": "Deregister",
          "old_text": null,
          "new_text": "factory_->Deregister(this)",
          "old_line_content": "}",
          "new_line_content": "  if (factory_ != nullptr) factory_->Deregister(this);",
          "content_same": false
        },
        {
          "line": 1774,
          "old_api": null,
          "new_api": "::tensorflow::Status::OK()",
          "old_text": null,
          "new_text": "::tensorflow::Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return ::tensorflow::Status::OK();",
          "content_same": false
        },
        {
          "line": 1781,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "d->resource_manager()->Cleanup(name).ok()",
          "old_line_content": "          }",
          "new_line_content": "          if (!d->resource_manager()->Cleanup(name).ok()) {",
          "content_same": false
        },
        {
          "line": 1784,
          "old_api": null,
          "new_api": "GetScopedAllocatorMgr",
          "old_text": null,
          "new_text": "d->GetScopedAllocatorMgr()",
          "old_line_content": "        }",
          "new_line_content": "          ScopedAllocatorMgr* sam = d->GetScopedAllocatorMgr();",
          "content_same": false
        },
        {
          "line": 1785,
          "old_api": null,
          "new_api": "Cleanup",
          "old_text": null,
          "new_text": "sam->Cleanup(step_id)",
          "old_line_content": "      }) {}",
          "new_line_content": "          if (sam) sam->Cleanup(step_id);",
          "content_same": false
        },
        {
          "line": 1805,
          "old_api": null,
          "new_api": "errors::Cancelled(\"PRun cancellation\")",
          "old_text": null,
          "new_text": "errors::Cancelled(\"PRun cancellation\")",
          "old_line_content": "  }",
          "new_line_content": "    rendez->StartAbort(errors::Cancelled(\"PRun cancellation\"));",
          "content_same": false
        },
        {
          "line": 1806,
          "old_api": null,
          "new_api": "WaitForNotification",
          "old_text": null,
          "new_text": "executors_done.WaitForNotification()",
          "old_line_content": "}",
          "new_line_content": "    executors_done.WaitForNotification();",
          "content_same": false
        },
        {
          "line": 1823,
          "old_api": null,
          "new_api": "WaitForNotification",
          "old_text": null,
          "new_text": "WaitForNotification(n, timeout_in_ms)",
          "old_line_content": "    {",
          "new_line_content": "  const Status status = WaitForNotification(n, timeout_in_ms);",
          "content_same": false
        },
        {
          "line": 1824,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "status.ok()",
          "old_line_content": "      mutex_lock l(run_state->mu);",
          "new_line_content": "  if (!status.ok()) {",
          "content_same": false
        },
        {
          "line": 1829,
          "old_api": null,
          "new_api": "StartCancel",
          "old_text": null,
          "new_text": "cm->StartCancel()",
          "old_line_content": "    // references to `cm` and other per-step state. After this notification, it",
          "new_line_content": "    cm->StartCancel();",
          "content_same": false
        },
        {
          "line": 1833,
          "old_api": null,
          "new_api": "WaitForNotification",
          "old_text": null,
          "new_text": "n->WaitForNotification()",
          "old_line_content": "}",
          "new_line_content": "    n->WaitForNotification();",
          "content_same": false
        },
        {
          "line": 1844,
          "old_api": null,
          "new_api": "Status",
          "old_text": null,
          "new_text": "Status(error::DEADLINE_EXCEEDED,\n                    \"Timed out waiting for notification\")",
          "old_line_content": "    }",
          "new_line_content": "      return Status(error::DEADLINE_EXCEEDED,",
          "content_same": false
        },
        {
          "line": 1850,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 1855,
          "old_api": null,
          "new_api": "CheckNotClosed",
          "old_text": null,
          "new_text": "CheckNotClosed()",
          "old_line_content": "",
          "new_line_content": "  TF_RETURN_IF_ERROR(CheckNotClosed());",
          "content_same": false
        },
        {
          "line": 1856,
          "old_api": null,
          "new_api": "CheckGraphCreated",
          "old_text": null,
          "new_text": "CheckGraphCreated(\"MakeCallable()\")",
          "old_line_content": "  std::unique_ptr<ExecutorsAndKeys> ek;",
          "new_line_content": "  TF_RETURN_IF_ERROR(CheckGraphCreated(\"MakeCallable()\"));",
          "content_same": false
        },
        {
          "line": 1861,
          "old_api": null,
          "new_api": "TF_RETURN_IF_ERROR",
          "old_text": null,
          "new_text": "TF_RETURN_IF_ERROR(\n      CreateExecutors(callable_options, &ek, &func_info, &run_state_args))",
          "old_line_content": "  {",
          "new_line_content": "  TF_RETURN_IF_ERROR(",
          "content_same": false
        },
        {
          "line": 1862,
          "old_api": null,
          "new_api": "CreateExecutors",
          "old_text": null,
          "new_text": "CreateExecutors(callable_options, &ek, &func_info, &run_state_args)",
          "old_line_content": "    mutex_lock l(callables_lock_);",
          "new_line_content": "      CreateExecutors(callable_options, &ek, &func_info, &run_state_args));",
          "content_same": false
        },
        {
          "line": 1868,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 1883,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "executors_and_keys_->input_types.size()",
          "old_line_content": "  size_t num_retvals() const override {",
          "new_line_content": "    return executors_and_keys_->input_types.size();",
          "content_same": false
        },
        {
          "line": 1886,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "executors_and_keys_->output_types.size()",
          "old_line_content": "",
          "new_line_content": "    return executors_and_keys_->output_types.size();",
          "content_same": false
        },
        {
          "line": 1890,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "feed_tensors_->size()",
          "old_line_content": "    } else {",
          "new_line_content": "    if (TF_PREDICT_FALSE(index > feed_tensors_->size())) {",
          "content_same": false
        },
        {
          "line": 1891,
          "old_api": null,
          "new_api": "errors::Internal(\"Args index out of bounds: \", index)",
          "old_text": null,
          "new_text": "errors::Internal(\"Args index out of bounds: \", index)",
          "old_line_content": "      *val = &(*feed_tensors_)[index];",
          "new_line_content": "      return errors::Internal(\"Args index out of bounds: \", index);",
          "content_same": false
        },
        {
          "line": 1895,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "    return Status::OK();",
          "content_same": false
        },
        {
          "line": 1899,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "fetch_tensors_->size()",
          "old_line_content": "    }",
          "new_line_content": "    if (index > fetch_tensors_->size()) {",
          "content_same": false
        },
        {
          "line": 1900,
          "old_api": null,
          "new_api": "errors::Internal(\"RetVal index out of bounds: \", index)",
          "old_text": null,
          "new_text": "errors::Internal(\"RetVal index out of bounds: \", index)",
          "old_line_content": "    (*fetch_tensors_)[index] = val;",
          "new_line_content": "      return errors::Internal(\"RetVal index out of bounds: \", index);",
          "content_same": false
        },
        {
          "line": 1903,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "    return Status::OK();",
          "content_same": false
        },
        {
          "line": 1916,
          "old_api": null,
          "new_api": "RunCallable",
          "old_text": null,
          "new_text": "RunCallable(handle, feed_tensors, fetch_tensors, run_metadata,\n                     thread::ThreadPoolOptions())",
          "old_line_content": "}",
          "new_line_content": "  return RunCallable(handle, feed_tensors, fetch_tensors, run_metadata,",
          "content_same": false
        },
        {
          "line": 1917,
          "old_api": null,
          "new_api": "thread::ThreadPoolOptions()",
          "old_text": null,
          "new_text": "thread::ThreadPoolOptions()",
          "old_line_content": "",
          "new_line_content": "                     thread::ThreadPoolOptions());",
          "content_same": false
        },
        {
          "line": 1925,
          "old_api": null,
          "new_api": "CheckGraphCreated",
          "old_text": null,
          "new_text": "CheckGraphCreated(\"RunCallable()\")",
          "old_line_content": "",
          "new_line_content": "  TF_RETURN_IF_ERROR(CheckGraphCreated(\"RunCallable()\"));",
          "content_same": false
        },
        {
          "line": 1926,
          "old_api": null,
          "new_api": "GetCell",
          "old_text": null,
          "new_text": "direct_session_runs->GetCell()->IncrementBy(1)",
          "old_line_content": "  // Check if we already have an executor for these arguments.",
          "new_line_content": "  direct_session_runs->GetCell()->IncrementBy(1);",
          "content_same": false
        },
        {
          "line": 1930,
          "old_api": null,
          "new_api": "fetch_add",
          "old_text": null,
          "new_text": "step_id_counter_.fetch_add(1)",
          "old_line_content": "  {",
          "new_line_content": "  const int64_t step_id = step_id_counter_.fetch_add(1);",
          "content_same": false
        },
        {
          "line": 1935,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\"No such callable handle: \", handle)",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\"No such callable handle: \", handle)",
          "old_line_content": "    executors_and_keys = callables_[handle].executors_and_keys;",
          "new_line_content": "      return errors::InvalidArgument(\"No such callable handle: \", handle);",
          "content_same": false
        },
        {
          "line": 1941,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\n        \"Attempted to run callable after handle was released: \", handle)",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\n        \"Attempted to run callable after handle was released: \", handle)",
          "old_line_content": "  }",
          "new_line_content": "    return errors::InvalidArgument(",
          "content_same": false
        },
        {
          "line": 1954,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "executors_and_keys->input_types.size()",
          "old_line_content": "  }",
          "new_line_content": "        \"Expected \", executors_and_keys->input_types.size(),",
          "content_same": false
        },
        {
          "line": 1955,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "feed_tensors.size()",
          "old_line_content": "  if (fetch_tensors != nullptr) {",
          "new_line_content": "        \" feed tensors, but got \", feed_tensors.size());",
          "content_same": false
        },
        {
          "line": 1959,
          "old_api": null,
          "new_api": "empty",
          "old_text": null,
          "new_text": "executors_and_keys->output_types.empty()",
          "old_line_content": "        \"`fetch_tensors` must be provided when the callable has one or more \"",
          "new_line_content": "  } else if (!executors_and_keys->output_types.empty()) {",
          "content_same": false
        },
        {
          "line": 1960,
          "old_api": null,
          "new_api": "errors::InvalidArgument(\n        \"`fetch_tensors` must be provided when the callable has one or more \"\n        \"outputs.\")",
          "old_text": null,
          "new_text": "errors::InvalidArgument(\n        \"`fetch_tensors` must be provided when the callable has one or more \"\n        \"outputs.\")",
          "old_line_content": "        \"outputs.\");",
          "new_line_content": "    return errors::InvalidArgument(",
          "content_same": false
        },
        {
          "line": 1968,
          "old_api": null,
          "new_api": "AllocatedBytes",
          "old_text": null,
          "new_text": "tensor.AllocatedBytes()",
          "old_line_content": "  }",
          "new_line_content": "    input_size += tensor.AllocatedBytes();",
          "content_same": false
        },
        {
          "line": 1971,
          "old_api": null,
          "new_api": "metrics::RecordGraphInputTensors(input_size)",
          "old_text": null,
          "new_text": "metrics::RecordGraphInputTensors(input_size)",
          "old_line_content": "  std::unique_ptr<std::vector<Tensor>> converted_feed_tensors;",
          "new_line_content": "  metrics::RecordGraphInputTensors(input_size);",
          "content_same": false
        },
        {
          "line": 1977,
          "old_api": null,
          "new_api": "absl::make_unique<std::vector<Tensor>>()",
          "old_text": null,
          "new_text": "absl::make_unique<std::vector<Tensor>>()",
          "old_line_content": "    for (const Tensor& t : feed_tensors) {",
          "new_line_content": "    converted_feed_tensors = absl::make_unique<std::vector<Tensor>>();",
          "content_same": false
        },
        {
          "line": 1982,
          "old_api": null,
          "new_api": "back",
          "old_text": null,
          "new_text": "converted_feed_tensors->back()",
          "old_line_content": "      } else {",
          "new_line_content": "        Tensor* tensor_from_handle = &converted_feed_tensors->back();",
          "content_same": false
        },
        {
          "line": 1985,
          "old_api": null,
          "new_api": "emplace_back",
          "old_text": null,
          "new_text": "converted_feed_tensors->emplace_back(t)",
          "old_line_content": "    }",
          "new_line_content": "        converted_feed_tensors->emplace_back(t);",
          "content_same": false
        },
        {
          "line": 1988,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "converted_feed_tensors.get()",
          "old_line_content": "    actual_feed_tensors = &feed_tensors;",
          "new_line_content": "    actual_feed_tensors = converted_feed_tensors.get();",
          "content_same": false
        },
        {
          "line": 1995,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "executors_and_keys.get()",
          "old_line_content": "",
          "new_line_content": "  RunCallableCallFrame call_frame(this, executors_and_keys.get(),",
          "content_same": false
        },
        {
          "line": 1998,
          "old_api": null,
          "new_api": "LogMemory::IsEnabled()",
          "old_text": null,
          "new_text": "LogMemory::IsEnabled()",
          "old_line_content": "  }",
          "new_line_content": "  if (LogMemory::IsEnabled()) {",
          "content_same": false
        },
        {
          "line": 1999,
          "old_api": null,
          "new_api": "LogMemory::RecordStep(step_id, run_state_args.handle)",
          "old_text": null,
          "new_text": "LogMemory::RecordStep(step_id, run_state_args.handle)",
          "old_line_content": "",
          "new_line_content": "    LogMemory::RecordStep(step_id, run_state_args.handle);",
          "content_same": false
        },
        {
          "line": 2003,
          "old_api": null,
          "new_api": "run_options",
          "old_text": null,
          "new_text": "executors_and_keys->callable_options.run_options()",
          "old_line_content": "",
          "new_line_content": "      step_id, executors_and_keys->callable_options.run_options(), &call_frame,",
          "content_same": false
        },
        {
          "line": 2004,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "executors_and_keys.get()",
          "old_line_content": "  if (fetch_tensors != nullptr) {",
          "new_line_content": "      executors_and_keys.get(), run_metadata, threadpool_options));",
          "content_same": false
        },
        {
          "line": 2011,
          "old_api": null,
          "new_api": "metrics::RecordGraphOutputTensors(output_size)",
          "old_text": null,
          "new_text": "metrics::RecordGraphOutputTensors(output_size)",
          "old_line_content": "",
          "new_line_content": "    metrics::RecordGraphOutputTensors(output_size);",
          "content_same": false
        },
        {
          "line": 2014,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 2022,
          "old_api": null,
          "new_api": "erase",
          "old_text": null,
          "new_text": "callables_.erase(handle)",
          "old_line_content": "}",
          "new_line_content": "  callables_.erase(handle);",
          "content_same": false
        },
        {
          "line": 2023,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 2029,
          "old_api": null,
          "new_api": "errors::FailedPrecondition(\"Session already finalized.\")",
          "old_text": null,
          "new_text": "errors::FailedPrecondition(\"Session already finalized.\")",
          "old_line_content": "  if (!graph_created_) {",
          "new_line_content": "    return errors::FailedPrecondition(\"Session already finalized.\");",
          "content_same": false
        },
        {
          "line": 2034,
          "old_api": null,
          "new_api": "reset",
          "old_text": null,
          "new_text": "execution_state_.reset()",
          "old_line_content": "  finalized_ = true;",
          "new_line_content": "  execution_state_.reset();",
          "content_same": false
        },
        {
          "line": 2037,
          "old_api": null,
          "new_api": "Status::OK()",
          "old_text": null,
          "new_text": "Status::OK()",
          "old_line_content": "",
          "new_line_content": "  return Status::OK();",
          "content_same": false
        },
        {
          "line": 2046,
          "old_api": null,
          "new_api": "reset",
          "old_text": null,
          "new_text": "executors_and_keys.reset()",
          "old_line_content": "}",
          "new_line_content": "  executors_and_keys.reset();",
          "content_same": false
        },
        {
          "line": 2047,
          "old_api": null,
          "new_api": "reset",
          "old_text": null,
          "new_text": "function_info.reset()",
          "old_line_content": "",
          "new_line_content": "  function_info.reset();",
          "content_same": false
        }
      ],
      "deletions": [
        {
          "line": 445,
          "old_api": "reset",
          "new_api": null,
          "old_text": "flib_def_.reset(\n        new FunctionLibraryDefinition(OpRegistry::Global(), graph.library()))",
          "new_text": null,
          "old_line_content": "    flib_def_.reset(",
          "new_line_content": "    options.session_options = &options_;",
          "content_same": false
        },
        {
          "line": 446,
          "old_api": "library",
          "new_api": null,
          "old_text": "graph.library()",
          "new_text": null,
          "old_line_content": "        new FunctionLibraryDefinition(OpRegistry::Global(), graph.library()));",
          "new_line_content": "    options.session_handle = session_handle_;",
          "content_same": false
        },
        {
          "line": 451,
          "old_api": "GraphExecutionState::MakeForBaseGraph(\n        std::move(graph), options, &execution_state_)",
          "new_api": null,
          "old_text": "GraphExecutionState::MakeForBaseGraph(\n        std::move(graph), options, &execution_state_)",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(GraphExecutionState::MakeForBaseGraph(",
          "new_line_content": "    // constructor of FunctionLibraryDefinition avoids duplicating the memory",
          "content_same": false
        },
        {
          "line": 452,
          "old_api": "std::move(graph)",
          "new_api": null,
          "old_text": "std::move(graph)",
          "new_text": null,
          "old_line_content": "        std::move(graph), options, &execution_state_));",
          "new_line_content": "    // that is occupied by its shared_ptr members.",
          "content_same": false
        },
        {
          "line": 455,
          "old_api": "library",
          "new_api": null,
          "old_text": "graph.library()",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(flib_def_->AddLibrary(graph.library()));",
          "new_line_content": "    graph_created_ = true;",
          "content_same": false
        },
        {
          "line": 459,
          "old_api": "Extend",
          "new_api": null,
          "old_text": "execution_state_->Extend(graph, &state)",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(execution_state_->Extend(graph, &state));",
          "new_line_content": "    // value and move `graph` in here.",
          "content_same": false
        },
        {
          "line": 470,
          "old_api": "RunOptions",
          "new_api": null,
          "old_text": "RunOptions()",
          "new_text": null,
          "old_line_content": "  return Run(RunOptions(), inputs, output_names, target_nodes, outputs,",
          "new_line_content": "                          std::vector<Tensor>* outputs) {",
          "content_same": false
        },
        {
          "line": 478,
          "old_api": "run_options",
          "new_api": null,
          "old_text": "DebuggerStateRegistry::CreateState(\n      callable_options.run_options().debug_options(), debugger_state)",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(DebuggerStateRegistry::CreateState(",
          "new_line_content": "    int64_t session_run_index, int64_t executor_step_index,",
          "content_same": false
        },
        {
          "line": 479,
          "old_api": "run_options",
          "new_api": null,
          "old_text": "callable_options.run_options().debug_options()",
          "new_text": null,
          "old_line_content": "      callable_options.run_options().debug_options(), debugger_state));",
          "new_line_content": "    std::unique_ptr<DebuggerStateInterface>* debugger_state) {",
          "content_same": false
        },
        {
          "line": 490,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "  return Status::OK();",
          "new_line_content": "      global_step, session_run_index, executor_step_index, input_names,",
          "content_same": false
        },
        {
          "line": 496,
          "old_api": "TF_RETURN_IF_ERROR",
          "new_api": null,
          "old_text": "TF_RETURN_IF_ERROR(\n      DebugGraphDecoratorRegistry::CreateDecorator(debug_options, &decorator))",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(",
          "new_line_content": "    const DebugOptions& debug_options, Graph* graph, Device* device) {",
          "content_same": false
        },
        {
          "line": 497,
          "old_api": "DebugGraphDecoratorRegistry::CreateDecorator(debug_options, &decorator)",
          "new_api": null,
          "old_text": "DebugGraphDecoratorRegistry::CreateDecorator(debug_options, &decorator)",
          "new_text": null,
          "old_line_content": "      DebugGraphDecoratorRegistry::CreateDecorator(debug_options, &decorator));",
          "new_line_content": "  std::unique_ptr<DebugGraphDecoratorInterface> decorator;",
          "content_same": false
        },
        {
          "line": 500,
          "old_api": "name",
          "new_api": null,
          "old_text": "device->name()",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(decorator->PublishGraph(*graph, device->name()));",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 509,
          "old_api": "NowMicros",
          "new_api": null,
          "old_text": "options_.env->NowMicros()",
          "new_text": null,
          "old_line_content": "  const uint64 start_time_usecs = options_.env->NowMicros();",
          "new_line_content": "    RunMetadata* run_metadata,",
          "content_same": false
        },
        {
          "line": 518,
          "old_api": "experimental",
          "new_api": null,
          "old_text": "options_.config.experimental().has_session_metadata()",
          "new_text": null,
          "old_line_content": "        if (options_.config.experimental().has_session_metadata()) {",
          "new_line_content": "      // To TraceMeConsumers in ExecutorState::Process/Finish.",
          "content_same": false
        },
        {
          "line": 521,
          "old_api": "name",
          "new_api": null,
          "old_text": "model_metadata.name()",
          "new_text": null,
          "old_line_content": "          string model_id = strings::StrCat(model_metadata.name(), \":\",",
          "new_line_content": "          const auto& model_metadata =",
          "content_same": false
        },
        {
          "line": 528,
          "old_api": "profiler::TraceMeEncode(\n              \"SessionRun\", {{\"id\", step_id}, {\"_r\", 1} /*root_event*/})",
          "new_api": null,
          "old_text": "profiler::TraceMeEncode(\n              \"SessionRun\", {{\"id\", step_id}, {\"_r\", 1} /*root_event*/})",
          "new_text": null,
          "old_line_content": "          return profiler::TraceMeEncode(",
          "new_line_content": "                                          {\"model_id\", model_id}});",
          "content_same": false
        },
        {
          "line": 536,
          "old_api": "debug_options",
          "new_api": null,
          "old_text": "run_options.debug_options().debug_tensor_watch_opts().empty()",
          "new_text": null,
          "old_line_content": "  if (!run_options.debug_options().debug_tensor_watch_opts().empty()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 537,
          "old_api": "debug_options",
          "new_api": null,
          "old_text": "TF_RETURN_IF_ERROR(\n        CreateDebuggerState(executors_and_keys->callable_options,\n                            run_options.debug_options().global_step(), step_id,\n                            executor_step_count, &debugger_state))",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(",
          "new_line_content": "  std::unique_ptr<DebuggerStateInterface> debugger_state;",
          "content_same": false
        },
        {
          "line": 547,
          "old_api": "experimental",
          "new_api": null,
          "old_text": "run_options.experimental().collective_graph_key()",
          "new_text": null,
          "old_line_content": "    if (run_options.experimental().collective_graph_key() !=",
          "new_line_content": "  if (executors_and_keys->collective_graph_key !=",
          "content_same": false
        },
        {
          "line": 551,
          "old_api": "experimental",
          "new_api": null,
          "old_text": "run_options.experimental().collective_graph_key()",
          "new_text": null,
          "old_line_content": "      if (run_options.experimental().collective_graph_key() !=",
          "new_line_content": "      // If a collective_graph_key was specified in run_options, ensure that it",
          "content_same": false
        },
        {
          "line": 561,
          "old_api": "get",
          "new_api": null,
          "old_text": "CreateProdLocalCollectiveExecutorMgr(\n          options_.config, device_mgr_.get(),\n          MaybeCreateNcclCommunicator(options_.config))",
          "new_text": null,
          "old_line_content": "      collective_executor_mgr_ = CreateProdLocalCollectiveExecutorMgr(",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 562,
          "old_api": "get",
          "new_api": null,
          "old_text": "device_mgr_.get()",
          "new_text": null,
          "old_line_content": "          options_.config, device_mgr_.get(),",
          "new_line_content": "    if (!collective_executor_mgr_) {",
          "content_same": false
        },
        {
          "line": 566,
          "old_api": "FindOrCreate",
          "new_api": null,
          "old_text": "collective_executor_mgr_->FindOrCreate(step_id)",
          "new_text": null,
          "old_line_content": "        collective_executor_mgr_->FindOrCreate(step_id), true /*inherit_ref*/));",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 575,
          "old_api": "inter_op_thread_pool",
          "new_api": null,
          "old_text": "run_options.inter_op_thread_pool()",
          "new_text": null,
          "old_line_content": "      run_in_caller_thread_ || run_options.inter_op_thread_pool() == -1;",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 580,
          "old_api": "size",
          "new_api": null,
          "old_text": "executors_and_keys->items.size()",
          "new_text": null,
          "old_line_content": "    if (executors_and_keys->items.size() > 1) {",
          "new_line_content": "    // We allow using the caller thread only when having a single executor",
          "content_same": false
        },
        {
          "line": 583,
          "old_api": "VLOG",
          "new_api": null,
          "old_text": "VLOG(1)",
          "new_text": null,
          "old_line_content": "      VLOG(1) << \"Executing Session::Run() synchronously!\";",
          "new_line_content": "      pool = thread_pools_[0].first;",
          "content_same": false
        },
        {
          "line": 587,
          "old_api": "absl::make_unique<thread::ThreadPool>(\n        threadpool_options.inter_op_threadpool)",
          "new_api": null,
          "old_text": "absl::make_unique<thread::ThreadPool>(\n        threadpool_options.inter_op_threadpool)",
          "new_text": null,
          "old_line_content": "    threadpool_wrapper = absl::make_unique<thread::ThreadPool>(",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 592,
          "old_api": "inter_op_thread_pool",
          "new_api": null,
          "old_text": "run_options.inter_op_thread_pool()",
          "new_text": null,
          "old_line_content": "        run_options.inter_op_thread_pool() >=",
          "new_line_content": "  } else {",
          "content_same": false
        },
        {
          "line": 598,
          "old_api": "inter_op_thread_pool",
          "new_api": null,
          "old_text": "run_options.inter_op_thread_pool()",
          "new_text": null,
          "old_line_content": "    pool = thread_pools_[run_options.inter_op_thread_pool()].first;",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 601,
          "old_api": "timeout_in_ms",
          "new_api": null,
          "old_text": "run_options.timeout_in_ms()",
          "new_text": null,
          "old_line_content": "  const int64_t call_timeout = run_options.timeout_in_ms() > 0",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 602,
          "old_api": "timeout_in_ms",
          "new_api": null,
          "old_text": "run_options.timeout_in_ms()",
          "new_text": null,
          "old_line_content": "                                   ? run_options.timeout_in_ms()",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 606,
          "old_api": "absl::Milliseconds(call_timeout)",
          "new_api": null,
          "old_text": "absl::Milliseconds(call_timeout)",
          "new_text": null,
          "old_line_content": "    deadline = absl::Now() + absl::Milliseconds(call_timeout);",
          "new_line_content": "  absl::optional<absl::Time> deadline;",
          "content_same": false
        },
        {
          "line": 610,
          "old_api": "ShouldUseRunHandlerPool",
          "new_api": null,
          "old_text": "ShouldUseRunHandlerPool(run_options)",
          "new_text": null,
          "old_line_content": "  if (ShouldUseRunHandlerPool(run_options) &&",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 611,
          "old_api": "experimental",
          "new_api": null,
          "old_text": "run_options.experimental().use_run_handler_pool()",
          "new_text": null,
          "old_line_content": "      run_options.experimental().use_run_handler_pool()) {",
          "new_line_content": "  std::unique_ptr<RunHandler> handler;",
          "content_same": false
        },
        {
          "line": 622,
          "old_api": "get",
          "new_api": null,
          "old_text": "handler.get()",
          "new_text": null,
          "old_line_content": "  auto* handler_ptr = handler.get();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 627,
          "old_api": "c",
          "new_api": null,
          "old_text": "c()",
          "new_text": null,
          "old_line_content": "    default_runner = [](const Executor::Args::Closure& c) { c(); };",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 630,
          "old_api": "std::move(c)",
          "new_api": null,
          "old_text": "std::move(c)",
          "new_text": null,
          "old_line_content": "      handler_ptr->ScheduleInterOpClosure(std::move(c));",
          "new_line_content": "  } else if (handler_ptr != nullptr) {",
          "content_same": false
        },
        {
          "line": 634,
          "old_api": "std::move(c)",
          "new_api": null,
          "old_text": "std::move(c)",
          "new_text": null,
          "old_line_content": "      pool->Schedule(std::move(c));",
          "new_line_content": "  } else {",
          "content_same": false
        },
        {
          "line": 647,
          "old_api": "size",
          "new_api": null,
          "old_text": "executors_and_keys->items.size()",
          "new_text": null,
          "old_line_content": "      executors_and_keys->items.size() == 1 && call_timeout == 0;",
          "new_line_content": "  // timeout expires.",
          "content_same": false
        },
        {
          "line": 653,
          "old_api": "get",
          "new_api": null,
          "old_text": "run_state.collective_executor->get()",
          "new_text": null,
          "old_line_content": "      (run_state.collective_executor ? run_state.collective_executor->get()",
          "new_line_content": "  args.call_frame = call_frame;",
          "content_same": false
        },
        {
          "line": 665,
          "old_api": "trace_level",
          "new_api": null,
          "old_text": "run_options.trace_level()",
          "new_text": null,
          "old_line_content": "  const bool do_trace = (run_options.trace_level() > RunOptions::NO_TRACE);",
          "new_line_content": "  args.deadline = deadline;",
          "content_same": false
        },
        {
          "line": 668,
          "old_api": "graph_options",
          "new_api": null,
          "old_text": "options_.config.graph_options().build_cost_model()",
          "new_text": null,
          "old_line_content": "  if (options_.config.graph_options().build_cost_model() > 0) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 680,
          "old_api": "report_tensor_allocations_upon_oom",
          "new_api": null,
          "old_text": "run_options.report_tensor_allocations_upon_oom()",
          "new_text": null,
          "old_line_content": "      run_options.report_tensor_allocations_upon_oom()) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 681,
          "old_api": "reset",
          "new_api": null,
          "old_text": "run_state.collector.reset(\n        new StepStatsCollector(run_metadata->mutable_step_stats()))",
          "new_text": null,
          "old_line_content": "    run_state.collector.reset(",
          "new_line_content": "  if (do_trace || update_cost_model ||",
          "content_same": false
        },
        {
          "line": 687,
          "old_api": "trace_level",
          "new_api": null,
          "old_text": "run_options.trace_level()",
          "new_text": null,
          "old_line_content": "  if (run_options.trace_level() >= RunOptions::HARDWARE_TRACE) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 688,
          "old_api": "DeviceProfilerSession::Create()",
          "new_api": null,
          "old_text": "DeviceProfilerSession::Create()",
          "new_text": null,
          "old_line_content": "    device_profiler_session = DeviceProfilerSession::Create();",
          "new_line_content": "  std::unique_ptr<DeviceProfilerSession> device_profiler_session;",
          "content_same": false
        },
        {
          "line": 694,
          "old_api": "IsCancelled",
          "new_api": null,
          "old_text": "step_cancellation_manager.IsCancelled()",
          "new_text": null,
          "old_line_content": "  if (step_cancellation_manager.IsCancelled()) {",
          "new_line_content": "  // `Session::Close()` will cancel the step.",
          "content_same": false
        },
        {
          "line": 695,
          "old_api": "errors::Cancelled(\"Run call was cancelled\")",
          "new_api": null,
          "old_text": "errors::Cancelled(\"Run call was cancelled\")",
          "new_text": null,
          "old_line_content": "    return errors::Cancelled(\"Run call was cancelled\");",
          "new_line_content": "  CancellationManager step_cancellation_manager(cancellation_manager_);",
          "content_same": false
        },
        {
          "line": 709,
          "old_api": "tensorflow_device_thread_pool",
          "new_api": null,
          "old_text": "item.device->tensorflow_device_thread_pool()",
          "new_text": null,
          "old_line_content": "            item.device->tensorflow_device_thread_pool();",
          "new_line_content": "        //     less threads to the main compute pool by default.",
          "content_same": false
        },
        {
          "line": 716,
          "old_api": "std::move(c)",
          "new_api": null,
          "old_text": "std::move(c)",
          "new_text": null,
          "old_line_content": "            device_thread_pool->Schedule(std::move(c));",
          "new_line_content": "        } else {",
          "content_same": false
        },
        {
          "line": 721,
          "old_api": "AsIntraThreadPoolInterface",
          "new_api": null,
          "old_text": "handler->AsIntraThreadPoolInterface()",
          "new_text": null,
          "old_line_content": "              handler->AsIntraThreadPoolInterface();",
          "new_line_content": "        if (handler != nullptr) {",
          "content_same": false
        },
        {
          "line": 726,
          "old_api": "get",
          "new_api": null,
          "old_text": "device_mgr_.get()",
          "new_text": null,
          "old_line_content": "    PrivateIntraProcessRendezvous rendezvous(device_mgr_.get());",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 730,
          "old_api": "set_threadpool_args_for_item",
          "new_api": null,
          "old_text": "set_threadpool_args_for_item(item, &args)",
          "new_text": null,
          "old_line_content": "    set_threadpool_args_for_item(item, &args);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 731,
          "old_api": "Run",
          "new_api": null,
          "old_text": "item.executor->Run(args)",
          "new_text": null,
          "old_line_content": "    run_status = item.executor->Run(args);",
          "new_line_content": "    const auto& item = executors_and_keys->items[0];",
          "content_same": false
        },
        {
          "line": 734,
          "old_api": "get",
          "new_api": null,
          "old_text": "device_mgr_.get()",
          "new_text": null,
          "old_line_content": "        new RefCountedIntraProcessRendezvous(device_mgr_.get()));",
          "new_line_content": "  } else {",
          "content_same": false
        },
        {
          "line": 735,
          "old_api": "get",
          "new_api": null,
          "old_text": "rendezvous.get()",
          "new_text": null,
          "old_line_content": "    args.rendezvous = rendezvous.get();",
          "new_line_content": "    core::RefCountPtr<RefCountedIntraProcessRendezvous> rendezvous(",
          "content_same": false
        },
        {
          "line": 740,
          "old_api": "get",
          "new_api": null,
          "old_text": "rendezvous.get()",
          "new_text": null,
          "old_line_content": "        new ExecutorBarrier(num_executors, rendezvous.get(),",
          "new_line_content": "    Notification executors_done;",
          "content_same": false
        },
        {
          "line": 744,
          "old_api": "Update",
          "new_api": null,
          "old_text": "run_state.status.Update(ret)",
          "new_text": null,
          "old_line_content": "                                run_state.status.Update(ret);",
          "new_line_content": "                              {",
          "content_same": false
        },
        {
          "line": 750,
          "old_api": "set_threadpool_args_for_item",
          "new_api": null,
          "old_text": "set_threadpool_args_for_item(item, &args)",
          "new_text": null,
          "old_line_content": "      set_threadpool_args_for_item(item, &args);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 751,
          "old_api": "Get",
          "new_api": null,
          "old_text": "barrier->Get()",
          "new_text": null,
          "old_line_content": "      item.executor->RunAsync(args, barrier->Get());",
          "new_line_content": "    for (const auto& item : executors_and_keys->items) {",
          "content_same": false
        },
        {
          "line": 754,
          "old_api": "WaitForNotification",
          "new_api": null,
          "old_text": "WaitForNotification(&executors_done, &run_state, &step_cancellation_manager,\n                        call_timeout)",
          "new_text": null,
          "old_line_content": "    WaitForNotification(&executors_done, &run_state, &step_cancellation_manager,",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 762,
          "old_api": "IsCancelled",
          "new_api": null,
          "old_text": "step_cancellation_manager.IsCancelled()",
          "new_text": null,
          "old_line_content": "  if (step_cancellation_manager.IsCancelled()) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 763,
          "old_api": "errors::Cancelled(\"Run call was cancelled\")",
          "new_api": null,
          "old_text": "errors::Cancelled(\"Run call was cancelled\")",
          "new_text": null,
          "old_line_content": "    run_status.Update(errors::Cancelled(\"Run call was cancelled\"));",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 767,
          "old_api": "CollectData",
          "new_api": null,
          "old_text": "device_profiler_session->CollectData(\n        run_metadata->mutable_step_stats())",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(device_profiler_session->CollectData(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 768,
          "old_api": "mutable_step_stats",
          "new_api": null,
          "old_text": "run_metadata->mutable_step_stats()",
          "new_text": null,
          "old_line_content": "        run_metadata->mutable_step_stats()));",
          "new_line_content": "  if (device_profiler_session) {",
          "content_same": false
        },
        {
          "line": 771,
          "old_api": "TF_RETURN_IF_ERROR",
          "new_api": null,
          "old_text": "TF_RETURN_IF_ERROR(run_status)",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(run_status);",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 774,
          "old_api": "empty",
          "new_api": null,
          "old_text": "run_state.tensor_store.empty()",
          "new_text": null,
          "old_line_content": "  if (!run_state.tensor_store.empty()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 775,
          "old_api": "SaveTensors",
          "new_api": null,
          "old_text": "run_state.tensor_store.SaveTensors(\n        {executors_and_keys->callable_options.fetch().begin(),\n         executors_and_keys->callable_options.fetch().end()},\n        &session_state_)",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(run_state.tensor_store.SaveTensors(",
          "new_line_content": "  // Save the output tensors of this run we choose to keep.",
          "content_same": false
        },
        {
          "line": 782,
          "old_api": "Finalize",
          "new_api": null,
          "old_text": "run_state.collector->Finalize()",
          "new_text": null,
          "old_line_content": "    run_state.collector->Finalize();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 791,
          "old_api": "get",
          "new_api": null,
          "old_text": "partition.graph.get()",
          "new_text": null,
          "old_line_content": "      const Graph* graph = partition.graph.get();",
          "new_line_content": "    for (const PerPartitionExecutorsAndLib& partition :",
          "content_same": false
        },
        {
          "line": 792,
          "old_api": "device",
          "new_api": null,
          "old_text": "partition.flib->device()->name()",
          "new_text": null,
          "old_line_content": "      const string& device = partition.flib->device()->name();",
          "new_line_content": "         executors_and_keys->items) {",
          "content_same": false
        },
        {
          "line": 797,
          "old_api": "BuildCostModel",
          "new_api": null,
          "old_text": "run_state.collector->BuildCostModel(&cost_model_manager_, device_to_graph)",
          "new_text": null,
          "old_line_content": "    run_state.collector->BuildCostModel(&cost_model_manager_, device_to_graph);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 800,
          "old_api": "mutable_cost_graph",
          "new_api": null,
          "old_text": "run_metadata->mutable_cost_graph()",
          "new_text": null,
          "old_line_content": "    CostGraphDef* cost_graph = run_metadata->mutable_cost_graph();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 803,
          "old_api": "get",
          "new_api": null,
          "old_text": "item.graph.get()",
          "new_text": null,
          "old_line_content": "          cost_model_manager_.AddToCostGraphDef(item.graph.get(), cost_graph));",
          "new_line_content": "    for (const auto& item : executors_and_keys->items) {",
          "content_same": false
        },
        {
          "line": 808,
          "old_api": "output_partition_graphs",
          "new_api": null,
          "old_text": "run_options.output_partition_graphs()",
          "new_text": null,
          "old_line_content": "  if (run_options.output_partition_graphs()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 809,
          "old_api": "experimental",
          "new_api": null,
          "old_text": "options_.config.experimental().disable_output_partition_graphs()",
          "new_text": null,
          "old_line_content": "    if (options_.config.experimental().disable_output_partition_graphs()) {",
          "new_line_content": "  // If requested via RunOptions, output the partition graphs.",
          "content_same": false
        },
        {
          "line": 815,
          "old_api": "mutable_partition_graphs",
          "new_api": null,
          "old_text": "run_metadata->mutable_partition_graphs()",
          "new_text": null,
          "old_line_content": "          run_metadata->mutable_partition_graphs();",
          "new_line_content": "    } else {",
          "content_same": false
        },
        {
          "line": 818,
          "old_api": "Add",
          "new_api": null,
          "old_text": "partition_graph_defs->Add()",
          "new_text": null,
          "old_line_content": "        GraphDef* partition_graph_def = partition_graph_defs->Add();",
          "new_line_content": "      for (const PerPartitionExecutorsAndLib& exec_and_lib :",
          "content_same": false
        },
        {
          "line": 819,
          "old_api": "ToGraphDef",
          "new_api": null,
          "old_text": "exec_and_lib.graph->ToGraphDef(partition_graph_def)",
          "new_text": null,
          "old_line_content": "        exec_and_lib.graph->ToGraphDef(partition_graph_def);",
          "new_line_content": "           executors_and_keys->items) {",
          "content_same": false
        },
        {
          "line": 823,
          "old_api": "NowMicros",
          "new_api": null,
          "old_text": "options_.env->NowMicros()",
          "new_text": null,
          "old_line_content": "  metrics::UpdateGraphExecTime(options_.env->NowMicros() - start_time_usecs);",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 834,
          "old_api": "Run",
          "new_api": null,
          "old_text": "Run(run_options, inputs, output_names, target_nodes, outputs,\n             run_metadata, thread::ThreadPoolOptions())",
          "new_text": null,
          "old_line_content": "  return Run(run_options, inputs, output_names, target_nodes, outputs,",
          "new_line_content": "                          std::vector<Tensor>* outputs,",
          "content_same": false
        },
        {
          "line": 835,
          "old_api": "thread::ThreadPoolOptions()",
          "new_api": null,
          "old_text": "thread::ThreadPoolOptions()",
          "new_text": null,
          "old_line_content": "             run_metadata, thread::ThreadPoolOptions());",
          "new_line_content": "                          RunMetadata* run_metadata) {",
          "content_same": false
        },
        {
          "line": 845,
          "old_api": "CheckNotClosed",
          "new_api": null,
          "old_text": "CheckNotClosed()",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(CheckNotClosed());",
          "new_line_content": "                          RunMetadata* run_metadata,",
          "content_same": false
        },
        {
          "line": 846,
          "old_api": "CheckGraphCreated",
          "new_api": null,
          "old_text": "CheckGraphCreated(\"Run()\")",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(CheckGraphCreated(\"Run()\"));",
          "new_line_content": "                          const thread::ThreadPoolOptions& threadpool_options) {",
          "content_same": false
        },
        {
          "line": 851,
          "old_api": "size",
          "new_api": null,
          "old_text": "inputs.size()",
          "new_text": null,
          "old_line_content": "  input_tensor_names.reserve(inputs.size());",
          "new_line_content": "  // Extract the inputs names for this run of the session.",
          "content_same": false
        },
        {
          "line": 854,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "input_tensor_names.push_back(it.first)",
          "new_text": null,
          "old_line_content": "    input_tensor_names.push_back(it.first);",
          "new_line_content": "  size_t input_size = 0;",
          "content_same": false
        },
        {
          "line": 855,
          "old_api": "AllocatedBytes",
          "new_api": null,
          "old_text": "it.second.AllocatedBytes()",
          "new_text": null,
          "old_line_content": "    input_size += it.second.AllocatedBytes();",
          "new_line_content": "  for (const auto& it : inputs) {",
          "content_same": false
        },
        {
          "line": 861,
          "old_api": "debug_options",
          "new_api": null,
          "old_text": "run_options.debug_options()",
          "new_text": null,
          "old_line_content": "  RunStateArgs run_state_args(run_options.debug_options());",
          "new_line_content": "  // Check if we already have an executor for these arguments.",
          "content_same": false
        },
        {
          "line": 877,
          "old_api": "size",
          "new_api": null,
          "old_text": "inputs.size()",
          "new_text": null,
          "old_line_content": "  gtl::InlinedVector<Tensor, 4> feed_args(inputs.size());",
          "new_line_content": "  FunctionCallFrame call_frame(executors_and_keys->input_types,",
          "content_same": false
        },
        {
          "line": 882,
          "old_api": "ResourceHandleToInputTensor",
          "new_api": null,
          "old_text": "ResourceHandleToInputTensor(it.second, &tensor_from_handle)",
          "new_text": null,
          "old_line_content": "          ResourceHandleToInputTensor(it.second, &tensor_from_handle));",
          "new_line_content": "      Tensor tensor_from_handle;",
          "content_same": false
        },
        {
          "line": 889,
          "old_api": "SetArgs",
          "new_api": null,
          "old_text": "call_frame.SetArgs(feed_args)",
          "new_text": null,
          "old_line_content": "  const Status s = call_frame.SetArgs(feed_args);",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 890,
          "old_api": "errors::IsInternal(s)",
          "new_api": null,
          "old_text": "errors::IsInternal(s)",
          "new_text": null,
          "old_line_content": "  if (errors::IsInternal(s)) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 896,
          "old_api": "fetch_add",
          "new_api": null,
          "old_text": "step_id_counter_.fetch_add(1)",
          "new_text": null,
          "old_line_content": "  const int64_t step_id = step_id_counter_.fetch_add(1);",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 899,
          "old_api": "LogMemory::RecordStep(step_id, run_state_args.handle)",
          "new_api": null,
          "old_text": "LogMemory::RecordStep(step_id, run_state_args.handle)",
          "new_text": null,
          "old_line_content": "    LogMemory::RecordStep(step_id, run_state_args.handle);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 902,
          "old_api": "RunInternal",
          "new_api": null,
          "old_text": "RunInternal(step_id, run_options, &call_frame,\n                                 executors_and_keys, run_metadata,\n                                 threadpool_options)",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(RunInternal(step_id, run_options, &call_frame,",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 909,
          "old_api": "ConsumeRetvals",
          "new_api": null,
          "old_text": "call_frame.ConsumeRetvals(\n        &sorted_outputs, /* allow_dead_tensors = */ false)",
          "new_text": null,
          "old_line_content": "    const Status s = call_frame.ConsumeRetvals(",
          "new_line_content": "  if (outputs) {",
          "content_same": false
        },
        {
          "line": 912,
          "old_api": "error_message",
          "new_api": null,
          "old_text": "s.error_message()",
          "new_text": null,
          "old_line_content": "      return errors::InvalidArgument(s.error_message());",
          "new_line_content": "        &sorted_outputs, /* allow_dead_tensors = */ false);",
          "content_same": false
        },
        {
          "line": 917,
          "old_api": "size",
          "new_api": null,
          "old_text": "executors_and_keys->output_name_to_index.size()",
          "new_text": null,
          "old_line_content": "        output_names.size() == executors_and_keys->output_name_to_index.size();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 922,
          "old_api": "size",
          "new_api": null,
          "old_text": "output_names.size()",
          "new_text": null,
          "old_line_content": "      first_indices.reserve(output_names.size());",
          "new_line_content": "    std::vector<int> first_indices;",
          "content_same": false
        },
        {
          "line": 925,
          "old_api": "end",
          "new_api": null,
          "old_text": "output_names.end()",
          "new_text": null,
          "old_line_content": "            std::find(output_names.begin(), output_names.end(), name) -",
          "new_line_content": "      for (const auto& name : output_names) {",
          "content_same": false
        },
        {
          "line": 929,
          "old_api": "clear",
          "new_api": null,
          "old_text": "outputs->clear()",
          "new_text": null,
          "old_line_content": "    outputs->clear();",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 932,
          "old_api": "size",
          "new_api": null,
          "old_text": "output_names.size()",
          "new_text": null,
          "old_line_content": "    for (int i = 0; i < output_names.size(); ++i) {",
          "new_line_content": "    size_t output_size = 0;",
          "content_same": false
        },
        {
          "line": 935,
          "old_api": "emplace_back",
          "new_api": null,
          "old_text": "outputs->emplace_back(\n            std::move(sorted_outputs[executors_and_keys\n                                         ->output_name_to_index[output_name]]))",
          "new_text": null,
          "old_line_content": "        outputs->emplace_back(",
          "new_line_content": "      const string& output_name = output_names[i];",
          "content_same": false
        },
        {
          "line": 939,
          "old_api": "push_back",
          "new_api": null,
          "old_text": "outputs->push_back((*outputs)[first_indices[i]])",
          "new_text": null,
          "old_line_content": "        outputs->push_back((*outputs)[first_indices[i]]);",
          "new_line_content": "                                         ->output_name_to_index[output_name]]));",
          "content_same": false
        },
        {
          "line": 946,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "  return Status::OK();",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 953,
          "old_api": "CheckNotClosed",
          "new_api": null,
          "old_text": "CheckNotClosed()",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(CheckNotClosed());",
          "new_line_content": "                                const std::vector<string>& target_nodes,",
          "content_same": false
        },
        {
          "line": 954,
          "old_api": "CheckGraphCreated",
          "new_api": null,
          "old_text": "CheckGraphCreated(\"PRunSetup()\")",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(CheckGraphCreated(\"PRunSetup()\"));",
          "new_line_content": "                                string* handle) {",
          "content_same": false
        },
        {
          "line": 965,
          "old_api": "GetOrCreateExecutors",
          "new_api": null,
          "old_text": "GetOrCreateExecutors(input_names, output_names,\n                                          target_nodes, &executors_and_keys,\n                                          &run_state_args)",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(GetOrCreateExecutors(input_names, output_names,",
          "new_line_content": "  RunStateArgs run_state_args(debug_options);",
          "content_same": false
        },
        {
          "line": 971,
          "old_api": "fetch_add",
          "new_api": null,
          "old_text": "step_id_counter_.fetch_add(1)",
          "new_text": null,
          "old_line_content": "  args.step_id = step_id_counter_.fetch_add(1);",
          "new_line_content": "  // Create the run state and save it for future PRun calls.",
          "content_same": false
        },
        {
          "line": 974,
          "old_api": "get",
          "new_api": null,
          "old_text": "device_mgr_.get()",
          "new_text": null,
          "old_line_content": "  run_state->rendez.reset(new IntraProcessRendezvous(device_mgr_.get()));",
          "new_line_content": "  PartialRunState* run_state =",
          "content_same": false
        },
        {
          "line": 977,
          "old_api": "emplace",
          "new_api": null,
          "old_text": "partial_runs_\n             .emplace(run_state_args.handle,\n                      std::unique_ptr<PartialRunState>(run_state))",
          "new_text": null,
          "old_line_content": "    if (!partial_runs_",
          "new_line_content": "  {",
          "content_same": false
        },
        {
          "line": 987,
          "old_api": "size",
          "new_api": null,
          "old_text": "executors_and_keys->items.size()",
          "new_text": null,
          "old_line_content": "  const size_t num_executors = executors_and_keys->items.size();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 990,
          "old_api": "ok",
          "new_api": null,
          "old_text": "ret.ok()",
          "new_text": null,
          "old_line_content": "        if (!ret.ok()) {",
          "new_line_content": "  ExecutorBarrier* barrier = new ExecutorBarrier(",
          "content_same": false
        },
        {
          "line": 997,
          "old_api": "get",
          "new_api": null,
          "old_text": "run_state->rendez.get()",
          "new_text": null,
          "old_line_content": "  args.rendezvous = run_state->rendez.get();",
          "new_line_content": "      });",
          "content_same": false
        },
        {
          "line": 1004,
          "old_api": "std::move(c)",
          "new_api": null,
          "old_text": "std::move(c)",
          "new_text": null,
          "old_line_content": "    pool->Schedule(std::move(c));",
          "new_line_content": "  args.collective_executor = nullptr;",
          "content_same": false
        },
        {
          "line": 1010,
          "old_api": "LogMemory::IsEnabled()",
          "new_api": null,
          "old_text": "LogMemory::IsEnabled()",
          "new_text": null,
          "old_line_content": "  if (LogMemory::IsEnabled()) {",
          "new_line_content": "  args.tensor_store = &run_state->tensor_store;",
          "content_same": false
        },
        {
          "line": 1011,
          "old_api": "LogMemory::RecordStep(args.step_id, run_state_args.handle)",
          "new_api": null,
          "old_text": "LogMemory::RecordStep(args.step_id, run_state_args.handle)",
          "new_text": null,
          "old_line_content": "    LogMemory::RecordStep(args.step_id, run_state_args.handle);",
          "new_line_content": "  args.step_container = &run_state->step_container;",
          "content_same": false
        },
        {
          "line": 1015,
          "old_api": "graph_options",
          "new_api": null,
          "old_text": "options_.config.graph_options().build_cost_model()",
          "new_text": null,
          "old_line_content": "  if (options_.config.graph_options().build_cost_model()) {",
          "new_line_content": "  args.sync_on_finish = sync_on_finish_;",
          "content_same": false
        },
        {
          "line": 1016,
          "old_api": "reset",
          "new_api": null,
          "old_text": "run_state->collector.reset(new StepStatsCollector(nullptr))",
          "new_text": null,
          "old_line_content": "    run_state->collector.reset(new StepStatsCollector(nullptr));",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1021,
          "old_api": "Get",
          "new_api": null,
          "old_text": "barrier->Get()",
          "new_text": null,
          "old_line_content": "    item.executor->RunAsync(args, barrier->Get());",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1025,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "  return Status::OK();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1031,
          "old_api": "CheckNotClosed",
          "new_api": null,
          "old_text": "CheckNotClosed()",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(CheckNotClosed());",
          "new_line_content": "                           const std::vector<string>& output_names,",
          "content_same": false
        },
        {
          "line": 1032,
          "old_api": "str_util::Split(handle, ';')",
          "new_api": null,
          "old_text": "str_util::Split(handle, ';')",
          "new_text": null,
          "old_line_content": "  std::vector<string> parts = str_util::Split(handle, ';');",
          "new_line_content": "                           std::vector<Tensor>* outputs) {",
          "content_same": false
        },
        {
          "line": 1039,
          "old_api": "find",
          "new_api": null,
          "old_text": "executors_.find(key)",
          "new_text": null,
          "old_line_content": "    auto exc_it = executors_.find(key);",
          "new_line_content": "  {",
          "content_same": false
        },
        {
          "line": 1040,
          "old_api": "end",
          "new_api": null,
          "old_text": "executors_.end()",
          "new_text": null,
          "old_line_content": "    if (exc_it == executors_.end()) {",
          "new_line_content": "    mutex_lock l(executor_lock_);  // could use reader lock",
          "content_same": false
        },
        {
          "line": 1044,
          "old_api": "get",
          "new_api": null,
          "old_text": "exc_it->second.get()",
          "new_text": null,
          "old_line_content": "    executors_and_keys = exc_it->second.get();",
          "new_line_content": "          \"Must run 'setup' before performing partial runs!\");",
          "content_same": false
        },
        {
          "line": 1047,
          "old_api": "end",
          "new_api": null,
          "old_text": "partial_runs_.end()",
          "new_text": null,
          "old_line_content": "    if (prun_it == partial_runs_.end()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1051,
          "old_api": "get",
          "new_api": null,
          "old_text": "prun_it->second.get()",
          "new_text": null,
          "old_line_content": "    run_state = prun_it->second.get();",
          "new_line_content": "          \"Must run 'setup' before performing partial runs!\");",
          "content_same": false
        },
        {
          "line": 1055,
          "old_api": "find",
          "new_api": null,
          "old_text": "run_state->pending_inputs.find(input.first)",
          "new_text": null,
          "old_line_content": "      auto it = run_state->pending_inputs.find(input.first);",
          "new_line_content": "    // Make sure that this is a new set of feeds that are still pending.",
          "content_same": false
        },
        {
          "line": 1056,
          "old_api": "end",
          "new_api": null,
          "old_text": "run_state->pending_inputs.end()",
          "new_text": null,
          "old_line_content": "      if (it == run_state->pending_inputs.end()) {",
          "new_line_content": "    for (const auto& input : inputs) {",
          "content_same": false
        },
        {
          "line": 1061,
          "old_api": "errors::InvalidArgument(\"The feed \", input.first,\n                                       \" has already been fed.\")",
          "new_api": null,
          "old_text": "errors::InvalidArgument(\"The feed \", input.first,\n                                       \" has already been fed.\")",
          "new_text": null,
          "old_line_content": "        return errors::InvalidArgument(\"The feed \", input.first,",
          "new_line_content": "            \" was not specified in partial_run_setup.\");",
          "content_same": false
        },
        {
          "line": 1067,
          "old_api": "find",
          "new_api": null,
          "old_text": "run_state->pending_outputs.find(output)",
          "new_text": null,
          "old_line_content": "      auto it = run_state->pending_outputs.find(output);",
          "new_line_content": "    // Check that this is a new set of fetches that are still pending.",
          "content_same": false
        },
        {
          "line": 1068,
          "old_api": "end",
          "new_api": null,
          "old_text": "run_state->pending_outputs.end()",
          "new_text": null,
          "old_line_content": "      if (it == run_state->pending_outputs.end()) {",
          "new_line_content": "    for (const auto& output : output_names) {",
          "content_same": false
        },
        {
          "line": 1072,
          "old_api": "errors::InvalidArgument(\"The fetch \", output,\n                                       \" has already been fetched.\")",
          "new_api": null,
          "old_text": "errors::InvalidArgument(\"The fetch \", output,\n                                       \" has already been fetched.\")",
          "new_text": null,
          "old_line_content": "        return errors::InvalidArgument(\"The fetch \", output,",
          "new_line_content": "            \"The fetch \", output, \" was not specified in partial_run_setup.\");",
          "content_same": false
        },
        {
          "line": 1080,
          "old_api": "TF_RETURN_IF_ERROR",
          "new_api": null,
          "old_text": "TF_RETURN_IF_ERROR(\n      CheckFetch(inputs, output_names, executors_and_keys, run_state))",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(",
          "new_line_content": "  // Check that this new set of fetches can be computed from all the",
          "content_same": false
        },
        {
          "line": 1081,
          "old_api": "CheckFetch",
          "new_api": null,
          "old_text": "CheckFetch(inputs, output_names, executors_and_keys, run_state)",
          "new_text": null,
          "old_line_content": "      CheckFetch(inputs, output_names, executors_and_keys, run_state));",
          "new_line_content": "  // feeds we have supplied.",
          "content_same": false
        },
        {
          "line": 1085,
          "old_api": "get",
          "new_api": null,
          "old_text": "run_state->rendez.get()",
          "new_text": null,
          "old_line_content": "      SendPRunInputs(inputs, executors_and_keys, run_state->rendez.get());",
          "new_line_content": "  // Send inputs.",
          "content_same": false
        },
        {
          "line": 1088,
          "old_api": "ok",
          "new_api": null,
          "old_text": "s.ok()",
          "new_text": null,
          "old_line_content": "  if (s.ok()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1089,
          "old_api": "RecvPRunOutputs",
          "new_api": null,
          "old_text": "RecvPRunOutputs(output_names, executors_and_keys, run_state, outputs)",
          "new_text": null,
          "old_line_content": "    s = RecvPRunOutputs(output_names, executors_and_keys, run_state, outputs);",
          "new_line_content": "  // Receive outputs.",
          "content_same": false
        },
        {
          "line": 1093,
          "old_api": "ok",
          "new_api": null,
          "old_text": "s.ok()",
          "new_text": null,
          "old_line_content": "  if (s.ok()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1094,
          "old_api": "SaveTensors",
          "new_api": null,
          "old_text": "run_state->tensor_store.SaveTensors(output_names, &session_state_)",
          "new_text": null,
          "old_line_content": "    s = run_state->tensor_store.SaveTensors(output_names, &session_state_);",
          "new_line_content": "  // Save the output tensors of this run we choose to keep.",
          "content_same": false
        },
        {
          "line": 1101,
          "old_api": "ok",
          "new_api": null,
          "old_text": "s.ok()",
          "new_text": null,
          "old_line_content": "    if (s.ok()) {",
          "new_line_content": "    // Delete the run state if there is an error or all fetches are done.",
          "content_same": false
        },
        {
          "line": 1104,
          "old_api": "ok",
          "new_api": null,
          "old_text": "run_state->status.ok()",
          "new_text": null,
          "old_line_content": "        if (!run_state->status.ok()) {",
          "new_line_content": "      {",
          "content_same": false
        },
        {
          "line": 1105,
          "old_api": "LOG",
          "new_api": null,
          "old_text": "LOG(WARNING)",
          "new_text": null,
          "old_line_content": "          LOG(WARNING) << \"An error unrelated to this prun has been detected. \"",
          "new_line_content": "        mutex_lock l(run_state->mu);",
          "content_same": false
        },
        {
          "line": 1110,
          "old_api": "find",
          "new_api": null,
          "old_text": "run_state->pending_inputs.find(input.first)",
          "new_text": null,
          "old_line_content": "        auto it = run_state->pending_inputs.find(input.first);",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 1114,
          "old_api": "find",
          "new_api": null,
          "old_text": "run_state->pending_outputs.find(name)",
          "new_text": null,
          "old_line_content": "        auto it = run_state->pending_outputs.find(name);",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 1117,
          "old_api": "PendingDone",
          "new_api": null,
          "old_text": "run_state->PendingDone()",
          "new_text": null,
          "old_line_content": "      done = run_state->PendingDone();",
          "new_line_content": "        it->second = true;",
          "content_same": false
        },
        {
          "line": 1120,
          "old_api": "WaitForNotification",
          "new_api": null,
          "old_text": "WaitForNotification(&run_state->executors_done, run_state,\n                          cancellation_manager_, operation_timeout_in_ms_)",
          "new_text": null,
          "old_line_content": "      WaitForNotification(&run_state->executors_done, run_state,",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 1131,
          "old_api": "dtype",
          "new_api": null,
          "old_text": "resource_tensor.dtype()",
          "new_text": null,
          "old_line_content": "  if (resource_tensor.dtype() != DT_RESOURCE) {",
          "new_line_content": "Status DirectSession::ResourceHandleToInputTensor(const Tensor& resource_tensor,",
          "content_same": false
        },
        {
          "line": 1132,
          "old_api": "dtype",
          "new_api": null,
          "old_text": "strings::StrCat(\n        \"ResourceHandleToInputTensor() received non-DT_RESOURCE Tensor: \",\n        resource_tensor.dtype())",
          "new_text": null,
          "old_line_content": "    return errors::InvalidArgument(strings::StrCat(",
          "new_line_content": "                                                  Tensor* retrieved_tensor) {",
          "content_same": false
        },
        {
          "line": 1138,
          "old_api": "resource_tensor.scalar<ResourceHandle>()()",
          "new_api": null,
          "old_text": "resource_tensor.scalar<ResourceHandle>()()",
          "new_text": null,
          "old_line_content": "      resource_tensor.scalar<ResourceHandle>()();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1145,
          "old_api": "hash_code",
          "new_api": null,
          "old_text": "resource_handle.hash_code()",
          "new_text": null,
          "old_line_content": "        \"Invalid resource type hash code: \", resource_handle.hash_code(),",
          "new_line_content": "  } else {",
          "content_same": false
        },
        {
          "line": 1164,
          "old_api": "find",
          "new_api": null,
          "old_text": "executors_and_keys->input_name_to_rendezvous_key.find(input.first)",
          "new_text": null,
          "old_line_content": "        executors_and_keys->input_name_to_rendezvous_key.find(input.first);",
          "new_line_content": "  for (const auto& input : inputs) {",
          "content_same": false
        },
        {
          "line": 1165,
          "old_api": "end",
          "new_api": null,
          "old_text": "executors_and_keys->input_name_to_rendezvous_key.end()",
          "new_text": null,
          "old_line_content": "    if (it == executors_and_keys->input_name_to_rendezvous_key.end()) {",
          "new_line_content": "    auto it =",
          "content_same": false
        },
        {
          "line": 1170,
          "old_api": "Rendezvous::ParseKey(input_key, &parsed)",
          "new_api": null,
          "old_text": "Rendezvous::ParseKey(input_key, &parsed)",
          "new_text": null,
          "old_line_content": "    s = Rendezvous::ParseKey(input_key, &parsed);",
          "new_line_content": "    const string& input_key = it->second;",
          "content_same": false
        },
        {
          "line": 1171,
          "old_api": "ok",
          "new_api": null,
          "old_text": "s.ok()",
          "new_text": null,
          "old_line_content": "    if (!s.ok()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1176,
          "old_api": "dtype",
          "new_api": null,
          "old_text": "input.second.dtype()",
          "new_text": null,
          "old_line_content": "    if (input.second.dtype() == DT_RESOURCE) {",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 1179,
          "old_api": "ok",
          "new_api": null,
          "old_text": "s.ok()",
          "new_text": null,
          "old_line_content": "      if (s.ok()) {",
          "new_line_content": "      Tensor tensor_from_handle;",
          "content_same": false
        },
        {
          "line": 1183,
          "old_api": "Rendezvous::Args()",
          "new_api": null,
          "old_text": "Rendezvous::Args()",
          "new_text": null,
          "old_line_content": "      s = rendez->Send(parsed, Rendezvous::Args(), input.second, false);",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 1186,
          "old_api": "ok",
          "new_api": null,
          "old_text": "s.ok()",
          "new_text": null,
          "old_line_content": "    if (!s.ok()) {",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 1187,
          "old_api": "StartAbort",
          "new_api": null,
          "old_text": "rendez->StartAbort(s)",
          "new_text": null,
          "old_line_content": "      rendez->StartAbort(s);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1191,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "  return Status::OK();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 1199,
          "old_api": "empty",
          "new_api": null,
          "old_text": "output_names.empty()",
          "new_text": null,
          "old_line_content": "  if (!output_names.empty()) {",
          "new_line_content": "    std::vector<Tensor>* outputs) {",
          "content_same": false
        },
        {
          "line": 1200,
          "old_api": "size",
          "new_api": null,
          "old_text": "output_names.size()",
          "new_text": null,
          "old_line_content": "    outputs->resize(output_names.size());",
          "new_line_content": "  Status s;",
          "content_same": false
        },
        {
          "line": 1205,
          "old_api": "size",
          "new_api": null,
          "old_text": "output_names.size()",
          "new_text": null,
          "old_line_content": "  for (size_t output_offset = 0; output_offset < output_names.size();",
          "new_line_content": "  Rendezvous::ParsedKey parsed;",
          "content_same": false
        },
        {
          "line": 1209,
          "old_api": "find",
          "new_api": null,
          "old_text": "executors_and_keys->output_name_to_rendezvous_key.find(output_name)",
          "new_text": null,
          "old_line_content": "        executors_and_keys->output_name_to_rendezvous_key.find(output_name);",
          "new_line_content": "    const string& output_name = output_names[output_offset];",
          "content_same": false
        },
        {
          "line": 1210,
          "old_api": "end",
          "new_api": null,
          "old_text": "executors_and_keys->output_name_to_rendezvous_key.end()",
          "new_text": null,
          "old_line_content": "    if (it == executors_and_keys->output_name_to_rendezvous_key.end()) {",
          "new_line_content": "    auto it =",
          "content_same": false
        },
        {
          "line": 1218,
          "old_api": "Rendezvous::ParseKey(output_key, &parsed)",
          "new_api": null,
          "old_text": "Rendezvous::ParseKey(output_key, &parsed)",
          "new_text": null,
          "old_line_content": "    s = Rendezvous::ParseKey(output_key, &parsed);",
          "new_line_content": "    bool is_dead;",
          "content_same": false
        },
        {
          "line": 1219,
          "old_api": "ok",
          "new_api": null,
          "old_text": "s.ok()",
          "new_text": null,
          "old_line_content": "    if (s.ok()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1224,
          "old_api": "errors::InvalidArgument(\"The tensor returned for \", output_name,\n                                    \" was not valid.\")",
          "new_api": null,
          "old_text": "errors::InvalidArgument(\"The tensor returned for \", output_name,\n                                    \" was not valid.\")",
          "new_text": null,
          "old_line_content": "        s = errors::InvalidArgument(\"The tensor returned for \", output_name,",
          "new_line_content": "                                  &is_dead, operation_timeout_in_ms_);",
          "content_same": false
        },
        {
          "line": 1228,
          "old_api": "ok",
          "new_api": null,
          "old_text": "s.ok()",
          "new_text": null,
          "old_line_content": "    if (!s.ok()) {",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 1229,
          "old_api": "StartAbort",
          "new_api": null,
          "old_text": "run_state->rendez->StartAbort(s)",
          "new_text": null,
          "old_line_content": "      run_state->rendez->StartAbort(s);",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 1236,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "  return Status::OK();",
          "new_line_content": "    (*outputs)[output_offset] = output_tensor;",
          "content_same": false
        },
        {
          "line": 1243,
          "old_api": "get",
          "new_api": null,
          "old_text": "executors_and_keys->graph.get()",
          "new_text": null,
          "old_line_content": "  const Graph* graph = executors_and_keys->graph.get();",
          "new_line_content": "                                 const ExecutorsAndKeys* executors_and_keys,",
          "content_same": false
        },
        {
          "line": 1253,
          "old_api": "ParseTensorName",
          "new_api": null,
          "old_text": "ParseTensorName(input.first)",
          "new_text": null,
          "old_line_content": "      TensorId id(ParseTensorName(input.first));",
          "new_line_content": "      // Skip if the feed has already been fed.",
          "content_same": false
        },
        {
          "line": 1254,
          "old_api": "find",
          "new_api": null,
          "old_text": "name_to_node->find(id.first)",
          "new_text": null,
          "old_line_content": "      auto it = name_to_node->find(id.first);",
          "new_line_content": "      if (input.second) continue;",
          "content_same": false
        },
        {
          "line": 1262,
          "old_api": "ParseTensorName",
          "new_api": null,
          "old_text": "ParseTensorName(it.first)",
          "new_text": null,
          "old_line_content": "    TensorId id(ParseTensorName(it.first));",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 1263,
          "old_api": "erase",
          "new_api": null,
          "old_text": "pending_feeds.erase(id)",
          "new_text": null,
          "old_line_content": "    pending_feeds.erase(id);",
          "new_line_content": "  for (const auto& it : feeds) {",
          "content_same": false
        },
        {
          "line": 1270,
          "old_api": "find",
          "new_api": null,
          "old_text": "name_to_node->find(id.first)",
          "new_text": null,
          "old_line_content": "    auto it = name_to_node->find(id.first);",
          "new_line_content": "  for (const string& fetch : fetches) {",
          "content_same": false
        },
        {
          "line": 1271,
          "old_api": "end",
          "new_api": null,
          "old_text": "name_to_node->end()",
          "new_text": null,
          "old_line_content": "    if (it == name_to_node->end()) {",
          "new_line_content": "    TensorId id(ParseTensorName(fetch));",
          "content_same": false
        },
        {
          "line": 1278,
          "old_api": "num_node_ids",
          "new_api": null,
          "old_text": "graph->num_node_ids()",
          "new_text": null,
          "old_line_content": "  std::vector<bool> visited(graph->num_node_ids(), false);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1279,
          "old_api": "empty",
          "new_api": null,
          "old_text": "stack.empty()",
          "new_text": null,
          "old_line_content": "  while (!stack.empty()) {",
          "new_line_content": "  // Any tensor needed for fetches can't be in pending_feeds.",
          "content_same": false
        },
        {
          "line": 1284,
          "old_api": "src",
          "new_api": null,
          "old_text": "in_edge->src()",
          "new_text": null,
          "old_line_content": "      const Node* in_node = in_edge->src();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1291,
          "old_api": "id",
          "new_api": null,
          "old_text": "in_node->id()",
          "new_text": null,
          "old_line_content": "      if (!visited[in_node->id()]) {",
          "new_line_content": "                                       \" that have been fed so far.\");",
          "content_same": false
        },
        {
          "line": 1292,
          "old_api": "id",
          "new_api": null,
          "old_text": "in_node->id()",
          "new_text": null,
          "old_line_content": "        visited[in_node->id()] = true;",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 1297,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "  return Status::OK();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 1309,
          "old_api": "run_options",
          "new_api": null,
          "old_text": "callable_options.run_options().experimental().collective_graph_key()",
          "new_text": null,
          "old_line_content": "      callable_options.run_options().experimental().collective_graph_key();",
          "new_line_content": "  options.use_function_convention = !run_state_args->is_partial_run;",
          "content_same": false
        },
        {
          "line": 1310,
          "old_api": "experimental",
          "new_api": null,
          "old_text": "options_.config.experimental()\n          .collective_deterministic_sequential_execution()",
          "new_text": null,
          "old_line_content": "  if (options_.config.experimental()",
          "new_line_content": "  options.collective_graph_key =",
          "content_same": false
        },
        {
          "line": 1313,
          "old_api": "experimental",
          "new_api": null,
          "old_text": "options_.config.experimental().collective_nccl()",
          "new_text": null,
          "old_line_content": "  } else if (options_.config.experimental().collective_nccl()) {",
          "new_line_content": "          .collective_deterministic_sequential_execution()) {",
          "content_same": false
        },
        {
          "line": 1323,
          "old_api": "CreateGraphs",
          "new_api": null,
          "old_text": "CreateGraphs(\n      options, &graphs, &func_info->flib_def, run_state_args, &ek->input_types,\n      &ek->output_types, &ek->collective_graph_key)",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(CreateGraphs(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1328,
          "old_api": "std::move(run_state_args->graph)",
          "new_api": null,
          "old_text": "std::move(run_state_args->graph)",
          "new_text": null,
          "old_line_content": "    ek->graph = std::move(run_state_args->graph);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1339,
          "old_api": "name",
          "new_api": null,
          "old_text": "n->name()",
          "new_text": null,
          "old_line_content": "      if (names.count(n->name()) > 0) {",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 1344,
          "old_api": "size",
          "new_api": null,
          "old_text": "graphs.size()",
          "new_text": null,
          "old_line_content": "  ek->items.reserve(graphs.size());",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 1351,
          "old_api": "experimental",
          "new_api": null,
          "old_text": "options_.config.experimental().has_session_metadata()",
          "new_text": null,
          "old_line_content": "      options_.config.experimental().has_session_metadata()",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1352,
          "old_api": "experimental",
          "new_api": null,
          "old_text": "options_.config.experimental().session_metadata()",
          "new_text": null,
          "old_line_content": "          ? &options_.config.experimental().session_metadata()",
          "new_line_content": "  const auto* session_metadata =",
          "content_same": false
        },
        {
          "line": 1355,
          "old_api": "get",
          "new_api": null,
          "old_text": "device_mgr_.get()",
          "new_text": null,
          "old_line_content": "      device_mgr_.get(), options_.env, &options_.config, graph_def_version,",
          "new_line_content": "          : nullptr;",
          "content_same": false
        },
        {
          "line": 1361,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "            return Status::OK();",
          "new_line_content": "          [](const int64_t, const DeviceMgr* device_mgr, Rendezvous** r) {",
          "content_same": false
        },
        {
          "line": 1365,
          "old_api": "end",
          "new_api": null,
          "old_text": "graphs.end()",
          "new_text": null,
          "old_line_content": "  for (auto iter = graphs.begin(); iter != graphs.end(); ++iter) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1370,
          "old_api": "LookupDevice",
          "new_api": null,
          "old_text": "device_mgr_->LookupDevice(partition_name, &device)",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(device_mgr_->LookupDevice(partition_name, &device));",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1373,
          "old_api": "back",
          "new_api": null,
          "old_text": "ek->items.back()",
          "new_text": null,
          "old_line_content": "    auto* item = &(ek->items.back());",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1384,
          "old_api": "op_segment",
          "new_api": null,
          "old_text": "device->op_segment()",
          "new_text": null,
          "old_line_content": "    auto opseg = device->op_segment();",
          "new_line_content": "    params.session_metadata = session_metadata;",
          "content_same": false
        },
        {
          "line": 1392,
          "old_api": "op",
          "new_api": null,
          "old_text": "props->node_def.op()",
          "new_text": null,
          "old_line_content": "          if (!OpSegment::ShouldOwnKernel(lib, props->node_def.op())) {",
          "new_line_content": "          // is tied to a particular subgraph. Even if the function itself",
          "content_same": false
        },
        {
          "line": 1393,
          "old_api": "CreateKernel",
          "new_api": null,
          "old_text": "lib->CreateKernel(props, kernel)",
          "new_text": null,
          "old_line_content": "            return lib->CreateKernel(props, kernel);",
          "new_line_content": "          // is stateful, the `CallOp` that invokes it is not.",
          "content_same": false
        },
        {
          "line": 1396,
          "old_api": "CreateKernel",
          "new_api": null,
          "old_text": "lib->CreateKernel(props, kernel)",
          "new_text": null,
          "old_line_content": "            return lib->CreateKernel(props, kernel);",
          "new_line_content": "          }",
          "content_same": false
        },
        {
          "line": 1401,
          "old_api": "name",
          "new_api": null,
          "old_text": "props->node_def.name()",
          "new_text": null,
          "old_line_content": "          return opseg->FindOrCreate(session_handle_, props->node_def.name(),",
          "new_line_content": "          // cache miss, create_fn() is invoked to create a kernel based",
          "content_same": false
        },
        {
          "line": 1405,
          "old_api": "type_string",
          "new_api": null,
          "old_text": "kernel->type_string()",
          "new_text": null,
          "old_line_content": "      if (kernel && !OpSegment::ShouldOwnKernel(lib, kernel->type_string()))",
          "new_line_content": "        };",
          "content_same": false
        },
        {
          "line": 1409,
          "old_api": "Optimize",
          "new_api": null,
          "old_text": "optimizer.Optimize(lib, options_.env, device, &partition_graph,\n                       GraphOptimizer::Options())",
          "new_text": null,
          "old_line_content": "    optimizer.Optimize(lib, options_.env, device, &partition_graph,",
          "new_line_content": "    };",
          "content_same": false
        },
        {
          "line": 1410,
          "old_api": "GraphOptimizer::Options()",
          "new_api": null,
          "old_text": "GraphOptimizer::Options()",
          "new_text": null,
          "old_line_content": "                       GraphOptimizer::Options());",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1414,
          "old_api": "run_options",
          "new_api": null,
          "old_text": "options.callable_options.run_options().debug_options()",
          "new_text": null,
          "old_line_content": "        options.callable_options.run_options().debug_options();",
          "new_line_content": "    // TensorFlow Debugger (tfdbg) inserts debug nodes in the graph.",
          "content_same": false
        },
        {
          "line": 1415,
          "old_api": "debug_tensor_watch_opts",
          "new_api": null,
          "old_text": "debug_options.debug_tensor_watch_opts().empty()",
          "new_text": null,
          "old_line_content": "    if (!debug_options.debug_tensor_watch_opts().empty()) {",
          "new_line_content": "    const DebugOptions& debug_options =",
          "content_same": false
        },
        {
          "line": 1420,
          "old_api": "device_type",
          "new_api": null,
          "old_text": "device->device_type()",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(EnsureMemoryTypes(DeviceType(device->device_type()),",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 1421,
          "old_api": "name",
          "new_api": null,
          "old_text": "device->name()",
          "new_text": null,
          "old_line_content": "                                         device->name(),",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1426,
          "old_api": "experimental",
          "new_api": null,
          "old_text": "options_.config.experimental().executor_type()",
          "new_text": null,
          "old_line_content": "    auto executor_type = options_.config.experimental().executor_type();",
          "new_line_content": "    item->executor = nullptr;",
          "content_same": false
        },
        {
          "line": 1427,
          "old_api": "TF_RETURN_IF_ERROR",
          "new_api": null,
          "old_text": "TF_RETURN_IF_ERROR(\n        NewExecutor(executor_type, params, *partition_graph, &item->executor))",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(",
          "new_line_content": "    item->device = device;",
          "content_same": false
        },
        {
          "line": 1441,
          "old_api": "feed",
          "new_api": null,
          "old_text": "callable_options.feed().size()",
          "new_text": null,
          "old_line_content": "    for (int i = 0; i < callable_options.feed().size(); ++i) {",
          "new_line_content": "    // maintain a mapping from input/output names to",
          "content_same": false
        },
        {
          "line": 1442,
          "old_api": "feed",
          "new_api": null,
          "old_text": "callable_options.feed(i)",
          "new_text": null,
          "old_line_content": "      const string& input = callable_options.feed(i);",
          "new_line_content": "    // argument/return-value ordinal index.",
          "content_same": false
        },
        {
          "line": 1445,
          "old_api": "fetch",
          "new_api": null,
          "old_text": "callable_options.fetch().size()",
          "new_text": null,
          "old_line_content": "    for (int i = 0; i < callable_options.fetch().size(); ++i) {",
          "new_line_content": "      ek->input_name_to_index[input] = i;",
          "content_same": false
        },
        {
          "line": 1446,
          "old_api": "fetch",
          "new_api": null,
          "old_text": "callable_options.fetch(i)",
          "new_text": null,
          "old_line_content": "      const string& output = callable_options.fetch(i);",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 1455,
          "old_api": "feed",
          "new_api": null,
          "old_text": "callable_options.feed().size()",
          "new_text": null,
          "old_line_content": "    for (int i = 0; i < callable_options.feed().size(); ++i) {",
          "new_line_content": "    // We always use the first device as the device name portion of the",
          "content_same": false
        },
        {
          "line": 1456,
          "old_api": "feed",
          "new_api": null,
          "old_text": "callable_options.feed(i)",
          "new_text": null,
          "old_line_content": "      const string& input = callable_options.feed(i);",
          "new_line_content": "    // key, even if we're feeding another graph.",
          "content_same": false
        },
        {
          "line": 1461,
          "old_api": "fetch",
          "new_api": null,
          "old_text": "callable_options.fetch(i)",
          "new_text": null,
          "old_line_content": "      const string& output = callable_options.fetch(i);",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 1464,
          "old_api": "FrameAndIter",
          "new_api": null,
          "old_text": "FrameAndIter(0, 0)",
          "new_text": null,
          "old_line_content": "                           FrameAndIter(0, 0));",
          "new_line_content": "      ek->output_name_to_rendezvous_key[output] =",
          "content_same": false
        },
        {
          "line": 1468,
          "old_api": "std::move(ek)",
          "new_api": null,
          "old_text": "std::move(ek)",
          "new_text": null,
          "old_line_content": "  *out_executors_and_keys = std::move(ek);",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 1469,
          "old_api": "std::move(func_info)",
          "new_api": null,
          "old_text": "std::move(func_info)",
          "new_text": null,
          "old_line_content": "  *out_func_info = std::move(func_info);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1478,
          "old_api": "LogMemory::IsEnabled()",
          "new_api": null,
          "old_text": "LogMemory::IsEnabled()",
          "new_text": null,
          "old_line_content": "  if (LogMemory::IsEnabled() || run_state_args->is_partial_run) {",
          "new_line_content": "    RunStateArgs* run_state_args) {",
          "content_same": false
        },
        {
          "line": 1479,
          "old_api": "fetch_add",
          "new_api": null,
          "old_text": "handle_name_counter_.fetch_add(1)",
          "new_text": null,
          "old_line_content": "    handle_name_counter_value = handle_name_counter_.fetch_add(1);",
          "new_line_content": "  int64_t handle_name_counter_value = -1;",
          "content_same": false
        },
        {
          "line": 1483,
          "old_api": "debug_tensor_watch_opts",
          "new_api": null,
          "old_text": "run_state_args->debug_options.debug_tensor_watch_opts().empty()",
          "new_text": null,
          "old_line_content": "  if (!run_state_args->debug_options.debug_tensor_watch_opts().empty()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1484,
          "old_api": "debug_tensor_watch_opts",
          "new_api": null,
          "old_text": "SummarizeDebugTensorWatches(\n        run_state_args->debug_options.debug_tensor_watch_opts())",
          "new_text": null,
          "old_line_content": "    debug_tensor_watches_summary = SummarizeDebugTensorWatches(",
          "new_line_content": "  string debug_tensor_watches_summary;",
          "content_same": false
        },
        {
          "line": 1489,
          "old_api": "strings::StrCat(\n      absl::StrJoin(inputs, \",\"), \"->\", absl::StrJoin(outputs, \",\"), \"/\",\n      absl::StrJoin(target_nodes, \",\"), \"/\", run_state_args->is_partial_run,\n      \"/\", debug_tensor_watches_summary)",
          "new_api": null,
          "old_text": "strings::StrCat(\n      absl::StrJoin(inputs, \",\"), \"->\", absl::StrJoin(outputs, \",\"), \"/\",\n      absl::StrJoin(target_nodes, \",\"), \"/\", run_state_args->is_partial_run,\n      \"/\", debug_tensor_watches_summary)",
          "new_text": null,
          "old_line_content": "  const string key = strings::StrCat(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1490,
          "old_api": "absl::StrJoin(outputs, \",\")",
          "new_api": null,
          "old_text": "absl::StrJoin(outputs, \",\")",
          "new_text": null,
          "old_line_content": "      absl::StrJoin(inputs, \",\"), \"->\", absl::StrJoin(outputs, \",\"), \"/\",",
          "new_line_content": "  // Fast lookup path, no sorting.",
          "content_same": false
        },
        {
          "line": 1496,
          "old_api": "strings::StrCat(key, \";\", handle_name_counter_value)",
          "new_api": null,
          "old_text": "strings::StrCat(key, \";\", handle_name_counter_value)",
          "new_text": null,
          "old_line_content": "        strings::StrCat(key, \";\", handle_name_counter_value);",
          "new_line_content": "  if (handle_name_counter_value >= 0) {",
          "content_same": false
        },
        {
          "line": 1502,
          "old_api": "find",
          "new_api": null,
          "old_text": "executors_.find(key)",
          "new_text": null,
          "old_line_content": "    auto it = executors_.find(key);",
          "new_line_content": "  {",
          "content_same": false
        },
        {
          "line": 1503,
          "old_api": "end",
          "new_api": null,
          "old_text": "executors_.end()",
          "new_text": null,
          "old_line_content": "    if (it != executors_.end()) {",
          "new_line_content": "    mutex_lock l(executor_lock_);  // could use reader lock",
          "content_same": false
        },
        {
          "line": 1515,
          "old_api": "end",
          "new_api": null,
          "old_text": "inputs.end()",
          "new_text": null,
          "old_line_content": "  std::vector<string> inputs_sorted(inputs.begin(), inputs.end());",
          "new_line_content": "  // We could consider some other signature instead of sorting that",
          "content_same": false
        },
        {
          "line": 1516,
          "old_api": "end",
          "new_api": null,
          "old_text": "inputs_sorted.end()",
          "new_text": null,
          "old_line_content": "  std::sort(inputs_sorted.begin(), inputs_sorted.end());",
          "new_line_content": "  // preserves the same property to avoid the sort in the future.",
          "content_same": false
        },
        {
          "line": 1523,
          "old_api": "absl::StrJoin(inputs_sorted, \",\")",
          "new_api": null,
          "old_text": "absl::StrJoin(inputs_sorted, \",\")",
          "new_text": null,
          "old_line_content": "      absl::StrJoin(inputs_sorted, \",\"), \"->\",",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1529,
          "old_api": "strings::StrCat(sorted_key, \";\", handle_name_counter_value)",
          "new_api": null,
          "old_text": "strings::StrCat(sorted_key, \";\", handle_name_counter_value)",
          "new_text": null,
          "old_line_content": "        strings::StrCat(sorted_key, \";\", handle_name_counter_value);",
          "new_line_content": "  if (handle_name_counter_value >= 0) {",
          "content_same": false
        },
        {
          "line": 1535,
          "old_api": "find",
          "new_api": null,
          "old_text": "executors_.find(sorted_key)",
          "new_text": null,
          "old_line_content": "    auto it = executors_.find(sorted_key);",
          "new_line_content": "  {",
          "content_same": false
        },
        {
          "line": 1536,
          "old_api": "end",
          "new_api": null,
          "old_text": "executors_.end()",
          "new_text": null,
          "old_line_content": "    if (it != executors_.end()) {",
          "new_line_content": "    mutex_lock l(executor_lock_);",
          "content_same": false
        },
        {
          "line": 1546,
          "old_api": "size",
          "new_api": null,
          "old_text": "inputs_sorted.size()",
          "new_text": null,
          "old_line_content": "  callable_options.mutable_feed()->Reserve(inputs_sorted.size());",
          "new_line_content": "  // being created.",
          "content_same": false
        },
        {
          "line": 1565,
          "old_api": "TF_RETURN_IF_ERROR",
          "new_api": null,
          "old_text": "TF_RETURN_IF_ERROR(\n      CreateExecutors(callable_options, &ek, &func_info, run_state_args))",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(",
          "new_line_content": "  std::unique_ptr<ExecutorsAndKeys> ek;",
          "content_same": false
        },
        {
          "line": 1566,
          "old_api": "CreateExecutors",
          "new_api": null,
          "old_text": "CreateExecutors(callable_options, &ek, &func_info, run_state_args)",
          "new_text": null,
          "old_line_content": "      CreateExecutors(callable_options, &ek, &func_info, run_state_args));",
          "new_line_content": "  std::unique_ptr<FunctionInfo> func_info;",
          "content_same": false
        },
        {
          "line": 1573,
          "old_api": "emplace",
          "new_api": null,
          "old_text": "executors_.emplace(\n      sorted_key, std::shared_ptr<ExecutorsAndKeys>(std::move(ek)))",
          "new_text": null,
          "old_line_content": "  auto insert_result = executors_.emplace(",
          "new_line_content": "  // Another thread may have created the entry before us, in which case we will",
          "content_same": false
        },
        {
          "line": 1574,
          "old_api": "std::move(ek)",
          "new_api": null,
          "old_text": "std::move(ek)",
          "new_text": null,
          "old_line_content": "      sorted_key, std::shared_ptr<ExecutorsAndKeys>(std::move(ek)));",
          "new_line_content": "  // reuse the already created one.",
          "content_same": false
        },
        {
          "line": 1581,
          "old_api": "emplace",
          "new_api": null,
          "old_text": "executors_.emplace(key, insert_result.first->second)",
          "new_text": null,
          "old_line_content": "  executors_.emplace(key, insert_result.first->second);",
          "new_line_content": "  // Insert the value under the original key, so the fast path lookup will work",
          "content_same": false
        },
        {
          "line": 1582,
          "old_api": "get",
          "new_api": null,
          "old_text": "insert_result.first->second.get()",
          "new_text": null,
          "old_line_content": "  *executors_and_keys = insert_result.first->second.get();",
          "new_line_content": "  // if the user uses the same order of inputs, outputs, and targets again.",
          "content_same": false
        },
        {
          "line": 1595,
          "old_api": "errors::FailedPrecondition(\"Session has been finalized.\")",
          "new_api": null,
          "old_text": "errors::FailedPrecondition(\"Session has been finalized.\")",
          "new_text": null,
          "old_line_content": "    return errors::FailedPrecondition(\"Session has been finalized.\");",
          "new_line_content": "  mutex_lock l(graph_state_lock_);",
          "content_same": false
        },
        {
          "line": 1602,
          "old_api": "graph_options",
          "new_api": null,
          "old_text": "options_.config.graph_options().place_pruned_graph()",
          "new_text": null,
          "old_line_content": "  if (options_.config.graph_options().place_pruned_graph()) {",
          "new_line_content": "  std::unique_ptr<GraphExecutionState> temp_exec_state_holder;",
          "content_same": false
        },
        {
          "line": 1611,
          "old_api": "GraphExecutionState::MakeForPrunedGraph(\n        *execution_state_, prune_options, subgraph_options,\n        &temp_exec_state_holder, &client_graph)",
          "new_api": null,
          "old_text": "GraphExecutionState::MakeForPrunedGraph(\n        *execution_state_, prune_options, subgraph_options,\n        &temp_exec_state_holder, &client_graph)",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(GraphExecutionState::MakeForPrunedGraph(",
          "new_line_content": "    prune_options.stateful_placements = stateful_placements_;",
          "content_same": false
        },
        {
          "line": 1614,
          "old_api": "get",
          "new_api": null,
          "old_text": "temp_exec_state_holder.get()",
          "new_text": null,
          "old_line_content": "    execution_state = temp_exec_state_holder.get();",
          "new_line_content": "        *execution_state_, prune_options, subgraph_options,",
          "content_same": false
        },
        {
          "line": 1617,
          "old_api": "BuildGraph",
          "new_api": null,
          "old_text": "TF_RETURN_IF_ERROR(\n        execution_state->BuildGraph(subgraph_options, &client_graph))",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(",
          "new_line_content": "  } else {",
          "content_same": false
        },
        {
          "line": 1622,
          "old_api": "feed_size",
          "new_api": null,
          "old_text": "subgraph_options.callable_options.feed_size()",
          "new_text": null,
          "old_line_content": "  if (subgraph_options.callable_options.feed_size() !=",
          "new_line_content": "  *collective_graph_key = client_graph->collective_graph_key;",
          "content_same": false
        },
        {
          "line": 1623,
          "old_api": "size",
          "new_api": null,
          "old_text": "client_graph->feed_types.size()",
          "new_text": null,
          "old_line_content": "      client_graph->feed_types.size()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1631,
          "old_api": "size",
          "new_api": null,
          "old_text": "client_graph->fetch_types.size()",
          "new_text": null,
          "old_line_content": "      client_graph->fetch_types.size()) {",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 1639,
          "old_api": "GetStatefulPlacements",
          "new_api": null,
          "old_text": "execution_state->GetStatefulPlacements()",
          "new_text": null,
          "old_line_content": "  auto current_stateful_placements = execution_state->GetStatefulPlacements();",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 1646,
          "old_api": "find",
          "new_api": null,
          "old_text": "stateful_placements_.find(node_name)",
          "new_text": null,
          "old_line_content": "    auto iter = stateful_placements_.find(node_name);",
          "new_line_content": "    const string& node_name = placement_pair.first;",
          "content_same": false
        },
        {
          "line": 1647,
          "old_api": "end",
          "new_api": null,
          "old_text": "stateful_placements_.end()",
          "new_text": null,
          "old_line_content": "    if (iter == stateful_placements_.end()) {",
          "new_line_content": "    const string& placement = placement_pair.second;",
          "content_same": false
        },
        {
          "line": 1657,
          "old_api": "GetStatefulPlacements",
          "new_api": null,
          "old_text": "execution_state->GetStatefulPlacements()",
          "new_text": null,
          "old_line_content": "  stateful_placements_ = execution_state->GetStatefulPlacements();",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 1661,
          "old_api": "get",
          "new_api": null,
          "old_text": "flib_def_.get()",
          "new_text": null,
          "old_line_content": "    run_state_args->graph.reset(new Graph(flib_def_.get()));",
          "new_line_content": "  // Remember the graph in run state if this is a partial run.",
          "content_same": false
        },
        {
          "line": 1662,
          "old_api": "get",
          "new_api": null,
          "old_text": "run_state_args->graph.get()",
          "new_text": null,
          "old_line_content": "    CopyGraph(*execution_state->full_graph(), run_state_args->graph.get());",
          "new_line_content": "  if (run_state_args->is_partial_run) {",
          "content_same": false
        },
        {
          "line": 1668,
          "old_api": "assigned_device_name",
          "new_api": null,
          "old_text": "node->assigned_device_name()",
          "new_text": null,
          "old_line_content": "    return node->assigned_device_name();",
          "new_line_content": "  PartitionOptions popts;",
          "content_same": false
        },
        {
          "line": 1671,
          "old_api": "fetch_add",
          "new_api": null,
          "old_text": "edge_name_counter_.fetch_add(1)",
          "new_text": null,
          "old_line_content": "    return strings::StrCat(prefix, \"/_\", edge_name_counter_.fetch_add(1));",
          "new_line_content": "  };",
          "content_same": false
        },
        {
          "line": 1678,
          "old_api": "get",
          "new_api": null,
          "old_text": "flib_def->get()",
          "new_text": null,
          "old_line_content": "  popts.flib_def = flib_def->get();",
          "new_line_content": "    return 1;",
          "content_same": false
        },
        {
          "line": 1682,
          "old_api": "Partition",
          "new_api": null,
          "old_text": "Partition(popts, &client_graph->graph, &partitions)",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(Partition(popts, &client_graph->graph, &partitions));",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1687,
          "old_api": "name",
          "new_api": null,
          "old_text": "device->name()",
          "new_text": null,
          "old_line_content": "    device_names.push_back(DeviceNameUtils::LocalName(device->name()));",
          "new_line_content": "  for (auto device : devices_) {",
          "content_same": false
        },
        {
          "line": 1693,
          "old_api": "DeviceNameUtils::LocalName(partition.first)",
          "new_api": null,
          "old_text": "DeviceNameUtils::LocalName(partition.first)",
          "new_text": null,
          "old_line_content": "        DeviceNameUtils::LocalName(partition.first);",
          "new_line_content": "  for (const auto& partition : partitions) {",
          "content_same": false
        },
        {
          "line": 1694,
          "old_api": "end",
          "new_api": null,
          "old_text": "device_names.end()",
          "new_text": null,
          "old_line_content": "    if (std::count(device_names.begin(), device_names.end(),",
          "new_line_content": "    const string local_partition_name =",
          "content_same": false
        },
        {
          "line": 1700,
          "old_api": "absl::StrJoin(device_names, \",\")",
          "new_api": null,
          "old_text": "absl::StrJoin(device_names, \",\")",
          "new_text": null,
          "old_line_content": "          absl::StrJoin(device_names, \",\"));",
          "new_line_content": "          \" which doesn't exist in the list of available devices. Available \"",
          "content_same": false
        },
        {
          "line": 1706,
          "old_api": "get",
          "new_api": null,
          "old_text": "client_graph->flib_def.get()",
          "new_text": null,
          "old_line_content": "        new Graph(client_graph->flib_def.get()));",
          "new_line_content": "  for (auto& partition : partitions) {",
          "content_same": false
        },
        {
          "line": 1707,
          "old_api": "SetConstructionContext",
          "new_api": null,
          "old_text": "device_graph->SetConstructionContext(ConstructionContext::kDirectSession)",
          "new_text": null,
          "old_line_content": "    device_graph->SetConstructionContext(ConstructionContext::kDirectSession);",
          "new_line_content": "    std::unique_ptr<Graph> device_graph(",
          "content_same": false
        },
        {
          "line": 1712,
          "old_api": "get",
          "new_api": null,
          "old_text": "ConvertGraphDefToGraph(\n        device_opts, std::move(partition.second), device_graph.get())",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(ConvertGraphDefToGraph(",
          "new_line_content": "    device_opts.allow_internal_ops = true;",
          "content_same": false
        },
        {
          "line": 1713,
          "old_api": "get",
          "new_api": null,
          "old_text": "device_graph.get()",
          "new_text": null,
          "old_line_content": "        device_opts, std::move(partition.second), device_graph.get()));",
          "new_line_content": "    device_opts.expect_device_spec = true;",
          "content_same": false
        },
        {
          "line": 1719,
          "old_api": "get",
          "new_api": null,
          "old_text": "client_graph->flib_def.get()",
          "new_text": null,
          "old_line_content": "  optimization_options.flib_def = client_graph->flib_def.get();",
          "new_line_content": "  GraphOptimizationPassOptions optimization_options;",
          "content_same": false
        },
        {
          "line": 1729,
          "old_api": "get",
          "new_api": null,
          "old_text": "graph->get()",
          "new_text": null,
          "old_line_content": "    VLOG(2) << \"Created \" << DebugString(graph->get()) << \" for \"",
          "new_line_content": "    std::unique_ptr<Graph>* graph = &partition.second;",
          "content_same": false
        },
        {
          "line": 1734,
          "old_api": "LookupDevice",
          "new_api": null,
          "old_text": "device_mgr_->LookupDevice(partition_name, &d)",
          "new_text": null,
          "old_line_content": "    s = device_mgr_->LookupDevice(partition_name, &d);",
          "new_line_content": "    // Give the device an opportunity to rewrite its subgraph.",
          "content_same": false
        },
        {
          "line": 1735,
          "old_api": "ok",
          "new_api": null,
          "old_text": "s.ok()",
          "new_text": null,
          "old_line_content": "    if (!s.ok()) break;",
          "new_line_content": "    Device* d;",
          "content_same": false
        },
        {
          "line": 1741,
          "old_api": "std::move(client_graph->flib_def)",
          "new_api": null,
          "old_text": "std::move(client_graph->flib_def)",
          "new_text": null,
          "old_line_content": "  *flib_def = std::move(client_graph->flib_def);",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 1742,
          "old_api": "std::swap(*input_types, client_graph->feed_types)",
          "new_api": null,
          "old_text": "std::swap(*input_types, client_graph->feed_types)",
          "new_text": null,
          "old_line_content": "  std::swap(*input_types, client_graph->feed_types);",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 1749,
          "old_api": "clear",
          "new_api": null,
          "old_text": "response->clear()",
          "new_text": null,
          "old_line_content": "  response->clear();",
          "new_line_content": "::tensorflow::Status DirectSession::ListDevices(",
          "content_same": false
        },
        {
          "line": 1750,
          "old_api": "size",
          "new_api": null,
          "old_text": "devices_.size()",
          "new_text": null,
          "old_line_content": "  response->reserve(devices_.size());",
          "new_line_content": "    std::vector<DeviceAttributes>* response) {",
          "content_same": false
        },
        {
          "line": 1753,
          "old_api": "emplace_back",
          "new_api": null,
          "old_text": "response->emplace_back(attrs)",
          "new_text": null,
          "old_line_content": "    response->emplace_back(attrs);",
          "new_line_content": "  for (Device* d : devices_) {",
          "content_same": false
        },
        {
          "line": 1760,
          "old_api": "ClearContainers",
          "new_api": null,
          "old_text": "device_mgr_->ClearContainers(containers)",
          "new_text": null,
          "old_line_content": "  device_mgr_->ClearContainers(containers);",
          "new_line_content": "::tensorflow::Status DirectSession::Reset(",
          "content_same": false
        },
        {
          "line": 1761,
          "old_api": "::tensorflow::Status::OK()",
          "new_api": null,
          "old_text": "::tensorflow::Status::OK()",
          "new_text": null,
          "old_line_content": "  return ::tensorflow::Status::OK();",
          "new_line_content": "    const std::vector<string>& containers) {",
          "content_same": false
        },
        {
          "line": 1765,
          "old_api": "StartCancel",
          "new_api": null,
          "old_text": "cancellation_manager_->StartCancel()",
          "new_text": null,
          "old_line_content": "  cancellation_manager_->StartCancel();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1768,
          "old_api": "::tensorflow::Status::OK()",
          "new_api": null,
          "old_text": "::tensorflow::Status::OK()",
          "new_text": null,
          "old_line_content": "    if (closed_) return ::tensorflow::Status::OK();",
          "new_line_content": "  {",
          "content_same": false
        },
        {
          "line": 1771,
          "old_api": "Deregister",
          "new_api": null,
          "old_text": "factory_->Deregister(this)",
          "new_text": null,
          "old_line_content": "  if (factory_ != nullptr) factory_->Deregister(this);",
          "new_line_content": "    closed_ = true;",
          "content_same": false
        },
        {
          "line": 1772,
          "old_api": "::tensorflow::Status::OK()",
          "new_api": null,
          "old_text": "::tensorflow::Status::OK()",
          "new_text": null,
          "old_line_content": "  return ::tensorflow::Status::OK();",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 1779,
          "old_api": "ok",
          "new_api": null,
          "old_text": "d->resource_manager()->Cleanup(name).ok()",
          "new_text": null,
          "old_line_content": "          if (!d->resource_manager()->Cleanup(name).ok()) {",
          "new_line_content": "    : step_container(step_id, [devices, step_id](const string& name) {",
          "content_same": false
        },
        {
          "line": 1782,
          "old_api": "GetScopedAllocatorMgr",
          "new_api": null,
          "old_text": "d->GetScopedAllocatorMgr()",
          "new_text": null,
          "old_line_content": "          ScopedAllocatorMgr* sam = d->GetScopedAllocatorMgr();",
          "new_line_content": "            // Do nothing...",
          "content_same": false
        },
        {
          "line": 1783,
          "old_api": "Cleanup",
          "new_api": null,
          "old_text": "sam->Cleanup(step_id)",
          "new_text": null,
          "old_line_content": "          if (sam) sam->Cleanup(step_id);",
          "new_line_content": "          }",
          "content_same": false
        },
        {
          "line": 1803,
          "old_api": "errors::Cancelled(\"PRun cancellation\")",
          "new_api": null,
          "old_text": "errors::Cancelled(\"PRun cancellation\")",
          "new_text": null,
          "old_line_content": "    rendez->StartAbort(errors::Cancelled(\"PRun cancellation\"));",
          "new_line_content": "DirectSession::PartialRunState::~PartialRunState() {",
          "content_same": false
        },
        {
          "line": 1804,
          "old_api": "WaitForNotification",
          "new_api": null,
          "old_text": "executors_done.WaitForNotification()",
          "new_text": null,
          "old_line_content": "    executors_done.WaitForNotification();",
          "new_line_content": "  if (rendez != nullptr) {",
          "content_same": false
        },
        {
          "line": 1821,
          "old_api": "WaitForNotification",
          "new_api": null,
          "old_text": "WaitForNotification(n, timeout_in_ms)",
          "new_text": null,
          "old_line_content": "  const Status status = WaitForNotification(n, timeout_in_ms);",
          "new_line_content": "                                        CancellationManager* cm,",
          "content_same": false
        },
        {
          "line": 1822,
          "old_api": "ok",
          "new_api": null,
          "old_text": "status.ok()",
          "new_text": null,
          "old_line_content": "  if (!status.ok()) {",
          "new_line_content": "                                        int64_t timeout_in_ms) {",
          "content_same": false
        },
        {
          "line": 1825,
          "old_api": "Update",
          "new_api": null,
          "old_text": "run_state->status.Update(status)",
          "new_text": null,
          "old_line_content": "      run_state->status.Update(status);",
          "new_line_content": "    {",
          "content_same": false
        },
        {
          "line": 1831,
          "old_api": "WaitForNotification",
          "new_api": null,
          "old_text": "n->WaitForNotification()",
          "new_text": null,
          "old_line_content": "    n->WaitForNotification();",
          "new_line_content": "    // references to `cm` and other per-step state. After this notification, it",
          "content_same": false
        },
        {
          "line": 1840,
          "old_api": "WaitForNotificationWithTimeout",
          "new_api": null,
          "old_text": "WaitForNotificationWithTimeout(notification, timeout_in_us)",
          "new_text": null,
          "old_line_content": "        WaitForNotificationWithTimeout(notification, timeout_in_us);",
          "new_line_content": "    const int64_t timeout_in_us = timeout_in_ms * 1000;",
          "content_same": false
        },
        {
          "line": 1846,
          "old_api": "WaitForNotification",
          "new_api": null,
          "old_text": "notification->WaitForNotification()",
          "new_text": null,
          "old_line_content": "    notification->WaitForNotification();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 1853,
          "old_api": "CheckNotClosed",
          "new_api": null,
          "old_text": "CheckNotClosed()",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(CheckNotClosed());",
          "new_line_content": "Status DirectSession::MakeCallable(const CallableOptions& callable_options,",
          "content_same": false
        },
        {
          "line": 1854,
          "old_api": "CheckGraphCreated",
          "new_api": null,
          "old_text": "CheckGraphCreated(\"MakeCallable()\")",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(CheckGraphCreated(\"MakeCallable()\"));",
          "new_line_content": "                                   CallableHandle* out_handle) {",
          "content_same": false
        },
        {
          "line": 1858,
          "old_api": "run_options",
          "new_api": null,
          "old_text": "callable_options.run_options().debug_options()",
          "new_text": null,
          "old_line_content": "  RunStateArgs run_state_args(callable_options.run_options().debug_options());",
          "new_line_content": "  std::unique_ptr<ExecutorsAndKeys> ek;",
          "content_same": false
        },
        {
          "line": 1859,
          "old_api": "TF_RETURN_IF_ERROR",
          "new_api": null,
          "old_text": "TF_RETURN_IF_ERROR(\n      CreateExecutors(callable_options, &ek, &func_info, &run_state_args))",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(",
          "new_line_content": "  std::unique_ptr<FunctionInfo> func_info;",
          "content_same": false
        },
        {
          "line": 1864,
          "old_api": "std::move(func_info)",
          "new_api": null,
          "old_text": "std::move(func_info)",
          "new_text": null,
          "old_line_content": "    callables_[*out_handle] = {std::move(ek), std::move(func_info)};",
          "new_line_content": "    mutex_lock l(callables_lock_);",
          "content_same": false
        },
        {
          "line": 1881,
          "old_api": "size",
          "new_api": null,
          "old_text": "executors_and_keys_->input_types.size()",
          "new_text": null,
          "old_line_content": "    return executors_and_keys_->input_types.size();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1884,
          "old_api": "size",
          "new_api": null,
          "old_text": "executors_and_keys_->output_types.size()",
          "new_text": null,
          "old_line_content": "    return executors_and_keys_->output_types.size();",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 1888,
          "old_api": "size",
          "new_api": null,
          "old_text": "feed_tensors_->size()",
          "new_text": null,
          "old_line_content": "    if (TF_PREDICT_FALSE(index > feed_tensors_->size())) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1889,
          "old_api": "errors::Internal(\"Args index out of bounds: \", index)",
          "new_api": null,
          "old_text": "errors::Internal(\"Args index out of bounds: \", index)",
          "new_text": null,
          "old_line_content": "      return errors::Internal(\"Args index out of bounds: \", index);",
          "new_line_content": "  Status GetArg(int index, const Tensor** val) override {",
          "content_same": false
        },
        {
          "line": 1893,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "    return Status::OK();",
          "new_line_content": "      *val = &(*feed_tensors_)[index];",
          "content_same": false
        },
        {
          "line": 1897,
          "old_api": "size",
          "new_api": null,
          "old_text": "fetch_tensors_->size()",
          "new_text": null,
          "old_line_content": "    if (index > fetch_tensors_->size()) {",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1898,
          "old_api": "errors::Internal(\"RetVal index out of bounds: \", index)",
          "new_api": null,
          "old_text": "errors::Internal(\"RetVal index out of bounds: \", index)",
          "new_text": null,
          "old_line_content": "      return errors::Internal(\"RetVal index out of bounds: \", index);",
          "new_line_content": "  Status SetRetval(int index, const Tensor& val) override {",
          "content_same": false
        },
        {
          "line": 1901,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "    return Status::OK();",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 1914,
          "old_api": "RunCallable",
          "new_api": null,
          "old_text": "RunCallable(handle, feed_tensors, fetch_tensors, run_metadata,\n                     thread::ThreadPoolOptions())",
          "new_text": null,
          "old_line_content": "  return RunCallable(handle, feed_tensors, fetch_tensors, run_metadata,",
          "new_line_content": "    CallableHandle handle, const std::vector<Tensor>& feed_tensors,",
          "content_same": false
        },
        {
          "line": 1915,
          "old_api": "thread::ThreadPoolOptions()",
          "new_api": null,
          "old_text": "thread::ThreadPoolOptions()",
          "new_text": null,
          "old_line_content": "                     thread::ThreadPoolOptions());",
          "new_line_content": "    std::vector<Tensor>* fetch_tensors, RunMetadata* run_metadata) {",
          "content_same": false
        },
        {
          "line": 1922,
          "old_api": "CheckNotClosed",
          "new_api": null,
          "old_text": "CheckNotClosed()",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(CheckNotClosed());",
          "new_line_content": "    std::vector<Tensor>* fetch_tensors, RunMetadata* run_metadata,",
          "content_same": false
        },
        {
          "line": 1923,
          "old_api": "CheckGraphCreated",
          "new_api": null,
          "old_text": "CheckGraphCreated(\"RunCallable()\")",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(CheckGraphCreated(\"RunCallable()\"));",
          "new_line_content": "    const thread::ThreadPoolOptions& threadpool_options) {",
          "content_same": false
        },
        {
          "line": 1928,
          "old_api": "fetch_add",
          "new_api": null,
          "old_text": "step_id_counter_.fetch_add(1)",
          "new_text": null,
          "old_line_content": "  const int64_t step_id = step_id_counter_.fetch_add(1);",
          "new_line_content": "  // Check if we already have an executor for these arguments.",
          "content_same": false
        },
        {
          "line": 1933,
          "old_api": "errors::InvalidArgument(\"No such callable handle: \", handle)",
          "new_api": null,
          "old_text": "errors::InvalidArgument(\"No such callable handle: \", handle)",
          "new_text": null,
          "old_line_content": "      return errors::InvalidArgument(\"No such callable handle: \", handle);",
          "new_line_content": "    tf_shared_lock l(callables_lock_);",
          "content_same": false
        },
        {
          "line": 1939,
          "old_api": "errors::InvalidArgument(\n        \"Attempted to run callable after handle was released: \", handle)",
          "new_api": null,
          "old_text": "errors::InvalidArgument(\n        \"Attempted to run callable after handle was released: \", handle)",
          "new_text": null,
          "old_line_content": "    return errors::InvalidArgument(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1950,
          "old_api": "size",
          "new_api": null,
          "old_text": "executors_and_keys->input_types.size()",
          "new_text": null,
          "old_line_content": "  if (feed_tensors.size() != executors_and_keys->input_types.size()) {",
          "new_line_content": "  // Configure a call frame for the step, which we use to feed and",
          "content_same": false
        },
        {
          "line": 1951,
          "old_api": "size",
          "new_api": null,
          "old_text": "errors::InvalidArgument(\n        \"Expected \", executors_and_keys->input_types.size(),\n        \" feed tensors, but got \", feed_tensors.size())",
          "new_text": null,
          "old_line_content": "    return errors::InvalidArgument(",
          "new_line_content": "  // fetch values to and from the executors.",
          "content_same": false
        },
        {
          "line": 1956,
          "old_api": "size",
          "new_api": null,
          "old_text": "executors_and_keys->output_types.size()",
          "new_text": null,
          "old_line_content": "    fetch_tensors->resize(executors_and_keys->output_types.size());",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 1957,
          "old_api": "empty",
          "new_api": null,
          "old_text": "executors_and_keys->output_types.empty()",
          "new_text": null,
          "old_line_content": "  } else if (!executors_and_keys->output_types.empty()) {",
          "new_line_content": "  if (fetch_tensors != nullptr) {",
          "content_same": false
        },
        {
          "line": 1966,
          "old_api": "AllocatedBytes",
          "new_api": null,
          "old_text": "tensor.AllocatedBytes()",
          "new_text": null,
          "old_line_content": "    input_size += tensor.AllocatedBytes();",
          "new_line_content": "  bool any_resource_feeds = false;",
          "content_same": false
        },
        {
          "line": 1967,
          "old_api": "dtype",
          "new_api": null,
          "old_text": "tensor.dtype()",
          "new_text": null,
          "old_line_content": "    any_resource_feeds = any_resource_feeds || tensor.dtype() == DT_RESOURCE;",
          "new_line_content": "  for (auto& tensor : feed_tensors) {",
          "content_same": false
        },
        {
          "line": 1974,
          "old_api": "TF_PREDICT_FALSE",
          "new_api": null,
          "old_text": "TF_PREDICT_FALSE(any_resource_feeds)",
          "new_text": null,
          "old_line_content": "  if (TF_PREDICT_FALSE(any_resource_feeds)) {",
          "new_line_content": "  const std::vector<Tensor>* actual_feed_tensors;",
          "content_same": false
        },
        {
          "line": 1975,
          "old_api": "absl::make_unique<std::vector<Tensor>>()",
          "new_api": null,
          "old_text": "absl::make_unique<std::vector<Tensor>>()",
          "new_text": null,
          "old_line_content": "    converted_feed_tensors = absl::make_unique<std::vector<Tensor>>();",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 1979,
          "old_api": "emplace_back",
          "new_api": null,
          "old_text": "converted_feed_tensors->emplace_back()",
          "new_text": null,
          "old_line_content": "        converted_feed_tensors->emplace_back();",
          "new_line_content": "    for (const Tensor& t : feed_tensors) {",
          "content_same": false
        },
        {
          "line": 1986,
          "old_api": "get",
          "new_api": null,
          "old_text": "converted_feed_tensors.get()",
          "new_text": null,
          "old_line_content": "    actual_feed_tensors = converted_feed_tensors.get();",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 1993,
          "old_api": "get",
          "new_api": null,
          "old_text": "executors_and_keys.get()",
          "new_text": null,
          "old_line_content": "  RunCallableCallFrame call_frame(this, executors_and_keys.get(),",
          "new_line_content": "  // A specialized CallFrame implementation that takes advantage of the",
          "content_same": false
        },
        {
          "line": 1996,
          "old_api": "LogMemory::IsEnabled()",
          "new_api": null,
          "old_text": "LogMemory::IsEnabled()",
          "new_text": null,
          "old_line_content": "  if (LogMemory::IsEnabled()) {",
          "new_line_content": "                                  actual_feed_tensors, fetch_tensors);",
          "content_same": false
        },
        {
          "line": 1997,
          "old_api": "LogMemory::RecordStep(step_id, run_state_args.handle)",
          "new_api": null,
          "old_text": "LogMemory::RecordStep(step_id, run_state_args.handle)",
          "new_text": null,
          "old_line_content": "    LogMemory::RecordStep(step_id, run_state_args.handle);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 2000,
          "old_api": "run_options",
          "new_api": null,
          "old_text": "RunInternal(\n      step_id, executors_and_keys->callable_options.run_options(), &call_frame,\n      executors_and_keys.get(), run_metadata, threadpool_options)",
          "new_text": null,
          "old_line_content": "  TF_RETURN_IF_ERROR(RunInternal(",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 2001,
          "old_api": "run_options",
          "new_api": null,
          "old_text": "executors_and_keys->callable_options.run_options()",
          "new_text": null,
          "old_line_content": "      step_id, executors_and_keys->callable_options.run_options(), &call_frame,",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 2007,
          "old_api": "AllocatedBytes",
          "new_api": null,
          "old_text": "tensor.AllocatedBytes()",
          "new_text": null,
          "old_line_content": "      output_size += tensor.AllocatedBytes();",
          "new_line_content": "    size_t output_size = 0;",
          "content_same": false
        },
        {
          "line": 2012,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "  return Status::OK();",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 2018,
          "old_api": "errors::InvalidArgument(\"No such callable handle: \", handle)",
          "new_api": null,
          "old_text": "errors::InvalidArgument(\"No such callable handle: \", handle)",
          "new_text": null,
          "old_line_content": "    return errors::InvalidArgument(\"No such callable handle: \", handle);",
          "new_line_content": "  mutex_lock l(callables_lock_);",
          "content_same": false
        },
        {
          "line": 2021,
          "old_api": "Status::OK()",
          "new_api": null,
          "old_text": "Status::OK()",
          "new_text": null,
          "old_line_content": "  return Status::OK();",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 2027,
          "old_api": "errors::FailedPrecondition(\"Session already finalized.\")",
          "new_api": null,
          "old_text": "errors::FailedPrecondition(\"Session already finalized.\")",
          "new_text": null,
          "old_line_content": "    return errors::FailedPrecondition(\"Session already finalized.\");",
          "new_line_content": "  mutex_lock l(graph_state_lock_);",
          "content_same": false
        },
        {
          "line": 2030,
          "old_api": "errors::FailedPrecondition(\"Session not yet created.\")",
          "new_api": null,
          "old_text": "errors::FailedPrecondition(\"Session not yet created.\")",
          "new_text": null,
          "old_line_content": "    return errors::FailedPrecondition(\"Session not yet created.\");",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 2033,
          "old_api": "reset",
          "new_api": null,
          "old_text": "flib_def_.reset()",
          "new_text": null,
          "old_line_content": "  flib_def_.reset();",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 2044,
          "old_api": "reset",
          "new_api": null,
          "old_text": "executors_and_keys.reset()",
          "new_text": null,
          "old_line_content": "  executors_and_keys.reset();",
          "new_line_content": "  // on the `FunctionLibraryRuntime` to know if the kernel is stateful",
          "content_same": false
        },
        {
          "line": 2045,
          "old_api": "reset",
          "new_api": null,
          "old_text": "function_info.reset()",
          "new_text": null,
          "old_line_content": "  function_info.reset();",
          "new_line_content": "  // or not).",
          "content_same": false
        }
      ]
    },
    "api_summary": {
      "total_replacements": 155,
      "total_additions": 343,
      "total_deletions": 343,
      "total_api_changes": 841
    },
    "non_api_changes": {
      "has_non_api_changes": true,
      "evidence": {
        "total_diff_lines": 12,
        "api_related_lines": 841,
        "non_api_lines": 4,
        "non_api_line_numbers": [
          449,
          450,
          443,
          444
        ]
      }
    },
    "api_calls_before": 849,
    "api_calls_after": 848,
    "diff_info": {
      "added_lines": 7,
      "removed_lines": 5,
      "total_diff_lines": 37
    }
  }
}