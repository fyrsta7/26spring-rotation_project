{
  "status": "completed",
  "commit_dir": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/56441e7103d2c85de781db5902a81eeaeaa83d6f",
  "file_info": {
    "before_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/56441e7103d2c85de781db5902a81eeaeaa83d6f/before.cc",
    "after_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/56441e7103d2c85de781db5902a81eeaeaa83d6f/after.cc",
    "diff_file": "/home/zyw/llm_on_code/llm_on_code_optimization/knowledge_base/tensorflow/modified_file/56441e7103d2c85de781db5902a81eeaeaa83d6f/diff.txt"
  },
  "semgrep_analysis": {
    "is_api_change": false,
    "api_changes": {
      "replacements": [
        {
          "line": 516,
          "old_api": "set_xla_gpu_dump_autotune_results_to",
          "new_api": "set_xla_gpu_autotune_level",
          "old_text": "options.set_xla_gpu_dump_autotune_results_to(\"\")",
          "new_text": "options.set_xla_gpu_autotune_level(0)",
          "old_line_content": "    options.set_xla_gpu_dump_autotune_results_to(\"\");",
          "new_line_content": "    options.set_xla_gpu_autotune_level(0);",
          "content_same": false
        },
        {
          "line": 518,
          "old_api": "set_xla_gpu_dump_llvmir",
          "new_api": "set_xla_dump_to",
          "old_text": "options.set_xla_gpu_dump_llvmir(false)",
          "new_text": "options.set_xla_dump_to(\"\")",
          "old_line_content": "    options.set_xla_gpu_dump_llvmir(false);",
          "new_line_content": "    options.set_xla_dump_to(\"\");",
          "content_same": false
        },
        {
          "line": 520,
          "old_api": "set_xla_gpu_force_compilation_parallelism",
          "new_api": "set_xla_gpu_load_autotune_results_from",
          "old_text": "options.set_xla_gpu_force_compilation_parallelism(1)",
          "new_text": "options.set_xla_gpu_load_autotune_results_from(\"\")",
          "old_line_content": "    options.set_xla_gpu_force_compilation_parallelism(1);",
          "new_line_content": "    options.set_xla_gpu_load_autotune_results_from(\"\");",
          "content_same": false
        },
        {
          "line": 521,
          "old_api": "set_debug_options",
          "new_api": "set_xla_gpu_dump_llvmir",
          "old_text": "module->config().set_debug_options(options)",
          "new_text": "options.set_xla_gpu_dump_llvmir(false)",
          "old_line_content": "    module->config().set_debug_options(options);",
          "new_line_content": "    options.set_xla_gpu_dump_llvmir(false);",
          "content_same": false
        },
        {
          "line": 523,
          "old_api": "std::move(module)",
          "new_api": "set_xla_gpu_force_compilation_parallelism",
          "old_text": "std::move(module)",
          "new_text": "options.set_xla_gpu_force_compilation_parallelism(1)",
          "old_line_content": "    return custom_hlo_runner.CompileRunningHloPasses(std::move(module));",
          "new_line_content": "    options.set_xla_gpu_force_compilation_parallelism(1);",
          "content_same": false
        },
        {
          "line": 546,
          "old_api": "get",
          "new_api": "find",
          "old_text": "it->second.get()",
          "new_text": "non_triton_executable_cache.find(cache_key)",
          "old_line_content": "        executable = it->second.get();",
          "new_line_content": "      auto it = non_triton_executable_cache.find(cache_key);",
          "content_same": false
        },
        {
          "line": 555,
          "old_api": "emplace",
          "new_api": "CompileMatmulWithCublas",
          "old_text": "non_triton_executable_cache.emplace(\n          cache_key, std::move(new_executable))",
          "new_text": "CompileMatmulWithCublas(original_computation, *custom_hlo_runner)",
          "old_line_content": "      auto [it, inserted] = non_triton_executable_cache.emplace(",
          "new_line_content": "          CompileMatmulWithCublas(original_computation, *custom_hlo_runner));",
          "content_same": false
        },
        {
          "line": 559,
          "old_api": "TF_RET_CHECK",
          "new_api": "std::move(new_executable)",
          "old_text": "TF_RET_CHECK(executable != nullptr)",
          "new_text": "std::move(new_executable)",
          "old_line_content": "    TF_RET_CHECK(executable != nullptr);",
          "new_line_content": "          cache_key, std::move(new_executable));",
          "content_same": false
        },
        {
          "line": 567,
          "old_api": "size",
          "new_api": "parameter_instructions",
          "old_text": "params.size()",
          "new_text": "original_computation.parameter_instructions()",
          "old_line_content": "    for (int i = 0; i < params.size(); ++i) {",
          "new_line_content": "        original_computation.parameter_instructions();",
          "content_same": false
        },
        {
          "line": 568,
          "old_api": "at",
          "new_api": "size",
          "old_text": "params.at(i)->shape()",
          "new_text": "params.size()",
          "old_line_content": "      execution_inputs.emplace_back(params.at(i)->shape());",
          "new_line_content": "    TF_RET_CHECK(input_buffers.size() == params.size());",
          "content_same": false
        },
        {
          "line": 571,
          "old_api": "back",
          "new_api": "at",
          "old_text": "execution_inputs.back().SetUnownedBuffer(\n          /*index=*/{},\n          MaybeOwningDeviceMemory(/*unowned=*/input_buffers.at(i)))",
          "new_text": "params.at(i)->shape()",
          "old_line_content": "      execution_inputs.back().SetUnownedBuffer(",
          "new_line_content": "      execution_inputs.emplace_back(params.at(i)->shape());",
          "content_same": false
        },
        {
          "line": 584,
          "old_api": "root_buffer",
          "new_api": "ConsumeResult",
          "old_text": "result.root_buffer()",
          "new_text": "execution_output.ConsumeResult()",
          "old_line_content": "    stream->ThenMemcpy(&output_buffer, result.root_buffer(),",
          "new_line_content": "    ScopedShapedBuffer result = execution_output.ConsumeResult();",
          "content_same": false
        },
        {
          "line": 586,
          "old_api": "OkStatus",
          "new_api": "root_buffer",
          "old_text": "OkStatus()",
          "new_text": "result.root_buffer().size()",
          "old_line_content": "    return OkStatus();",
          "new_line_content": "    TF_RET_CHECK(output_buffer.size() == result.root_buffer().size());",
          "content_same": false
        },
        {
          "line": 609,
          "old_api": "has_value",
          "new_api": "end",
          "old_text": "res.has_value()",
          "new_text": "compilation_cache.end()",
          "old_line_content": "        if (res.has_value()) {",
          "new_line_content": "      if (it != compilation_cache.end()) {",
          "content_same": false
        },
        {
          "line": 620,
          "old_api": "emplace",
          "new_api": "CompileNoCache",
          "old_text": "compilation_cache.emplace(key, res)",
          "new_text": "CompileNoCache(hlo_computation, autotune_config)",
          "old_line_content": "      auto [it2, inserted] = compilation_cache.emplace(key, res);",
          "new_line_content": "                        CompileNoCache(hlo_computation, autotune_config));",
          "content_same": false
        },
        {
          "line": 635,
          "old_api": "GetExecutor",
          "new_api": "NowNanos",
          "old_text": "config_.GetExecutor()->GetDeviceDescription()",
          "new_text": "tsl::Env::Default()->NowNanos()",
          "old_line_content": "        config_.GetExecutor()->GetDeviceDescription();",
          "new_line_content": "    uint64_t start_compilation_nanos = tsl::Env::Default()->NowNanos();",
          "content_same": false
        },
        {
          "line": 640,
          "old_api": "FusionInstruction",
          "new_api": "GetExecutor",
          "old_text": "original_computation.FusionInstruction()",
          "new_text": "config_.GetExecutor()",
          "old_line_content": "        *original_computation.FusionInstruction());",
          "new_line_content": "        GetGpuDeviceInfo(config_.GetExecutor());",
          "content_same": false
        },
        {
          "line": 656,
          "old_api": "set_xla_gpu_enable_xla_runtime_executable",
          "new_api": "parent",
          "old_text": "options.set_xla_gpu_enable_xla_runtime_executable(false)",
          "new_text": "original_computation.parent()->config().debug_options()",
          "old_line_content": "    options.set_xla_gpu_enable_xla_runtime_executable(false);",
          "new_line_content": "        original_computation.parent()->config().debug_options();",
          "content_same": false
        },
        {
          "line": 659,
          "old_api": "set_xla_gpu_dump_autotune_results_to",
          "new_api": "set_xla_gpu_enable_xla_runtime_executable",
          "old_text": "options.set_xla_gpu_dump_autotune_results_to(\"\")",
          "new_text": "options.set_xla_gpu_enable_xla_runtime_executable(false)",
          "old_line_content": "    options.set_xla_gpu_dump_autotune_results_to(\"\");",
          "new_line_content": "    options.set_xla_gpu_enable_xla_runtime_executable(false);",
          "content_same": false
        },
        {
          "line": 661,
          "old_api": "set_xla_gpu_dump_llvmir",
          "new_api": "set_xla_dump_to",
          "old_text": "options.set_xla_gpu_dump_llvmir(false)",
          "new_text": "options.set_xla_dump_to(\"\")",
          "old_line_content": "    options.set_xla_gpu_dump_llvmir(false);",
          "new_line_content": "    options.set_xla_dump_to(\"\");",
          "content_same": false
        },
        {
          "line": 664,
          "old_api": "set_xla_gpu_force_compilation_parallelism",
          "new_api": "set_xla_gpu_dump_llvmir",
          "old_text": "options.set_xla_gpu_force_compilation_parallelism(1)",
          "new_text": "options.set_xla_gpu_dump_llvmir(false)",
          "old_line_content": "    options.set_xla_gpu_force_compilation_parallelism(1);",
          "new_line_content": "    options.set_xla_gpu_dump_llvmir(false);",
          "content_same": false
        },
        {
          "line": 667,
          "old_api": "root_instruction",
          "new_api": "set_xla_gpu_force_compilation_parallelism",
          "old_text": "entry_computation->root_instruction()",
          "new_text": "options.set_xla_gpu_force_compilation_parallelism(1)",
          "old_line_content": "    HloInstruction* cloned_dot_fusion = entry_computation->root_instruction();",
          "new_line_content": "    options.set_xla_gpu_force_compilation_parallelism(1);",
          "content_same": false
        },
        {
          "line": 675,
          "old_api": "split_k",
          "new_api": "mutable_triton_gemm_config",
          "old_text": "autotune_config.split_k()",
          "new_text": "backend_config.mutable_triton_gemm_config()",
          "old_line_content": "    if (autotune_config.split_k() > 1) {",
          "new_line_content": "    *backend_config.mutable_triton_gemm_config() = autotune_config;",
          "content_same": false
        },
        {
          "line": 676,
          "old_api": "ok",
          "new_api": "set_backend_config",
          "old_text": "MakeDotSplitKBatch(cloned_dot_fusion, autotune_config).ok()",
          "new_text": "cloned_dot_fusion->set_backend_config(backend_config)",
          "old_line_content": "      if (!MakeDotSplitKBatch(cloned_dot_fusion, autotune_config).ok()) {",
          "new_line_content": "    TF_RETURN_IF_ERROR(cloned_dot_fusion->set_backend_config(backend_config));",
          "content_same": false
        },
        {
          "line": 689,
          "old_api": "opcode",
          "new_api": "root_instruction",
          "old_text": "root->opcode()",
          "new_text": "entry_computation->root_instruction()",
          "old_line_content": "      if (root->opcode() == HloOpcode::kReduce) {",
          "new_line_content": "      HloInstruction* root = entry_computation->root_instruction();",
          "content_same": false
        },
        {
          "line": 692,
          "old_api": "operand",
          "new_api": "opcode",
          "old_text": "root->operand(0)",
          "new_text": "root->opcode()",
          "old_line_content": "                root->shape(), ChooseFusionKind(*root->operand(0), *root),",
          "new_line_content": "      if (root->opcode() == HloOpcode::kReduce) {",
          "content_same": false
        },
        {
          "line": 694,
          "old_api": "mutable_operand",
          "new_api": "shape",
          "old_text": "root->mutable_operand(1)",
          "new_text": "HloInstruction::CreateFusion(\n                root->shape(), ChooseFusionKind(*root->operand(0), *root),\n                root)",
          "old_line_content": "        HloInstruction* init_value = root->mutable_operand(1);",
          "new_line_content": "            entry_computation->AddInstruction(HloInstruction::CreateFusion(",
          "content_same": false
        },
        {
          "line": 695,
          "old_api": "ReplaceInstruction",
          "new_api": "operand",
          "old_text": "TF_CHECK_OK(\n            entry_computation->ReplaceInstruction(root, fusion_instruction))",
          "new_text": "root->operand(0)",
          "old_line_content": "        TF_CHECK_OK(",
          "new_line_content": "                root->shape(), ChooseFusionKind(*root->operand(0), *root),",
          "content_same": false
        },
        {
          "line": 697,
          "old_api": "FuseInstruction",
          "new_api": "mutable_operand",
          "old_text": "fusion_instruction->FuseInstruction(init_value)",
          "new_text": "root->mutable_operand(1)",
          "old_line_content": "        fusion_instruction->FuseInstruction(init_value);",
          "new_line_content": "        HloInstruction* init_value = root->mutable_operand(1);",
          "content_same": false
        },
        {
          "line": 698,
          "old_api": "RemoveInstruction",
          "new_api": "ReplaceInstruction",
          "old_text": "entry_computation->RemoveInstruction(init_value)",
          "new_text": "TF_CHECK_OK(\n            entry_computation->ReplaceInstruction(root, fusion_instruction))",
          "old_line_content": "        TF_CHECK_OK(entry_computation->RemoveInstruction(init_value));",
          "new_line_content": "        TF_CHECK_OK(",
          "content_same": false
        },
        {
          "line": 714,
          "old_api": "nvptx::DataLayout()",
          "new_api": "get",
          "old_text": "nvptx::DataLayout()",
          "new_text": "xla::gpu::CompileModuleToLlvmIrImpl(\n        new_hlo_module.get(), &llvm_context,\n        /*target_triple=*/nvptx::TargetTriple(),\n        /*data_layout=*/nvptx::DataLayout(),\n        /*platform_name=*/config_.GetExecutor()->platform()->Name(),\n        /*platform_id=*/config_.GetExecutor()->platform()->id(),\n        gpu_device_info, device_description.cuda_compute_capability(),\n        device_description.rocm_compute_capability(),\n        DummyCanShareBufferFunction,\n        /*pointer_size=*/8, &compile_module_results)",
          "old_line_content": "        /*data_layout=*/nvptx::DataLayout(),",
          "new_line_content": "    Status compilation_status = xla::gpu::CompileModuleToLlvmIrImpl(",
          "content_same": false
        },
        {
          "line": 715,
          "old_api": "GetExecutor",
          "new_api": "get",
          "old_text": "config_.GetExecutor()->platform()->Name()",
          "new_text": "new_hlo_module.get()",
          "old_line_content": "        /*platform_name=*/config_.GetExecutor()->platform()->Name(),",
          "new_line_content": "        new_hlo_module.get(), &llvm_context,",
          "content_same": false
        },
        {
          "line": 716,
          "old_api": "GetExecutor",
          "new_api": "nvptx::TargetTriple()",
          "old_text": "config_.GetExecutor()->platform()->id()",
          "new_text": "nvptx::TargetTriple()",
          "old_line_content": "        /*platform_id=*/config_.GetExecutor()->platform()->id(),",
          "new_line_content": "        /*target_triple=*/nvptx::TargetTriple(),",
          "content_same": false
        },
        {
          "line": 717,
          "old_api": "cuda_compute_capability",
          "new_api": "nvptx::DataLayout()",
          "old_text": "device_description.cuda_compute_capability()",
          "new_text": "nvptx::DataLayout()",
          "old_line_content": "        gpu_device_info, device_description.cuda_compute_capability(),",
          "new_line_content": "        /*data_layout=*/nvptx::DataLayout(),",
          "content_same": false
        },
        {
          "line": 718,
          "old_api": "rocm_compute_capability",
          "new_api": "GetExecutor",
          "old_text": "device_description.rocm_compute_capability()",
          "new_text": "config_.GetExecutor()->platform()->Name()",
          "old_line_content": "        device_description.rocm_compute_capability(),",
          "new_line_content": "        /*platform_name=*/config_.GetExecutor()->platform()->Name(),",
          "content_same": false
        },
        {
          "line": 721,
          "old_api": "ok",
          "new_api": "rocm_compute_capability",
          "old_text": "compilation_status.ok()",
          "new_text": "device_description.rocm_compute_capability()",
          "old_line_content": "    if (!compilation_status.ok()) {",
          "new_line_content": "        device_description.rocm_compute_capability(),",
          "content_same": false
        },
        {
          "line": 732,
          "old_api": "std::get<GpuExecutable::OwnedThunkSequence>(\n            compile_module_results.executable)",
          "new_api": "std::holds_alternative<GpuExecutable::OwnedThunkSequence>(\n        compile_module_results.executable)",
          "old_text": "std::get<GpuExecutable::OwnedThunkSequence>(\n            compile_module_results.executable)",
          "new_text": "std::holds_alternative<GpuExecutable::OwnedThunkSequence>(\n        compile_module_results.executable)",
          "old_line_content": "        *std::get<GpuExecutable::OwnedThunkSequence>(",
          "new_line_content": "    CHECK(std::holds_alternative<GpuExecutable::OwnedThunkSequence>(",
          "content_same": false
        },
        {
          "line": 735,
          "old_api": "size",
          "new_api": "std::get<GpuExecutable::OwnedThunkSequence>(\n            compile_module_results.executable)",
          "old_text": "thunk_sequence.size()",
          "new_text": "std::get<GpuExecutable::OwnedThunkSequence>(\n            compile_module_results.executable)",
          "old_line_content": "    CHECK_LE(thunk_sequence.size(), 2);",
          "new_line_content": "        *std::get<GpuExecutable::OwnedThunkSequence>(",
          "content_same": false
        },
        {
          "line": 738,
          "old_api": "get",
          "new_api": "size",
          "old_text": "thunk.get()",
          "new_text": "thunk_sequence.size()",
          "old_line_content": "      KernelThunk* kernel_thunk = static_cast<KernelThunk*>(thunk.get());",
          "new_line_content": "    CHECK_LE(thunk_sequence.size(), 2);",
          "content_same": false
        },
        {
          "line": 740,
          "old_api": "launch_dimensions",
          "new_api": "kind",
          "old_text": "kernel_thunk->launch_dimensions()",
          "new_text": "thunk->kind()",
          "old_line_content": "      launch_dimensions.push_back(kernel_thunk->launch_dimensions());",
          "new_line_content": "      CHECK_EQ(thunk->kind(), Thunk::kKernel);",
          "content_same": false
        },
        {
          "line": 759,
          "old_api": "VLOG",
          "new_api": "NowNanos",
          "old_text": "VLOG(1)",
          "new_text": "tsl::Env::Default()->NowNanos()",
          "old_line_content": "    VLOG(1) << \"Compilation took: \" << compilation_time_span;",
          "new_line_content": "    uint64_t end_compilation_nanos = tsl::Env::Default()->NowNanos();",
          "content_same": false
        },
        {
          "line": 761,
          "old_api": "std::make_optional(\n        CompilationResult{ptx, cubin, kernel_names, launch_dimensions})",
          "new_api": "absl::Nanoseconds(end_compilation_nanos - start_compilation_nanos)",
          "old_text": "std::make_optional(\n        CompilationResult{ptx, cubin, kernel_names, launch_dimensions})",
          "new_text": "absl::Nanoseconds(end_compilation_nanos - start_compilation_nanos)",
          "old_line_content": "    return std::make_optional(",
          "new_line_content": "        absl::Nanoseconds(end_compilation_nanos - start_compilation_nanos);",
          "content_same": false
        },
        {
          "line": 815,
          "old_api": "IsAtLeast",
          "new_api": "GemmKey",
          "old_text": "compute_capability.IsAtLeast(se::CudaComputeCapability::AMPERE)",
          "new_text": "GemmKey(16, 128, 32, 8, 1, 4)",
          "old_line_content": "  if (compute_capability.IsAtLeast(se::CudaComputeCapability::AMPERE)) {",
          "new_line_content": "      GemmKey(16, 64, 128, 1, 1, 4), GemmKey(16, 128, 32, 8, 1, 4),",
          "content_same": false
        },
        {
          "line": 816,
          "old_api": "absl::c_copy(\n        std::vector<AutotuneResult::TritonGemmKey>{\n            GemmKey(128, 256, 32, 1, 3, 8),  GemmKey(256, 128, 32, 1, 3, 8),\n            GemmKey(256, 64, 32, 1, 4, 4),   GemmKey(64, 256, 32, 1, 4, 4),\n            GemmKey(128, 64, 32, 1, 4, 4),   GemmKey(64, 128, 32, 1, 4, 4),\n            GemmKey(128, 256, 32, 1, 3, 8),  GemmKey(256, 128, 128, 1, 3, 8),\n            GemmKey(256, 64, 128, 1, 4, 4),  GemmKey(64, 256, 128, 1, 4, 4),\n            GemmKey(128, 128, 128, 1, 4, 4), GemmKey(128, 64, 64, 1, 4, 4),\n            GemmKey(64, 128, 64, 1, 4, 4),   GemmKey(128, 32, 64, 1, 4, 4),\n            GemmKey(64, 32, 64, 1, 4, 4),    GemmKey(32, 128, 32, 1, 4, 4),\n            GemmKey(128, 128, 32, 1, 4, 4),  GemmKey(16, 16, 256, 1, 3, 4),\n            GemmKey(128, 128, 64, 2, 1, 8),  GemmKey(64, 64, 64, 1, 2, 4),\n            GemmKey(16, 64, 256, 8, 1, 4),   GemmKey(256, 256, 128, 1, 3, 8)},\n        std::back_inserter(configs))",
          "new_api": "GemmKey",
          "old_text": "absl::c_copy(\n        std::vector<AutotuneResult::TritonGemmKey>{\n            GemmKey(128, 256, 32, 1, 3, 8),  GemmKey(256, 128, 32, 1, 3, 8),\n            GemmKey(256, 64, 32, 1, 4, 4),   GemmKey(64, 256, 32, 1, 4, 4),\n            GemmKey(128, 64, 32, 1, 4, 4),   GemmKey(64, 128, 32, 1, 4, 4),\n            GemmKey(128, 256, 32, 1, 3, 8),  GemmKey(256, 128, 128, 1, 3, 8),\n            GemmKey(256, 64, 128, 1, 4, 4),  GemmKey(64, 256, 128, 1, 4, 4),\n            GemmKey(128, 128, 128, 1, 4, 4), GemmKey(128, 64, 64, 1, 4, 4),\n            GemmKey(64, 128, 64, 1, 4, 4),   GemmKey(128, 32, 64, 1, 4, 4),\n            GemmKey(64, 32, 64, 1, 4, 4),    GemmKey(32, 128, 32, 1, 4, 4),\n            GemmKey(128, 128, 32, 1, 4, 4),  GemmKey(16, 16, 256, 1, 3, 4),\n            GemmKey(128, 128, 64, 2, 1, 8),  GemmKey(64, 64, 64, 1, 2, 4),\n            GemmKey(16, 64, 256, 8, 1, 4),   GemmKey(256, 256, 128, 1, 3, 8)},\n        std::back_inserter(configs))",
          "new_text": "GemmKey(32, 16, 512, 1, 1, 4)",
          "old_line_content": "    absl::c_copy(",
          "new_line_content": "      GemmKey(16, 16, 512, 1, 1, 4), GemmKey(32, 16, 512, 1, 1, 4),",
          "content_same": false
        },
        {
          "line": 818,
          "old_api": "GemmKey",
          "new_api": "IsAtLeast",
          "old_text": "GemmKey(256, 128, 32, 1, 3, 8)",
          "new_text": "compute_capability.IsAtLeast(se::CudaComputeCapability::AMPERE)",
          "old_line_content": "            GemmKey(128, 256, 32, 1, 3, 8),  GemmKey(256, 128, 32, 1, 3, 8),",
          "new_line_content": "  if (compute_capability.IsAtLeast(se::CudaComputeCapability::AMPERE)) {",
          "content_same": false
        },
        {
          "line": 819,
          "old_api": "GemmKey",
          "new_api": "absl::c_copy(\n        std::vector<AutotuneResult::TritonGemmKey>{\n            GemmKey(128, 256, 32, 1, 3, 8),  GemmKey(256, 128, 32, 1, 3, 8),\n            GemmKey(256, 64, 32, 1, 4, 4),   GemmKey(64, 256, 32, 1, 4, 4),\n            GemmKey(128, 64, 32, 1, 4, 4),   GemmKey(64, 128, 32, 1, 4, 4),\n            GemmKey(128, 256, 32, 1, 3, 8),  GemmKey(256, 128, 128, 1, 3, 8),\n            GemmKey(256, 64, 128, 1, 4, 4),  GemmKey(64, 256, 128, 1, 4, 4),\n            GemmKey(128, 128, 128, 1, 4, 4), GemmKey(128, 64, 64, 1, 4, 4),\n            GemmKey(64, 128, 64, 1, 4, 4),   GemmKey(128, 32, 64, 1, 4, 4),\n            GemmKey(64, 32, 64, 1, 4, 4),    GemmKey(32, 128, 32, 1, 4, 4),\n            GemmKey(128, 128, 32, 1, 4, 4),  GemmKey(16, 16, 256, 1, 3, 4),\n            GemmKey(128, 128, 64, 2, 1, 8),  GemmKey(64, 64, 64, 1, 2, 4),\n            GemmKey(16, 64, 256, 8, 1, 4),   GemmKey(256, 256, 128, 1, 3, 8)},\n        std::back_inserter(configs))",
          "old_text": "GemmKey(64, 256, 32, 1, 4, 4)",
          "new_text": "absl::c_copy(\n        std::vector<AutotuneResult::TritonGemmKey>{\n            GemmKey(128, 256, 32, 1, 3, 8),  GemmKey(256, 128, 32, 1, 3, 8),\n            GemmKey(256, 64, 32, 1, 4, 4),   GemmKey(64, 256, 32, 1, 4, 4),\n            GemmKey(128, 64, 32, 1, 4, 4),   GemmKey(64, 128, 32, 1, 4, 4),\n            GemmKey(128, 256, 32, 1, 3, 8),  GemmKey(256, 128, 128, 1, 3, 8),\n            GemmKey(256, 64, 128, 1, 4, 4),  GemmKey(64, 256, 128, 1, 4, 4),\n            GemmKey(128, 128, 128, 1, 4, 4), GemmKey(128, 64, 64, 1, 4, 4),\n            GemmKey(64, 128, 64, 1, 4, 4),   GemmKey(128, 32, 64, 1, 4, 4),\n            GemmKey(64, 32, 64, 1, 4, 4),    GemmKey(32, 128, 32, 1, 4, 4),\n            GemmKey(128, 128, 32, 1, 4, 4),  GemmKey(16, 16, 256, 1, 3, 4),\n            GemmKey(128, 128, 64, 2, 1, 8),  GemmKey(64, 64, 64, 1, 2, 4),\n            GemmKey(16, 64, 256, 8, 1, 4),   GemmKey(256, 256, 128, 1, 3, 8)},\n        std::back_inserter(configs))",
          "old_line_content": "            GemmKey(256, 64, 32, 1, 4, 4),   GemmKey(64, 256, 32, 1, 4, 4),",
          "new_line_content": "    absl::c_copy(",
          "content_same": false
        },
        {
          "line": 829,
          "old_api": "std::back_inserter(configs)",
          "new_api": "GemmKey",
          "old_text": "std::back_inserter(configs)",
          "new_text": "GemmKey(16, 16, 256, 1, 3, 4)",
          "old_line_content": "        std::back_inserter(configs));",
          "new_line_content": "            GemmKey(128, 128, 32, 1, 4, 4),  GemmKey(16, 16, 256, 1, 3, 4),",
          "content_same": false
        },
        {
          "line": 831,
          "old_api": "IsAtLeast",
          "new_api": "GemmKey",
          "old_text": "compute_capability.IsAtLeast(se::CudaComputeCapability::HOPPER)",
          "new_text": "GemmKey(256, 256, 128, 1, 3, 8)",
          "old_line_content": "  if (compute_capability.IsAtLeast(se::CudaComputeCapability::HOPPER)) {",
          "new_line_content": "            GemmKey(16, 64, 256, 8, 1, 4),   GemmKey(256, 256, 128, 1, 3, 8)},",
          "content_same": false
        },
        {
          "line": 832,
          "old_api": "erase",
          "new_api": "std::back_inserter(configs)",
          "old_text": "configs.erase(\n        std::remove_if(configs.begin(), configs.end(),\n                       [](const AutotuneResult::TritonGemmKey& config) {\n                         return (config.block_m() * config.block_n() / 256) %\n                                    config.num_warps() !=\n                                0;\n                       }),\n        configs.end())",
          "new_text": "std::back_inserter(configs)",
          "old_line_content": "    configs.erase(",
          "new_line_content": "        std::back_inserter(configs));",
          "content_same": false
        },
        {
          "line": 835,
          "old_api": "block_n",
          "new_api": "erase",
          "old_text": "config.block_n()",
          "new_text": "configs.erase(\n        std::remove_if(configs.begin(), configs.end(),\n                       [](const AutotuneResult::TritonGemmKey& config) {\n                         return (config.block_m() * config.block_n() / 256) %\n                                    config.num_warps() !=\n                                0;\n                       }),\n        configs.end())",
          "old_line_content": "                         return (config.block_m() * config.block_n() / 256) %",
          "new_line_content": "    configs.erase(",
          "content_same": false
        },
        {
          "line": 836,
          "old_api": "num_warps",
          "new_api": "end",
          "old_text": "config.num_warps()",
          "new_text": "configs.end()",
          "old_line_content": "                                    config.num_warps() !=",
          "new_line_content": "        std::remove_if(configs.begin(), configs.end(),",
          "content_same": false
        },
        {
          "line": 839,
          "old_api": "end",
          "new_api": "num_warps",
          "old_text": "configs.end()",
          "new_text": "config.num_warps()",
          "old_line_content": "        configs.end());",
          "new_line_content": "                                    config.num_warps() !=",
          "content_same": false
        },
        {
          "line": 861,
          "old_api": "get",
          "new_api": "GetModule",
          "old_text": "new_hlo_module.get()",
          "new_text": "hlo.GetModule()->comp_envs()",
          "old_line_content": "  HloCloneContext clone_context(new_hlo_module.get());",
          "new_line_content": "      std::make_unique<CompilationEnvironments>(hlo.GetModule()->comp_envs()));",
          "content_same": false
        },
        {
          "line": 866,
          "old_api": "name",
          "new_api": "operands",
          "old_text": "operand->name()",
          "new_text": "hlo.operands()",
          "old_line_content": "                                        operand->name());",
          "new_line_content": "  for (const HloInstruction* operand : hlo.operands()) {",
          "content_same": false
        },
        {
          "line": 868,
          "old_api": "std::move(new_parameter)",
          "new_api": "shape",
          "old_text": "std::move(new_parameter)",
          "new_text": "operand->shape()",
          "old_line_content": "    new_operands.push_back(builder.AddInstruction(std::move(new_parameter)));",
          "new_line_content": "        HloInstruction::CreateParameter(parameter_number, operand->shape(),",
          "content_same": false
        },
        {
          "line": 871,
          "old_api": "shape",
          "new_api": "std::move(new_parameter)",
          "old_text": "hlo.shape()",
          "new_text": "std::move(new_parameter)",
          "old_line_content": "      hlo.CloneWithNewOperands(hlo.shape(), new_operands, &clone_context);",
          "new_line_content": "    new_operands.push_back(builder.AddInstruction(std::move(new_parameter)));",
          "content_same": false
        },
        {
          "line": 883,
          "old_api": "get",
          "new_api": "parent",
          "old_text": "new_hlo_module.get()",
          "new_text": "std::make_unique<HloModule>(\"extracted\", HloModuleConfig{},\n                                  std::make_unique<CompilationEnvironments>(\n                                      computation.parent()->comp_envs()))",
          "old_line_content": "  HloCloneContext clone_context(new_hlo_module.get());",
          "new_line_content": "      std::make_unique<HloModule>(\"extracted\", HloModuleConfig{},",
          "content_same": false
        },
        {
          "line": 884,
          "old_api": "CloneInContext",
          "new_api": "parent",
          "old_text": "new_hlo_module->AddEntryComputationWithLayouts(\n      computation.CloneInContext(clone_context))",
          "new_text": "std::make_unique<CompilationEnvironments>(\n                                      computation.parent()->comp_envs())",
          "old_line_content": "  new_hlo_module->AddEntryComputationWithLayouts(",
          "new_line_content": "                                  std::make_unique<CompilationEnvironments>(",
          "content_same": false
        },
        {
          "line": 885,
          "old_api": "CloneInContext",
          "new_api": "parent",
          "old_text": "computation.CloneInContext(clone_context)",
          "new_text": "computation.parent()->comp_envs()",
          "old_line_content": "      computation.CloneInContext(clone_context));",
          "new_line_content": "                                      computation.parent()->comp_envs()));",
          "content_same": false
        },
        {
          "line": 895,
          "old_api": "RunOnModule",
          "new_api": "debug_options",
          "old_text": "TritonAutotunerVisitor{config_, thread_pool_}.RunOnModule(\n      module, execution_threads)",
          "new_text": "module->config().debug_options().xla_gpu_autotune_level()",
          "old_line_content": "  return TritonAutotunerVisitor{config_, thread_pool_}.RunOnModule(",
          "new_line_content": "  if (module->config().debug_options().xla_gpu_autotune_level() == 0) {",
          "content_same": false
        }
      ],
      "additions": [
        {
          "line": 519,
          "old_api": null,
          "new_api": "set_xla_gpu_dump_autotune_results_to",
          "old_text": null,
          "new_text": "options.set_xla_gpu_dump_autotune_results_to(\"\")",
          "old_line_content": "    // Avoid using another thread pool.",
          "new_line_content": "    options.set_xla_gpu_dump_autotune_results_to(\"\");",
          "content_same": false
        },
        {
          "line": 524,
          "old_api": null,
          "new_api": "set_debug_options",
          "old_text": null,
          "new_text": "module->config().set_debug_options(options)",
          "old_line_content": "  }",
          "new_line_content": "    module->config().set_debug_options(options);",
          "content_same": false
        },
        {
          "line": 526,
          "old_api": null,
          "new_api": "std::move(module)",
          "old_text": null,
          "new_text": "std::move(module)",
          "old_line_content": "  // Runs a matmul fusion without Triton - with cuBLAS, to generate a reference",
          "new_line_content": "    return custom_hlo_runner.CompileRunningHloPasses(std::move(module));",
          "content_same": false
        },
        {
          "line": 539,
          "old_api": null,
          "new_api": "TF_ASSIGN_OR_RETURN",
          "old_text": null,
          "new_text": "TF_ASSIGN_OR_RETURN(std::unique_ptr<CustomHloRunner> custom_hlo_runner,\n                        CustomHloRunner::Create(*stream, *allocator))",
          "old_line_content": "    Executable* executable = nullptr;",
          "new_line_content": "    TF_ASSIGN_OR_RETURN(std::unique_ptr<CustomHloRunner> custom_hlo_runner,",
          "content_same": false
        },
        {
          "line": 540,
          "old_api": null,
          "new_api": "CustomHloRunner::Create(*stream, *allocator)",
          "old_text": null,
          "new_text": "CustomHloRunner::Create(*stream, *allocator)",
          "old_line_content": "    {",
          "new_line_content": "                        CustomHloRunner::Create(*stream, *allocator));",
          "content_same": false
        },
        {
          "line": 547,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "non_triton_executable_cache.end()",
          "old_line_content": "      }",
          "new_line_content": "      if (it != non_triton_executable_cache.end()) {",
          "content_same": false
        },
        {
          "line": 548,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(4)",
          "old_line_content": "    }",
          "new_line_content": "        VLOG(4) << \"Non-Triton executable cache hit\";",
          "content_same": false
        },
        {
          "line": 549,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "it->second.get()",
          "old_line_content": "    if (executable == nullptr) {",
          "new_line_content": "        executable = it->second.get();",
          "content_same": false
        },
        {
          "line": 553,
          "old_api": null,
          "new_api": "TF_ASSIGN_OR_RETURN",
          "old_text": null,
          "new_text": "TF_ASSIGN_OR_RETURN(\n          std::unique_ptr<Executable> new_executable,\n          CompileMatmulWithCublas(original_computation, *custom_hlo_runner))",
          "old_line_content": "",
          "new_line_content": "      TF_ASSIGN_OR_RETURN(",
          "content_same": false
        },
        {
          "line": 558,
          "old_api": null,
          "new_api": "emplace",
          "old_text": null,
          "new_text": "non_triton_executable_cache.emplace(\n          cache_key, std::move(new_executable))",
          "old_line_content": "    }",
          "new_line_content": "      auto [it, inserted] = non_triton_executable_cache.emplace(",
          "content_same": false
        },
        {
          "line": 560,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "it->second.get()",
          "old_line_content": "",
          "new_line_content": "      executable = it->second.get();",
          "content_same": false
        },
        {
          "line": 562,
          "old_api": null,
          "new_api": "TF_RET_CHECK",
          "old_text": null,
          "new_text": "TF_RET_CHECK(executable != nullptr)",
          "old_line_content": "    std::vector<ExecutionInput> execution_inputs;",
          "new_line_content": "    TF_RET_CHECK(executable != nullptr);",
          "content_same": false
        },
        {
          "line": 569,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "params.size()",
          "old_line_content": "      // Our executable doesn't have input-output aliasing, so we can pass",
          "new_line_content": "    execution_inputs.reserve(params.size());",
          "content_same": false
        },
        {
          "line": 570,
          "old_api": null,
          "new_api": "size",
          "old_text": null,
          "new_text": "params.size()",
          "old_line_content": "      // unowned input buffers.",
          "new_line_content": "    for (int i = 0; i < params.size(); ++i) {",
          "content_same": false
        },
        {
          "line": 574,
          "old_api": null,
          "new_api": "back",
          "old_text": null,
          "new_text": "execution_inputs.back().SetUnownedBuffer(\n          /*index=*/{},\n          MaybeOwningDeviceMemory(/*unowned=*/input_buffers.at(i)))",
          "old_line_content": "    }",
          "new_line_content": "      execution_inputs.back().SetUnownedBuffer(",
          "content_same": false
        },
        {
          "line": 576,
          "old_api": null,
          "new_api": "at",
          "old_text": null,
          "new_text": "input_buffers.at(i)",
          "old_line_content": "    // Not locking a GPU mutex here, because",
          "new_line_content": "          MaybeOwningDeviceMemory(/*unowned=*/input_buffers.at(i)));",
          "content_same": false
        },
        {
          "line": 587,
          "old_api": null,
          "new_api": "root_buffer",
          "old_text": null,
          "new_text": "result.root_buffer()",
          "old_line_content": "  }",
          "new_line_content": "    stream->ThenMemcpy(&output_buffer, result.root_buffer(),",
          "content_same": false
        },
        {
          "line": 588,
          "old_api": null,
          "new_api": "root_buffer",
          "old_text": null,
          "new_text": "result.root_buffer().size()",
          "old_line_content": "",
          "new_line_content": "                       result.root_buffer().size());",
          "content_same": false
        },
        {
          "line": 589,
          "old_api": null,
          "new_api": "OkStatus",
          "old_text": null,
          "new_text": "OkStatus()",
          "old_line_content": "  // Compile a given computation with a given autotuning config, utilizing",
          "new_line_content": "    return OkStatus();",
          "content_same": false
        },
        {
          "line": 603,
          "old_api": null,
          "new_api": "std::make_pair(cache_key, TritonTilingWrapper{autotune_config})",
          "old_text": null,
          "new_text": "std::make_pair(cache_key, TritonTilingWrapper{autotune_config})",
          "old_line_content": "    {",
          "new_line_content": "        std::make_pair(cache_key, TritonTilingWrapper{autotune_config});",
          "content_same": false
        },
        {
          "line": 608,
          "old_api": null,
          "new_api": "find",
          "old_text": null,
          "new_text": "compilation_cache.find(key)",
          "old_line_content": "        std::optional<CompilationResult>& res = it->second;",
          "new_line_content": "      auto it = compilation_cache.find(key);",
          "content_same": false
        },
        {
          "line": 610,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(4)",
          "old_line_content": "          return &*res;",
          "new_line_content": "        VLOG(4) << \"Compilation cache hit\";",
          "content_same": false
        },
        {
          "line": 612,
          "old_api": null,
          "new_api": "has_value",
          "old_text": null,
          "new_text": "res.has_value()",
          "old_line_content": "        return nullptr;",
          "new_line_content": "        if (res.has_value()) {",
          "content_same": false
        },
        {
          "line": 619,
          "old_api": null,
          "new_api": "TF_ASSIGN_OR_RETURN",
          "old_text": null,
          "new_text": "TF_ASSIGN_OR_RETURN(std::optional<CompilationResult> res,\n                        CompileNoCache(hlo_computation, autotune_config))",
          "old_line_content": "      absl::MutexLock lock(&compilation_cache_mutex);",
          "new_line_content": "    TF_ASSIGN_OR_RETURN(std::optional<CompilationResult> res,",
          "content_same": false
        },
        {
          "line": 623,
          "old_api": null,
          "new_api": "emplace",
          "old_text": null,
          "new_text": "compilation_cache.emplace(key, res)",
          "old_line_content": "        return &*res_inserted;",
          "new_line_content": "      auto [it2, inserted] = compilation_cache.emplace(key, res);",
          "content_same": false
        },
        {
          "line": 625,
          "old_api": null,
          "new_api": "has_value",
          "old_text": null,
          "new_text": "res_inserted.has_value()",
          "old_line_content": "      return nullptr;",
          "new_line_content": "      if (res_inserted.has_value()) {",
          "content_same": false
        },
        {
          "line": 638,
          "old_api": null,
          "new_api": "GetExecutor",
          "old_text": null,
          "new_text": "config_.GetExecutor()->GetDeviceDescription()",
          "old_line_content": "",
          "new_line_content": "        config_.GetExecutor()->GetDeviceDescription();",
          "content_same": false
        },
        {
          "line": 642,
          "old_api": null,
          "new_api": "FusionInstruction",
          "old_text": null,
          "new_text": "ExtractInstructionIntoNewModule(\n        *original_computation.FusionInstruction())",
          "old_line_content": "    // Copy the config from the original computations's module, but use the new",
          "new_line_content": "    std::unique_ptr<HloModule> new_hlo_module = ExtractInstructionIntoNewModule(",
          "content_same": false
        },
        {
          "line": 643,
          "old_api": null,
          "new_api": "FusionInstruction",
          "old_text": null,
          "new_text": "original_computation.FusionInstruction()",
          "old_line_content": "    // entry computation layout. If we extract an instruction into a new",
          "new_line_content": "        *original_computation.FusionInstruction());",
          "content_same": false
        },
        {
          "line": 650,
          "old_api": null,
          "new_api": "entry_computation_layout",
          "old_text": null,
          "new_text": "new_hlo_module->config().entry_computation_layout()",
          "old_line_content": "        new_entry_computation_layout;",
          "new_line_content": "        new_hlo_module->config().entry_computation_layout();",
          "content_same": false
        },
        {
          "line": 651,
          "old_api": null,
          "new_api": "parent",
          "old_text": null,
          "new_text": "original_computation.parent()->config()",
          "old_line_content": "",
          "new_line_content": "    new_hlo_module->set_config(original_computation.parent()->config());",
          "content_same": false
        },
        {
          "line": 652,
          "old_api": null,
          "new_api": "mutable_entry_computation_layout",
          "old_text": null,
          "new_text": "new_hlo_module->config().mutable_entry_computation_layout()",
          "old_line_content": "    DebugOptions options =",
          "new_line_content": "    *new_hlo_module->config().mutable_entry_computation_layout() =",
          "content_same": false
        },
        {
          "line": 662,
          "old_api": null,
          "new_api": "set_xla_gpu_dump_autotune_results_to",
          "old_text": null,
          "new_text": "options.set_xla_gpu_dump_autotune_results_to(\"\")",
          "old_line_content": "    // Avoid using another thread pool for PTX compilation - there are maximum",
          "new_line_content": "    options.set_xla_gpu_dump_autotune_results_to(\"\");",
          "content_same": false
        },
        {
          "line": 663,
          "old_api": null,
          "new_api": "set_xla_gpu_load_autotune_results_from",
          "old_text": null,
          "new_text": "options.set_xla_gpu_load_autotune_results_from(\"\")",
          "old_line_content": "    // two functions to compile here.",
          "new_line_content": "    options.set_xla_gpu_load_autotune_results_from(\"\");",
          "content_same": false
        },
        {
          "line": 668,
          "old_api": null,
          "new_api": "set_debug_options",
          "old_text": null,
          "new_text": "new_hlo_module->config().set_debug_options(options)",
          "old_line_content": "",
          "new_line_content": "    new_hlo_module->config().set_debug_options(options);",
          "content_same": false
        },
        {
          "line": 669,
          "old_api": null,
          "new_api": "entry_computation",
          "old_text": null,
          "new_text": "new_hlo_module->entry_computation()",
          "old_line_content": "    TF_ASSIGN_OR_RETURN(",
          "new_line_content": "    HloComputation* entry_computation = new_hlo_module->entry_computation();",
          "content_same": false
        },
        {
          "line": 670,
          "old_api": null,
          "new_api": "root_instruction",
          "old_text": null,
          "new_text": "entry_computation->root_instruction()",
          "old_line_content": "        auto backend_config,",
          "new_line_content": "    HloInstruction* cloned_dot_fusion = entry_computation->root_instruction();",
          "content_same": false
        },
        {
          "line": 678,
          "old_api": null,
          "new_api": "split_k",
          "old_text": null,
          "new_text": "autotune_config.split_k()",
          "old_line_content": "      }",
          "new_line_content": "    if (autotune_config.split_k() > 1) {",
          "content_same": false
        },
        {
          "line": 679,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "MakeDotSplitKBatch(cloned_dot_fusion, autotune_config).ok()",
          "old_line_content": "      GpuFloatSupport bf16_support(BF16);",
          "new_line_content": "      if (!MakeDotSplitKBatch(cloned_dot_fusion, autotune_config).ok()) {",
          "content_same": false
        },
        {
          "line": 684,
          "old_api": null,
          "new_api": "Run",
          "old_text": null,
          "new_text": "TF_RETURN_IF_ERROR(\n          float_normalization.Run(new_hlo_module.get()).status())",
          "old_line_content": "                                              gpu_device_info);",
          "new_line_content": "      TF_RETURN_IF_ERROR(",
          "content_same": false
        },
        {
          "line": 688,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "new_hlo_module.get()",
          "old_line_content": "      // into a fusion for a universal set of arguments for execution.",
          "new_line_content": "      TF_RETURN_IF_ERROR(instruction_fusion.Run(new_hlo_module.get()).status());",
          "content_same": false
        },
        {
          "line": 699,
          "old_api": null,
          "new_api": "ReplaceInstruction",
          "old_text": null,
          "new_text": "entry_computation->ReplaceInstruction(root, fusion_instruction)",
          "old_line_content": "      }",
          "new_line_content": "            entry_computation->ReplaceInstruction(root, fusion_instruction));",
          "content_same": false
        },
        {
          "line": 700,
          "old_api": null,
          "new_api": "FuseInstruction",
          "old_text": null,
          "new_text": "fusion_instruction->FuseInstruction(init_value)",
          "old_line_content": "    }",
          "new_line_content": "        fusion_instruction->FuseInstruction(init_value);",
          "content_same": false
        },
        {
          "line": 701,
          "old_api": null,
          "new_api": "RemoveInstruction",
          "old_text": null,
          "new_text": "entry_computation->RemoveInstruction(init_value)",
          "old_line_content": "",
          "new_line_content": "        TF_CHECK_OK(entry_computation->RemoveInstruction(init_value));",
          "content_same": false
        },
        {
          "line": 709,
          "old_api": null,
          "new_api": "Run",
          "old_text": null,
          "new_text": "HloVerifier(/*layout_sensitive=*/true,\n                                   /*allow_mixed_precision=*/false)\n                           .Run(new_hlo_module.get())\n                           .status()",
          "old_line_content": "                           .status());",
          "new_line_content": "    TF_RETURN_IF_ERROR(HloVerifier(/*layout_sensitive=*/true,",
          "content_same": false
        },
        {
          "line": 719,
          "old_api": null,
          "new_api": "GetExecutor",
          "old_text": null,
          "new_text": "config_.GetExecutor()->platform()->id()",
          "old_line_content": "        DummyCanShareBufferFunction,",
          "new_line_content": "        /*platform_id=*/config_.GetExecutor()->platform()->id(),",
          "content_same": false
        },
        {
          "line": 720,
          "old_api": null,
          "new_api": "cuda_compute_capability",
          "old_text": null,
          "new_text": "device_description.cuda_compute_capability()",
          "old_line_content": "        /*pointer_size=*/8, &compile_module_results);",
          "new_line_content": "        gpu_device_info, device_description.cuda_compute_capability(),",
          "content_same": false
        },
        {
          "line": 724,
          "old_api": null,
          "new_api": "ok",
          "old_text": null,
          "new_text": "compilation_status.ok()",
          "old_line_content": "      return {std::nullopt};",
          "new_line_content": "    if (!compilation_status.ok()) {",
          "content_same": false
        },
        {
          "line": 725,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(2)",
          "old_line_content": "    }",
          "new_line_content": "      VLOG(2) << \"Compilation of autotuning variant failed: \"",
          "content_same": false
        },
        {
          "line": 741,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "thunk.get()",
          "old_line_content": "    }",
          "new_line_content": "      KernelThunk* kernel_thunk = static_cast<KernelThunk*>(thunk.get());",
          "content_same": false
        },
        {
          "line": 742,
          "old_api": null,
          "new_api": "kernel_name",
          "old_text": null,
          "new_text": "kernel_thunk->kernel_name()",
          "old_line_content": "",
          "new_line_content": "      kernel_names.push_back(kernel_thunk->kernel_name());",
          "content_same": false
        },
        {
          "line": 743,
          "old_api": null,
          "new_api": "launch_dimensions",
          "old_text": null,
          "new_text": "kernel_thunk->launch_dimensions()",
          "old_line_content": "    TF_ASSIGN_OR_RETURN(",
          "new_line_content": "      launch_dimensions.push_back(kernel_thunk->launch_dimensions());",
          "content_same": false
        },
        {
          "line": 753,
          "old_api": null,
          "new_api": "debug_options",
          "old_text": null,
          "new_text": "new_hlo_module->config().debug_options()",
          "old_line_content": "        se::CompileGpuAsm(config_.GetExecutor()->device_ordinal(), ptx.c_str(),",
          "new_line_content": "        PtxOptsFromDebugOptions(new_hlo_module->config().debug_options());",
          "content_same": false
        },
        {
          "line": 762,
          "old_api": null,
          "new_api": "VLOG",
          "old_text": null,
          "new_text": "VLOG(1)",
          "old_line_content": "        CompilationResult{ptx, cubin, kernel_names, launch_dimensions});",
          "new_line_content": "    VLOG(1) << \"Compilation took: \" << compilation_time_span;",
          "content_same": false
        },
        {
          "line": 764,
          "old_api": null,
          "new_api": "std::make_optional(\n        CompilationResult{ptx, cubin, kernel_names, launch_dimensions})",
          "old_text": null,
          "new_text": "std::make_optional(\n        CompilationResult{ptx, cubin, kernel_names, launch_dimensions})",
          "old_line_content": "",
          "new_line_content": "    return std::make_optional(",
          "content_same": false
        },
        {
          "line": 774,
          "old_api": null,
          "new_api": "constexpr",
          "old_text": null,
          "new_text": "constexpr",
          "old_line_content": "",
          "new_line_content": "constexpr std::array<int, 4> NUM_STAGES = {1, 2, 3, 4};",
          "content_same": false
        },
        {
          "line": 775,
          "old_api": null,
          "new_api": "constexpr",
          "old_text": null,
          "new_text": "constexpr",
          "old_line_content": "std::vector<AutotuneResult::TritonGemmKey> GetExhaustiveMatmulAutotuneConfigs(",
          "new_line_content": "constexpr std::array<int, 4> NUM_WARPS = {2, 4, 8, 16};",
          "content_same": false
        },
        {
          "line": 776,
          "old_api": null,
          "new_api": "constexpr",
          "old_text": null,
          "new_text": "constexpr",
          "old_line_content": "    const se::CudaComputeCapability compute_capability) {",
          "new_line_content": "constexpr std::array<int, 4> SPLIT_K = {1, 2, 4, 8};",
          "content_same": false
        },
        {
          "line": 782,
          "old_api": null,
          "new_api": "IsAtLeast",
          "old_text": null,
          "new_text": "compute_capability.IsAtLeast(se::CudaComputeCapability::AMPERE)",
          "old_line_content": "      // Volta doesn't support num_stages > 2.",
          "new_line_content": "      compute_capability.IsAtLeast(se::CudaComputeCapability::AMPERE);",
          "content_same": false
        },
        {
          "line": 797,
          "old_api": null,
          "new_api": "GemmKey",
          "old_text": null,
          "new_text": "GemmKey(block_m, block_n, block_k, split_k,\n                                    num_stages, num_warps)",
          "old_line_content": "            }",
          "new_line_content": "              auto config = GemmKey(block_m, block_n, block_k, split_k,",
          "content_same": false
        },
        {
          "line": 799,
          "old_api": null,
          "new_api": "std::move(config)",
          "old_text": null,
          "new_text": "std::move(config)",
          "old_line_content": "        }",
          "new_line_content": "              configs.push_back(std::move(config));",
          "content_same": false
        },
        {
          "line": 817,
          "old_api": null,
          "new_api": "GemmKey",
          "old_text": null,
          "new_text": "GemmKey(64, 32, 64, 1, 2, 8)",
          "old_line_content": "        std::vector<AutotuneResult::TritonGemmKey>{",
          "new_line_content": "      GemmKey(64, 32, 64, 1, 2, 8)};",
          "content_same": false
        },
        {
          "line": 830,
          "old_api": null,
          "new_api": "GemmKey",
          "old_text": null,
          "new_text": "GemmKey(64, 64, 64, 1, 2, 4)",
          "old_line_content": "  }",
          "new_line_content": "            GemmKey(128, 128, 64, 2, 1, 8),  GemmKey(64, 64, 64, 1, 2, 4),",
          "content_same": false
        },
        {
          "line": 834,
          "old_api": null,
          "new_api": "IsAtLeast",
          "old_text": null,
          "new_text": "compute_capability.IsAtLeast(se::CudaComputeCapability::HOPPER)",
          "old_line_content": "                       [](const AutotuneResult::TritonGemmKey& config) {",
          "new_line_content": "  if (compute_capability.IsAtLeast(se::CudaComputeCapability::HOPPER)) {",
          "content_same": false
        },
        {
          "line": 838,
          "old_api": null,
          "new_api": "block_n",
          "old_text": null,
          "new_text": "config.block_n()",
          "old_line_content": "                       }),",
          "new_line_content": "                         return (config.block_m() * config.block_n() / 256) %",
          "content_same": false
        },
        {
          "line": 842,
          "old_api": null,
          "new_api": "end",
          "old_text": null,
          "new_text": "configs.end()",
          "old_line_content": "}",
          "new_line_content": "        configs.end());",
          "content_same": false
        },
        {
          "line": 853,
          "old_api": null,
          "new_api": "GetExhaustiveMatmulAutotuneConfigs",
          "old_text": null,
          "new_text": "GetExhaustiveMatmulAutotuneConfigs(compute_capability)",
          "old_line_content": "",
          "new_line_content": "             ? GetExhaustiveMatmulAutotuneConfigs(compute_capability)",
          "content_same": false
        },
        {
          "line": 854,
          "old_api": null,
          "new_api": "GetFixedMatmulAutotuneConfigs",
          "old_text": null,
          "new_text": "GetFixedMatmulAutotuneConfigs(compute_capability)",
          "old_line_content": "std::unique_ptr<HloModule> ExtractInstructionIntoNewModule(",
          "new_line_content": "             : GetFixedMatmulAutotuneConfigs(compute_capability);",
          "content_same": false
        },
        {
          "line": 859,
          "old_api": null,
          "new_api": "GetModule",
          "old_text": null,
          "new_text": "std::make_unique<HloModule>(\n      \"extracted\", HloModuleConfig{},\n      std::make_unique<CompilationEnvironments>(hlo.GetModule()->comp_envs()))",
          "old_line_content": "  int parameter_number = 0;",
          "new_line_content": "  auto new_hlo_module = std::make_unique<HloModule>(",
          "content_same": false
        },
        {
          "line": 864,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "new_hlo_module.get()",
          "old_line_content": "    std::unique_ptr<HloInstruction> new_parameter =",
          "new_line_content": "  HloCloneContext clone_context(new_hlo_module.get());",
          "content_same": false
        },
        {
          "line": 869,
          "old_api": null,
          "new_api": "name",
          "old_text": null,
          "new_text": "operand->name()",
          "old_line_content": "  }",
          "new_line_content": "                                        operand->name());",
          "content_same": false
        },
        {
          "line": 874,
          "old_api": null,
          "new_api": "shape",
          "old_text": null,
          "new_text": "hlo.shape()",
          "old_line_content": "  return new_hlo_module;",
          "new_line_content": "      hlo.CloneWithNewOperands(hlo.shape(), new_operands, &clone_context);",
          "content_same": false
        },
        {
          "line": 875,
          "old_api": null,
          "new_api": "std::move(new_instruction)",
          "old_text": null,
          "new_text": "std::move(new_instruction)",
          "old_line_content": "}",
          "new_line_content": "  builder.AddInstruction(std::move(new_instruction));",
          "content_same": false
        },
        {
          "line": 876,
          "old_api": null,
          "new_api": "Build",
          "old_text": null,
          "new_text": "builder.Build()",
          "old_line_content": "",
          "new_line_content": "  new_hlo_module->AddEntryComputationWithLayouts(builder.Build());",
          "content_same": false
        },
        {
          "line": 886,
          "old_api": null,
          "new_api": "get",
          "old_text": null,
          "new_text": "new_hlo_module.get()",
          "old_line_content": "  return new_hlo_module;",
          "new_line_content": "  HloCloneContext clone_context(new_hlo_module.get());",
          "content_same": false
        },
        {
          "line": 887,
          "old_api": null,
          "new_api": "CloneInContext",
          "old_text": null,
          "new_text": "new_hlo_module->AddEntryComputationWithLayouts(\n      computation.CloneInContext(clone_context))",
          "old_line_content": "}",
          "new_line_content": "  new_hlo_module->AddEntryComputationWithLayouts(",
          "content_same": false
        },
        {
          "line": 888,
          "old_api": null,
          "new_api": "CloneInContext",
          "old_text": null,
          "new_text": "computation.CloneInContext(clone_context)",
          "old_line_content": "",
          "new_line_content": "      computation.CloneInContext(clone_context));",
          "content_same": false
        },
        {
          "line": 898,
          "old_api": null,
          "new_api": "RunOnModule",
          "old_text": null,
          "new_text": "TritonAutotunerVisitor{config_, thread_pool_}.RunOnModule(\n      module, execution_threads)",
          "old_line_content": "",
          "new_line_content": "  return TritonAutotunerVisitor{config_, thread_pool_}.RunOnModule(",
          "content_same": false
        },
        {
          "line": 904,
          "old_api": null,
          "new_api": "clear",
          "old_text": null,
          "new_text": "compilation_cache.clear()",
          "old_line_content": "}  // namespace gpu",
          "new_line_content": "  compilation_cache.clear();",
          "content_same": false
        }
      ],
      "deletions": [
        {
          "line": 515,
          "old_api": "set_xla_dump_to",
          "new_api": null,
          "old_text": "options.set_xla_dump_to(\"\")",
          "new_text": null,
          "old_line_content": "    options.set_xla_dump_to(\"\");",
          "new_line_content": "    // use default algorithms to save compilation time and memory.",
          "content_same": false
        },
        {
          "line": 517,
          "old_api": "set_xla_gpu_load_autotune_results_from",
          "new_api": null,
          "old_text": "options.set_xla_gpu_load_autotune_results_from(\"\")",
          "new_text": null,
          "old_line_content": "    options.set_xla_gpu_load_autotune_results_from(\"\");",
          "new_line_content": "    // Avoid dumping compilation steps.",
          "content_same": false
        },
        {
          "line": 536,
          "old_api": "TF_ASSIGN_OR_RETURN",
          "new_api": null,
          "old_text": "TF_ASSIGN_OR_RETURN(std::unique_ptr<CustomHloRunner> custom_hlo_runner,\n                        CustomHloRunner::Create(*stream, *allocator))",
          "new_text": null,
          "old_line_content": "    TF_ASSIGN_OR_RETURN(std::unique_ptr<CustomHloRunner> custom_hlo_runner,",
          "new_line_content": "      se::DeviceMemoryAllocator* allocator,",
          "content_same": false
        },
        {
          "line": 537,
          "old_api": "CustomHloRunner::Create(*stream, *allocator)",
          "new_api": null,
          "old_text": "CustomHloRunner::Create(*stream, *allocator)",
          "new_text": null,
          "old_line_content": "                        CustomHloRunner::Create(*stream, *allocator));",
          "new_line_content": "      absl::Span<se::DeviceMemoryBase const> input_buffers,",
          "content_same": false
        },
        {
          "line": 543,
          "old_api": "find",
          "new_api": null,
          "old_text": "non_triton_executable_cache.find(cache_key)",
          "new_text": null,
          "old_line_content": "      auto it = non_triton_executable_cache.find(cache_key);",
          "new_line_content": "    {",
          "content_same": false
        },
        {
          "line": 544,
          "old_api": "end",
          "new_api": null,
          "old_text": "non_triton_executable_cache.end()",
          "new_text": null,
          "old_line_content": "      if (it != non_triton_executable_cache.end()) {",
          "new_line_content": "      absl::MutexLock lock(&non_triton_executable_cache_mutex);",
          "content_same": false
        },
        {
          "line": 545,
          "old_api": "VLOG",
          "new_api": null,
          "old_text": "VLOG(4)",
          "new_text": null,
          "old_line_content": "        VLOG(4) << \"Non-Triton executable cache hit\";",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 550,
          "old_api": "TF_ASSIGN_OR_RETURN",
          "new_api": null,
          "old_text": "TF_ASSIGN_OR_RETURN(\n          std::unique_ptr<Executable> new_executable,\n          CompileMatmulWithCublas(original_computation, *custom_hlo_runner))",
          "new_text": null,
          "old_line_content": "      TF_ASSIGN_OR_RETURN(",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 552,
          "old_api": "CompileMatmulWithCublas",
          "new_api": null,
          "old_text": "CompileMatmulWithCublas(original_computation, *custom_hlo_runner)",
          "new_text": null,
          "old_line_content": "          CompileMatmulWithCublas(original_computation, *custom_hlo_runner));",
          "new_line_content": "    if (executable == nullptr) {",
          "content_same": false
        },
        {
          "line": 556,
          "old_api": "std::move(new_executable)",
          "new_api": null,
          "old_text": "std::move(new_executable)",
          "new_text": null,
          "old_line_content": "          cache_key, std::move(new_executable));",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 557,
          "old_api": "get",
          "new_api": null,
          "old_text": "it->second.get()",
          "new_text": null,
          "old_line_content": "      executable = it->second.get();",
          "new_line_content": "      absl::MutexLock lock(&non_triton_executable_cache_mutex);",
          "content_same": false
        },
        {
          "line": 564,
          "old_api": "parameter_instructions",
          "new_api": null,
          "old_text": "original_computation.parameter_instructions()",
          "new_text": null,
          "old_line_content": "        original_computation.parameter_instructions();",
          "new_line_content": "    // Construct the parameters from the existing input buffers.",
          "content_same": false
        },
        {
          "line": 565,
          "old_api": "size",
          "new_api": null,
          "old_text": "params.size()",
          "new_text": null,
          "old_line_content": "    TF_RET_CHECK(input_buffers.size() == params.size());",
          "new_line_content": "    std::vector<ExecutionInput> execution_inputs;",
          "content_same": false
        },
        {
          "line": 566,
          "old_api": "size",
          "new_api": null,
          "old_text": "params.size()",
          "new_text": null,
          "old_line_content": "    execution_inputs.reserve(params.size());",
          "new_line_content": "    const HloInstruction::InstructionVector& params =",
          "content_same": false
        },
        {
          "line": 573,
          "old_api": "at",
          "new_api": null,
          "old_text": "input_buffers.at(i)",
          "new_text": null,
          "old_line_content": "          MaybeOwningDeviceMemory(/*unowned=*/input_buffers.at(i)));",
          "new_line_content": "      // unowned input buffers.",
          "content_same": false
        },
        {
          "line": 581,
          "old_api": "ConsumeResult",
          "new_api": null,
          "old_text": "execution_output.ConsumeResult()",
          "new_text": null,
          "old_line_content": "    ScopedShapedBuffer result = execution_output.ConsumeResult();",
          "new_line_content": "    TF_ASSIGN_OR_RETURN(",
          "content_same": false
        },
        {
          "line": 583,
          "old_api": "root_buffer",
          "new_api": null,
          "old_text": "result.root_buffer().size()",
          "new_text": null,
          "old_line_content": "    TF_RET_CHECK(output_buffer.size() == result.root_buffer().size());",
          "new_line_content": "        custom_hlo_runner->Execute(*executable, std::move(execution_inputs)));",
          "content_same": false
        },
        {
          "line": 585,
          "old_api": "root_buffer",
          "new_api": null,
          "old_text": "result.root_buffer().size()",
          "new_text": null,
          "old_line_content": "                       result.root_buffer().size());",
          "new_line_content": "    // Copy back the output.",
          "content_same": false
        },
        {
          "line": 600,
          "old_api": "std::make_pair(cache_key, TritonTilingWrapper{autotune_config})",
          "new_api": null,
          "old_text": "std::make_pair(cache_key, TritonTilingWrapper{autotune_config})",
          "new_text": null,
          "old_line_content": "        std::make_pair(cache_key, TritonTilingWrapper{autotune_config});",
          "new_line_content": "      const AutotuneResult::TritonGemmKey& autotune_config,",
          "content_same": false
        },
        {
          "line": 605,
          "old_api": "find",
          "new_api": null,
          "old_text": "compilation_cache.find(key)",
          "new_text": null,
          "old_line_content": "      auto it = compilation_cache.find(key);",
          "new_line_content": "    // TODO(b/266210099): Avoid duplication.",
          "content_same": false
        },
        {
          "line": 606,
          "old_api": "end",
          "new_api": null,
          "old_text": "compilation_cache.end()",
          "new_text": null,
          "old_line_content": "      if (it != compilation_cache.end()) {",
          "new_line_content": "    {",
          "content_same": false
        },
        {
          "line": 607,
          "old_api": "VLOG",
          "new_api": null,
          "old_text": "VLOG(4)",
          "new_text": null,
          "old_line_content": "        VLOG(4) << \"Compilation cache hit\";",
          "new_line_content": "      absl::MutexLock lock(&compilation_cache_mutex);",
          "content_same": false
        },
        {
          "line": 616,
          "old_api": "TF_ASSIGN_OR_RETURN",
          "new_api": null,
          "old_text": "TF_ASSIGN_OR_RETURN(std::optional<CompilationResult> res,\n                        CompileNoCache(hlo_computation, autotune_config))",
          "new_text": null,
          "old_line_content": "    TF_ASSIGN_OR_RETURN(std::optional<CompilationResult> res,",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 617,
          "old_api": "CompileNoCache",
          "new_api": null,
          "old_text": "CompileNoCache(hlo_computation, autotune_config)",
          "new_text": null,
          "old_line_content": "                        CompileNoCache(hlo_computation, autotune_config));",
          "new_line_content": "    }",
          "content_same": false
        },
        {
          "line": 622,
          "old_api": "has_value",
          "new_api": null,
          "old_text": "res_inserted.has_value()",
          "new_text": null,
          "old_line_content": "      if (res_inserted.has_value()) {",
          "new_line_content": "      absl::MutexLock lock(&compilation_cache_mutex);",
          "content_same": false
        },
        {
          "line": 632,
          "old_api": "NowNanos",
          "new_api": null,
          "old_text": "tsl::Env::Default()->NowNanos()",
          "new_text": null,
          "old_line_content": "    uint64_t start_compilation_nanos = tsl::Env::Default()->NowNanos();",
          "new_line_content": "  StatusOr<std::optional<CompilationResult>> CompileNoCache(",
          "content_same": false
        },
        {
          "line": 637,
          "old_api": "GetExecutor",
          "new_api": null,
          "old_text": "config_.GetExecutor()",
          "new_text": null,
          "old_line_content": "        GetGpuDeviceInfo(config_.GetExecutor());",
          "new_line_content": "    const se::DeviceDescription& device_description =",
          "content_same": false
        },
        {
          "line": 639,
          "old_api": "FusionInstruction",
          "new_api": null,
          "old_text": "ExtractInstructionIntoNewModule(\n        *original_computation.FusionInstruction())",
          "new_text": null,
          "old_line_content": "    std::unique_ptr<HloModule> new_hlo_module = ExtractInstructionIntoNewModule(",
          "new_line_content": "    const GpuDeviceInfo gpu_device_info =",
          "content_same": false
        },
        {
          "line": 647,
          "old_api": "entry_computation_layout",
          "new_api": null,
          "old_text": "new_hlo_module->config().entry_computation_layout()",
          "new_text": null,
          "old_line_content": "        new_hlo_module->config().entry_computation_layout();",
          "new_line_content": "    // module, then its entry computation layout can be different from that of",
          "content_same": false
        },
        {
          "line": 648,
          "old_api": "parent",
          "new_api": null,
          "old_text": "original_computation.parent()->config()",
          "new_text": null,
          "old_line_content": "    new_hlo_module->set_config(original_computation.parent()->config());",
          "new_line_content": "    // the original module.",
          "content_same": false
        },
        {
          "line": 649,
          "old_api": "mutable_entry_computation_layout",
          "new_api": null,
          "old_text": "new_hlo_module->config().mutable_entry_computation_layout()",
          "new_text": null,
          "old_line_content": "    *new_hlo_module->config().mutable_entry_computation_layout() =",
          "new_line_content": "    ComputationLayout new_entry_computation_layout =",
          "content_same": false
        },
        {
          "line": 653,
          "old_api": "parent",
          "new_api": null,
          "old_text": "original_computation.parent()->config().debug_options()",
          "new_text": null,
          "old_line_content": "        original_computation.parent()->config().debug_options();",
          "new_line_content": "        new_entry_computation_layout;",
          "content_same": false
        },
        {
          "line": 658,
          "old_api": "set_xla_dump_to",
          "new_api": null,
          "old_text": "options.set_xla_dump_to(\"\")",
          "new_text": null,
          "old_line_content": "    options.set_xla_dump_to(\"\");",
          "new_line_content": "    // TODO(b/277066525): stop using thunks.",
          "content_same": false
        },
        {
          "line": 660,
          "old_api": "set_xla_gpu_load_autotune_results_from",
          "new_api": null,
          "old_text": "options.set_xla_gpu_load_autotune_results_from(\"\")",
          "new_text": null,
          "old_line_content": "    options.set_xla_gpu_load_autotune_results_from(\"\");",
          "new_line_content": "    // Avoid dumping compilation steps of every autotuning variant.",
          "content_same": false
        },
        {
          "line": 665,
          "old_api": "set_debug_options",
          "new_api": null,
          "old_text": "new_hlo_module->config().set_debug_options(options)",
          "new_text": null,
          "old_line_content": "    new_hlo_module->config().set_debug_options(options);",
          "new_line_content": "    // Avoid using another thread pool for PTX compilation - there are maximum",
          "content_same": false
        },
        {
          "line": 666,
          "old_api": "entry_computation",
          "new_api": null,
          "old_text": "new_hlo_module->entry_computation()",
          "new_text": null,
          "old_line_content": "    HloComputation* entry_computation = new_hlo_module->entry_computation();",
          "new_line_content": "    // two functions to compile here.",
          "content_same": false
        },
        {
          "line": 672,
          "old_api": "mutable_triton_gemm_config",
          "new_api": null,
          "old_text": "backend_config.mutable_triton_gemm_config()",
          "new_text": null,
          "old_line_content": "    *backend_config.mutable_triton_gemm_config() = autotune_config;",
          "new_line_content": "    TF_ASSIGN_OR_RETURN(",
          "content_same": false
        },
        {
          "line": 673,
          "old_api": "set_backend_config",
          "new_api": null,
          "old_text": "cloned_dot_fusion->set_backend_config(backend_config)",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(cloned_dot_fusion->set_backend_config(backend_config));",
          "new_line_content": "        auto backend_config,",
          "content_same": false
        },
        {
          "line": 681,
          "old_api": "Run",
          "new_api": null,
          "old_text": "TF_RETURN_IF_ERROR(\n          float_normalization.Run(new_hlo_module.get()).status())",
          "new_text": null,
          "old_line_content": "      TF_RETURN_IF_ERROR(",
          "new_line_content": "      }",
          "content_same": false
        },
        {
          "line": 682,
          "old_api": "get",
          "new_api": null,
          "old_text": "new_hlo_module.get()",
          "new_text": null,
          "old_line_content": "          float_normalization.Run(new_hlo_module.get()).status());",
          "new_line_content": "      GpuFloatSupport bf16_support(BF16);",
          "content_same": false
        },
        {
          "line": 686,
          "old_api": "root_instruction",
          "new_api": null,
          "old_text": "entry_computation->root_instruction()",
          "new_text": null,
          "old_line_content": "      HloInstruction* root = entry_computation->root_instruction();",
          "new_line_content": "      GpuInstructionFusion instruction_fusion(/*may_duplicate=*/false,",
          "content_same": false
        },
        {
          "line": 691,
          "old_api": "shape",
          "new_api": null,
          "old_text": "HloInstruction::CreateFusion(\n                root->shape(), ChooseFusionKind(*root->operand(0), *root),\n                root)",
          "new_text": null,
          "old_line_content": "            entry_computation->AddInstruction(HloInstruction::CreateFusion(",
          "new_line_content": "      // into a fusion for a universal set of arguments for execution.",
          "content_same": false
        },
        {
          "line": 696,
          "old_api": "ReplaceInstruction",
          "new_api": null,
          "old_text": "entry_computation->ReplaceInstruction(root, fusion_instruction)",
          "new_text": null,
          "old_line_content": "            entry_computation->ReplaceInstruction(root, fusion_instruction));",
          "new_line_content": "                root));",
          "content_same": false
        },
        {
          "line": 706,
          "old_api": "Run",
          "new_api": null,
          "old_text": "HloVerifier(/*layout_sensitive=*/true,\n                                   /*allow_mixed_precision=*/false)\n                           .Run(new_hlo_module.get())\n                           .status()",
          "new_text": null,
          "old_line_content": "    TF_RETURN_IF_ERROR(HloVerifier(/*layout_sensitive=*/true,",
          "new_line_content": "    CompileModuleResults compile_module_results;",
          "content_same": false
        },
        {
          "line": 708,
          "old_api": "get",
          "new_api": null,
          "old_text": "new_hlo_module.get()",
          "new_text": null,
          "old_line_content": "                           .Run(new_hlo_module.get())",
          "new_line_content": "    // Verify the HLO here to catch potential rewrite errors.",
          "content_same": false
        },
        {
          "line": 712,
          "old_api": "get",
          "new_api": null,
          "old_text": "new_hlo_module.get()",
          "new_text": null,
          "old_line_content": "        new_hlo_module.get(), &llvm_context,",
          "new_line_content": "                           .status());",
          "content_same": false
        },
        {
          "line": 713,
          "old_api": "nvptx::TargetTriple()",
          "new_api": null,
          "old_text": "nvptx::TargetTriple()",
          "new_text": null,
          "old_line_content": "        /*target_triple=*/nvptx::TargetTriple(),",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 722,
          "old_api": "VLOG",
          "new_api": null,
          "old_text": "VLOG(2)",
          "new_text": null,
          "old_line_content": "      VLOG(2) << \"Compilation of autotuning variant failed: \"",
          "new_line_content": "        DummyCanShareBufferFunction,",
          "content_same": false
        },
        {
          "line": 729,
          "old_api": "std::holds_alternative<GpuExecutable::OwnedThunkSequence>(\n        compile_module_results.executable)",
          "new_api": null,
          "old_text": "std::holds_alternative<GpuExecutable::OwnedThunkSequence>(\n        compile_module_results.executable)",
          "new_text": null,
          "old_line_content": "    CHECK(std::holds_alternative<GpuExecutable::OwnedThunkSequence>(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 737,
          "old_api": "kind",
          "new_api": null,
          "old_text": "thunk->kind()",
          "new_text": null,
          "old_line_content": "      CHECK_EQ(thunk->kind(), Thunk::kKernel);",
          "new_line_content": "    // Expect at maximum two kernels: matmul and an optional reduction.",
          "content_same": false
        },
        {
          "line": 739,
          "old_api": "kernel_name",
          "new_api": null,
          "old_text": "kernel_thunk->kernel_name()",
          "new_text": null,
          "old_line_content": "      kernel_names.push_back(kernel_thunk->kernel_name());",
          "new_line_content": "    for (const std::unique_ptr<Thunk>& thunk : thunk_sequence) {",
          "content_same": false
        },
        {
          "line": 750,
          "old_api": "debug_options",
          "new_api": null,
          "old_text": "new_hlo_module->config().debug_options()",
          "new_text": null,
          "old_line_content": "        PtxOptsFromDebugOptions(new_hlo_module->config().debug_options());",
          "new_line_content": "                            new_hlo_module->config().debug_options()));",
          "content_same": false
        },
        {
          "line": 756,
          "old_api": "NowNanos",
          "new_api": null,
          "old_text": "tsl::Env::Default()->NowNanos()",
          "new_text": null,
          "old_line_content": "    uint64_t end_compilation_nanos = tsl::Env::Default()->NowNanos();",
          "new_line_content": "        se::CompileGpuAsm(config_.GetExecutor()->device_ordinal(), ptx.c_str(),",
          "content_same": false
        },
        {
          "line": 758,
          "old_api": "absl::Nanoseconds(end_compilation_nanos - start_compilation_nanos)",
          "new_api": null,
          "old_text": "absl::Nanoseconds(end_compilation_nanos - start_compilation_nanos)",
          "new_text": null,
          "old_line_content": "        absl::Nanoseconds(end_compilation_nanos - start_compilation_nanos);",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 770,
          "old_api": "constexpr",
          "new_api": null,
          "old_text": "constexpr",
          "new_text": null,
          "old_line_content": "constexpr std::array<int, 5> BLOCK_SIZES = {16, 32, 64, 128, 256};",
          "new_line_content": "};",
          "content_same": false
        },
        {
          "line": 771,
          "old_api": "constexpr",
          "new_api": null,
          "old_text": "constexpr",
          "new_text": null,
          "old_line_content": "constexpr std::array<int, 4> NUM_STAGES = {1, 2, 3, 4};",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 772,
          "old_api": "constexpr",
          "new_api": null,
          "old_text": "constexpr",
          "new_text": null,
          "old_line_content": "constexpr std::array<int, 4> NUM_WARPS = {2, 4, 8, 16};",
          "new_line_content": "// Search space for exhaustive matmul autotuning.",
          "content_same": false
        },
        {
          "line": 779,
          "old_api": "IsAtLeast",
          "new_api": null,
          "old_text": "compute_capability.IsAtLeast(se::CudaComputeCapability::AMPERE)",
          "new_text": null,
          "old_line_content": "      compute_capability.IsAtLeast(se::CudaComputeCapability::AMPERE);",
          "new_line_content": "    const se::CudaComputeCapability compute_capability) {",
          "content_same": false
        },
        {
          "line": 794,
          "old_api": "GemmKey",
          "new_api": null,
          "old_text": "GemmKey(block_m, block_n, block_k, split_k,\n                                    num_stages, num_warps)",
          "new_text": null,
          "old_line_content": "              auto config = GemmKey(block_m, block_n, block_k, split_k,",
          "new_line_content": "          }",
          "content_same": false
        },
        {
          "line": 796,
          "old_api": "std::move(config)",
          "new_api": null,
          "old_text": "std::move(config)",
          "new_text": null,
          "old_line_content": "              configs.push_back(std::move(config));",
          "new_line_content": "            for (int split_k : SPLIT_K) {",
          "content_same": false
        },
        {
          "line": 809,
          "old_api": "GemmKey",
          "new_api": null,
          "old_text": "GemmKey(64, 32, 32, 16, 1, 4)",
          "new_text": null,
          "old_line_content": "      GemmKey(32, 32, 256, 1, 1, 4), GemmKey(64, 32, 32, 16, 1, 4),",
          "new_line_content": "std::vector<AutotuneResult::TritonGemmKey> GetFixedMatmulAutotuneConfigs(",
          "content_same": false
        },
        {
          "line": 810,
          "old_api": "GemmKey",
          "new_api": null,
          "old_text": "GemmKey(128, 128, 64, 4, 1, 4)",
          "new_text": null,
          "old_line_content": "      GemmKey(32, 64, 64, 4, 1, 4),  GemmKey(128, 128, 64, 4, 1, 4),",
          "new_line_content": "    const se::CudaComputeCapability compute_capability) {",
          "content_same": false
        },
        {
          "line": 811,
          "old_api": "GemmKey",
          "new_api": null,
          "old_text": "GemmKey(16, 128, 32, 16, 1, 4)",
          "new_text": null,
          "old_line_content": "      GemmKey(16, 16, 256, 1, 1, 4), GemmKey(16, 128, 32, 16, 1, 4),",
          "new_line_content": "  std::vector<AutotuneResult::TritonGemmKey> configs = {",
          "content_same": false
        },
        {
          "line": 820,
          "old_api": "GemmKey",
          "new_api": null,
          "old_text": "GemmKey(64, 128, 32, 1, 4, 4)",
          "new_text": null,
          "old_line_content": "            GemmKey(128, 64, 32, 1, 4, 4),   GemmKey(64, 128, 32, 1, 4, 4),",
          "new_line_content": "        std::vector<AutotuneResult::TritonGemmKey>{",
          "content_same": false
        },
        {
          "line": 833,
          "old_api": "end",
          "new_api": null,
          "old_text": "configs.end()",
          "new_text": null,
          "old_line_content": "        std::remove_if(configs.begin(), configs.end(),",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 850,
          "old_api": "GetExhaustiveMatmulAutotuneConfigs",
          "new_api": null,
          "old_text": "GetExhaustiveMatmulAutotuneConfigs(compute_capability)",
          "new_text": null,
          "old_line_content": "             ? GetExhaustiveMatmulAutotuneConfigs(compute_capability)",
          "new_line_content": "    const se::CudaComputeCapability compute_capability,",
          "content_same": false
        },
        {
          "line": 851,
          "old_api": "GetFixedMatmulAutotuneConfigs",
          "new_api": null,
          "old_text": "GetFixedMatmulAutotuneConfigs(compute_capability)",
          "new_text": null,
          "old_line_content": "             : GetFixedMatmulAutotuneConfigs(compute_capability);",
          "new_line_content": "    bool exhaustive_tiling_search) {",
          "content_same": false
        },
        {
          "line": 856,
          "old_api": "GetModule",
          "new_api": null,
          "old_text": "std::make_unique<HloModule>(\n      \"extracted\", HloModuleConfig{},\n      std::make_unique<CompilationEnvironments>(hlo.GetModule()->comp_envs()))",
          "new_text": null,
          "old_line_content": "  auto new_hlo_module = std::make_unique<HloModule>(",
          "new_line_content": "",
          "content_same": false
        },
        {
          "line": 858,
          "old_api": "GetModule",
          "new_api": null,
          "old_text": "hlo.GetModule()->comp_envs()",
          "new_text": null,
          "old_line_content": "      std::make_unique<CompilationEnvironments>(hlo.GetModule()->comp_envs()));",
          "new_line_content": "    const HloInstruction& hlo) {",
          "content_same": false
        },
        {
          "line": 863,
          "old_api": "operands",
          "new_api": null,
          "old_text": "hlo.operands()",
          "new_text": null,
          "old_line_content": "  for (const HloInstruction* operand : hlo.operands()) {",
          "new_line_content": "  HloComputation::Builder builder(\"entry_computation\");",
          "content_same": false
        },
        {
          "line": 865,
          "old_api": "shape",
          "new_api": null,
          "old_text": "operand->shape()",
          "new_text": null,
          "old_line_content": "        HloInstruction::CreateParameter(parameter_number, operand->shape(),",
          "new_line_content": "  std::vector<HloInstruction*> new_operands;",
          "content_same": false
        },
        {
          "line": 872,
          "old_api": "std::move(new_instruction)",
          "new_api": null,
          "old_text": "std::move(new_instruction)",
          "new_text": null,
          "old_line_content": "  builder.AddInstruction(std::move(new_instruction));",
          "new_line_content": "  }",
          "content_same": false
        },
        {
          "line": 873,
          "old_api": "Build",
          "new_api": null,
          "old_text": "builder.Build()",
          "new_text": null,
          "old_line_content": "  new_hlo_module->AddEntryComputationWithLayouts(builder.Build());",
          "new_line_content": "  std::unique_ptr<HloInstruction> new_instruction =",
          "content_same": false
        },
        {
          "line": 880,
          "old_api": "parent",
          "new_api": null,
          "old_text": "std::make_unique<HloModule>(\"extracted\", HloModuleConfig{},\n                                  std::make_unique<CompilationEnvironments>(\n                                      computation.parent()->comp_envs()))",
          "new_text": null,
          "old_line_content": "      std::make_unique<HloModule>(\"extracted\", HloModuleConfig{},",
          "new_line_content": "std::unique_ptr<HloModule> ExtractComputationIntoNewModule(",
          "content_same": false
        },
        {
          "line": 881,
          "old_api": "parent",
          "new_api": null,
          "old_text": "std::make_unique<CompilationEnvironments>(\n                                      computation.parent()->comp_envs())",
          "new_text": null,
          "old_line_content": "                                  std::make_unique<CompilationEnvironments>(",
          "new_line_content": "    const HloComputation& computation) {",
          "content_same": false
        },
        {
          "line": 882,
          "old_api": "parent",
          "new_api": null,
          "old_text": "computation.parent()->comp_envs()",
          "new_text": null,
          "old_line_content": "                                      computation.parent()->comp_envs()));",
          "new_line_content": "  auto new_hlo_module =",
          "content_same": false
        },
        {
          "line": 892,
          "old_api": "debug_options",
          "new_api": null,
          "old_text": "module->config().debug_options().xla_gpu_autotune_level()",
          "new_text": null,
          "old_line_content": "  if (module->config().debug_options().xla_gpu_autotune_level() == 0) {",
          "new_line_content": "StatusOr<bool> TritonAutotuner::Run(",
          "content_same": false
        },
        {
          "line": 901,
          "old_api": "clear",
          "new_api": null,
          "old_text": "compilation_cache.clear()",
          "new_text": null,
          "old_line_content": "  compilation_cache.clear();",
          "new_line_content": "",
          "content_same": false
        }
      ]
    },
    "api_summary": {
      "total_replacements": 60,
      "total_additions": 79,
      "total_deletions": 78,
      "total_api_changes": 217
    },
    "non_api_changes": {
      "has_non_api_changes": true,
      "evidence": {
        "total_diff_lines": 3,
        "api_related_lines": 217,
        "non_api_lines": 1,
        "non_api_line_numbers": [
          514
        ]
      }
    },
    "api_calls_before": 366,
    "api_calls_after": 367,
    "diff_info": {
      "added_lines": 3,
      "removed_lines": 0,
      "total_diff_lines": 15
    }
  }
}