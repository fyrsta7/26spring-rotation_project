[
    {
        "repository_name": "git",
        "hash": "002933f3fe2b016022ebbbbb359f6aeba58309a4",
        "author": "SZEDER G\u00e1bor",
        "date": "2020-05-11T09:33:56-07:00",
        "message": "line-log: try to use generation number-based topo-ordering\n\nThe previous patch made it possible to perform line-level filtering\nduring history traversal instead of in an expensive preprocessing\nstep, but it still requires some simpler preprocessing steps, notably\ntopo-ordering.  However, nowadays we have commit-graphs storing\ngeneration numbers, which make it possible to incrementally traverse\nthe history in topological order, without the preparatory limit_list()\nand sort_in_topological_order() steps; see b45424181e (revision.c:\ngeneration-based topo-order algorithm, 2018-11-01).\n\nThis patch combines the two, so we can do both the topo-ordering and\nthe line-level filtering during history traversal, eliminating even\nthose simpler preprocessing steps, and thus further reducing the delay\nbefore showing the first commit modifying the given line range.\n\nThe 'revs->limited' flag plays the central role in this, because, due\nto limitations of the current implementation, the generation\nnumber-based topo-ordering is only enabled when this flag remains\nunset.  Line-level log, however, always sets this flag in\nsetup_revisions() ever since the feature was introduced in 12da1d1f6f\n(Implement line-history search (git log -L), 2013-03-28).  The reason\nfor setting 'limited' is unclear, though, because the line-level log\nitself doesn't directly depend on it, and it doesn't affect how the\nlimit_list() function limits the revision range.  However, there is an\nindirect dependency: the line-level log requires topo-ordering, and\nthe \"traditional\" sort_in_topological_order() requires an already\nlimited commit list since e6c3505b44 (Make sure we generate the whole\ncommit list before trying to sort it topologically, 2005-07-06).  The\nnew, generation numbers-based topo-ordering doesn't require a limited\ncommit list anymore.\n\nSo don't set 'revs->limited' for line-level log, unless it is really\nnecessary, namely:\n\n  - The user explicitly requested parent rewriting, because that is\n    still done in the line_log_filter() preprocessing step (see\n    previous patch), which requires sort_in_topological_order() and in\n    turn limit_list() as well.\n\n  - A commit-graph file is not available or it doesn't yet contain\n    generation numbers.  In these cases we had to fall back on\n    sort_in_topological_order() and in turn limit_list().  The\n    existing condition with generation_numbers_enabled() has already\n    ensured that the 'limited' flag is set in these cases; this patch\n    just makes sure that the line-level log sets 'revs->topo_order'\n    before that condition.\n\nWhile the reduced delay before showing the first commit is measurable\nin git.git, it takes a bigger repository to make it clearly noticable.\nIn both cases below the line ranges were chosen so that they were\nmodified rather close to the starting revisions, so the effect of this\nchange is most noticable.\n\n  # git.git\n  $ time git --no-pager log -L:read_alternate_refs:sha1-file.c -1 v2.23.0\n\n  Before:\n\n    real    0m0.107s\n    user    0m0.091s\n    sys     0m0.013s\n\n  After:\n\n    real    0m0.058s\n    user    0m0.050s\n    sys     0m0.005s\n\n  # linux.git\n  $ time git --no-pager log \\\n    -L:build_restore_work_registers:arch/mips/mm/tlbex.c -1 v5.2\n\n  Before:\n\n    real   0m1.129s\n    user   0m1.061s\n    sys    0m0.069s\n\n  After:\n\n    real   0m0.096s\n    user   0m0.087s\n    sys    0m0.009s\n\nAdditional testing by Derrick Stolee: Since this patch improves\nthe performance for the first result, I repeated the experiment\nfrom the previous patch on the Linux kernel repository, reporting\nreal time here:\n\n    Command: git log -L 100,200:MAINTAINERS -n 1 >/dev/null\n     Before: 0.71 s\n      After: 0.05 s\n\nNow, we have dropped the full topo-order of all ~910,000 commits\nbefore reporting the first result. The remaining performance\nimprovements then are:\n\n 1. Update the parent-rewriting logic to be incremental similar to\n    how \"git log --graph\" behaves.\n\n 2. Use changed-path Bloom filters to reduce the time spend in the\n    tree-diff to see if the path(s) changed.\n\nSigned-off-by: SZEDER G\u00e1bor <szeder.dev@gmail.com>\nSigned-off-by: Derrick Stolee <dstolee@microsoft.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "revision.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/002933f3fe2b016022ebbbbb359f6aeba58309a4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "setup_revisions"
        ],
        "added_lines": 6,
        "deleted_lines": 5,
        "total_changed_lines": 11,
        "net_line_change": 1,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "008ed7df93082103c8c74d045e573e19868b2c6b",
        "author": "Karthik Nayak",
        "date": "2015-10-18T16:07:36-07:00",
        "message": "tag.c: use the correct algorithm for the '--contains' option\n\nIn b7cc53e9 (tag.c: use 'ref-filter' APIs, 2015-09-11) we port tag.c\nto use the ref-filter APIs for filtering and printing refs.  In\nref-filter we have two implementations for filtering refs when the\n'--contains' option is used.\n\nAlthough they do the same thing, one is optimized for filtering\nbranches and the other for tags (borrowed from branch.c and tag.c\nrespectively) and the 'filter->with_commit_tag_algo' bit decides\nwhich algorithm must be used.  We should unify these.\n\nWhen we ported tag.c to use ref-filter APIs we missed out on setting\nthe 'filter->with_commit_tag_algo' bit.  As reported by Jerry\nSnitselaar, this causes \"git tag --contains\" to work way slower than\nexpected, fix this by setting 'filter->with_commit_tag_algo' in\ntag.c before calling 'filter_refs()'.\n\nMentored-by: Matthieu Moy <matthieu.moy@grenoble-inp.fr>\nTested-by: Jerry Snitselaar <jsnitsel@redhat.com>\nSigned-off-by: Karthik Nayak <karthik.188@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/tag.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/008ed7df93082103c8c74d045e573e19868b2c6b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "list_tags"
        ],
        "added_lines": 1,
        "deleted_lines": 0,
        "total_changed_lines": 1,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "010e5eacfb004218087da054a61772da8fc40463",
        "author": "Jeff King",
        "date": "2020-12-08T14:48:16-08:00",
        "message": "pack-bitmap-write: pass ownership of intermediate bitmaps\n\nOur algorithm to generate reachability bitmaps walks through the commit\ngraph from the bottom up, passing bitmap data from each commit to its\ndescendants. For a linear stretch of history like:\n\n  A -- B -- C\n\nour sequence of steps is:\n\n  - compute the bitmap for A by walking its trees, etc\n\n  - duplicate A's bitmap as a starting point for B; we can now free A's\n    bitmap, since we only needed it as an intermediate result\n\n  - OR in any extra objects that B can reach into its bitmap\n\n  - duplicate B's bitmap as a starting point for C; likewise, free B's\n    bitmap\n\n  - OR in objects for C, and so on...\n\nRather than duplicating bitmaps and immediately freeing the original, we\ncan just pass ownership from commit to commit. Note that this doesn't\nalways work:\n\n  - the recipient may be a merge which already has an intermediate\n    bitmap from its other ancestor. In that case we have to OR our\n    result into it. Note that the first ancestor to reach the merge does\n    get to pass ownership, though.\n\n  - we may have multiple children; we can only pass ownership to one of\n    them\n\nHowever, it happens often enough and copying bitmaps is expensive enough\nthat this provides a noticeable speedup. On a clone of linux.git, this\nreduces the time to generate bitmaps from 205s to 70s. This is about the\nsame amount of time it took to generate bitmaps using our old \"many\ntraversals\" algorithm (the previous commit measures the identical\nscenario as taking 63s). It unfortunately provides only a very modest\nreduction in the peak memory usage, though.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Taylor Blau <me@ttaylorr.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "pack-bitmap-write.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/010e5eacfb004218087da054a61772da8fc40463",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "bitmap_writer_build"
        ],
        "added_lines": 8,
        "deleted_lines": 2,
        "total_changed_lines": 10,
        "net_line_change": 6,
        "modified_code_blocks": 4,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "037df60013bb3f1534d4db6bf850d7547f1c1d13",
        "author": "Patrick Steinhardt",
        "date": "2024-06-12T12:57:18-07:00",
        "message": "object-name: don't try to abbreviate to lengths greater than hexsz\n\nWhen given a length that equals the current hash algorithm's hex size,\nthen `repo_find_unique_abbrev_r()` exits early without trying to find an\nabbreviation. This is only sensible because there is nothing to\nabbreviate in the first place, so searching through objects to find a\nunique prefix would be a waste of compute.\n\nWhat we don't handle though is the case where the user passes a length\ngreater than the hash length. This is fine in practice as we still\ncompute the correct result. But at the very least, this is a waste of\nresources as we try to abbreviate a value that cannot be abbreviated,\nwhich causes us to hit the object database.\n\nStart to explicitly handle values larger than hexsz to avoid this\nperformance penalty, which leads to a measureable speedup. The following\nbenchmark has been executed in linux.git:\n\n  Benchmark 1: git -c core.abbrev=9000 log --abbrev-commit (revision = HEAD~)\n    Time (mean \u00b1 \u03c3):     12.812 s \u00b1  0.040 s    [User: 12.225 s, System: 0.554 s]\n    Range (min \u2026 max):   12.723 s \u2026 12.857 s    10 runs\n\n  Benchmark 2: git -c core.abbrev=9000 log --abbrev-commit (revision = HEAD)\n    Time (mean \u00b1 \u03c3):     11.095 s \u00b1  0.029 s    [User: 10.546 s, System: 0.521 s]\n    Range (min \u2026 max):   11.037 s \u2026 11.122 s    10 runs\n\n  Summary\n    git -c core.abbrev=9000 log --abbrev-commit HEAD (revision = HEAD) ran\n      1.15 \u00b1 0.00 times faster than git -c core.abbrev=9000 log --abbrev-commit HEAD (revision = HEAD~)\n\nSigned-off-by: Patrick Steinhardt <ps@pks.im>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "object-name.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/037df60013bb3f1534d4db6bf850d7547f1c1d13",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "repo_find_unique_abbrev_r"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "04bc8d1ecc30bae9589f3d77a0a89f3dca28a024",
        "author": "Derrick Stolee",
        "date": "2018-05-22T12:36:34+09:00",
        "message": "commit: use generation number in remove_redundant()\n\nThe static remove_redundant() method is used to filter a list\nof commits by removing those that are reachable from another\ncommit in the list. This is used to remove all possible merge-\nbases except a maximal, mutually independent set.\n\nTo determine these commits are independent, we use a number of\npaint_down_to_common() walks and use the PARENT1, PARENT2 flags\nto determine reachability. Since we only care about reachability\nand not the full set of merge-bases between 'one' and 'twos', we\ncan use the 'min_generation' parameter to short-circuit the walk.\n\nWhen no commit-graph exists, there is no change in behavior.\n\nFor a copy of the Linux repository, we measured the following\nperformance improvements:\n\ngit merge-base v3.3 v4.5\n\nBefore: 234 ms\n After: 208 ms\n Rel %: -11%\n\ngit merge-base v4.3 v4.5\n\nBefore: 102 ms\n After:  83 ms\n Rel %: -19%\n\nThe experiments above were chosen to demonstrate that we are\nimproving the filtering of the merge-base set. In the first\nexample, more time is spent walking the history to find the\nset of merge bases before the remove_redundant() call. The\nstarting commits are closer together in the second example,\ntherefore more time is spent in remove_redundant(). The relative\nchange in performance differs as expected.\n\nReported-by: Jakub Narebski <jnareb@gmail.com>\nSigned-off-by: Derrick Stolee <dstolee@microsoft.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "commit.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/04bc8d1ecc30bae9589f3d77a0a89f3dca28a024",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "remove_redundant"
        ],
        "added_lines": 6,
        "deleted_lines": 1,
        "total_changed_lines": 7,
        "net_line_change": 5,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "04d67b6ab222060546af328207ad48ae8ad58fe9",
        "author": "Junio C Hamano",
        "date": "2019-02-05T14:26:14-08:00",
        "message": "Merge branch 'ab/commit-graph-write-optim'\n\nThe codepath to write out commit-graph has been optimized by\nfollowing the usual pattern of visiting objects in in-pack order.\n\n* ab/commit-graph-write-optim:\n  commit-graph write: use pack order when finding commits",
        "modified_files_count": 1,
        "modified_files": [
            "commit-graph.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/04d67b6ab222060546af328207ad48ae8ad58fe9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "write_commit_graph"
        ],
        "added_lines": 4,
        "deleted_lines": 2,
        "total_changed_lines": 6,
        "net_line_change": 2,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "068fa54c0034be0b953d798628b06815f9cfaff0",
        "author": "Derrick Stolee",
        "date": "2022-07-19T08:38:17-07:00",
        "message": "midx: reduce memory pressure while writing bitmaps\n\nWe noticed that some 'git multi-pack-index write --bitmap' processes\nwere running with very high memory. It turns out that a lot of this\nmemory is required to store a list of every object in the written\nmulti-pack-index, with a second copy that has additional information\nused for the bitmap writing logic.\n\nUsing 'valgrind --tool=massif' before this change, the following chart\nshows how memory load increased and was maintained throughout the\nprocess:\n\n    GB\n4.102^                                                             ::\n     |              @  @::@@::@@::::::::@::::::@@:#:::::::::::::@@:: :\n     |         :::::@@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     |      :::: :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     |    :::: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     |    : :: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     |    : :: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     |   :: :: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     |   :: :: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     |   :: :: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     |   :: :: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     |   :: :: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     |   :: :: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     |   :: :: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     | @ :: :: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     | @ :: :: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     | @::: :: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     | @::: :: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     | @::: :: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n     | @::: :: : :: @@:@: @ ::@ ::: ::::@: ::: @@:#:::::: :: : :@ :: :\n   0 +--------------------------------------------------------------->\n\nIt turns out that the 'struct write_midx_context' data is persisting\nthrough the life of the process, including the 'entries' array. This\narray is used last inside find_commits_for_midx_bitmap() within\nwrite_midx_bitmap(). If we free (and nullify) the array at that point,\nwe can free a decent chunk of memory before the bitmap logic adds more\nto the memory footprint.\n\nHere is the massif memory load chart after this change:\n\n    GB\n3.111^      #\n     |      #                              :::::::::::@::::::::::::::@\n     |      #        ::::::::::::::::::::::::: : :: : @:: ::::: :: ::@\n     |     @#  :::::::::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |     @#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |     @#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |     @#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |     @#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |     @#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |     @#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |     @#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |     @#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |     @#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |     @#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |     @#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |     @#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |  :::@#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |  :: @#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |  :: @#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n     |  :: @#::: ::: :::::: :::: :: : :::::::: : :: : @:: ::::: :: ::@\n   0 +--------------------------------------------------------------->\n\nThe previous change introduced a refactoring of write_midx_bitmap() to\nmake it more clear how much of the 'struct write_midx_context' instance\nis needed at different parts of the process. In addition, the following\ndefensive programming measures were put in place:\n\n 1. Using FREE_AND_NULL() we will at least get a segfault from reading a\n    NULL pointer instead of a use-after-free.\n\n 2. 'entries_nr' is also set to zero to make any loop that would iterate\n    over the entries be trivial.\n\n 3. Add significant comments in write_midx_internal() to add warnings\n    for future authors who might accidentally add references to this\n    cleared memory.\n\nSigned-off-by: Derrick Stolee <derrickstolee@github.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "midx.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/068fa54c0034be0b953d798628b06815f9cfaff0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "write_midx_internal"
        ],
        "added_lines": 13,
        "deleted_lines": 0,
        "total_changed_lines": 13,
        "net_line_change": 13,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "07f7d55a346f0eb73a358736ce065f8c08b46452",
        "author": "Ren\u00e9 Scharfe",
        "date": "2017-12-28T13:50:05-08:00",
        "message": "commit: avoid allocation in clear_commit_marks_many()\n\nPass the entries of the commit array directly to clear_commit_marks_1()\ninstead of adding them to a commit_list first.  The function clears the\ncommit and any first parent without allocation; only higher numbered\nparents are added to a list for later treatment.  This change extends\nthat optimization to clear_commit_marks_many().\n\nSigned-off-by: Rene Scharfe <l.s.r@web.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "commit.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/07f7d55a346f0eb73a358736ce065f8c08b46452",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "clear_commit_marks_many"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "0910e8cab828b53fd7188a93c0476cab0af81cdc",
        "author": "Linus Torvalds",
        "date": "2005-10-19T00:01:01-07:00",
        "message": "Optimize common case of git-rev-list\n\nI took a look at webgit, and it looks like at least for the \"projects\"\npage, the most common operation ends up being basically\n\n\tgit-rev-list --header --parents --max-count=1 HEAD\n\nNow, the thing is, the way \"git-rev-list\" works, it always keeps on\npopping the parents and parsing them in order to build the list of\nparents, and it turns out that even though we just want a single commit,\ngit-rev-list will invariably look up _three_ generations of commits.\n\nIt will parse:\n - the commit we want (it obviously needs this)\n - it's parent(s) as part of the \"pop_most_recent_commit()\" logic\n - it will then pop one of the parents before it notices that it doesn't\n   need any more\n - and as part of popping the parent, it will parse the grandparent (again\n   due to \"pop_most_recent_commit()\".\n\nNow, I've strace'd it, and it really is pretty efficient on the whole, but\nif things aren't nicely cached, and with long-latency IO, doing those two\nextra objects (at a minimum - if the parent is a merge it will be more) is\njust wasted time, and potentially a lot of it.\n\nSo here's a quick special-case for the trivial case of \"just one commit,\nand no date-limits or other special rules\".\n\nSigned-off-by: Linus Torvalds <torvalds@osdl.org>\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "rev-list.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/0910e8cab828b53fd7188a93c0476cab0af81cdc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "added_lines": 5,
        "deleted_lines": 0,
        "total_changed_lines": 5,
        "net_line_change": 5,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "091f4cf3586957c3fd99d4c4c59c569d009137ad",
        "author": "Derrick Stolee",
        "date": "2018-08-30T11:17:57-07:00",
        "message": "commit: don't use generation numbers if not needed\n\nIn 3afc679b \"commit: use generations in paint_down_to_common()\",\nthe queue in paint_down_to_common() was changed to use a priority\norder based on generation number before commit date. This served\ntwo purposes:\n\n 1. When generation numbers are present, the walk guarantees\n    correct topological relationships, regardless of clock skew in\n    commit dates.\n\n 2. It enables short-circuiting the walk when the min_generation\n    parameter is added in d7c1ec3e \"commit: add short-circuit to\n    paint_down_to_common()\". This short-circuit helps commands\n    like 'git branch --contains' from needing to walk to a merge\n    base when we know the result is false.\n\nThe commit message for 3afc679b includes the following sentence:\n\n    This change does not affect the number of commits that are\n    walked during the execution of paint_down_to_common(), only\n    the order that those commits are inspected.\n\nThis statement is incorrect. Because it changes the order in which\nthe commits are inspected, it changes the order they are added to\nthe queue, and hence can change the number of loops before the\nqueue_has_nonstale() method returns true.\n\nThis change makes a concrete difference depending on the topology\nof the commit graph. For instance, computing the merge-base between\nconsecutive versions of the Linux kernel has no effect for versions\nafter v4.9, but 'git merge-base v4.8 v4.9' presents a performance\nregression:\n\n    v2.18.0: 0.122s\nv2.19.0-rc1: 0.547s\n       HEAD: 0.127s\n\nTo determine that this was simply an ordering issue, I inserted\na counter within the while loop of paint_down_to_common() and\nfound that the loop runs 167,468 times in v2.18.0 and 635,579\ntimes in v2.19.0-rc1.\n\nThe topology of this case can be described in a simplified way\nhere:\n\n  v4.9\n   |  \\\n   |   \\\n  v4.8  \\\n   | \\   \\\n   |  \\   |\n  ...  A  B\n   |  /  /\n   | /  /\n   |/__/\n   C\n\nHere, the \"...\" means \"a very long line of commits\". By generation\nnumber, A and B have generation one more than C. However, A and B\nhave commit date higher than most of the commits reachable from\nv4.8. When the walk reaches v4.8, we realize that it has PARENT1\nand PARENT2 flags, so everything it can reach is marked as STALE,\nincluding A. B has only the PARENT1 flag, so is not STALE.\n\nWhen paint_down_to_common() is run using\ncompare_commits_by_commit_date, A and B are removed from the queue\nearly and C is inserted into the queue. At this point, C and the\nrest of the queue entries are marked as STALE. The loop then\nterminates.\n\nWhen paint_down_to_common() is run using\ncompare_commits_by_gen_then_commit_date, B is removed from the\nqueue only after the many commits reachable from v4.8 are explored.\nThis causes the loop to run longer. The reason for this regression\nis simple: the queue order is intended to not explore a commit\nuntil everything that _could_ reach that commit is explored. From\nthe information gathered by the original ordering, we have no\nguarantee that there is not a commit D reachable from v4.8 that\ncan also reach B. We gained absolute correctness in exchange for\na performance regression.\n\nThe performance regression is probably the worse option, since\nthese incorrect results in paint_down_to_common() are rare. The\ntopology required for the performance regression are less rare,\nbut still require multiple merge commits where the parents differ\ngreatly in generation number. In our example above, the commit A\nis as important as the commit B to demonstrate the problem, since\notherwise the commit C will sit in the queue as non-stale just as\nlong in both orders.\n\nThe solution provided uses the min_generation parameter to decide\nif we should use generation numbers in our ordering. When\nmin_generation is equal to zero, it means that the caller has no\nknown cutoff for the walk, so we should rely on our commit-date\nheuristic as before; this is the case with merge_bases_many().\nWhen min_generation is non-zero, then the caller knows a valuable\ncutoff for the short-circuit mechanism; this is the case with\nremove_redundant() and in_merge_bases_many().\n\nSigned-off-by: Derrick Stolee <dstolee@microsoft.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "commit.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/091f4cf3586957c3fd99d4c4c59c569d009137ad",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "paint_down_to_common"
        ],
        "added_lines": 4,
        "deleted_lines": 1,
        "total_changed_lines": 5,
        "net_line_change": 3,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "09b2e40944f297d6cabe0fb0ce2e3a72e610f657",
        "author": "Junio C Hamano",
        "date": "2019-02-05T14:26:10-08:00",
        "message": "Merge branch 'jt/get-reference-with-commit-graph'\n\nMicro-optimize the code that prepares commit objects to be walked\nby \"git rev-list\" when the commit-graph is available.\n\n* jt/get-reference-with-commit-graph:\n  revision: use commit graph in get_reference()",
        "modified_files_count": 1,
        "modified_files": [
            "revision.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/09b2e40944f297d6cabe0fb0ce2e3a72e610f657",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_reference"
        ],
        "added_lines": 14,
        "deleted_lines": 1,
        "total_changed_lines": 15,
        "net_line_change": 13,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "0b006014c87f400bd9a86267ed30fd3e7b383884",
        "author": "Jeff King",
        "date": "2017-08-09T11:03:25-07:00",
        "message": "hashcmp: use memcmp instead of open-coded loop\n\nIn 1a812f3a70 (hashcmp(): inline memcmp() by hand to\noptimize, 2011-04-28), it was reported that an open-coded\nloop outperformed memcmp() for comparing sha1s.\n\nDiscussion[1] a few years later in 2013 showed that this\ndepends on your libc's version of memcmp(). In particular,\nglibc 2.13 optimized their memcmp around 2011. Here are\ncurrent timings with glibc 2.24 (best-of-five, on\nlinux.git):\n\n  [before this patch, open-coded]\n  $ time git rev-list --objects --all\n  real\t0m35.357s\n  user\t0m35.016s\n  sys\t0m0.340s\n\n  [after this patch, memcmp]\n  real\t0m32.930s\n  user\t0m32.630s\n  sys\t0m0.300s\n\nNow that we've had 6 years for that version of glibc to\nmake its way onto people's machines, it's worth revisiting\nour benchmarks and switching to memcmp().\n\nIt may be that there are other non-glibc systems where\nmemcmp() isn't as well optimized. But since our single data\npoint in favor of open-coding was on a now-ancient glibc, we\nshould probably assume the system memcmp is good unless\nproven otherwise. We may end up with a SLOW_MEMCMP Makefile\nknob, but we can hold off on that until we actually find\nsuch a system in practice.\n\n[1] https://public-inbox.org/git/20130318073229.GA5551@sigill.intra.peff.net/\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "cache.h"
        ],
        "github_commit_url": "https://github.com/git/git/commit/0b006014c87f400bd9a86267ed30fd3e7b383884",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "hashcmp"
        ],
        "added_lines": 1,
        "deleted_lines": 8,
        "total_changed_lines": 9,
        "net_line_change": -7,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "0b868f0eecf4a5b4f25b5876e731f0b5456edc89",
        "author": "Stefan Beller",
        "date": "2015-02-13T13:42:17-08:00",
        "message": "hex.c: reduce memory footprint of sha1_to_hex static buffers\n\n41 bytes is the exact number of bytes needed for having the returned\nhex string represented. 50 seems to be an arbitrary number, such\nthat there are no benefits from alignment to certain address boundaries.\n\nSigned-off-by: Stefan Beller <sbeller@google.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "hex.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/0b868f0eecf4a5b4f25b5876e731f0b5456edc89",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sha1_to_hex"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "0cd0afc9c6193dd4a762f5a2d1bc23e58629b23f",
        "author": "Junio C Hamano",
        "date": "2020-06-17T21:54:00-07:00",
        "message": "Merge branch 'jk/diff-memuse-optim-with-stat-unmatch'\n\nReduce memory usage during \"diff --quiet\" in a worktree with too\nmany stat-unmatched paths.\n\n* jk/diff-memuse-optim-with-stat-unmatch:\n  diff: discard blob data from stat-unmatched pairs",
        "modified_files_count": 1,
        "modified_files": [
            "diff.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/0cd0afc9c6193dd4a762f5a2d1bc23e58629b23f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "diff_change"
        ],
        "added_lines": 4,
        "deleted_lines": 1,
        "total_changed_lines": 5,
        "net_line_change": 3,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "135a12bc1472290ca6b9a4c2f06c838a1495a612",
        "author": "Glen Choo",
        "date": "2022-01-18T16:22:57-08:00",
        "message": "fetch: skip tasks related to fetching objects\n\ncmd_fetch() does the following with the assumption that objects are\nfetched:\n\n* Run gc\n* Write commit graphs (if enabled by fetch.writeCommitGraph=true)\n\nHowever, neither of these tasks makes sense if objects are not fetched\ne.g. `git fetch --negotiate-only` never fetches objects.\n\nSpeed up cmd_fetch() by bailing out early if we know for certain that\nobjects will not be fetched. cmd_fetch() can bail out early whenever\nobjects are not fetched, but for now this only considers\n--negotiate-only.\n\nThe same optimization does not apply to `git fetch --dry-run` because\nthat actually fetches objects; the dry run refers to not updating refs.\n\nSigned-off-by: Glen Choo <chooglen@google.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/fetch.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/135a12bc1472290ca6b9a4c2f06c838a1495a612",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_fetch"
        ],
        "added_lines": 11,
        "deleted_lines": 0,
        "total_changed_lines": 11,
        "net_line_change": 11,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "149794dd1db18b22f4df94ef13cf61520d7be1d8",
        "author": "Junio C Hamano",
        "date": "2010-02-17T12:30:41-08:00",
        "message": "status: preload index to optimize lstat(2) calls\n\nNoticed by James Pickens\n\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin-commit.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/149794dd1db18b22f4df94ef13cf61520d7be1d8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_status"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "162eb5f838630f75f78f26d28b46b02781724b7d",
        "author": "Shawn O. Pearce",
        "date": "2010-04-19T17:55:59-07:00",
        "message": "http.c: Remove unnecessary strdup of sha1_to_hex result\n\nMost of the time the dumb HTTP transport is run without the verbose\nflag set, so we only need the result of sha1_to_hex(sha1) once, to\nconstruct the pack URL.  Don't bother with an unnecessary malloc,\ncopy, free chain of this buffer.\n\nIf verbose is set, we'll format the SHA-1 twice now.  But this\ntiny extra CPU time spent is nothing compared to the slowdown that\nis usually imposed by the verbose messages being sent to the tty,\nand is entirely trivial compared to the latency involved with the\nremote HTTP server sending something as big as a pack file.\n\nSigned-off-by: Shawn O. Pearce <spearce@spearce.org>\nAcked-by: Tay Ray Chuan <rctay89@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "http.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/162eb5f838630f75f78f26d28b46b02781724b7d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "fetch_pack_index"
        ],
        "added_lines": 2,
        "deleted_lines": 4,
        "total_changed_lines": 6,
        "net_line_change": -2,
        "modified_code_blocks": 4,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "174791f0fb23e29de1d879c1aae3a164bb998885",
        "author": "Elijah Newren",
        "date": "2021-03-10T22:18:05-08:00",
        "message": "merge-ort: use relevant_sources to filter possible rename sources\n\nThe past several commits determined conditions when rename sources might\nbe needed, and filled a relevant_sources strset with those paths.  Pass\nthese along to diffcore_rename_extended() to use to limit the sources\nthat we need to detect renames for.\n\nFor the testcases mentioned in commit 557ac0350d (\"merge-ort: begin\nperformance work; instrument with trace2_region_* calls\", 2020-10-28),\nthis change improves the performance as follows:\n\n                            Before                  After\n    no-renames:       12.596 s \u00b1  0.061 s     6.003 s \u00b1  0.048 s\n    mega-renames:    130.465 s \u00b1  0.259 s   114.009 s \u00b1  0.236 s\n    just-one-mega:     3.958 s \u00b1  0.010 s     3.489 s \u00b1  0.017 s\n\nSigned-off-by: Elijah Newren <newren@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "merge-ort.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/174791f0fb23e29de1d879c1aae3a164bb998885",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "detect_regular_renames"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "183a638b7daf47dde1b62cc8f8a00eb3e12983e7",
        "author": "Jeff King",
        "date": "2018-08-23T06:20:58-07:00",
        "message": "hashcmp: assert constant hash size\n\nPrior to 509f6f62a4 (cache: update object ID functions for\nthe_hash_algo, 2018-07-16), hashcmp() called memcmp() with a\nconstant size of 20 bytes. Some compilers were able to turn\nthat into a few quad-word comparisons, which is faster than\nactually calling memcmp().\n\nIn 509f6f62a4, we started using the_hash_algo->rawsz\ninstead. Even though this will always be 20, the compiler\ndoesn't know that while inlining hashcmp() and ends up just\ngenerating a call to memcmp().\n\nEventually we'll have to deal with multiple hash sizes, but\nfor the upcoming v2.19, we can restore some of the original\nperformance by asserting on the size. That gives the\ncompiler enough information to know that the memcmp will\nalways be called with a length of 20, and it performs the\nsame optimization.\n\nHere are numbers for p0001.2 run against linux.git on a few\nversions. This is using -O2 with gcc 8.2.0.\n\n  Test     v2.18.0             v2.19.0-rc0               HEAD\n  ------------------------------------------------------------------------------\n  0001.2:  34.24(33.81+0.43)   34.83(34.42+0.40) +1.7%   33.90(33.47+0.42) -1.0%\n\nYou can see that v2.19 is a little slower than v2.18. This\ncommit ended up slightly faster than v2.18, but there's a\nfair bit of run-to-run noise (the generated code in the two\ncases is basically the same). This patch does seem to be\nconsistently 1-2% faster than v2.19.\n\nI tried changing hashcpy(), which was also touched by\n509f6f62a4, in the same way, but couldn't measure any\nspeedup. Which makes sense, at least for this workload. A\ntraversal of the whole commit graph requires looking up\nevery entry of every tree via lookup_object(). That's many\nmultiples of the numbers of objects in the repository (most\nof the lookups just return \"yes, we already saw that\nobject\").\n\n[jn: verified using \"make object.s\" that the memcmp call goes away.]\n\nReported-by: Derrick Stolee <stolee@gmail.com>\nSigned-off-by: Jeff King <peff@peff.net\nReviewed-by: Jonathan Nieder <jrnieder@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "cache.h"
        ],
        "github_commit_url": "https://github.com/git/git/commit/183a638b7daf47dde1b62cc8f8a00eb3e12983e7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "hashcmp"
        ],
        "added_lines": 10,
        "deleted_lines": 0,
        "total_changed_lines": 10,
        "net_line_change": 10,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "18c08abc824c6cdb7bc17e1b5f85f8b118507aa5",
        "author": "Jeff King",
        "date": "2022-06-16T10:03:40-07:00",
        "message": "is_promisor_object(): walk promisor packs in pack-order\n\nWhen we generate the list of promisor objects, we walk every pack with a\n.promisor file and examine its objects for any links to other objects.\nBy default, for_each_packed_object() will go in pack .idx order.\n\nThis is the worst case with respect to our delta base cache. If we have\na delta chain of A->B->C->D, then visiting A may require reconstructing\nboth B and C, unless we also visited B recently, in which case we may\nhave cached its value. Because .idx order is based on sha1, it's random\nwith respect to the actual object contents and deltas, and thus we're\nunlikely to get many cache hits.\n\nIf we instead traverse in pack order, then we get the optimal case:\npacks are written to keep delta families together, and to place bases\nbefore their children.\n\nEven on a modest repository like git.git, this has a noticeable speedup\non p5600.4, which runs \"fsck\" on a partial clone with blob:none (so lots\nof trees which need to be walked, and which delta well):\n\nTest       HEAD^               HEAD\n-------------------------------------------------------\n5600.4:    17.87(17.83+0.04)   15.42(15.35+0.06) -13.7%\n\nOn a larger repository like linux.git, the speedup is even more\npronounced:\n\nTest       HEAD^                 HEAD\n-----------------------------------------------------------\n5600.4:    322.47(322.01+0.42)   186.41(185.76+0.63) -42.2%\n\nAny other operations that call is_promisor_object(), like \"rev-list\n--exclude-promisor-objects\", would similarly benefit, but the\ninvocations in p5600 don't actually trigger any such cases.\n\nNote that we may pay a small price to build a rev-index in-memory to do\nthe pack-order traversal. But it's still a big net win, and even that\nsmall cost goes away if you are using pack.writeReverseIndex.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "packfile.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/18c08abc824c6cdb7bc17e1b5f85f8b118507aa5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "is_promisor_object"
        ],
        "added_lines": 2,
        "deleted_lines": 1,
        "total_changed_lines": 3,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "19752d9c912478b9eef0bd83c2cf6da98974f536",
        "author": "Jeff King",
        "date": "2024-10-03T14:22:22-07:00",
        "message": "diff: return line_prefix directly when possible\n\nWe may point our output_prefix callback to diff_output_prefix_callback()\nin any of these cases:\n\n  1. we have a user-provided line_prefix\n\n  2. we have a graph prefix to show\n\n  3. both (1) and (2)\n\nThe function combines the available elements into a strbuf and returns\nits pointer.\n\nIn the case that we just have the line_prefix, though, there is no need\nfor the strbuf. We can return the string directly.\n\nThis is a minor optimization by itself, but also will allow us to clean\nup some memory ownership issues on top.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "graph.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/19752d9c912478b9eef0bd83c2cf6da98974f536",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "diff_output_prefix_callback"
        ],
        "added_lines": 3,
        "deleted_lines": 0,
        "total_changed_lines": 3,
        "net_line_change": 3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "1991b223c05d45d2a915842990b2a7c4819dcbcf",
        "author": "Junio C Hamano",
        "date": "2005-09-20T15:07:53-07:00",
        "message": "Fast-path 'update-index --refresh' a bit.\n\nIf the length in the stat information does not match what is recorded\nin the index, there is no point rehashing the contents to see if the\nindex entry can be refreshed.\n\nWe need to be a bit careful.  Immediately after read-tree or\ncheckout-index without -u, ce_size is set to zero and does not match\nthe length of the blob that is recorded, and we need to actually look\nat the contents to see if it has been changed.\n\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "update-index.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/1991b223c05d45d2a915842990b2a7c4819dcbcf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "refresh_entry"
        ],
        "added_lines": 7,
        "deleted_lines": 0,
        "total_changed_lines": 7,
        "net_line_change": 7,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "19b9496c1f0630a4ba252abcdfd313bf9c46347a",
        "author": "Patrick Steinhardt",
        "date": "2024-01-03T09:54:21-08:00",
        "message": "reftable/merged: transfer ownership of records when iterating\n\nWhen iterating over records with the merged iterator we put the records\ninto a priority queue before yielding them to the caller. This means\nthat we need to allocate the contents of these records before we can\npass them over to the caller.\n\nThe handover to the caller is quite inefficient though because we first\ndeallocate the record passed in by the caller and then copy over the new\nrecord, which requires us to reallocate memory.\n\nRefactor the code to instead transfer ownership of the new record to the\ncaller. So instead of reallocating all contents, we now release the old\nrecord and then copy contents of the new record into place.\n\nThe following benchmark of `git show-ref --quiet` in a repository with\naround 350k refs shows a clear improvement. Before:\n\n    HEAP SUMMARY:\n        in use at exit: 21,163 bytes in 193 blocks\n      total heap usage: 708,058 allocs, 707,865 frees, 36,783,255 bytes allocated\n\nAfter:\n\n    HEAP SUMMARY:\n        in use at exit: 21,163 bytes in 193 blocks\n      total heap usage: 357,007 allocs, 356,814 frees, 24,193,602 bytes allocated\n\nThis shows that we now have roundabout a single allocation per record\nthat we're yielding from the iterator. Ideally, we'd also get rid of\nthis allocation so that the number of allocations doesn't scale with the\nnumber of refs anymore. This would require some larger surgery though\nbecause the memory is owned by the priority queue before transferring it\nover to the caller.\n\nSigned-off-by: Patrick Steinhardt <ps@pks.im>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "reftable/merged.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/19b9496c1f0630a4ba252abcdfd313bf9c46347a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "merged_iter_next_entry"
        ],
        "added_lines": 4,
        "deleted_lines": 2,
        "total_changed_lines": 6,
        "net_line_change": 2,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "1b2be06e04c5dba2fc25d2eb0cc2bd85d469e350",
        "author": "Junio C Hamano",
        "date": "2021-08-24T15:32:41-07:00",
        "message": "Merge branch 'ps/fetch-pack-load-refs-optim'\n\nLoading of ref tips to prepare for common ancestry negotiation in\n\"git fetch-pack\" has been optimized by taking advantage of the\ncommit graph when available.\n\n* ps/fetch-pack-load-refs-optim:\n  fetch-pack: speed up loading of refs via commit graph",
        "modified_files_count": 1,
        "modified_files": [
            "fetch-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/1b2be06e04c5dba2fc25d2eb0cc2bd85d469e350",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "deref_without_lazy_fetch"
        ],
        "added_lines": 8,
        "deleted_lines": 2,
        "total_changed_lines": 10,
        "net_line_change": 6,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "1b4d8827ff2303f2db209bb34614e53c98e82bd6",
        "author": "Derrick Stolee",
        "date": "2019-05-28T10:39:47-07:00",
        "message": "revision: use generation for A..B --topo-order queries\n\nIf a commit-graph exists with computed generation numbers, then a\n'git rev-list --topo-order -n <N> <rev>' query will use those generation\nnumbers to reduce the number of commits walked before writing N commits.\n\nOne caveat put in b454241 (revision.c: generation-based topo-order\nalgorithm, 2018-11-01) was to not enable the new algorithm for queries\nwith a revision range \"A..B\". The logic was placed to walk from \"A\" and\nmark those commits as uninteresting, but the performance was actually\nworse than the existing logic in some cases.\n\nThe root cause of this performance degradation is that generation\nnumbers _increase_ the number of commits we walk relative to the\nexisting heuristic of walking by commit date. While generation numbers\nactually guarantee that the algorithm is correct, the existing logic\nis very rarely wrong and that added requirement is not worth the cost.\n\nThis motivates the planned \"corrected commit date\" to replace\ngeneration numbers in a future version of Git.\n\nThe current change enables the logic to use whatever reachability\nindex is currently in the commit-graph (generation numbers or\ncorrected commit date).\n\nThe limited flag in struct rev_info forces a full walk of the\ncommit history (after discovering the A..B range). Previosuly, it\nis enabled whenever we see an uninteresting commit. We prevent\nenabling the parameter when we are planning to use the reachability\nindex for a topo-order.\n\nSigned-off-by: Derrick Stolee <dstolee@microsoft.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "revision.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/1b4d8827ff2303f2db209bb34614e53c98e82bd6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "handle_commit"
        ],
        "added_lines": 3,
        "deleted_lines": 1,
        "total_changed_lines": 4,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "1b74092373898a53885cfb7e89aa54f9329a92d3",
        "author": "Dan McGee",
        "date": "2011-09-28T18:26:12-07:00",
        "message": "tree-walk: micro-optimization in tree_entry_interesting\n\nIn the case of a wide breadth top-level tree (~2400 entries, all trees\nin this case), we can see a noticeable cost in the profiler calling\nstrncmp() here. Most of the time we are at the base level of the\nrepository, so base is \"\" and baselen == 0, which means we will always\ntest true. Break out this one tiny case so we can short circuit the\nstrncmp() call.\n\nTest cases are as follows. packages.git is the Arch Linux git-svn clone\nof the packages repository which has the characteristics above.\n\nCommands:\n[1] packages.git, /usr/bin/time git log >/dev/null\n[2] packages.git, /usr/bin/time git log -- autogen/trunk pacman/trunk wget/trunk >/dev/null\n[3] linux.git, /usr/bin/time git log >/dev/null\n[4] linux.git, /usr/bin/time git log -- drivers/ata drivers/uio tools >/dev/null\n\nResults:\n     before  after  %faster\n[1]   2.56    2.55   0.4%\n[2]  51.82   48.66   6.5%\n[3]   5.58    5.61  -0.5%\n[4]   1.55    1.51   0.2%\n\nThe takeaway here is this doesn't matter in many operations, but it does\nfor a certain style of repository and operation where it nets a 6.5%\nmeasured improvement. The other changes are likely not significant by\nreasonable statistics methods.\n\nNote: the measured improvement when originally submitted was ~11% (43 to\n38 secs) for operation [2]. At the time, the repository had 117220\ncommits; it now has 137537 commits.\n\nSigned-off-by: Dan McGee <dpmcgee@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "tree-walk.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/1b74092373898a53885cfb7e89aa54f9329a92d3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "tree_entry_interesting"
        ],
        "added_lines": 2,
        "deleted_lines": 2,
        "total_changed_lines": 4,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "1d8e31a3f63cbc8533bf763c6d4b89d8355769f0",
        "author": "Derrick Stolee",
        "date": "2019-05-28T10:39:49-07:00",
        "message": "revision: keep topo-walk free of unintersting commits\n\nWhen updating the topo-order walk in b454241 (revision.c: generation-based\ntopo-order algorithm, 2018-11-01), the logic was a huge rewrite of the\nwalk logic. In that massive change, we accidentally included the\nUNINTERESTING commits in expand_topo_walk(). This means that a simple\nquery like\n\n    git rev-list --topo-order HEAD~1..HEAD\n\nwill expand the topo walk for all commits reachable from HEAD, and not\njust one commit.\n\nThis change should speed up these cases, but there is still a need\nfor corrected commit-date for some A..B queries.\n\nSigned-off-by: Derrick Stolee <dstolee@microsoft.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "revision.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/1d8e31a3f63cbc8533bf763c6d4b89d8355769f0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "expand_topo_walk"
        ],
        "added_lines": 3,
        "deleted_lines": 0,
        "total_changed_lines": 3,
        "net_line_change": 3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "1ea5e46cb96d17c3b3927b4eff9765183cf87f8d",
        "author": "Junio C Hamano",
        "date": "2021-09-15T13:15:27-07:00",
        "message": "Merge branch 'ab/reverse-midx-optim'\n\nThe code that optionally creates the *.rev reverse index file has\nbeen optimized to avoid needless computation when it is not writing\nthe file out.\n\n* ab/reverse-midx-optim:\n  pack-write: skip *.rev work when not writing *.rev",
        "modified_files_count": 1,
        "modified_files": [
            "pack-write.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/1ea5e46cb96d17c3b3927b4eff9765183cf87f8d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "write_rev_file"
        ],
        "added_lines": 3,
        "deleted_lines": 0,
        "total_changed_lines": 3,
        "net_line_change": 3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "1f9e18b77282070e8fef6dbe6983a8c94a3b0efa",
        "author": "Jeff King",
        "date": "2017-04-24T21:16:44-07:00",
        "message": "prio_queue_reverse: don't swap elements with themselves\n\nOur array-reverse algorithm does the usual \"walk from both\nends, swapping elements\". We can quit when the two indices\nare equal, since:\n\n  1. Swapping an element with itself is a noop.\n\n  2. If i and j are equal, then in the next iteration i is\n     guaranteed to be bigge than j, and we will exit the\n     loop.\n\nSo exiting the loop on equality is slightly more efficient.\nAnd more importantly, the new SWAP() macro does not expect\nto handle noop swaps; it will call memcpy() with the same src\nand dst pointers in this case. It's unclear whether that\ncauses a problem on any platforms by violating the\n\"overlapping memory\" constraint of memcpy, but it does cause\nvalgrind to complain.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "prio-queue.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/1f9e18b77282070e8fef6dbe6983a8c94a3b0efa",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "prio_queue_reverse"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "200abe7458357c83f3859ce6dbf89ea5d4d09b3d",
        "author": "Jeff King",
        "date": "2014-01-21T14:46:24-08:00",
        "message": "list-objects: only look at cmdline trees with edge_hint\n\nWhen rev-list is given a command-line like:\n\n  git rev-list --objects $commit --not --all\n\nthe most accurate answer is the difference between the set\nof objects reachable from $commit and the set reachable from\nall of the existing refs. However, we have not historically\nprovided that answer, because it is very expensive to\ncalculate. We would have to open every tree of every commit\nin the entire history.\n\nInstead, we find the accurate set difference of the\nreachable commits, and then mark the trees at the boundaries\nas uninteresting. This misses objects which appear in the\ntrees of both the interesting commits and deep within the\nuninteresting history.\n\nCommit fbd4a70 (list-objects: mark more commits as edges in\nmark_edges_uninteresting, 2013-08-16) noticed that we miss\nthose objects during pack-objects, and added code to examine\nthe trees of all of the \"--not\" refs given on the\ncommand-line.  Note that this is still not the complete set\ndifference, because we look only at the tips of the\ncommand-line arguments, not all of their reachable commits.\nBut it increases the set of boundary objects we consider,\nwhich is especially important for shallow fetches.  So we\nare trading extra CPU time for a larger set of boundary\nobjects, which can improve the resulting pack size for a\n--thin pack.\n\nThis tradeoff probably makes sense in the context of\npack-objects, where we have set revs->edge_hint to have the\ntraversal feed us the set of boundary objects.  For a\nregular rev-list, though, it is probably not a good\ntradeoff. It is true that it makes our list slightly closer\nto a true set difference, but it is a rare case where this\nis important. And because we do not have revs->edge_hint\nset, we do nothing useful with the larger set of boundary\nobjects.\n\nThis patch therefore ties the extra tree examination to the\nrevs->edge_hint flag; it is the presence of that flag that\nmakes the tradeoff worthwhile.\n\nHere is output from the p0001-rev-list showing the\nimprovement in performance:\n\nTest                                             HEAD^             HEAD\n-----------------------------------------------------------------------------------------\n0001.1: rev-list --all                           0.69(0.65+0.02)   0.69(0.66+0.02) +0.0%\n0001.2: rev-list --all --objects                 3.22(3.19+0.03)   3.23(3.20+0.03) +0.3%\n0001.4: rev-list $commit --not --all             0.04(0.04+0.00)   0.04(0.04+0.00) +0.0%\n0001.5: rev-list --objects $commit --not --all   0.27(0.26+0.01)   0.04(0.04+0.00) -85.2%\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "list-objects.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/200abe7458357c83f3859ce6dbf89ea5d4d09b3d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mark_edges_uninteresting"
        ],
        "added_lines": 11,
        "deleted_lines": 9,
        "total_changed_lines": 20,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "22631473e0b7a33356587ba3e38a9b4cc4dba2f1",
        "author": "Linus Torvalds",
        "date": "2007-08-10T13:57:43-07:00",
        "message": "Fix \"git commit directory/\" performance anomaly\n\nThis trivial patch avoids re-hashing files that are already clean in the\nindex. This mirrors what commit 0781b8a9b2fe760fc4ed519a3a26e4b9bd6ccffe\ndid for \"git add .\", only for \"git commit .\" instead.\n\nThis improves the cold-cache case immensely, since we don't need to bring\nin all the file contents, just the index and any files dirty in the index.\n\nBefore:\n\n\t[torvalds@woody linux]$ time git commit .\n\treal    1m49.537s\n\tuser    0m3.892s\n\tsys     0m2.432s\n\nAfter:\n\n\t[torvalds@woody linux]$ time git commit .\n\treal    0m14.273s\n\tuser    0m1.312s\n\tsys     0m0.516s\n\n(both after doing a \"echo 3 > /proc/sys/vm/drop_caches\" to get cold-cache\nbehaviour - even with the index optimization git still has to \"lstat()\"\nall the files, so with a truly cold cache, bringing all the inodes in\nwill take some time).\n\n[jc: trivial \"return 0;\" fixed]\n\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin-update-index.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/22631473e0b7a33356587ba3e38a9b4cc4dba2f1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "add_one_path"
        ],
        "added_lines": 8,
        "deleted_lines": 2,
        "total_changed_lines": 10,
        "net_line_change": 6,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "24072c0256a520408575416fe8706667b576ff99",
        "author": "Benjamin Kramer",
        "date": "2010-01-26T10:44:10-08:00",
        "message": "grep: use REG_STARTEND (if available) to speed up regexec\n\nBSD and glibc have an extension to regexec which takes a buffer + length pair\ninstead of a NUL-terminated string. Since we already have the length computed\nthis can save us a strlen call inside regexec.\n\nSigned-off-by: Benjamin Kramer <benny.kra@googlemail.com>\nAcked-by: Linus Torvalds <torvalds@linux-foundation.org>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "grep.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/24072c0256a520408575416fe8706667b576ff99",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "look_ahead"
        ],
        "added_lines": 8,
        "deleted_lines": 1,
        "total_changed_lines": 9,
        "net_line_change": 7,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "2523c4be855af84460e70ab5c8375534f8cefed5",
        "author": "Nguy\u1ec5n Th\u00e1i Ng\u1ecdc Duy",
        "date": "2018-01-24T12:40:13-08:00",
        "message": "dir.c: avoid stat() in valid_cached_dir()\n\nstat() may follow a symlink and return stat data of the link's target\ninstead of the link itself. We are concerned about the link itself.\n\nIt's kind of hard to demonstrate the bug. I think when path->buf is a\nsymlink, we most likely find that its target's stat data does not\nmatch our cached one, which means we ignore the cache and fall back to\nslow path.\n\nThis is performance issue, not correctness (though we could still\ncatch it by verifying test-dump-untracked-cache. The less unlikely\ncase is, link target stat data matches the cached version and we\nincorrectly go fast path, ignoring real data on disk. A test for this\nmay involve manipulating stat data, which may be not portable.\n\nSigned-off-by: Nguy\u1ec5n Th\u00e1i Ng\u1ecdc Duy <pclouds@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "dir.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/2523c4be855af84460e70ab5c8375534f8cefed5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "valid_cached_dir"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "252d560d215581637fcddd7a0a18f89204ecc8d1",
        "author": "Ren\u00e9 Scharfe",
        "date": "2009-03-07T11:34:53-08:00",
        "message": "grep: micro-optimize hit collection for AND nodes\n\nIn addition to returning if an expression matches a line,\nmatch_expr_eval() updates the expression's hit flag if the parameter\ncollect_hits is set.  It never sets collect_hits for children of AND\nnodes, though, so their hit flag will never be updated.  Because of\nthat we can return early if the first child didn't match, no matter\nif collect_hits is set or not.\n\nSigned-off-by: Rene Scharfe <rene.scharfe@lsrfire.ath.cx>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "grep.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/252d560d215581637fcddd7a0a18f89204ecc8d1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "match_expr_eval"
        ],
        "added_lines": 3,
        "deleted_lines": 7,
        "total_changed_lines": 10,
        "net_line_change": -4,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "26b89464219d3cfb0af7dc2274751eff641dea8d",
        "author": "Derrick Stolee",
        "date": "2022-02-17T14:47:13-08:00",
        "message": "dir: force untracked cache with core.untrackedCache\n\nThe GIT_FORCE_UNTRACKED_CACHE environment variable writes the untracked\ncache more frequently than the core.untrackedCache config variable. This\nis due to how read_directory() handles the creation of an untracked\ncache.\n\nBefore this change, Git would not create the untracked cache extension\nfor an index that did not already have one. Users would need to run a\ncommand such as 'git update-index --untracked-cache' before the index\nwould actually contain an untracked cache.\n\nIn particular, users noticed that the untracked cache would not appear\neven with core.untrackedCache=true. Some users reported setting\nGIT_FORCE_UNTRACKED_CACHE=1 in their engineering system environment to\nensure the untracked cache would be created.\n\nThe decision to not write the untracked cache without an environment\nvariable tracks back to fc9ecbeb9 (dir.c: don't flag the index as dirty\nfor changes to the untracked cache, 2018-02-05). The motivation of that\nchange is that writing the index is expensive, and if the untracked\ncache is the only thing that needs to be written, then it is more\nexpensive than the benefit of the cache. However, this also means that\nthe untracked cache never gets populated, so the user who enabled it via\nconfig does not actually get the extension until running 'git\nupdate-index --untracked-cache' manually or using the environment\nvariable.\n\nWe have had a version of this change in the microsoft/git fork for a few\nmajor releases now. It has been working well to get users into a good\nstate. Yes, that first index write is slow, but the remaining index\nwrites are much faster than they would be without this change.\n\nSigned-off-by: Derrick Stolee <derrickstolee@github.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "dir.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/26b89464219d3cfb0af7dc2274751eff641dea8d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "read_directory"
        ],
        "added_lines": 3,
        "deleted_lines": 1,
        "total_changed_lines": 4,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "2b970bc09fd76e210da4b19b5ee766b0722e1862",
        "author": "Junio C Hamano",
        "date": "2022-07-11T15:38:50-07:00",
        "message": "Merge branch 'jk/optim-promisor-object-enumeration'\n\nCollection of what is referenced by objects in promisor packs have\nbeen optimized to inspect these objects in the in-pack order.\n\n* jk/optim-promisor-object-enumeration:\n  is_promisor_object(): walk promisor packs in pack-order",
        "modified_files_count": 1,
        "modified_files": [
            "packfile.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/2b970bc09fd76e210da4b19b5ee766b0722e1862",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "is_promisor_object"
        ],
        "added_lines": 2,
        "deleted_lines": 1,
        "total_changed_lines": 3,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "2be421dbb6928421350fff407544ec34e68c1f73",
        "author": "Junio C Hamano",
        "date": "2015-10-26T15:55:22-07:00",
        "message": "Merge branch 'kn/for-each-tag'\n\nRecent update to \"git tag --contains\" caused a performance\nregression.\n\n* kn/for-each-tag:\n  tag.c: use the correct algorithm for the '--contains' option",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/tag.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/2be421dbb6928421350fff407544ec34e68c1f73",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "list_tags"
        ],
        "added_lines": 1,
        "deleted_lines": 0,
        "total_changed_lines": 1,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "2c08b3638339f9b73128c41a4882e115222608a3",
        "author": "Sergey Vlasov",
        "date": "2005-09-22T21:52:12-07:00",
        "message": "[PATCH] fetch.c: Remove call to parse_object() from process()\n\nThe call to parse_object() in process() is not actually needed - if\nthe object type is unknown, parse_object() will be called by loop();\nif the type is known, the object will be parsed by the appropriate\nprocess_*() function.\n\nAfter this change blobs which exist locally are no longer parsed,\nwhich gives about 2x CPU usage improvement; the downside is that there\nwill be no warnings for existing corrupted blobs, but detecting such\ncorruption is the job of git-fsck-objects, not the fetch programs.\nNewly fetched objects are still checked for corruption in http-fetch.c\nand ssh-fetch.c (local-fetch.c does not seem to do it, but the removed\nparse_object() call would not be reached for new objects anyway).\n\nSigned-off-by: Sergey Vlasov <vsu@altlinux.ru>\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "fetch.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/2c08b3638339f9b73128c41a4882e115222608a3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "process"
        ],
        "added_lines": 0,
        "deleted_lines": 1,
        "total_changed_lines": 1,
        "net_line_change": -1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "2d08e5dd730680f7f8645a6326ec653435e032df",
        "author": "Nicolas Pitre",
        "date": "2006-05-02T21:32:32-07:00",
        "message": "tiny optimization to diff-delta\n\nThis is my assembly freak side looking at generated code again.  And\nsince create_delta() is certainly pretty high on the radar every bits\ncount.  In this case shorter code is generated if hash_mask is not\ncopied to a local variable.\n\nSigned-off-by: Nicolas Pitre <nico@cam.org>\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "diff-delta.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/2d08e5dd730680f7f8645a6326ec653435e032df",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "create_delta"
        ],
        "added_lines": 2,
        "deleted_lines": 3,
        "total_changed_lines": 5,
        "net_line_change": -1,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "2e2d141afdaa2b086ac5d4228de0dd0003eb69ff",
        "author": "Jeff King",
        "date": "2020-12-08T14:48:16-08:00",
        "message": "ewah: make bitmap growth less aggressive\n\nIf you ask to set a bit in the Nth word and we haven't yet allocated\nthat many slots in our array, we'll increase the bitmap size to 2*N.\nThis means we might frequently end up with bitmaps that are twice the\nnecessary size (as soon as you ask for the biggest bit, we'll size up to\ntwice that).\n\nBut if we just allocate as many words as were asked for, we may not grow\nfast enough. The worst case there is setting bit 0, then 1, etc. Each\ntime we grow we'd just extend by one more word, giving us linear\nreallocations (and quadratic memory copies).\n\nA middle ground is relying on alloc_nr(), which causes us to grow by a\nfactor of roughly 3/2 instead of 2. That's less aggressive than\ndoubling, and it may help avoid fragmenting memory. (If we start with N,\nthen grow twice, our total is N*(3/2)^2 = 9N/4. After growing twice,\nthat array of size 9N/4 can fit into the space vacated by the original\narray and first growth, N+3N/2 = 10N/4 > 9N/4, leading to less\nfragmentation in memory).\n\nOur worst case is still 3/2N wasted bits (you set bit N-1, then setting\nbit N causes us to grow by 3/2), but our average should be much better.\n\nThis isn't usually that big a deal, but it will matter as we shift the\nreachability bitmap generation code to store more bitmaps in memory.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Taylor Blau <me@ttaylorr.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "ewah/bitmap.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/2e2d141afdaa2b086ac5d4228de0dd0003eb69ff",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "bitmap_grow"
        ],
        "added_lines": 4,
        "deleted_lines": 7,
        "total_changed_lines": 11,
        "net_line_change": -3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "2f88c19700feb8db8f116f94bf558e61c82d543c",
        "author": "Junio C Hamano",
        "date": "2011-08-29T15:09:17-07:00",
        "message": "diff-index: pass pathspec down to unpack-trees machinery\n\nAnd finally, pass the pathspec down through unpack_trees() to traverse_trees()\ncallchain.\n\nBefore and after applying this series, looking for changes in the kernel\nrepository with a fairly narrow pathspec becomes somewhat faster.\n\n  (without patch)\n  $ /usr/bin/time git diff --raw v2.6.27 -- net/ipv6 >/dev/null\n  0.48user 0.05system 0:00.53elapsed 100%CPU (0avgtext+0avgdata 163296maxresident)k\n  0inputs+952outputs (0major+11163minor)pagefaults 0swaps\n\n  (with patch)\n  $ /usr/bin/time git diff --raw v2.6.27 -- net/ipv6 >/dev/null\n  0.01user 0.00system 0:00.02elapsed 104%CPU (0avgtext+0avgdata 43856maxresident)k\n  0inputs+24outputs (0major+3688minor)pagefaults 0swaps\n\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "diff-lib.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/2f88c19700feb8db8f116f94bf558e61c82d543c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "run_diff_index"
        ],
        "added_lines": 1,
        "deleted_lines": 0,
        "total_changed_lines": 1,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "2fce1f3c862845d23b2bd8305f97abb115623192",
        "author": "Shawn O. Pearce",
        "date": "2007-01-15T07:12:23-05:00",
        "message": "Optimize index creation on large object sets in fast-import.\n\nWhen we are generating multiple packfiles at once we only need\nto scan the blocks of object_entry structs which contain objects\nfor the current packfile.  Because the most recent blocks are at\nthe front of the linked list, and because all new objects going\ninto the current file are allocated from the front of that list,\nwe can stop scanning for objects as soon as we identify one which\ndoesn't belong to the current packfile.\n\nSigned-off-by: Shawn O. Pearce <spearce@spearce.org>",
        "modified_files_count": 1,
        "modified_files": [
            "fast-import.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/2fce1f3c862845d23b2bd8305f97abb115623192",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "write_index"
        ],
        "added_lines": 8,
        "deleted_lines": 3,
        "total_changed_lines": 11,
        "net_line_change": 5,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "30b939c33ad5b8a9dfbe3fe5aafc36d89c40409f",
        "author": "Jeff King",
        "date": "2013-03-17T15:28:15-07:00",
        "message": "fast-export: do not load blob objects twice\n\nWhen fast-export wants to export a blob object, it first\ncalls parse_object to get a \"struct object\" and check\nwhether we have already shown the object.  If we haven't\nshown it, we then use read_sha1_file to pull it from disk\nand write it out.\n\nThat means we load each blob from disk twice: once for\nparse_object to find its type and check its sha1, and a\nsecond time when we actually output it. We can drop this to\na single load by using lookup_object to check the SHOWN\nflag, and then checking the signature on and outputting a\nsingle buffer.\n\nThis provides modest speedups on git.git (best-of-five, \"git\nfast-export HEAD >/dev/null\"):\n\n  [before]                [after]\n  real    0m14.347s       real    0m13.780s\n  user    0m14.084s       user    0m13.620s\n  sys     0m0.208s        sys     0m0.100s\n\nand somewhat more on more blob-heavy repos (this is a\nrepository full of media files):\n\n  [before]                [after]\n  real    0m52.236s       real    0m44.451s\n  user    0m50.568s       user    0m43.000s\n  sys     0m1.536s        sys     0m1.284s\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/fast-export.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/30b939c33ad5b8a9dfbe3fe5aafc36d89c40409f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "export_blob"
        ],
        "added_lines": 10,
        "deleted_lines": 6,
        "total_changed_lines": 16,
        "net_line_change": 4,
        "modified_code_blocks": 4,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "31216ee28a452d39d9fba6cd72d8b072eab50af1",
        "author": "Chandra Pratap",
        "date": "2024-08-21T09:41:41-07:00",
        "message": "t-reftable-block: use block_iter_reset() instead of block_iter_close()\n\nblock_iter_reset() restores a block iterator to its state at the time\nof initialization without freeing any memory while block_iter_close()\ndeallocates the memory for the iterator.\n\nIn the current testing setup, a block iterator is allocated and\ndeallocated for every iteration of a loop, which hurts performance.\nImprove upon this by using block_iter_reset() at the start of each\niteration instead. This has the added benifit of testing\nblock_iter_reset(), which currently remains untested.\n\nSimilarly, remove reftable_record_release() for a reftable record\nthat is still in use.\n\nMentored-by: Patrick Steinhardt <ps@pks.im>\nMentored-by: Christian Couder <chriscool@tuxfamily.org>\nSigned-off-by: Chandra Pratap <chandrapratap3519@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "t/unit-tests/t-reftable-block.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/31216ee28a452d39d9fba6cd72d8b072eab50af1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "t_block_read_write"
        ],
        "added_lines": 2,
        "deleted_lines": 6,
        "total_changed_lines": 8,
        "net_line_change": -4,
        "modified_code_blocks": 4,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "3446a59b3950d57960e27f8a2c7e41462bd2bcf4",
        "author": "Jeff King",
        "date": "2015-04-16T08:15:04-07:00",
        "message": "strbuf_getwholeline: use getc macro\n\nstrbuf_getwholeline calls fgetc in a tight loop. Using the\ngetc form, which can be implemented as a macro, should be\nfaster (and we do not care about it evaluating our argument\ntwice, as we just have a plain variable).\n\nOn my glibc system, running \"git rev-parse\nrefs/heads/does-not-exist\" on a file with an extremely large\n(1.6GB) packed-refs file went from (best of 3 runs):\n\n  real    0m19.383s\n  user    0m18.876s\n  sys     0m0.528s\n\nto:\n\n  real    0m18.900s\n  user    0m18.472s\n  sys     0m0.448s\n\nfor a wall-clock speedup of 2.5%.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "strbuf.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/3446a59b3950d57960e27f8a2c7e41462bd2bcf4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "strbuf_getwholeline"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "3449847168c9fa6e23db364e7da9077eadd39547",
        "author": "Christian Couder",
        "date": "2018-01-19T13:21:49-08:00",
        "message": "sha1_file: improve sha1_file_name() perfs\n\nAs sha1_file_name() could be performance sensitive, let's\nmake it faster by using strbuf_addstr() and strbuf_addc()\ninstead of strbuf_addf().\n\nHelped-by: Derrick Stolee <stolee@gmail.com>\nHelped-by: Jeff Hostetler <git@jeffhostetler.com>\nSigned-off-by: Christian Couder <chriscool@tuxfamily.org>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "sha1_file.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/3449847168c9fa6e23db364e7da9077eadd39547",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sha1_file_name"
        ],
        "added_lines": 2,
        "deleted_lines": 2,
        "total_changed_lines": 4,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "34597c1f5a77c710dae33092cb8a7cb01c6b21c1",
        "author": "Clemens Buchacher",
        "date": "2010-08-16T18:31:37-07:00",
        "message": "hash binary sha1 into patch id\n\nSince commit 2f82f760 (Take binary diffs into\naccount for \"git rebase\"), binary files are\nincluded in patch ID computation. Binary files are\ndiffed using the text diff algorithm, however,\nwhich has a huge impact on performance. The\nfollowing tests performance for a 50000 line file\nmarked as binary in .gitattributes.\n\n$ git format-patch --stdout --ignore-if-in-upstream master\n\nreal    0m0.367s\nuser    0m0.354s\nsys     0m0.010s\n\nInstead of diffing the binary files, hash the pre-\nand post-image sha1, which is just as unique. As a\nresult, performance is much improved.\n\n$ git format-patch --stdout --ignore-if-in-upstream master\n\nreal    0m0.016s\nuser    0m0.015s\nsys     0m0.001s\n\nSigned-off-by: Clemens Buchacher <drizzd@aon.at>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "diff.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/34597c1f5a77c710dae33092cb8a7cb01c6b21c1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "diff_get_patch_id"
        ],
        "added_lines": 7,
        "deleted_lines": 0,
        "total_changed_lines": 7,
        "net_line_change": 7,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "359b01ca8424dcfea9504236365f42b4e0d1aaea",
        "author": "Jeff King",
        "date": "2022-07-11T14:27:31-07:00",
        "message": "ref-filter: disable save_commit_buffer while traversing\n\nVarious ref-filter options like \"--contains\" or \"--merged\" may cause us\nto traverse large segments of the history graph. It's counter-productive\nto have save_commit_buffer turned on, as that will instruct the commit\ncode to cache in-memory the object contents for each commit we traverse.\n\nThis increases the amount of heap memory used while providing little or\nno benefit, since we're not actually planning to display those commits\n(which is the usual reason that tools like git-log want to keep them\naround). We can easily disable this feature while ref-filter is running.\nThis lowers peak heap (as measured by massif) for running:\n\n  git tag --contains 1da177e4c3\n\nin linux.git from ~100MB to ~20MB. It also seems to improve runtime by\n4-5% (600ms vs 630ms).\n\nA few points to note:\n\n  - it should be safe to temporarily disable save_commit_buffer like\n    this. The saved buffers are accessed through get_commit_buffer(),\n    which treats the saved ones like a cache, and loads on-demand from\n    the object database on a cache miss. So any code that was using this\n    would not be wrong, it might just incur an extra object lookup for\n    some objects. But...\n\n  - I don't think any ref-filter related code is using the cache. While\n    it's true that an option like \"--format=%(*contents:subject)\" or\n    \"--sort=*authordate\" will need to look at the commit contents,\n    ref-filter doesn't use get_commit_buffer() to do so! It always reads\n    the objects directly via read_object_file(), though it does avoid\n    re-reading objects if the format can be satisfied without them.\n\n    Timing \"git tag --format=%(*authordate)\" shows that we're the same\n    before and after, as expected.\n\n  - Note that all of this assumes you don't have a commit-graph file. if\n    you do, then the heap usage is even lower, and the runtime is 10x\n    faster. So in that sense this is not urgent, as there's a much\n    better solution. But since it's such an obvious and easy win for\n    fallback cases (including commits which aren't yet in the graph\n    file), there's no reason not to.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "ref-filter.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/359b01ca8424dcfea9504236365f42b4e0d1aaea",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "filter_refs"
        ],
        "added_lines": 5,
        "deleted_lines": 0,
        "total_changed_lines": 5,
        "net_line_change": 5,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "36c079756f9f3ad0bbbe2097550c62427670146b",
        "author": "Thomas Rast",
        "date": "2010-02-20T10:33:11-08:00",
        "message": "cherry_pick_list: quit early if one side is empty\n\nThe --cherry-pick logic starts by counting the commits on each side,\nso that it can filter away commits on the bigger one.  However, so\nfar it missed an opportunity for optimization: it doesn't need to do\nany work if either side is empty.\n\nThis in particular helps the common use-case 'git rebase -i HEAD~$n':\nit internally uses --cherry-pick, but since HEAD~$n is a direct\nancestor the left side is always empty.\n\nSigned-off-by: Thomas Rast <trast@student.ethz.ch>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "revision.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/36c079756f9f3ad0bbbe2097550c62427670146b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cherry_pick_list"
        ],
        "added_lines": 3,
        "deleted_lines": 0,
        "total_changed_lines": 3,
        "net_line_change": 3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "39556fbdadaacf67330bc1464e0172468e9c3a5e",
        "author": "Nicolas Pitre",
        "date": "2006-02-10T11:42:56-08:00",
        "message": "delta micro optimization\n\nMy kernel work habit made me look at the generated assembly for the\ndelta code, and one obvious albeit small improvement is this patch.\n\nSigned-off-by: Nicolas Pitre <nico@cam.org>\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "delta.h"
        ],
        "github_commit_url": "https://github.com/git/git/commit/39556fbdadaacf67330bc1464e0172468e9c3a5e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_delta_hdr_size"
        ],
        "added_lines": 5,
        "deleted_lines": 5,
        "total_changed_lines": 10,
        "net_line_change": 0,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "3d2a33e57faa84be3ab83a80c8b75dad3e747054",
        "author": "Jeff King",
        "date": "2012-05-24T10:02:37-07:00",
        "message": "fetch-pack: sort incoming heads list earlier\n\nCommit 4435968 started sorting heads fed to fetch-pack so\nthat later commits could use more optimized algorithms;\ncommit 7db8d53 switched the remove_duplicates function to\nsuch an algorithm.\n\nOf course, the sorting is more effective if you do it\n_before_ the algorithm in question.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/fetch-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/3d2a33e57faa84be3ab83a80c8b75dad3e747054",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "fetch_pack"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "3e5e6c6e94f09973d3a72049aad09fd2131a3648",
        "author": "Patrick Steinhardt",
        "date": "2021-08-04T10:45:32-07:00",
        "message": "fetch-pack: speed up loading of refs via commit graph\n\nWhen doing reference negotiation, git-fetch-pack(1) is loading all refs\nfrom disk in order to determine which commits it has in common with the\nremote repository. This can be quite expensive in repositories with many\nreferences though: in a real-world repository with around 2.2 million\nrefs, fetching a single commit by its ID takes around 44 seconds.\n\nDominating the loading time is decompression and parsing of the objects\nwhich are referenced by commits. Given the fact that we only care about\ncommits (or tags which can be peeled to one) in this context, there is\nthus an easy performance win by switching the parsing logic to make use\nof the commit graph in case we have one available. Like this, we avoid\nhitting the object database to parse these commits but instead only load\nthem from the commit-graph. This results in a significant performance\nboost when executing git-fetch in said repository with 2.2 million refs:\n\n    Benchmark #1: HEAD~: git fetch $remote $commit\n      Time (mean \u00b1 \u03c3):     44.168 s \u00b1  0.341 s    [User: 42.985 s, System: 1.106 s]\n      Range (min \u2026 max):   43.565 s \u2026 44.577 s    10 runs\n\n    Benchmark #2: HEAD: git fetch $remote $commit\n      Time (mean \u00b1 \u03c3):     19.498 s \u00b1  0.724 s    [User: 18.751 s, System: 0.690 s]\n      Range (min \u2026 max):   18.629 s \u2026 20.454 s    10 runs\n\n    Summary\n      'HEAD: git fetch $remote $commit' ran\n        2.27 \u00b1 0.09 times faster than 'HEAD~: git fetch $remote $commit'\n\nSigned-off-by: Patrick Steinhardt <ps@pks.im>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "fetch-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/3e5e6c6e94f09973d3a72049aad09fd2131a3648",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "deref_without_lazy_fetch"
        ],
        "added_lines": 8,
        "deleted_lines": 2,
        "total_changed_lines": 10,
        "net_line_change": 6,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "3fde386a40f38dbaa684c17603e71909b862d021",
        "author": "Martin von Zweigbergk",
        "date": "2013-01-15T09:38:08-08:00",
        "message": "reset [--mixed]: use diff-based reset whether or not pathspec was given\n\nThanks to b65982b (Optimize \"diff-index --cached\" using cache-tree,\n2009-05-20), resetting with paths is much faster than resetting\nwithout paths. Some timings for the linux-2.6 repo to illustrate this\n(best of five, warm cache):\n\n        reset       reset .\nreal    0m0.219s    0m0.080s\nuser    0m0.140s    0m0.040s\nsys     0m0.070s    0m0.030s\n\nThese two commands should do the same thing, so instead of having the\nuser type the trailing \" .\" to get the faster do_diff_cache()-based\nimplementation, always use it when doing a mixed reset, with or\nwithout paths (so \"git reset $rev\" would also be faster).\n\nTiming \"git reset\" shows that it indeed becomes as fast as\n\"git reset .\" after this patch.\n\nSigned-off-by: Martin von Zweigbergk <martinvonz@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/reset.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/3fde386a40f38dbaa684c17603e71909b862d021",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_reset"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "403ac1381cc8bed5e02963a955f2a2a626620eaa",
        "author": "Junio C Hamano",
        "date": "2019-12-06T15:09:22-08:00",
        "message": "Merge branch 'jk/send-pack-check-negative-with-quick'\n\nPerformance tweak on \"git push\" into a repository with many refs\nthat point at objects we have never heard of.\n\n* jk/send-pack-check-negative-with-quick:\n  send-pack: use OBJECT_INFO_QUICK to check negative objects",
        "modified_files_count": 1,
        "modified_files": [
            "send-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/403ac1381cc8bed5e02963a955f2a2a626620eaa",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "feed_object"
        ],
        "added_lines": 3,
        "deleted_lines": 1,
        "total_changed_lines": 4,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "4041483e5a3d2010e038ec686ef1638cde659f0b",
        "author": "Sergey Vlasov",
        "date": "2005-09-21T12:32:33-07:00",
        "message": "[PATCH] fetch.c: Remove call to parse_object() from process()\n\nThe call to parse_object() in process() is not actually needed - if\nthe object type is unknown, parse_object() will be called by loop();\nif the type is known, the object will be parsed by the appropriate\nprocess_*() function.\n\nAfter this change blobs which exist locally are no longer parsed,\nwhich gives about 2x CPU usage improvement; the downside is that there\nwill be no warnings for existing corrupted blobs, but detecting such\ncorruption is the job of git-fsck-objects, not the fetch programs.\nNewly fetched objects are still checked for corruption in http-fetch.c\nand ssh-fetch.c (local-fetch.c does not seem to do it, but the removed\nparse_object() call would not be reached for new objects anyway).\n\nSigned-off-by: Sergey Vlasov <vsu@altlinux.ru>\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "fetch.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/4041483e5a3d2010e038ec686ef1638cde659f0b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "process"
        ],
        "added_lines": 0,
        "deleted_lines": 1,
        "total_changed_lines": 1,
        "net_line_change": -1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "435c83323713066723e4194cd89c31bbec7011a2",
        "author": "Jeff King",
        "date": "2012-10-04T20:34:29-07:00",
        "message": "upload-pack: use peel_ref for ref advertisements\n\nWhen upload-pack advertises refs, we attempt to peel tags\nand advertise the peeled version. We currently hand-roll the\ntag dereferencing, and use as many optimizations as we can\nto avoid loading non-tag objects into memory.\n\nNot only has peel_ref recently learned these optimizations,\ntoo, but it also contains an even more important one: it\nhas access to the \"peeled\" data from the pack-refs file.\nThat means we can avoid not only loading annotated tags\nentirely, but also avoid doing any kind of object lookup at\nall.\n\nThis cut the CPU time to advertise refs by 50% in the\nlinux-2.6 repo, as measured by:\n\n  echo 0000 | git-upload-pack . >/dev/null\n\nbest-of-five, warm cache, objects and refs fully packed:\n\n  [before]             [after]\n  real    0m0.026s     real    0m0.013s\n  user    0m0.024s     user    0m0.008s\n  sys     0m0.000s     sys     0m0.000s\n\nThose numbers are irrelevantly small compared to an actual\nfetch. Here's a larger repo (400K refs, of which 12K are\nunique, and of which only 107 are unique annotated tags):\n\n  [before]             [after]\n  real    0m0.704s     real    0m0.596s\n  user    0m0.600s     user    0m0.496s\n  sys     0m0.096s     sys     0m0.092s\n\nThis shows only a 15% speedup (mostly because it has fewer\nactual tags to parse), but a larger absolute value (100ms,\nwhich isn't a lot compared to a real fetch, but this\nadvertisement happens on every fetch, even if the client is\njust finding out they are completely up to date).\n\nIn truly pathological cases, where you have a large number\nof unique annotated tags, it can make an even bigger\ndifference. Here are the numbers for a linux-2.6 repository\nthat has had every seventh commit tagged (so about 50K\ntags):\n\n  [before]             [after]\n  real    0m0.443s     real    0m0.097s\n  user    0m0.416s     user    0m0.080s\n  sys     0m0.024s     sys     0m0.012s\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "upload-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/435c83323713066723e4194cd89c31bbec7011a2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "send_ref"
        ],
        "added_lines": 3,
        "deleted_lines": 11,
        "total_changed_lines": 14,
        "net_line_change": -8,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "47bd9bf82daeac71b28a5a697ecc44e70b205e18",
        "author": "Felipe Contreras",
        "date": "2013-05-07T07:03:01-07:00",
        "message": "fast-export: don't parse commits while reading marks file\n\nWe don't need the parsed objects at this point, merely the\ninformation that they have marks.\n\nSeems to be three times faster in my setup with lots of objects.\n\nSigned-off-by: Felipe Contreras <felipe.contreras@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/fast-export.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/47bd9bf82daeac71b28a5a697ecc44e70b205e18",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "import_marks"
        ],
        "added_lines": 6,
        "deleted_lines": 1,
        "total_changed_lines": 7,
        "net_line_change": 5,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "47c61004c7cfbb8662b13fac813b45e3fd214665",
        "author": "Patrick Steinhardt",
        "date": "2021-09-01T12:43:56-07:00",
        "message": "fetch: avoid unpacking headers in object existence check\n\nWhen updating local refs after the fetch has transferred all objects, we\ndo an object existence test as a safety guard to avoid updating a ref to\nan object which we don't have. We do so via `oid_object_info()`: if it\nreturns an error, then we know the object does not exist.\n\nOne side effect of `oid_object_info()` is that it parses the object's\ntype, and to do so it must unpack the object header. This is completely\npointless: we don't care for the type, but only want to assert that the\nobject exists.\n\nRefactor the code to use `repo_has_object_file()`, which both makes the\ncode's intent clearer and is also faster because it does not unpack\nobject headers. In a real-world repo with 2.3M refs, this results in a\nsmall speedup when doing a mirror-fetch:\n\n    Benchmark #1: HEAD~: git-fetch\n      Time (mean \u00b1 \u03c3):     33.686 s \u00b1  0.176 s    [User: 30.119 s, System: 5.262 s]\n      Range (min \u2026 max):   33.512 s \u2026 33.944 s    5 runs\n\n    Benchmark #2: HEAD: git-fetch\n      Time (mean \u00b1 \u03c3):     31.247 s \u00b1  0.195 s    [User: 28.135 s, System: 5.066 s]\n      Range (min \u2026 max):   30.948 s \u2026 31.472 s    5 runs\n\n    Summary\n      'HEAD: git-fetch' ran\n        1.08 \u00b1 0.01 times faster than 'HEAD~: git-fetch'\n\nSigned-off-by: Patrick Steinhardt <ps@pks.im>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/fetch.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/47c61004c7cfbb8662b13fac813b45e3fd214665",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "update_local_ref"
        ],
        "added_lines": 1,
        "deleted_lines": 3,
        "total_changed_lines": 4,
        "net_line_change": -2,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "4818cfcdcc8011e5eef353d0f64cd9d2374ea381",
        "author": "Junio C Hamano",
        "date": "2013-05-29T14:29:59-07:00",
        "message": "Merge branch 'jk/lookup-object-prefer-latest'\n\nOptimizes object lookup when the object hashtable starts to become\ncrowded.\n\n* jk/lookup-object-prefer-latest:\n  lookup_object: prioritize recently found objects",
        "modified_files_count": 1,
        "modified_files": [
            "object.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/4818cfcdcc8011e5eef353d0f64cd9d2374ea381",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "lookup_object"
        ],
        "added_lines": 12,
        "deleted_lines": 2,
        "total_changed_lines": 14,
        "net_line_change": 10,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "48799d1c6b9cfb0279afbfe3420cbcd53c24907c",
        "author": "Junio C Hamano",
        "date": "2013-04-02T15:10:46-07:00",
        "message": "Merge branch 'tr/log-tree-optim'\n\nOptimize \"log\" that shows the difference between the parent and the\nchild.\n\n* tr/log-tree-optim:\n  Avoid loading commits twice in log with diffs",
        "modified_files_count": 1,
        "modified_files": [
            "log-tree.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/48799d1c6b9cfb0279afbfe3420cbcd53c24907c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "log_tree_diff"
        ],
        "added_lines": 10,
        "deleted_lines": 3,
        "total_changed_lines": 13,
        "net_line_change": 7,
        "modified_code_blocks": 4,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "4af31dc84a1d63c0c78cb004421405aa5a4f1f80",
        "author": "Patrick Steinhardt",
        "date": "2024-04-08T16:59:02-07:00",
        "message": "refs/reftable: skip duplicate name checks\n\nAll the callback functions which write refs in the reftable backend\nperform D/F conflict checks via `refs_verify_refname_available()`. But\nin reality we perform these D/F conflict checks a second time in the\nreftable library via `stack_check_addition()`.\n\nInterestingly, the code in the reftable library is inferior compared to\nthe generic function:\n\n  - It is slower than `refs_verify_refname_available()`, even though\n    this can probably be optimized.\n\n  - It does not provide a proper error message to the caller, and thus\n    all the user would see is a generic \"file/directory conflict\"\n    message.\n\nDisable the D/F conflict checks in the reftable library by setting the\n`skip_name_check` write option. This results in a non-negligible speedup\nwhen writing many refs. The following benchmark writes 100k refs in a\nsingle transaction:\n\n  Benchmark 1: update-ref: create many refs (HEAD~)\n    Time (mean \u00b1 \u03c3):      3.241 s \u00b1  0.040 s    [User: 1.854 s, System: 1.381 s]\n    Range (min \u2026 max):    3.185 s \u2026  3.454 s    100 runs\n\n  Benchmark 2: update-ref: create many refs (HEAD)\n    Time (mean \u00b1 \u03c3):      2.878 s \u00b1  0.024 s    [User: 1.506 s, System: 1.367 s]\n    Range (min \u2026 max):    2.838 s \u2026  2.960 s    100 runs\n\n  Summary\n    update-ref: create many refs (HEAD~) ran\n      1.13 \u00b1 0.02 times faster than update-ref: create many refs (HEAD)\n\nSigned-off-by: Patrick Steinhardt <ps@pks.im>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "refs/reftable-backend.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/4af31dc84a1d63c0c78cb004421405aa5a4f1f80",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "reftable_be_init"
        ],
        "added_lines": 5,
        "deleted_lines": 0,
        "total_changed_lines": 5,
        "net_line_change": 5,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "4c6c7971e0e42f0f1ce7e9472bc3aec8e0c96650",
        "author": "Derrick Stolee via GitGitGadget",
        "date": "2020-01-10T11:34:36-08:00",
        "message": "unpack-trees: correctly compute result count\n\nThe clear_ce_flags_dir() method processes the cache entries within\na common directory. The returned int is the number of cache entries\nprocessed by that directory. When using the sparse-checkout feature\nin cone mode, we can skip the pattern matching for entries in the\ndirectories that are entirely included or entirely excluded.\n\neb42feca (unpack-trees: hash less in cone mode, 2019-11-21)\nintroduced this performance feature. The old mechanism relied on\nthe counts returned by calling clear_ce_flags_1(), but the new\nmechanism calculated the number of rows by subtracting \"cache_end\"\nfrom \"cache\" to find the size of the range. However, the equation\nis wrong because it divides by sizeof(struct cache_entry *). This\nis not how pointer arithmetic works!\n\nA coverity build of Git for Windows in preparation for the 2.25.0\nrelease found this issue with the warning, \"Pointer differences,\nsuch as cache_end - cache, are automatically scaled down by the\nsize (8 bytes) of the pointed-to type (struct cache_entry *).\nMost likely, the division by sizeof(struct cache_entry *) is\nextraneous and should be eliminated.\" This warning is correct.\n\nThis leaves us with the question \"how did this even work?\" The\nproblem that occurs with this incorrect pointer arithmetic is\na performance-only bug, and a very slight one at that. Since\nthe entry count returned by clear_ce_flags_dir() is reduced by\na factor of 8, the loop in clear_ce_flags_1() will re-process\nentries from those directories.\n\nBy inserting global counters into unpack-tree.c and tracing\nthem with trace2_data_intmax() (in a private change, for\ntesting), I was able to see count how many times the loop inside\nclear_ce_flags_1() processed an entry and how many times\nclear_ce_flags_dir() was called. Each of these are reduced by at\nleast a factor of 8 with the current change. A factor larger\nthan 8 happens when multiple levels of directories are repeated.\n\nSpecifically, in the Linux kernel repo, the command\n\n\tgit sparse-checkout set LICENSES\n\nrestricts the working directory to only the files at root and\nin the LICENSES directory. Here are the measured counts:\n\nclear_ce_flags_1 loop blocks:\n\tBefore: 11,520\n\tAfter:   1,621\n\nclear_ce_flags_dir calls:\n\tBefore: 7,048\n\tAfter:    606\n\nWhile these are dramatic counts, the time spent in\nclear_ce_flags_1() is under one millisecond in each case, so\nthe improvement is not measurable as an end-to-end time.\n\nReported-by: Johannes Schindelin <Johannes.Schindelin@gmx.de>\nSigned-off-by: Derrick Stolee <dstolee@microsoft.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "unpack-trees.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/4c6c7971e0e42f0f1ce7e9472bc3aec8e0c96650",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "clear_ce_flags_dir"
        ],
        "added_lines": 2,
        "deleted_lines": 2,
        "total_changed_lines": 4,
        "net_line_change": 0,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "4e1d1a2eea25878a2128e376bff8b4a1b2216b15",
        "author": "Jeff King",
        "date": "2016-01-19T09:55:01-08:00",
        "message": "shortlog: optimize \"--summary\" mode\n\nIf the user asked us only to show counts for each author,\nrather than the individual summary lines, then there is no\npoint in us generating the summaries only to throw them\naway. With this patch, I measured the following speedup for\n\"git shortlog -ns HEAD\" on linux.git (best-of-five):\n\n  [before]\n  real    0m5.644s\n  user    0m5.472s\n  sys     0m0.176s\n\n  [after]\n  real    0m5.257s\n  user    0m5.104s\n  sys     0m0.156s\n\nThat's only ~7%, but it's so easy to do, there's no good\nreason not to. We don't have to touch any downstream code,\nsince we already fill in the magic string \"<none>\" to handle\ncommits without a message.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/shortlog.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/4e1d1a2eea25878a2128e376bff8b4a1b2216b15",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "shortlog_add_commit"
        ],
        "added_lines": 6,
        "deleted_lines": 4,
        "total_changed_lines": 10,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "5109f2aaabcd7ce2c493bb663417c2dd4d5b81fe",
        "author": "Junio C Hamano",
        "date": "2014-12-22T12:26:58-08:00",
        "message": "Merge branch 'mh/find-uniq-abbrev'\n\nThe code to abbreviate an object name to its short unique prefix\nhas been optimized when no abbreviation was requested.\n\n* mh/find-uniq-abbrev:\n  sha1_name: avoid unnecessary sha1 lookup in find_unique_abbrev",
        "modified_files_count": 1,
        "modified_files": [
            "sha1_name.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/5109f2aaabcd7ce2c493bb663417c2dd4d5b81fe",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "find_unique_abbrev"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "545f229a4b43212e683ac63e5aa740324ac7799e",
        "author": "Sergey Vlasov",
        "date": "2005-11-15T11:42:28-08:00",
        "message": "git-fsck-objects: Free tree entries after use\n\nThe Massif tool of Valgrind revealed that parsed tree entries occupy\nmore than 60% of memory allocated by git-fsck-objects.  These entries\ncan be freed immediately after use, which significantly decreases\nmemory consumption.\n\nSigned-off-by: Sergey Vlasov <vsu@altlinux.ru>\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "fsck-objects.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/545f229a4b43212e683ac63e5aa740324ac7799e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "fsck_tree"
        ],
        "added_lines": 7,
        "deleted_lines": 0,
        "total_changed_lines": 7,
        "net_line_change": 7,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "5473aca3767b00eab502b34a37b595de099980ae",
        "author": "Patrick Steinhardt",
        "date": "2024-01-03T09:54:21-08:00",
        "message": "reftable/merged: really reuse buffers to compute record keys\n\nIn 829231dc20 (reftable/merged: reuse buffer to compute record keys,\n2023-12-11), we have refactored the merged iterator to reuse a pair of\nlong-living strbufs by relying on the fact that `reftable_record_key()`\ntries to reuse already allocated strbufs by calling `strbuf_reset()`,\nwhich should give us significantly fewer reallocations compared to the\nold code that used on-stack strbufs that are allocated for each and\nevery iteration. Unfortunately, we called `strbuf_release()` on these\nlong-living strbufs that we meant to reuse on each iteration, defeating\nthe optimization.\n\nFix this performance issue by not releasing those buffers on iteration\nanymore, where we instead rely on `merged_iter_close()` to release the\nbuffers for us.\n\nUsing `git show-ref --quiet` in a repository with ~350k refs this leads\nto a significant drop in allocations. Before:\n\n    HEAP SUMMARY:\n        in use at exit: 21,163 bytes in 193 blocks\n      total heap usage: 1,410,148 allocs, 1,409,955 frees, 61,976,068 bytes allocated\n\nAfter:\n\n    HEAP SUMMARY:\n        in use at exit: 21,163 bytes in 193 blocks\n      total heap usage: 708,058 allocs, 707,865 frees, 36,783,255 bytes allocated\n\nSigned-off-by: Patrick Steinhardt <ps@pks.im>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "reftable/merged.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/5473aca3767b00eab502b34a37b595de099980ae",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "merged_iter_next_entry"
        ],
        "added_lines": 0,
        "deleted_lines": 2,
        "total_changed_lines": 2,
        "net_line_change": -2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "56384e61ead8d41c39bfafb535eedcf67ef4fcc3",
        "author": "Ren\u00e9 Scharfe",
        "date": "2009-03-02T18:28:06-08:00",
        "message": "optimize compat/ memmem()\n\nWhen memmem() was imported from glibc 2.2 into compat/, an optimization\nwas dropped in the process, in order to make the code smaller and simpler.\nIt was OK because memmem() wasn't used in performance-critical code.  Now\nthe situation has changed and we can benefit from this optimization.\n\nThe trick is to avoid calling memcmp() if the first character of the needle\nalready doesn't match.  Checking one character directly is much cheaper\nthan the function call overhead.  We keep the first character of the needle\nin the variable named point and the rest in the one named tail.\n\nThe following commands were run in a Linux kernel repository and timed, the\nbest of five results is shown:\n\n  $ STRING='Ensure that the real time constraints are schedulable.'\n  $ git log -S\"$STRING\" HEAD -- kernel/sched.c >/dev/null\n\nOn Windows Vista x64, before:\n\n  real    0m8.470s\n  user    0m0.000s\n  sys     0m0.000s\n\nAnd after the patch:\n\n  real    0m1.887s\n  user    0m0.000s\n  sys     0m0.000s\n\nSigned-off-by: Rene Scharfe <rene.scharfe@lsrfire.ath.cx>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "compat/memmem.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/56384e61ead8d41c39bfafb535eedcf67ef4fcc3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "gitmemmem"
        ],
        "added_lines": 4,
        "deleted_lines": 1,
        "total_changed_lines": 5,
        "net_line_change": 3,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "566b5c057c452d04605805ea2f7af210c6fb9b59",
        "author": "Linus Torvalds",
        "date": "2007-08-10T23:02:14-07:00",
        "message": "Optimize the three-way merge of git-read-tree\n\nAs mentioned, the three-way case *should* be as trivial as the\nfollowing. It passes all the tests, and I verified that a conflicting\nmerge in the 100,000 file horror-case merged correctly (with the conflict\nmarkers) in 0.687 seconds with this, so it works, but I'm lazy and\nsomebody else should double-check it [jc: followed all three-way merge\ncodepaths and verified it removes when it should].\n\nWithout this patch, the merge took 8.355 seconds, so this patch\nreally does make a huge difference for merge performance with lots and\nlots of files, and we're not talking percentages, we're talking\norders-of-magnitude differences!\n\nNow \"unpack_trees()\" is just fast enough that we don't need to avoid it\n(although it's probably still a good idea to eventually convert it to use\nthe traverse_trees() infrastructure some day - just to avoid having\nextraneous tree traversal functions).\n\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "unpack-trees.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/566b5c057c452d04605805ea2f7af210c6fb9b59",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "threeway_merge"
        ],
        "added_lines": 5,
        "deleted_lines": 2,
        "total_changed_lines": 7,
        "net_line_change": 3,
        "modified_code_blocks": 5,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "56a5f3afa74c70261dd2319ad76a6810e102026c",
        "author": "Anders Kaseorg",
        "date": "2010-12-09T11:20:25-08:00",
        "message": "describe: Use for_each_rawref\n\nDon't waste time checking for dangling refs; they wouldn't affect the\noutput of 'git describe' anyway.  Although this does not gain much\nperformance by itself, it does in conjunction with the next commits.\n\nSigned-off-by: Anders Kaseorg <andersk@ksplice.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/describe.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/56a5f3afa74c70261dd2319ad76a6810e102026c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_describe"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "5730a9dccf1d26f4d98a6d3868614ec2bb0e05a0",
        "author": "Patrick Steinhardt",
        "date": "2024-02-12T09:18:04-08:00",
        "message": "reftable/merged: skip comparison for records of the same subiter\n\nWhen retrieving the next entry of a merged iterator we need to drop all\nrecords of other sub-iterators that would be shadowed by the record that\nwe are about to return. We do this by comparing record keys, dropping\nall keys that are smaller or equal to the key of the record we are about\nto return.\n\nThere is an edge case here where we can skip that comparison: when the\nrecord in the priority queue comes from the same subiterator as the\nrecord we are about to return then we know that its key must be larger\nthan the key of the record we are about to return. This property is\nguaranteed by the sub-iterators, and if it didn't hold then the whole\nmerged iterator would return records in the wrong order, too.\n\nWhile this may seem like a very specific edge case it's in fact quite\nlikely to happen. For most repositories out there you can assume that we\nwill end up with one large table and several smaller ones on top of it.\nThus, it is very likely that the next entry will sort towards the top of\nthe priority queue.\n\nSpecial case this and break out of the loop in that case. The following\nbenchmark uses git-show-ref(1) to print a single ref matching a pattern\nout of 1 million refs:\n\n  Benchmark 1: show-ref: single matching ref (revision = HEAD~)\n    Time (mean \u00b1 \u03c3):     162.6 ms \u00b1   4.5 ms    [User: 159.0 ms, System: 3.5 ms]\n    Range (min \u2026 max):   156.6 ms \u2026 188.5 ms    1000 runs\n\n  Benchmark 2: show-ref: single matching ref (revision = HEAD)\n    Time (mean \u00b1 \u03c3):     156.8 ms \u00b1   4.7 ms    [User: 153.0 ms, System: 3.6 ms]\n    Range (min \u2026 max):   151.4 ms \u2026 188.4 ms    1000 runs\n\n  Summary\n    show-ref: single matching ref (revision = HEAD) ran\n      1.04 \u00b1 0.04 times faster than show-ref: single matching ref (revision = HEAD~)\n\nSigned-off-by: Patrick Steinhardt <ps@pks.im>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "reftable/merged.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/5730a9dccf1d26f4d98a6d3868614ec2bb0e05a0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "merged_iter_next_entry"
        ],
        "added_lines": 8,
        "deleted_lines": 0,
        "total_changed_lines": 8,
        "net_line_change": 8,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "57584d9eddc3482c5db0308203b9df50dc62109c",
        "author": "Junio C Hamano",
        "date": "2007-03-19T22:17:10-07:00",
        "message": "blame: micro-optimize cmp_suspect()\n\nThe commit structures are guaranteed their uniqueness by the object\nlayer, so we can check their address and see if they are the same\nwithout going down to the object sha1 level.\n\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin-blame.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/57584d9eddc3482c5db0308203b9df50dc62109c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmp_suspect"
        ],
        "added_lines": 2,
        "deleted_lines": 3,
        "total_changed_lines": 5,
        "net_line_change": -1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "590fc05293964160e4360431950325658d75fe23",
        "author": "Ren\u00e9 Scharfe",
        "date": "2017-02-13T14:33:32-08:00",
        "message": "rm: reuse strbuf for all remove_dir_recursively() calls, again\n\nDon't throw the memory allocated for remove_dir_recursively() away after\na single call, use it for the other entries as well instead.\n\nThis change was done before in deb8e15a (rm: reuse strbuf for all\nremove_dir_recursively() calls), but was reverted as a side-effect of\n55856a35 (rm: absorb a submodules git dir before deletion). Reinstate\nthe optimization.\n\nSigned-off-by: Rene Scharfe <l.s.r@web.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/rm.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/590fc05293964160e4360431950325658d75fe23",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_rm"
        ],
        "added_lines": 3,
        "deleted_lines": 3,
        "total_changed_lines": 6,
        "net_line_change": 0,
        "modified_code_blocks": 4,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "5981e09999e90b389a02843671529a0faaf72143",
        "author": "Junio C Hamano",
        "date": "2006-04-26T16:55:25-07:00",
        "message": "commit-tree.c: check_valid() microoptimization.\n\nThere is no point reading the whole object just to make sure it exists and\nit is of the expected type.  We added sha1_object_info() for such need\nafter this code was written, so use it.\n\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "commit-tree.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/5981e09999e90b389a02843671529a0faaf72143",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "check_valid"
        ],
        "added_lines": 5,
        "deleted_lines": 6,
        "total_changed_lines": 11,
        "net_line_change": -1,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "59b8d38f6e4f19b93c5dc4493ab11706acd101b5",
        "author": "Tay Ray Chuan",
        "date": "2009-09-11T01:45:36-07:00",
        "message": "http.c: remove verification of remote packs\n\nMake http.c::fetch_pack_index() no longer check for the remote pack\nwith a HEAD request before fetching the corresponding pack index file.\n\nNot only does sending a HEAD request before we do a GET incur a\nperformance penalty, it does not offer any significant error-\nprevention advantages (pack fetching in the *_http_pack_request()\nmethods is capable of handling any errors on its own).\n\nThis addresses an issue raised elsewhere:\n\n  http://code.google.com/p/msysgit/issues/detail?id=323\n  http://support.github.com/discussions/repos/957-cant-clone-over-http-or-git\n\nSigned-off-by: Tay Ray Chuan <rctay89@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "http.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/59b8d38f6e4f19b93c5dc4493ab11706acd101b5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "fetch_pack_index"
        ],
        "added_lines": 0,
        "deleted_lines": 11,
        "total_changed_lines": 11,
        "net_line_change": -11,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "5b2f6d9cd50b1c8909326c7175aef288a9915f33",
        "author": "Denton Liu",
        "date": "2020-04-07T16:57:30-07:00",
        "message": "sequencer: make file exists check more efficient\n\nWe currently check whether a file exists and return early before reading\nthe file. Instead of accessing the file twice, always read the file and\ncheck `errno` to see if the file doesn't exist.\n\nSigned-off-by: Denton Liu <liu.denton@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "sequencer.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/5b2f6d9cd50b1c8909326c7175aef288a9915f33",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "read_oneliner"
        ],
        "added_lines": 2,
        "deleted_lines": 4,
        "total_changed_lines": 6,
        "net_line_change": -2,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "5b8a94b1db4beba969d8cbb0e6e45033834b5913",
        "author": "Bj\u00f6rn Steinbrink",
        "date": "2008-06-28T19:50:56-07:00",
        "message": "git cat-file: Fix memory leak in batch mode\n\nWhen run in batch mode, git cat-file never frees the memory for the blob\ncontents it is printing. This quickly adds up and causes git-svn to be\nhardly usable for imports of large svn repos, because it uses cat-file in\nbatch mode and cat-file's memory usage easily reaches several hundred MB\nwithout any good reason.\n\nSigned-off-by: Bj\u00f6rn Steinbrink <B.Steinbrink@gmx.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin-cat-file.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/5b8a94b1db4beba969d8cbb0e6e45033834b5913",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "batch_one_object"
        ],
        "added_lines": 1,
        "deleted_lines": 0,
        "total_changed_lines": 1,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "5cd5ace72bf8944c920a20a7b98c82f7ed663d8a",
        "author": "Linus Torvalds",
        "date": "2005-10-01T23:56:16-07:00",
        "message": "[PATCH] Re-instate index file write optimization\n\nThis makes \"git-update-index\" avoid the new index file write if it didn't\nmake any changes to the index.\n\nIt still doesn't make things like \"git status\" be read-only operations in\ngeneral, but if the index file doesn't need refreshing, it now will at\nleast avoid making unnecessary changes.\n\nSigned-off-by: Linus Torvalds <torvalds@osdl.org>\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "update-index.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/5cd5ace72bf8944c920a20a7b98c82f7ed663d8a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "added_lines": 5,
        "deleted_lines": 3,
        "total_changed_lines": 8,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "5cf7a17dfbe60ea3cfb32ace7264edc3ad97611b",
        "author": "Jeff King",
        "date": "2019-11-30T09:10:39-08:00",
        "message": "send-pack: use OBJECT_INFO_QUICK to check negative objects\n\nWhen pushing, we feed pack-objects a list of both positive and negative\nobjects. The positive objects are what we want to send, and the negative\nobjects are what the other side told us they have, which we can use to\nlimit the size of the push.\n\nBefore passing along a negative object, send_pack() will make sure we\nactually have it (since we only know about it because the remote\nmentioned it, not because it's one of our refs). So it's expected that\nsome of these objects will be missing on the local side. But looking for\na missing object is more expensive than one that we have: it triggers\nreprepare_packed_git() to handle a racy repack, plus it has to explore\nevery alternate's loose object tree (which can be slow if you have a lot\nof them, or have a high-latency filesystem).\n\nThis isn't usually a big problem, since repositories you're pushing to\ndon't generally have a large number of refs that are unrelated to what\nthe client has. But there's no reason such a setup is wrong, and it\ncurrently performs poorly.\n\nWe can fix this by using OBJECT_INFO_QUICK, which tells the lookup\ncode that we expect objects to be missing. Notably, it will not re-scan\nthe packs, and it will use the loose cache from 61c7711cfe (sha1-file:\nuse loose object cache for quick existence check, 2018-11-12).\n\nThe downside is that in the rare case that we race with a local repack,\nwe might fail to feed some objects to pack-objects, making the resulting\npush larger. But we'd never produce an invalid or incorrect push, just a\nless optimal one. That seems like a reasonable tradeoff, and we already\ndo similar things on the fetch side (e.g., when marking COMPLETE\ncommits).\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "send-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/5cf7a17dfbe60ea3cfb32ace7264edc3ad97611b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "feed_object"
        ],
        "added_lines": 3,
        "deleted_lines": 1,
        "total_changed_lines": 4,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "5d55915c7a58e59d913b0cfc38a6f49514068cd2",
        "author": "Junio C Hamano",
        "date": "2012-08-27T18:36:39-07:00",
        "message": "receive-pack: use in_merge_bases() for fast-forward check\n\nThe original computed merge-base between the old commit and the new\ncommit and checked if the old commit was a merge base between them,\nin order to make sure we are fast-forwarding.\n\nInstead, call in_merge_bases(old, new) which does the same.\n\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/receive-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/5d55915c7a58e59d913b0cfc38a6f49514068cd2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "update"
        ],
        "added_lines": 1,
        "deleted_lines": 7,
        "total_changed_lines": 8,
        "net_line_change": -6,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "5d80ef5a6e727bbecd7d892a5043bae25f7ca5e2",
        "author": "Ren\u00e9 Scharfe",
        "date": "2013-06-02T15:31:15-07:00",
        "message": "unpack-trees: free cache_entry array members for merges\n\nThe merge functions duplicate entries as needed and they don't free\nthem.  Release them in unpack_nondirectories, the same function\nwhere they were allocated, after we're done.\n\nAs suggested by Felipe, use the same loop style (zero-based for loop)\nfor freeing as for allocating.\n\nImproved-by: Felipe Contreras <felipe.contreras@gmail.com>\nSigned-off-by: Ren\u00e9 Scharfe <rene.scharfe@lsrfire.ath.cx>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "unpack-trees.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/5d80ef5a6e727bbecd7d892a5043bae25f7ca5e2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "unpack_nondirectories"
        ],
        "added_lines": 10,
        "deleted_lines": 3,
        "total_changed_lines": 13,
        "net_line_change": 7,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "62b5a35a33ad6a4537e2ae75a49036e4173fcc87",
        "author": "Patrick Steinhardt",
        "date": "2021-09-01T12:43:56-07:00",
        "message": "fetch-pack: optimize loading of refs via commit graph\n\nIn order to negotiate a packfile, we need to dereference refs to see\nwhich commits we have in common with the remote. To do so, we first look\nup the object's type -- if it's a tag, we peel until we hit a non-tag\nobject. If we hit a commit eventually, then we return that commit.\n\nIn case the object ID points to a commit directly, we can avoid the\ninitial lookup of the object type by opportunistically looking up the\ncommit via the commit-graph, if available, which gives us a slight speed\nbump of about 2% in a huge repository with about 2.3M refs:\n\n    Benchmark #1: HEAD~: git-fetch\n      Time (mean \u00b1 \u03c3):     31.634 s \u00b1  0.258 s    [User: 28.400 s, System: 5.090 s]\n      Range (min \u2026 max):   31.280 s \u2026 31.896 s    5 runs\n\n    Benchmark #2: HEAD: git-fetch\n      Time (mean \u00b1 \u03c3):     31.129 s \u00b1  0.543 s    [User: 27.976 s, System: 5.056 s]\n      Range (min \u2026 max):   30.172 s \u2026 31.479 s    5 runs\n\n    Summary\n      'HEAD: git-fetch' ran\n        1.02 \u00b1 0.02 times faster than 'HEAD~: git-fetch'\n\nIn case this fails, we fall back to the old code which peels the\nobjects to a commit.\n\nSigned-off-by: Patrick Steinhardt <ps@pks.im>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "fetch-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/62b5a35a33ad6a4537e2ae75a49036e4173fcc87",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "deref_without_lazy_fetch"
        ],
        "added_lines": 5,
        "deleted_lines": 0,
        "total_changed_lines": 5,
        "net_line_change": 5,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "63ad8dbf169ec8e2b3cef40ff51499ee751a84a5",
        "author": "D Harithamma",
        "date": "2024-07-31T08:54:13-07:00",
        "message": "convert: return early when not tracing\n\nWhen Git adds a file requiring encoding conversion and tracing of encoding\nconversion is not requested via the GIT_TRACE_WORKING_TREE_ENCODING\nenvironment variable, the `trace_encoding()` function still allocates &\nprepares \"human readable\" copies of the file contents before and after\nconversion to show in the trace. This results in a high memory footprint\nand increased runtime without providing any user-visible benefit.\n\nThis fix introduces an early exit from the `trace_encoding()` function\nwhen tracing is not requested, preventing unnecessary memory allocation\nand processing.\n\nSigned-off-by: D Harithamma <harithamma.d@ibm.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "convert.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/63ad8dbf169ec8e2b3cef40ff51499ee751a84a5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "trace_encoding"
        ],
        "added_lines": 3,
        "deleted_lines": 0,
        "total_changed_lines": 3,
        "net_line_change": 3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "6571225137b1ba270b49a0dfc6a30aab6f4b86ba",
        "author": "Junio C Hamano",
        "date": "2012-08-27T18:36:39-07:00",
        "message": "http-push: use in_merge_bases() for fast-forward check\n\nThe original computed merge-base between HEAD and the remote ref and\nchecked if the remote ref is a merge base between them, in order to\nmake sure that we are fast-forwarding.\n\nInstead, call in_merge_bases(remote, HEAD) which does the same.\n\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "http-push.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/6571225137b1ba270b49a0dfc6a30aab6f4b86ba",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "verify_merge_base"
        ],
        "added_lines": 1,
        "deleted_lines": 2,
        "total_changed_lines": 3,
        "net_line_change": -1,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "658dd48c8572d0db49719cbef6605d384621d87c",
        "author": "Linus Torvalds",
        "date": "2009-05-09T20:42:19-07:00",
        "message": "Avoid unnecessary 'lstat()' calls in 'get_stat_data()'\n\nWhen we ask get_stat_data() to get the mode and size of an index entry,\nwe can avoid the lstat() call if we have marked the index entry as being\nuptodate due to earlier lstat() calls.\n\nThis avoids a lot of unnecessary lstat() calls in eg 'git checkout',\nwhere the last phase shows the differences to the working tree\n(requiring a diff), but earlier phases have already verified the index.\n\nOn the kernel repo (with a fast machine and everything cached), this\nchanges timings of a nul 'git checkout' from\n\n - Before (best of ten):\n\n\t0.14user 0.05system 0:00.19elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k\n\t0inputs+0outputs (0major+13237minor)pagefaults 0swaps\n\n - After\n\t0.11user 0.03system 0:00.15elapsed 98%CPU (0avgtext+0avgdata 0maxresident)k\n\t0inputs+0outputs (0major+13235minor)pagefaults 0swaps\n\nso it can obviously be noticeable, although equally obviously it's not a\nshow-stopper on this particular machine. The difference is likely larger\non slower machines, or with operating systems that don't do as good a job\nof name caching.\n\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "diff-lib.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/658dd48c8572d0db49719cbef6605d384621d87c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_stat_data"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "6620f9134cc36189eecd88375a226a7bd7836a8a",
        "author": "Patrick Steinhardt",
        "date": "2024-03-04T10:19:49-08:00",
        "message": "reftable/record: reuse refname when copying\n\nDo the same optimization as in the preceding commit, but this time for\n`reftable_record_copy()`. While not as noticeable, it still results in a\nsmall speedup when iterating over 1 million refs:\n\n  Benchmark 1: show-ref: single matching ref (revision = HEAD~)\n    Time (mean \u00b1 \u03c3):     114.0 ms \u00b1   3.8 ms    [User: 111.1 ms, System: 2.7 ms]\n    Range (min \u2026 max):   110.9 ms \u2026 144.3 ms    1000 runs\n\n  Benchmark 2: show-ref: single matching ref (revision = HEAD)\n    Time (mean \u00b1 \u03c3):     112.5 ms \u00b1   3.7 ms    [User: 109.5 ms, System: 2.8 ms]\n    Range (min \u2026 max):   109.2 ms \u2026 140.7 ms    1000 runs\n\n  Summary\n    show-ref: single matching ref (revision = HEAD) ran\n      1.01 \u00b1 0.05 times faster than show-ref: single matching ref (revision = HEAD~)\n\nSigned-off-by: Patrick Steinhardt <ps@pks.im>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "reftable/record.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/6620f9134cc36189eecd88375a226a7bd7836a8a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "reftable_ref_record_copy_from"
        ],
        "added_lines": 15,
        "deleted_lines": 3,
        "total_changed_lines": 18,
        "net_line_change": 12,
        "modified_code_blocks": 5,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "67686d95044e56475669ff1306448e41a794a865",
        "author": "Junio C Hamano",
        "date": "2006-03-19T13:43:42-08:00",
        "message": "unpack_delta_entry(): reduce memory footprint.\n\nCurrently we unpack the delta data from the pack and then unpack\nthe base object to apply that delta data to it.  When getting an\nobject that is deeply deltified, we can reduce memory footprint\nby unpacking the base object first and then unpacking the delta\ndata, because we will need to keep at most one delta data in\nmemory that way.\n\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "sha1_file.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/67686d95044e56475669ff1306448e41a794a865",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "unpack_delta_entry"
        ],
        "added_lines": 10,
        "deleted_lines": 8,
        "total_changed_lines": 18,
        "net_line_change": 2,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "680e0b4524482c4bb679030188f6ae8db4caff06",
        "author": "Jeff Hostetler",
        "date": "2020-08-17T11:27:16-07:00",
        "message": "mingw: improve performance of mingw_unlink()\n\nUpdate mingw_unlink() to first try to delete the file with existing\npermissions before trying to force it.\n\nWindows throws an error when trying to delete a read-only file.  The\nmingw_unlink() compatibility wrapper always tries to _wchmod(666) the\nfile before calling _wunlink() to avoid that error.  However, since\nmost files in the worktree are already writable, this is usually\nwasted effort.\n\nUpdate mingw_unlink() to just call DeleteFileW() directly and if that\nsucceeds return.  If that fails, fall back into the existing code path\nto update the permissions and use _wunlink() to get the existing\nerror code mapping.\n\nSigned-off-by: Jeff Hostetler <jeffhost@microsoft.com>\nSigned-off-by: Johannes Schindelin <johannes.schindelin@gmx.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "compat/mingw.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/680e0b4524482c4bb679030188f6ae8db4caff06",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mingw_unlink"
        ],
        "added_lines": 3,
        "deleted_lines": 0,
        "total_changed_lines": 3,
        "net_line_change": 3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "6a36e1e7bb64726cc712259aff57179d81361b5d",
        "author": "Jeff King",
        "date": "2016-05-18T14:17:39-07:00",
        "message": "cat-file: default to --buffer when --batch-all-objects is used\n\nTraditionally cat-file's batch-mode does not do any output\nbuffering. The reason is that a caller may have pipes\nconnected to its input and output, and would want to use\ncat-file interactively, getting output immediately for each\ninput it sends.\n\nThis may involve a lot of small write() calls, which can be\nslow. So we introduced --buffer to improve this, but we\ncan't turn it on by default, as it would break the\ninteractive case above.\n\nHowever, when --batch-all-objects is used, we do not read\nstdin at all. We generate the output ourselves as quickly as\npossible, and then exit. In this case buffering is a strict\nwin, and it is simply a hassle for the user to have to\nremember to specify --buffer.\n\nThis patch makes --buffer the default when --batch-all-objects\nis used. Specifying \"--buffer\" manually is still OK, and you\ncan even override it with \"--no-buffer\" if you're a\nmasochist (or debugging).\n\nFor some real numbers, running:\n\n  git cat-file --batch-all-objects --batch-check='%(objectname)'\n\non torvalds/linux goes from:\n\n  real    0m1.464s\n  user    0m1.208s\n  sys     0m0.252s\n\nto:\n\n  real    0m1.230s\n  user    0m1.172s\n  sys     0m0.056s\n\nfor a 16% speedup.\n\nSuggested-by: Charles Bailey <charles@hashpling.org>\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/cat-file.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/6a36e1e7bb64726cc712259aff57179d81361b5d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_cat_file"
        ],
        "added_lines": 4,
        "deleted_lines": 0,
        "total_changed_lines": 4,
        "net_line_change": 4,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "6bd2ae67a5be4e08cd2bfc611c3d08707b1416e1",
        "author": "Jeff King",
        "date": "2024-08-30T14:03:00-07:00",
        "message": "revision: free commit buffers for skipped commits\n\nIn git-log we leave the save_commit_buffer flag set to \"1\", which tells\nthe commit parsing code to store the object content after it has parsed\nit to find parents, tree, etc. That lets us reuse the contents for\npretty-printing the commit in the output. And then after printing each\ncommit, we call free_commit_buffer(), since we don't need it anymore.\n\nBut some options may cause us to traverse commits which are not part of\nthe output. And so git-log does not see them at all, and doesn't free\nthem. One such case is something like:\n\n  git log -n 1000 --skip=1000000\n\nwhich will churn through a million commits, before showing only a\nthousand. We loop through these inside get_revision(), without freeing\nthe contents. As a result, we end up storing the object data for those\nmillion commits simultaneously.\n\nWe should free the stored buffers (if any) for those commits as we skip\nover them, which is what this patch does. Running the above command in\nlinux.git drops the peak heap usage from ~1.1GB to ~200MB, according to\nvalgrind/massif. (I thought we might get an even bigger improvement, but\nthe remaining memory is going to commit/tree structs, which we do hold\non to forever).\n\nNote that this problem doesn't occur if:\n\n  - you're running a git-rev-list without a --format parameter; it turns\n    off save_commit_buffer by default, since it only output the object\n    id\n\n  - you've built a commit-graph file, since in that case we'd use the\n    optimized graph data instead of the initial parse, and then do a\n    lazy parse for commits we're actually going to output\n\nThere are probably some other option combinations that can likewise\nend up with useless stored commit buffers. For example, if you ask for\n\"foo..bar\", then we'll have to walk down to the merge base, and\neverything on the \"foo\" side won't be shown. Tuning the \"save\" behavior\nto handle that might be tricky (I guess maybe drop buffers for anything\nwe mark as UNINTERESTING?). And in the long run, the right solution here\nis probably to make sure the commit-graph is built (since it fixes the\nmemory problem _and_ drastically reduces CPU usage).\n\nBut since this \"--skip\" case is an easy one-liner, it's worth fixing in\nthe meantime. It should be OK to make this call even if there is no\nsaved buffer (e.g., because save_commit_buffer=0, or because a\ncommit-graph was used), since it's O(1) to look up the buffer and is a\nnoop if it isn't present. I verified by running the above command after\n\"git commit-graph write --reachable\", and it takes the same time with\nand without this patch.\n\nReported-by: Yuri Karnilaev <karnilaev@gmail.com>\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "revision.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/6bd2ae67a5be4e08cd2bfc611c3d08707b1416e1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_revision_internal"
        ],
        "added_lines": 1,
        "deleted_lines": 0,
        "total_changed_lines": 1,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "6c4ee2244aea924b6d04b4753ca8c7709e8e5f90",
        "author": "Junio C Hamano",
        "date": "2010-03-04T22:25:45-08:00",
        "message": "Merge branch 'jc/maint-status-preload' into maint\n\n* jc/maint-status-preload:\n  status: preload index to optimize lstat(2) calls",
        "modified_files_count": 1,
        "modified_files": [
            "builtin-commit.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/6c4ee2244aea924b6d04b4753ca8c7709e8e5f90",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_status"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "6d9617f4f77510b4fa76fbabae2a5f4a9604577f",
        "author": "Jeff King",
        "date": "2016-08-23T14:57:44-07:00",
        "message": "delta_base_cache: drop special treatment of blobs\n\nWhen the delta base cache runs out of allowed memory, it has\nto drop entries. It does so by walking an LRU list, dropping\nobjects until we are under the memory limit. But we actually\nwalk the list twice: once to drop blobs, and then again to\ndrop other objects (which are generally trees). This comes\nfrom 18bdec1 (Limit the size of the new delta_base_cache,\n2007-03-19).\n\nThis performs poorly as the number of entries grows, because\nany time dropping blobs does not satisfy the limit, we have\nto walk the _entire_ list, trees included, looking for blobs\nto drop, before starting to drop any trees.\n\nIt's not generally a problem now, as the cache is limited to\nonly 256 entries. But as we could benefit from increasing\nthat in a future patch, it's worth looking at how it\nperforms as the cache size grows. And the answer is \"not\nwell\".\n\nThe table below shows times for various operations with\ndifferent values of MAX_DELTA_CACHE (which is not a run-time\nknob; I recompiled with -DMAX_DELTA_CACHE=$n for each).\n\nI chose \"git log --raw\" (\"log-raw\" in the table) because it\nwill access all of the trees, but no blobs at all (so in a\nsense it is a worst case for this problem, because we will\nalways walk over the entire list of trees once before\nrealizing there are no blobs to drop). This is also\nrepresentative of other tree-only operations like \"rev-list\n--objects\" and \"git log -- <path>\".\n\nI also timed \"git log -Sfoo --raw\" (\"log-S\" in the table).\nIt similarly accesses all of the trees, but also the blobs\nfor each commit. It's representative of \"git log -p\", though\nit emphasizes the cost of blob access more, as \"-S\" is\ncheaper than computing an actual blob diff.\n\nAll timings are best-of-3 wall-clock times (though they all\nwere CPU bound, so the user CPU times are similar). The\nrepositories were fully packed with --depth=50, and the\ndefault core.deltaBaseCacheLimit of 96M was in effect.  The\ncurrent value of MAX_DELTA_CACHE is 256, so I started there\nand worked up by factors of 2.\n\nFirst, here are values for git.git (the asterisk signals the\nfastest run for each operation):\n\n    MAX_DELTA_CACHE    log-raw       log-S\n    ---------------   ---------    ---------\n                256   0m02.212s    0m12.634s\n                512   0m02.136s*   0m10.614s\n               1024   0m02.156s    0m08.614s\n               2048   0m02.208s    0m07.062s\n               4096   0m02.190s    0m06.484s*\n               8192   0m02.176s    0m07.635s\n              16384   0m02.913s    0m19.845s\n              32768   0m03.617s    1m05.507s\n              65536   0m04.031s    1m18.488s\n\nYou can see that for the tree-only log-raw case, we don't\nactually benefit that much as the cache grows (all the\ndifferences up through 8192 are basically just noise; this\nis probably because we don't actually have that many\ndistinct trees in git.git). But for log-S, we get a definite\nspeed improvement as the cache grows, but the improvements\nare lost as cache size grows and the linear LRU management\nstarts to dominate.\n\nHere's the same thing run against linux.git:\n\n    MAX_DELTA_CACHE    log-raw       log-S\n    ---------------   ---------    ----------\n                256   0m40.987s     5m13.216s\n                512   0m37.949s     5m03.243s\n               1024   0m35.977s     4m50.580s\n               2048   0m33.855s     4m39.818s\n               4096   0m32.913s     4m47.299s*\n               8192   0m32.176s*    5m14.650s\n              16384   0m32.185s     6m31.625s\n              32768   0m38.056s     9m31.136s\n              65536   1m30.518s    17m38.549s\n\nThe pattern is similar, though the effect in log-raw is more\npronounced here. The times dip down in the middle, and then\ngo back up as we keep growing.\n\nSo we know there's a problem. What's the solution?\n\nThe obvious one is to improve the data structure to avoid\nwalking over tree entries during the looking-for-blobs\ntraversal. We can do this by keeping _two_ LRU lists: one\nfor blobs, and one for other objects. We drop items from the\nblob LRU first, and then from the tree LRU (if necessary).\n\nHere's git.git using that strategy:\n\n    MAX_DELTA_CACHE    log-raw      log-S\n    ---------------   ---------   ----------\n                256   0m02.264s   0m12.830s\n                512   0m02.201s   0m10.771s\n               1024   0m02.181s   0m08.593s\n               2048   0m02.205s   0m07.116s\n               4096   0m02.158s   0m06.537s*\n               8192   0m02.213s   0m07.246s\n              16384   0m02.155s*  0m10.975s\n              32768   0m02.159s   0m16.047s\n              65536   0m02.181s   0m16.992s\n\nThe upswing on log-raw is gone completely. But log-S still\nhas it (albeit much better than without this strategy).\nLet's see what linux.git shows:\n\n    MAX_DELTA_CACHE    log-raw       log-S\n    ---------------   ---------    ---------\n                256   0m42.519s    5m14.654s\n                512   0m39.106s    5m04.708s\n               1024   0m36.802s    4m51.454s\n               2048   0m34.685s    4m39.378s*\n               4096   0m33.663s    4m44.047s\n               8192   0m33.157s    4m50.644s\n              16384   0m33.090s*   4m49.648s\n              32768   0m33.458s    4m53.371s\n              65536   0m33.563s    5m04.580s\n\nThe results are similar. The tree-only case again performs\nwell (not surprising; we're literally just dropping the one\nuseless walk, and not otherwise changing the cache eviction\nstrategy at all). But the log-S case again does a bit worse\nas the cache grows (though possibly that's within the noise,\nwhich is much larger for this case).\n\nPerhaps this is an indication that the \"remove blobs first\"\nstrategy is not actually optimal. The intent of it is to\navoid blowing out the tree cache when we see large blobs,\nbut it also means we'll throw away useful, recent blobs in\nfavor of older trees.\n\nLet's run the same numbers without caring about object type\nat all (i.e., one LRU list, and always evicting whatever is\nat the head, regardless of type).\n\nHere's git.git:\n\n    MAX_DELTA_CACHE    log-raw      log-S\n    ---------------   ---------   ---------\n                256   0m02.227s   0m12.821s\n                512   0m02.143s   0m10.602s\n               1024   0m02.127s   0m08.642s\n               2048   0m02.148s   0m07.123s\n               4096   0m02.194s   0m06.448s*\n               8192   0m02.239s   0m06.504s\n              16384   0m02.144s*  0m06.502s\n              32768   0m02.202s   0m06.622s\n              65536   0m02.230s   0m06.677s\n\nMuch smoother; there's no dramatic upswing as we increase\nthe cache size (some remains, though it's small enough that\nit's mostly run-to-run noise. E.g., in the log-raw case,\nnote how 8192 is 50-100ms higher than its neighbors). Note\nalso that we stop getting any real benefit for log-S after\nabout 4096 entries; that number will depend on the size of\nthe repository, the size of the blob entries, and the memory\nlimit of the cache.\n\nLet's see what linux.git shows for the same strategy:\n\n    MAX_DELTA_CACHE    log-raw      log-S\n    ---------------   ---------   ---------\n                256   0m41.661s   5m12.410s\n                512   0m39.547s   5m07.920s\n               1024   0m37.054s   4m54.666s\n               2048   0m35.871s   4m41.194s*\n               4096   0m34.646s   4m51.648s\n               8192   0m33.881s   4m55.342s\n              16384   0m35.190s   5m00.122s\n              32768   0m35.060s   4m58.851s\n              65536   0m33.311s*  4m51.420s\n\nIt's similarly good. As with the \"separate blob LRU\"\nstrategy, there's a lot of noise on the log-S run here. But\nit's certainly not any worse, is possibly a bit better, and\nthe improvement over \"separate blob LRU\" on the git.git case\nis dramatic.\n\nSo it seems like a clear winner, and that's what this patch\nimplements.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "sha1_file.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/6d9617f4f77510b4fa76fbabae2a5f4a9604577f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "add_delta_base_cache"
        ],
        "added_lines": 0,
        "deleted_lines": 8,
        "total_changed_lines": 8,
        "net_line_change": -8,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "70a9fef2402ff22db7691c6e3134943e1a4c1e1a",
        "author": "Matheus Tavares",
        "date": "2020-01-17T13:52:14-08:00",
        "message": "grep: move driver pre-load out of critical section\n\nIn builtin/grep.c:add_work() we pre-load the userdiff drivers before\nadding the grep_source in the todo list. This operation is currently\nbeing performed after acquiring the grep_mutex, but as it's already\nthread-safe, we don't need to protect it here. So let's move it out of\nthe critical section which should avoid thread contention and improve\nperformance.\n\nRunning[1] `git grep --threads=8 abcd[02] HEAD` on chromium's\nrepository[2], I got the following mean times for 30 executions after 2\nwarmups:\n\n        Original         |  6.2886s\n-------------------------|-----------\n Out of critical section |  5.7852s\n\n[1]: Tests performed on an i7-7700HQ with 16GB of RAM and SSD, running\n     Manjaro Linux.\n[2]: chromium\u2019s repo at commit 03ae96f (\u201cAdd filters testing at DSF=2\u201d,\n         04-06-2019), after a 'git gc' execution.\n\nSigned-off-by: Matheus Tavares <matheus.bernardino@usp.br>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/grep.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/70a9fef2402ff22db7691c6e3134943e1a4c1e1a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "add_work"
        ],
        "added_lines": 4,
        "deleted_lines": 4,
        "total_changed_lines": 8,
        "net_line_change": 0,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "72ed80c784e65770c4d4944b0ea54b08e098d7e3",
        "author": "Jeff King",
        "date": "2019-09-12T11:47:30-07:00",
        "message": "list-objects: don't queue root trees unless revs->tree_objects is set\n\nWhen traverse_commit_list() processes each commit, it queues the\ncommit's root tree in the pending array. Then, after all commits are\nprocessed, it calls traverse_trees_and_blobs() to walk over the pending\nlist, calling process_tree() on each. But if revs->tree_objects is not\nset, process_tree() just exists immediately!\n\nWe can save ourselves some work by not even bothering to queue these\ntrees in the first place. There are a few subtle points to make:\n\n  - we also detect commits with a NULL tree pointer here. But this isn't\n    an interesting check for broken commits, since the lookup_tree()\n    we'd have done during commit parsing doesn't actually check that we\n    have the tree on disk. So we're not losing any robustness.\n\n  - besides queueing, we also set the NOT_USER_GIVEN flag on the tree\n    object. This is used by the traverse_commit_list_filtered() variant.\n    But if we're not exploring trees, then we won't actually care about\n    this flag, which is used only inside process_tree() code-paths.\n\n  - queueing trees eventually leads to us queueing blobs, too. But we\n    don't need to check revs->blob_objects here. Even in the current\n    code, we still wouldn't find those blobs, because we'd never open up\n    the tree objects to list their contents.\n\n  - the user-visible impact to the caller is minimal. The pending trees\n    are all cleared by the time the function returns anyway, by\n    traverse_trees_and_blobs(). We do call a show_commit() callback,\n    which technically could be looking at revs->pending during the\n    callback. But it seems like a rather unlikely thing to do (if you\n    want the tree of the current commit, then accessing the tree struct\n    member is a lot simpler).\n\nSo this should be safe to do. Let's look at the benefits:\n\n  [before]\n  Benchmark #1: git -C linux rev-list HEAD >/dev/null\n    Time (mean \u00b1 \u03c3):      7.651 s \u00b1  0.021 s    [User: 7.399 s, System: 0.252 s]\n    Range (min \u2026 max):    7.607 s \u2026  7.683 s    10 runs\n\n  [after]\n  Benchmark #1: git -C linux rev-list HEAD >/dev/null\n    Time (mean \u00b1 \u03c3):      7.593 s \u00b1  0.023 s    [User: 7.329 s, System: 0.264 s]\n    Range (min \u2026 max):    7.565 s \u2026  7.634 s    10 runs\n\nNot too impressive, but then we're really just avoiding sticking a\npointer into a growable array. But still, I'll take a free 0.75%\nspeedup.\n\nLet's try it after running \"git commit-graph write\":\n\n  [before]\n  Benchmark #1: git -C linux rev-list HEAD >/dev/null\n    Time (mean \u00b1 \u03c3):      1.458 s \u00b1  0.011 s    [User: 1.199 s, System: 0.259 s]\n    Range (min \u2026 max):    1.447 s \u2026  1.481 s    10 runs\n\n  [after]\n  Benchmark #1: git -C linux rev-list HEAD >/dev/null\n    Time (mean \u00b1 \u03c3):      1.126 s \u00b1  0.023 s    [User: 896.5 ms, System: 229.0 ms]\n    Range (min \u2026 max):    1.106 s \u2026  1.181 s    10 runs\n\nNow that's more like it. We saved over 22% of the total time. Part of\nthat is because the runtime is shorter overall, but the absolute\nimprovement is also much larger. What's going on?\n\nWhen we fill in a commit struct using the commit graph, we don't bother\nto set the tree pointer, and instead lazy-load it when somebody calls\nget_commit_tree(). So we're not only skipping the pointer write to the\npending queue, but we're skipping the lazy-load of the tree entirely.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "list-objects.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/72ed80c784e65770c4d4944b0ea54b08e098d7e3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "do_traverse"
        ],
        "added_lines": 3,
        "deleted_lines": 1,
        "total_changed_lines": 4,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "737904622116cb9b01aa18a0b98e55be16c92a0c",
        "author": "Jeff King",
        "date": "2024-11-07T13:28:22+09:00",
        "message": "describe: stop digging for max_candidates+1\n\nBy default, describe considers only 10 candidate matches, and stops\ntraversing when we have enough. This makes things much faster in a large\nrepository, where collecting all candidates requires walking all the way\ndown to the root (or at least to the oldest tag). This goes all the way\nback to 8713ab3079 (Improve git-describe performance by reducing\nrevision listing., 2007-01-13).\n\nHowever, we don't stop immediately when we have enough candidates. We\nkeep traversing and only bail when we find one more candidate that we're\nignoring. Usually this is not too expensive, if the tags are sprinkled\nevenly throughout history. But if you are unlucky, you might hit the max\ncandidate quickly, and then have a huge swath of history before finding\nthe next one.\n\nOur p6100 test has exactly this unlucky case: with a max of \"1\", we find\na recent tag quickly and then have to go all the way to the root to find\nthe old tag that will be discarded.\n\nA more interesting real-world case is:\n\n  git describe --candidates=1 --match=v6.12-rc4 HEAD\n\nin the linux.git repo. There we restrict the set of tags to a single\none, so there is no older candidate to find at all! But despite\n--candidates=1, we keep traversing to the root only to find nothing.\n\nSo why do we keep traversing after hitting thet max? There are two\nreasons I can see:\n\n  1. In theory the extra information that there was another candidate\n     could be useful, and we record it in the gave_up_on variable. But\n     we only show this information with --debug.\n\n  2. After finding the candidate, there's more processing we do in our\n     loop. The most important of this is propagating the \"within\" flags\n     to our parent commits, and putting them in the commit_list we'll\n     use for finish_depth_computation().\n\n     That function continues the traversal until we've counted all\n     commits reachable from the starting point but not reachable from\n     our best candidate tag (so essentially counting \"$tag..$start\", but\n     avoiding re-walking over the bits we've seen).  If we break\n     immediately without putting those commits into the list, our depth\n     computation will be wrong (in the worst case we'll count all the\n     way down to the root, not realizing those commits are included in\n     our tag).\n\nBut we don't need to find a new candidate for (2). As soon as we finish\nthe loop iteration where we hit max_candidates, we can then quit on the\nnext iteration. This should produce the same output as the original code\n(which could, after all, find a candidate on the very next commit\nanyway) but ends the traversal with less pointless digging.\n\nWe still have to set \"gave_up_on\"; we've popped it off the list and it\nhas to go back. An alternative would be to re-order the loop so that it\nnever gets popped, but it's perhaps still useful to show in the --debug\noutput, so we need to know it anyway. We do have to adjust the --debug\noutput since it's now just a commit where we stopped traversing, and not\nthe max+1th candidate.\n\np6100 shows the speedup using linux.git:\n\n  Test                                           HEAD^             HEAD\n  ---------------------------------------------------------------------------------------\n  6100.2: describe HEAD                          0.70(0.63+0.06)   0.71(0.66+0.04) +1.4%\n  6100.3: describe HEAD with one max candidate   0.70(0.64+0.05)   0.01(0.00+0.00) -98.6%\n  6100.4: describe HEAD with one tag             0.70(0.67+0.03)   0.70(0.63+0.06) +0.0%\n\nReported-by: Josh Poimboeuf <jpoimboe@kernel.org>\nHelped-by: Rasmus Villemoes <ravi@prevas.dk>\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/describe.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/737904622116cb9b01aa18a0b98e55be16c92a0c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "describe_commit"
        ],
        "added_lines": 8,
        "deleted_lines": 7,
        "total_changed_lines": 15,
        "net_line_change": 1,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "75c660ac9373b588a7815fa922dac02b2e4519d4",
        "author": "Junio C Hamano",
        "date": "2005-06-28T17:13:32-07:00",
        "message": "[PATCH] Use enhanced diff_delta() in the similarity estimator.\n\nThe diff_delta() interface was extended to reject generating too big a\ndelta while we were working on the packed GIT archive format.\n\nTake advantage of that when generating delta in the similarity estimator\nused in diffcore-rename.c\n\nSigned-off-by: Junio C Hamano <junkio@cox.net>\nSigned-off-by: Linus Torvalds <torvalds@osdl.org>",
        "modified_files_count": 1,
        "modified_files": [
            "diffcore-rename.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/75c660ac9373b588a7815fa922dac02b2e4519d4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "estimate_similarity"
        ],
        "added_lines": 6,
        "deleted_lines": 1,
        "total_changed_lines": 7,
        "net_line_change": 5,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "76e7c8a7ed58250bb74cf55618a81baed1797eca",
        "author": "Theodore Leblond",
        "date": "2014-04-29T09:55:38-07:00",
        "message": "compat/poll: sleep 1 millisecond to avoid busy wait\n\nSwitchToThread() only gives away the rest of the current time slice\nto another thread in the current process. So if the thread that feeds\nthe file decscriptor we're polling is not in the current process, we\nget busy-waiting.\n\nI played around with this quite a bit. After trying some more complex\nschemes, I found that what worked best is to just sleep 1 millisecond\nbetween iterations. Though it's a very short time, it still completely\neliminates the busy wait condition, without hurting perf.\n\nThere code uses SleepEx(1, TRUE) to sleep. See this page for a good\ndiscussion of why that is better than calling SwitchToThread, which\nis what was used previously:\nhttp://stackoverflow.com/questions/1383943/switchtothread-vs-sleep1\n\nNote that calling SleepEx(0, TRUE) does *not* solve the busy wait.\n\nThe most striking case was when testing on a UNC share with a large repo,\non a single CPU machine. Without the fix, it took 4 minutes 15 seconds,\nand with the fix it took just 1:08! I think it's because git-upload-pack's\nbusy wait was eating the CPU away from the git process that's doing the\nreal work. With multi-proc, the timing is not much different, but tons of\nCPU time is still wasted, which can be a killer on a server that needs to\ndo bunch of other things.\n\nI also tested the very fast local case, and didn't see any measurable\ndifference. On a big repo with 4500 files, the upload-pack took about 2\nseconds with and without the fix.\n\n[jc: this was first accepted in msysgit tree in May 2012 via a pull\nrequest and Paolo Bonzini has also accepted the same fix to Gnulib\naround the same time; see $gmane/247518 for a bit more detail]\n\nSigned-off-by: Stepan Kasal <kasal@ucw.cz>\nAcked-by: Johannes Sixt <j6t@kdbg.org>\nAcked-by: Erik Faye-Lund <kusmabite@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "compat/poll/poll.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/76e7c8a7ed58250bb74cf55618a81baed1797eca",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "poll"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "787d2a784b1d5d9c59c0098533ce9fdb757942d9",
        "author": "Shawn O. Pearce",
        "date": "2011-02-06T22:50:26-08:00",
        "message": "bundle: Use OFS_DELTA in bundle files\n\ngit-bundle first appeared in 2e0afafe (\"Add git-bundle\") in Feb 2007,\nand first shipped in Git 1.5.1.\n\nHowever, OFS_DELTA is an even earlier invention, coming about in\neb32d236 (\"introduce delta objects with offset to base\") in Sep 2006,\nand first shipped in Git 1.4.4.5.\n\nOFS_DELTA is smaller, about 3.2%-5% smaller, and is typically faster\nto access than REF_DELTA because the exact location of the delta base\nis available after parsing the object header.  Since all bundle aware\nversions of Git are also OFS_DELTA aware, just make it the default.\n\nSigned-off-by: Shawn O. Pearce <spearce@spearce.org>\nAcked-by: Nicolas Pitre <nico@fluxnic.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "bundle.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/787d2a784b1d5d9c59c0098533ce9fdb757942d9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "create_bundle"
        ],
        "added_lines": 3,
        "deleted_lines": 2,
        "total_changed_lines": 5,
        "net_line_change": 1,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "79c887d29d8cd780ab19b844b031884840f25a02",
        "author": "Junio C Hamano",
        "date": "2021-10-12T13:51:45-07:00",
        "message": "Merge branch 'ab/reverse-midx-optim' into maint\n\nThe code that optionally creates the *.rev reverse index file has\nbeen optimized to avoid needless computation when it is not writing\nthe file out.\n\n* ab/reverse-midx-optim:\n  pack-write: skip *.rev work when not writing *.rev",
        "modified_files_count": 1,
        "modified_files": [
            "pack-write.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/79c887d29d8cd780ab19b844b031884840f25a02",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "write_rev_file"
        ],
        "added_lines": 3,
        "deleted_lines": 0,
        "total_changed_lines": 3,
        "net_line_change": 3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "7a4252c4df49fe07bf91dbb5be2c6012f6a65329",
        "author": "Phillip Wood",
        "date": "2019-01-10T10:38:19-08:00",
        "message": "diff --color-moved-ws: optimize allow-indentation-change\n\nWhen running\n\n  git diff --color-moved-ws=allow-indentation-change v2.18.0 v2.19.0\n\ncmp_in_block_with_wsd() is called 694908327 times. Of those 42.7%\nreturn after comparing a and b. By comparing the lengths first we can\nreturn early in all but 0.03% of those cases without dereferencing the\nstring pointers. The comparison between a and c fails in 6.8% of\ncalls, by comparing the lengths first we reject all the failing calls\nwithout dereferencing the string pointers.\n\nThis reduces the time to run the command above by by 42% from 14.6s to\n8.5s. This is still much slower than the normal --color-moved which\ntakes ~0.6-0.7s to run but is a significant improvement.\n\nThe next commits will replace the current implementation with one that\nworks with mixed tabs and spaces in the indentation. I think it is\nworth optimizing the current implementation first to enable a fair\ncomparison between the two implementations.\n\nSigned-off-by: Phillip Wood <phillip.wood@dunelm.org.uk>\nReviewed-by: Stefan Beller <sbeller@google.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "diff.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/7a4252c4df49fe07bf91dbb5be2c6012f6a65329",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmp_in_block_with_wsd"
        ],
        "added_lines": 11,
        "deleted_lines": 8,
        "total_changed_lines": 19,
        "net_line_change": 3,
        "modified_code_blocks": 5,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "7ce7ee2d8228a97f023c7e34488ed83a557d83fb",
        "author": "Johannes Schindelin",
        "date": "2016-04-22T15:01:15-07:00",
        "message": "mmap(win32): avoid copy-on-write when it is unnecessary\n\nOften we are mmap()ing read-only. In those cases, it is wasteful to map in\ncopy-on-write mode. Even worse: it can cause errors where we run out of\nspace in the page file.\n\nSo let's be extra careful to map files in read-only mode whenever\npossible.\n\nSigned-off-by: Johannes Schindelin <johannes.schindelin@gmx.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "compat/win32mmap.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/7ce7ee2d8228a97f023c7e34488ed83a557d83fb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "git_mmap"
        ],
        "added_lines": 3,
        "deleted_lines": 2,
        "total_changed_lines": 5,
        "net_line_change": 1,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "7d23ff818f156da48882bec9ac84fb4e33dd619a",
        "author": "Ren\u00e9 Scharfe",
        "date": "2020-08-02T13:02:52-07:00",
        "message": "bisect: use oid_to_hex_r() instead of memcpy()+oid_to_hex()\n\nWrite the hexadecimal object ID directly into the destination buffer\nusing oid_to_hex_r() instead of writing it into a static buffer first\nusing oid_to_hex() and then copying it from there using memcpy().\nThis is shorter, simpler and a bit more efficient.\n\nReviewed-by: brian m. carlson <sandals@crustytoothpaste.net>\nSigned-off-by: Ren\u00e9 Scharfe <l.s.r@web.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "bisect.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/7d23ff818f156da48882bec9ac84fb4e33dd619a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "bisect_checkout"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "7da41f48c8acea834e8204917fe59da2b975903b",
        "author": "Shawn O. Pearce",
        "date": "2006-12-14T02:40:33-08:00",
        "message": "Bypass expensive content comparsion during rename detection.\n\nWhen comparing file contents during the second loop through a rename\ndetection attempt we can skip the expensive byte-by-byte comparsion\nif both source and destination files have valid SHA1 values.  This\nimproves performance by avoiding either an expensive open/mmap to\nread the working tree copy, or an expensive inflate of a blob object.\n\nUnfortunately we still have to at least initialize the sizes of the\nsource and destination files even if the SHA1 values don't match.\nFailing to initialize the sizes causes a number of test cases to fail\nand start reporting different copy/rename behavior than was expected.\n\nSigned-off-by: Shawn O. Pearce <spearce@spearce.org>\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "diffcore-rename.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/7da41f48c8acea834e8204917fe59da2b975903b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "is_exact_match"
        ],
        "added_lines": 2,
        "deleted_lines": 0,
        "total_changed_lines": 2,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "7dc24aa5a62cc5f77e6637674581c837f4bdf78e",
        "author": "Shawn O. Pearce",
        "date": "2007-05-26T20:28:08-07:00",
        "message": "Micro-optimize prepare_alt_odb\n\nCalling getenv() is not that expensive, but its also not free,\nand its certainly not cheaper than testing to see if alt_odb_tail\nis not null.\n\nBecause we are calling prepare_alt_odb() from within find_sha1_file\nevery time we cannot find an object file locally we want to skip out\nof prepare_alt_odb() as early as possible once we have initialized\nour alternate list.\n\nSigned-off-by: Shawn O. Pearce <spearce@spearce.org>\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "sha1_file.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/7dc24aa5a62cc5f77e6637674581c837f4bdf78e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "prepare_alt_odb"
        ],
        "added_lines": 3,
        "deleted_lines": 2,
        "total_changed_lines": 5,
        "net_line_change": 1,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "809809bb75e8a65ef543ab706aab4791459be95c",
        "author": "Junio C Hamano",
        "date": "2009-11-20T22:13:47-08:00",
        "message": "diffcore-rename: reduce memory footprint by freeing blob data early\n\nAfter running one round of estimate_similarity(), filespecs on either\nside will have populated their cnt_data fields, and we do not need\nthe blob text anymore.  We used to retain the blob data to optimize\nfor smaller projects (not freeing the blob data here would mean that\nthe final output phase would not have to re-read it), but we are\nefficient enough without such optimization for smaller projects anyway,\nand freeing memory early will help larger projects.\n\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "diffcore-rename.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/809809bb75e8a65ef543ab706aab4791459be95c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "diffcore_rename"
        ],
        "added_lines": 5,
        "deleted_lines": 2,
        "total_changed_lines": 7,
        "net_line_change": 3,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "82912d1de86ae3d7f247bc3b16a81afd01aa31c7",
        "author": "Jeff King",
        "date": "2015-04-16T08:15:04-07:00",
        "message": "strbuf_getwholeline: use getc_unlocked\n\nstrbuf_getwholeline calls getc in a tight loop. On modern\nlibc implementations, the stdio code locks the handle for\nevery operation, which means we are paying a significant\noverhead.  We can get around this by locking the handle for\nthe whole loop and using the unlocked variant.\n\nRunning \"git rev-parse refs/heads/does-not-exist\" on a repo\nwith an extremely large (1.6GB) packed-refs file went from:\n\n  real    0m18.900s\n  user    0m18.472s\n  sys     0m0.448s\n\nto:\n\n  real    0m10.953s\n  user    0m10.384s\n  sys     0m0.580s\n\nfor a wall-clock speedup of 42%. All times are best-of-3,\nand done on a glibc 2.19 system.\n\nNote that we call into strbuf_grow while holding the lock.\nIt's possible for that function to call other stdio\nfunctions (e.g., printing to stderr when dying due to malloc\nerror); however, the POSIX.1-2001 definition of flockfile\nmakes it clear that the locks are per-handle, so we are fine\nunless somebody else tries to read from our same handle.\nThis doesn't ever happen in the current code, and is\nunlikely to be added in the future (we would have to do\nsomething exotic like add a die_routine that tried to read\nfrom stdin).\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "strbuf.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/82912d1de86ae3d7f247bc3b16a81afd01aa31c7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "strbuf_getwholeline"
        ],
        "added_lines": 3,
        "deleted_lines": 1,
        "total_changed_lines": 4,
        "net_line_change": 2,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "832cf74c0792a58c9c28e32a8fe5dbb694f0cce6",
        "author": "Brodie Rao",
        "date": "2014-01-07T09:51:56-08:00",
        "message": "sha1_name: don't resolve refs when core.warnambiguousrefs is false\n\nWhen seeing a full 40-hex object name, get_sha1_basic()\nunconditionally checks if the string can also be interpreted as a\nrefname, but the result will not be used unless warn_ambiguous_refs\nis in effect.\n\nOmitting this unnecessary ref resolution provides a substantial\nperformance improvement, especially when passing many hashes to a\ncommand (like \"git rev-list --stdin\") and core.warnambiguousrefs is\nset to false.  The check incurs 6 stat()s for every hash supplied,\nwhich can be costly over NFS.\n\nSigned-off-by: Brodie Rao <brodie@sf.io>\nAcked-by: Nguy\u1ec5n Th\u00e1i Ng\u1ecdc Duy <pclouds@gmail.com>\nAcked-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "sha1_name.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/832cf74c0792a58c9c28e32a8fe5dbb694f0cce6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_sha1_basic"
        ],
        "added_lines": 2,
        "deleted_lines": 2,
        "total_changed_lines": 4,
        "net_line_change": 0,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "848afebe5604877354bea42d81df380cff03b948",
        "author": "Ren\u00e9 Scharfe",
        "date": "2022-07-17T15:20:38-07:00",
        "message": "mergesort: tighten merge loop\n\nllist_merge() has special inner loops for taking elements from either of\nthe two lists to merge.  That helps consistently preferring one over the\nother, for stability.  Merge the loops, swap the lists when the other\none has the next element for the result and keep track on which one to\nprefer on equality.  This results in shorter code and object text:\n\nBefore:\n__TEXT\t__DATA\t__OBJC\tothers\tdec\thex\n412\t0\t0\t3441\t3853\tf0d\tmergesort.o\n\nWith this patch:\n__TEXT\t__DATA\t__OBJC\tothers\tdec\thex\n352\t0\t0\t3516\t3868\tf1c\tmergesort.o\n\nPerformance doesn't get worse:\n\nBefore:\n0071.12: llist_mergesort() unsorted    0.24(0.22+0.01)\n0071.14: llist_mergesort() sorted      0.12(0.10+0.01)\n0071.16: llist_mergesort() reversed    0.12(0.10+0.01)\n\nBenchmark 1: t/helper/test-tool mergesort test\n  Time (mean \u00b1 \u03c3):     109.2 ms \u00b1   0.2 ms    [User: 107.5 ms, System: 1.1 ms]\n  Range (min \u2026 max):   108.9 ms \u2026 109.6 ms    27 runs\n\nWith this patch:\n0071.12: llist_mergesort() unsorted    0.24(0.22+0.01)\n0071.14: llist_mergesort() sorted      0.12(0.10+0.01)\n0071.16: llist_mergesort() reversed    0.12(0.10+0.01)\n\nBenchmark 1: t/helper/test-tool mergesort test\n  Time (mean \u00b1 \u03c3):     108.4 ms \u00b1   0.2 ms    [User: 106.7 ms, System: 1.2 ms]\n  Range (min \u2026 max):   108.0 ms \u2026 108.8 ms    27 runs\n\nSigned-off-by: Ren\u00e9 Scharfe <l.s.r@web.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "mergesort.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/848afebe5604877354bea42d81df380cff03b948",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "void"
        ],
        "added_lines": 6,
        "deleted_lines": 13,
        "total_changed_lines": 19,
        "net_line_change": -7,
        "modified_code_blocks": 5,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "86ef236c989285954384cccfd9cea847f034143c",
        "author": "Junio C Hamano",
        "date": "2018-08-27T14:33:50-07:00",
        "message": "Merge branch 'jk/hashcmp-optim-for-2.19'\n\nPartially revert the support for multiple hash functions to regain\nhash comparison performance; we'd think of a way to do this better\nin the next cycle.\n\n* jk/hashcmp-optim-for-2.19:\n  hashcmp: assert constant hash size",
        "modified_files_count": 1,
        "modified_files": [
            "cache.h"
        ],
        "github_commit_url": "https://github.com/git/git/commit/86ef236c989285954384cccfd9cea847f034143c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "hashcmp"
        ],
        "added_lines": 10,
        "deleted_lines": 0,
        "total_changed_lines": 10,
        "net_line_change": 10,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "870eb53ab20e9ff453e3b89b4927c154c2b7211a",
        "author": "Jeff King",
        "date": "2023-07-17T14:16:05-07:00",
        "message": "ref-filter: avoid parsing non-tags in match_points_at()\n\nWhen handling --points-at, we have to try to peel each ref to see if\nit's a tag that points at a requested oid. We start this process by\ncalling parse_object() on the oid pointed to by each ref.\n\nThe cost of parsing each object adds up, especially in an output that\ndoesn't otherwise need to open the objects at all. Ideally we'd use\npeel_iterated_oid() here, which uses the cached information in the\npacked-refs file. But we can't, because our --points-at must match not\nonly the fully peeled value, but any interim values (so if tag A points\nto tag B which points to commit C, we should match --points-at=B, but\npeel_iterated_oid() will only tell us about C).\n\nSo the best we can do (absent changes to the packed-refs peel traits) is\nto avoid parsing non-tags. The obvious way to do that is to call\noid_object_info() to check the type before parsing. But there are a few\ngotchas there, like checking if the object has already been parsed.\n\nInstead we can just tell parse_object() that we are OK skipping the hash\ncheck, which lets it turn on several optimizations. Commits can be\nloaded via the commit graph (so it's both fast and we have the benefit\nof the parsed data if we need it later at the output stage). Blobs are\nnot loaded at all. Trees are still loaded, but it's rather rare to have\na ref point directly to a tree (and since this is just an optimization,\nkicking in 99% of the time is OK).\n\nEven though we're paying for an extra lookup, the cost to avoid parsing\nthe non-tags is a net benefit. In my git.git repository with 941 tags\nand 1440 other refs pointing to commits, this significantly cuts the\nruntime:\n\n  Benchmark 1: ./git.old for-each-ref --points-at=HEAD\n    Time (mean \u00b1 \u03c3):      26.8 ms \u00b1   0.5 ms    [User: 24.5 ms, System: 2.2 ms]\n    Range (min \u2026 max):    25.9 ms \u2026  29.2 ms    107 runs\n\n  Benchmark 2: ./git.new for-each-ref --points-at=HEAD\n    Time (mean \u00b1 \u03c3):       9.1 ms \u00b1   0.3 ms    [User: 6.8 ms, System: 2.2 ms]\n    Range (min \u2026 max):     8.6 ms \u2026  10.2 ms    308 runs\n\n  Summary\n    './git.new for-each-ref --points-at=HEAD' ran\n      2.96 \u00b1 0.10 times faster than './git.old for-each-ref --points-at=HEAD'\n\nIn a repository that is mostly annotated tags, we'd expect less\nimprovement (we might still skip a few object loads, but that's balanced\nby the extra lookups). In my clone of linux.git, which has 782 tags and\n3 branches, the run-time is about the same (it's actually ~1% faster on\naverage after this patch, but that's within the run-to-run noise).\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "ref-filter.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/870eb53ab20e9ff453e3b89b4927c154c2b7211a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "match_points_at"
        ],
        "added_lines": 2,
        "deleted_lines": 1,
        "total_changed_lines": 3,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "8777616e4db2868609bc42a4c66cc69d23532dbc",
        "author": "Andrew Ng",
        "date": "2020-05-19T15:35:46-07:00",
        "message": "merge: optimization to skip evaluate_result for single strategy\n\nFor a merge with a single strategy, the result of evaluate_result() is\neffectively not used and therefore is not needed, so avoid altogether.\n\nOn Windows, this optimization can halve the time required to perform a\nrecursive merge of a single commit with the LLVM repo.\n\nSigned-off-by: Andrew Ng <andrew.ng@sony.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/merge.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/8777616e4db2868609bc42a4c66cc69d23532dbc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_merge"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "87b5e236a14d4783b063041588c2f77f3cc6ee89",
        "author": "Jeff King",
        "date": "2017-11-22T10:50:11+09:00",
        "message": "sha1_file: fast-path null sha1 as a missing object\n\nIn theory nobody should ever ask the low-level object code\nfor a null sha1. It's used as a sentinel for \"no such\nobject\" in lots of places, so leaking through to this level\nis a sign that the higher-level code is not being careful\nabout its error-checking.  In practice, though, quite a few\ncode paths seem to rely on the null sha1 lookup failing as a\nway to quietly propagate non-existence (e.g., by feeding it\nto lookup_commit_reference_gently(), which then returns\nNULL).\n\nWhen this happens, we do two inefficient things:\n\n  1. We actually search for the null sha1 in packs and in\n     the loose object directory.\n\n  2. When we fail to find it, we re-scan the pack directory\n     in case a simultaneous repack happened to move it from\n     loose to packed. This can be very expensive if you have\n     a large number of packs.\n\nOnly the second one actually causes noticeable performance\nproblems, so we could treat them independently. But for the\nsake of simplicity (both of code and of reasoning about it),\nit makes sense to just declare that the null sha1 cannot be\na real on-disk object, and looking it up will always return\n\"no such object\".\n\nThere's no real loss of functionality to do so Its use as a\nsentinel value means that anybody who is unlucky enough to\nhit the 2^-160th chance of generating an object with that\nsha1 is already going to find the object largely unusable.\n\nIn an ideal world, we'd simply fix all of the callers to\nnotice the null sha1 and avoid passing it to us. But a\nsimple experiment to catch this with a BUG() shows that\nthere are a large number of code paths that do so.\n\nSo in the meantime, let's fix the performance problem by\ntaking a fast exit from the object lookup when we see a null\nsha1. p5551 shows off the improvement (when a fetched ref is\nnew, the \"old\" sha1 is 0{40}, which ends up being passed for\nfast-forward checks, the status table abbreviations, etc):\n\n  Test            HEAD^             HEAD\n  --------------------------------------------------------\n  5551.4: fetch   5.51(5.03+0.48)   0.17(0.10+0.06) -96.9%\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "sha1_file.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/87b5e236a14d4783b063041588c2f77f3cc6ee89",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sha1_object_info_extended"
        ],
        "added_lines": 3,
        "deleted_lines": 0,
        "total_changed_lines": 3,
        "net_line_change": 3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "88473c8baeefafe6b95ab0f62eb2f12e2b098ac7",
        "author": "Jeff King",
        "date": "2021-06-28T20:31:40-07:00",
        "message": "load_ref_decorations(): avoid parsing non-tag objects\n\nWhen we load the ref decorations, we parse the object pointed to by each\nref in order to get a \"struct object\". This is unnecessarily expensive;\nwe really only need the object struct, and don't even look at the parsed\ncontents. The exception is tags, which we do need to peel.\n\nWe can improve this by looking up the object type first (which is much\ncheaper), and skipping the parse entirely for non-tags. This increases\nthe work slightly for annotated tags (which now do a type lookup _and_ a\nparse), but decreases it a lot for other types. On balance, this seems\nto be a good tradeoff.\n\nIn my git.git clone, with ~2k refs, most of which are branches, the time\nto run \"git log -1 --decorate\" drops from 34ms to 11ms. Even on my\nlinux.git clone, which contains mostly tags and only a handful of\nbranches, the time drops from 30ms to 19ms. And on a more extreme\nreal-world case with ~220k refs, mostly non-tags, the time drops from\n2.6s to 650ms.\n\nThat command is a lop-sided example, of course, because it does as\nlittle non-loading work as possible. But it does show the absolute time\nimprovement. Even in something like a full \"git log --decorate\" on that\nextreme repo, we'd still be saving 2s of CPU time.\n\nIdeally we could push this even further, and avoid parsing even tags, by\nrelying on the packed-refs \"peel\" optimization (which we could do by\ncalling peel_iterated_oid() instead of peeling manually). But we can't\ndo that here. The packed-refs file only stores the bottom-layer of the\npeel (so in a \"tag->tag->commit\" chain, it stores only the commit as the\npeel result).  But the decoration code wants to peel the layers\nindividually, annotating the middle layers of the chain.\n\nIf the packed-refs file ever learns to store all of the peeled layers,\nthen we could switch to it. Or even if it stored a flag to indicate the\npeel was not multi-layer (because most of them aren't), then we could\nuse it most of the time and fall back to a manual peel for the rare\ncases.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "log-tree.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/88473c8baeefafe6b95ab0f62eb2f12e2b098ac7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "add_ref_decoration"
        ],
        "added_lines": 4,
        "deleted_lines": 2,
        "total_changed_lines": 6,
        "net_line_change": 2,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "8dbbd14ea3ae1b4e825f1e7d314afddf26c67298",
        "author": "Nicolas Pitre",
        "date": "2006-06-29T23:48:29-07:00",
        "message": "consider previous pack undeltified object state only when reusing delta data\n\nWithout this there would never be a chance to improve packing for\npreviously undeltified objects.\n\nSigned-off-by: Nicolas Pitre <nico@cam.org>\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "pack-objects.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/8dbbd14ea3ae1b4e825f1e7d314afddf26c67298",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "try_delta"
        ],
        "added_lines": 3,
        "deleted_lines": 2,
        "total_changed_lines": 5,
        "net_line_change": 1,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "8f0246551c3964eeb16d9c9f39845bd53af8bda8",
        "author": "Alex Riesen",
        "date": "2009-03-20T09:35:32-07:00",
        "message": "Microoptimize strbuf_cmp\n\nIt can be less object code and may be even faster, even if at the\nmoment there is no callers to take an advantage of that. This\nimplementation can be trivially made inlinable later.\n\nSigned-off-by: Alex Riesen <raa.lkml@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "strbuf.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/8f0246551c3964eeb16d9c9f39845bd53af8bda8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "strbuf_cmp"
        ],
        "added_lines": 5,
        "deleted_lines": 8,
        "total_changed_lines": 13,
        "net_line_change": -3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "8fe8bae9d28e2b02ceb482ab89ea88bb20556f1d",
        "author": "\u00c6var Arnfj\u00f6r\u00f0 Bjarmason",
        "date": "2021-09-07T22:04:03-07:00",
        "message": "pack-write: skip *.rev work when not writing *.rev\n\nFix a performance regression introduced in a587b5a786 (pack-write.c:\nextract 'write_rev_file_order', 2021-03-30) and stop needlessly\nallocating the \"pack_order\" array and sorting it with\n\"pack_order_cmp()\", only to throw that work away when we discover that\nwe're not writing *.rev files after all.\n\nThis redundant work was not present in the original version of this\ncode added in 8ef50d9958 (pack-write.c: prepare to write 'pack-*.rev'\nfiles, 2021-01-25). There we'd call write_rev_file() from\ne.g. finish_tmp_packfile(), but we'd \"return NULL\" early in\nwrite_rev_file() if not doing a \"WRITE_REV\" or \"WRITE_REV_VERIFY\".\n\nSigned-off-by: \u00c6var Arnfj\u00f6r\u00f0 Bjarmason <avarab@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "pack-write.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/8fe8bae9d28e2b02ceb482ab89ea88bb20556f1d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "write_rev_file"
        ],
        "added_lines": 3,
        "deleted_lines": 0,
        "total_changed_lines": 3,
        "net_line_change": 3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "9181ca2c2b1f2897baa67ff8e48b1984822115b5",
        "author": "Junio C Hamano",
        "date": "2006-03-28T17:29:09-08:00",
        "message": "rev-list: memory usage reduction.\n\nWe do not need to track object refs, neither we need to save commit\nunless we are doing verbose header.  A lot of traversal happens\ninside prepare_revision_walk() these days so setting things up before\ncalling that function is necessary.\n\nSigned-off-by: Junio C Hamano <junkio@cox.net>\nAcked-by: Linus Torvalds <torvalds@osdl.org>",
        "modified_files_count": 1,
        "modified_files": [
            "rev-list.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/9181ca2c2b1f2897baa67ff8e48b1984822115b5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "added_lines": 3,
        "deleted_lines": 3,
        "total_changed_lines": 6,
        "net_line_change": 0,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "9235a6ce47f012cd8fcfa80117fed29790bb929b",
        "author": "Junio C Hamano",
        "date": "2018-11-13T22:37:27+09:00",
        "message": "Merge branch 'bp/add-diff-files-optim'\n\n\"git add\" needs to internally run \"diff-files\" equivalent, and the\ncodepath learned the same optimization as \"diff-files\" has to run\nlstat(2) in parallel to find which paths have been updated in the\nworking tree.\n\n* bp/add-diff-files-optim:\n  add: speed up cmd_add() by utilizing read_cache_preload()",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/add.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/9235a6ce47f012cd8fcfa80117fed29790bb929b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_add"
        ],
        "added_lines": 4,
        "deleted_lines": 5,
        "total_changed_lines": 9,
        "net_line_change": -1,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "926f1dd95486b596de1f6b8e108053a870da0e18",
        "author": "Jeff King",
        "date": "2012-01-06T13:28:55-08:00",
        "message": "upload-pack: avoid parsing objects during ref advertisement\n\nWhen we advertise a ref, the first thing we do is parse the\npointed-to object. This gives us two things:\n\n  1. a \"struct object\" we can use to store flags\n\n  2. the type of the object, so we know whether we need to\n     dereference it as a tag\n\nInstead, we can just use lookup_unknown_object to get an\nobject struct, and then fill in just the type field using\nsha1_object_info (which, in the case of packed files, can\nfind the information without actually inflating the object\ndata).\n\nThis can save time if you have a large number of refs, and\nthe client isn't actually going to request those refs (e.g.,\nbecause most of them are already up-to-date).\n\nThe downside is that we are no longer verifying objects that\nwe advertise by fully parsing them (however, we do still\nknow we actually have them, because sha1_object_info must\nfind them to get the type). While we might fail to detect a\ncorrupt object here, if the client actually fetches the\nobject, we will parse (and verify) it then.\n\nOn a repository with 120K refs, the advertisement portion of\nupload-pack goes from ~3.4s to 3.2s (the failure to speed up\nmore is largely due to the fact that most of these refs are\ntags, which need dereferenced to find the tag destination\nanyway).\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "upload-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/926f1dd95486b596de1f6b8e108053a870da0e18",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "send_ref"
        ],
        "added_lines": 7,
        "deleted_lines": 3,
        "total_changed_lines": 10,
        "net_line_change": 4,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "92fa3253c8423815e84be91a2d9a3509df20a646",
        "author": "Patrick Steinhardt",
        "date": "2024-02-12T09:18:04-08:00",
        "message": "reftable/block: swap buffers instead of copying\n\nWhen iterating towards the next record in a reftable block we need to\nkeep track of the key that the last record had. This is required because\nreftable records use prefix compression, where subsequent records may\nreuse parts of their preceding record's key.\n\nThis key is stored in the `block_iter::last_key`, which we update after\nevery call to `block_iter_next()`: we simply reset the buffer and then\nadd the current key to it.\n\nThis is a bit inefficient though because it requires us to copy over the\nkey on every iteration, which adds up when iterating over many records.\nInstead, we can make use of the fact that the `block_iter::key` buffer\nis basically only a scratch buffer. So instead of copying over contents,\nwe can just swap both buffers.\n\nThe following benchmark prints a single ref matching a specific pattern\nout of 1 million refs via git-show-ref(1):\n\n  Benchmark 1: show-ref: single matching ref (revision = HEAD~)\n    Time (mean \u00b1 \u03c3):     155.7 ms \u00b1   5.0 ms    [User: 152.1 ms, System: 3.4 ms]\n    Range (min \u2026 max):   150.8 ms \u2026 185.7 ms    1000 runs\n\n  Benchmark 2: show-ref: single matching ref (revision = HEAD)\n    Time (mean \u00b1 \u03c3):     150.8 ms \u00b1   4.2 ms    [User: 147.1 ms, System: 3.5 ms]\n    Range (min \u2026 max):   145.1 ms \u2026 180.7 ms    1000 runs\n\n  Summary\n    show-ref: single matching ref (revision = HEAD) ran\n      1.03 \u00b1 0.04 times faster than show-ref: single matching ref (revision = HEAD~)\n\nSigned-off-by: Patrick Steinhardt <ps@pks.im>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "reftable/block.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/92fa3253c8423815e84be91a2d9a3509df20a646",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "block_iter_next"
        ],
        "added_lines": 1,
        "deleted_lines": 2,
        "total_changed_lines": 3,
        "net_line_change": -1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "96f6d3f61ad02ef2fd0393765207233845a7c7e0",
        "author": "Ren\u00e9 Scharfe",
        "date": "2017-02-13T12:06:10-08:00",
        "message": "ls-files: move only kept cache entries in prune_cache()\n\nprune_cache() first identifies those entries at the start of the sorted\narray that can be discarded.  Then it moves the rest of the entries up.\nLast it identifies the unwanted trailing entries among the moved ones\nand cuts them off.\n\nChange the order: Identify both start *and* end of the range to keep\nfirst and then move only those entries to the top.  The resulting code\nis slightly shorter and a bit more efficient.\n\nSigned-off-by: Rene Scharfe <l.s.r@web.de>\nReviewed-by: Brandon Williams <bmwill@google.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/ls-files.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/96f6d3f61ad02ef2fd0393765207233845a7c7e0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "prune_cache"
        ],
        "added_lines": 4,
        "deleted_lines": 5,
        "total_changed_lines": 9,
        "net_line_change": -1,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "98456eff08069696708b24ab4f1152f06a3b47f9",
        "author": "Taylor Blau",
        "date": "2023-07-10T14:48:56-07:00",
        "message": "ls-refs.c: avoid enumerating hidden refs where possible\n\nIn a similar fashion as in previous commits, teach `ls-refs` to avoid\nenumerating hidden references where possible.\n\nAs before, this is linux.git with one hidden reference per commit.\n\n    $ hyperfine -L v ,.compile 'git{v} -c protocol.version=2 ls-remote .'\n    Benchmark 1: git -c protocol.version=2 ls-remote .\n      Time (mean \u00b1 \u03c3):      89.8 ms \u00b1   0.6 ms    [User: 84.3 ms, System: 5.7 ms]\n      Range (min \u2026 max):    88.8 ms \u2026  91.3 ms    32 runs\n\n    Benchmark 2: git.compile -c protocol.version=2 ls-remote .\n      Time (mean \u00b1 \u03c3):       6.5 ms \u00b1   0.1 ms    [User: 2.4 ms, System: 4.3 ms]\n      Range (min \u2026 max):     6.2 ms \u2026   8.3 ms    397 runs\n\n    Summary\n      'git.compile -c protocol.version=2 ls-remote .' ran\n       13.85 \u00b1 0.33 times faster than 'git -c protocol.version=2 ls-remote .'\n\nSigned-off-by: Taylor Blau <me@ttaylorr.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "ls-refs.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/98456eff08069696708b24ab4f1152f06a3b47f9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ls_refs"
        ],
        "added_lines": 2,
        "deleted_lines": 1,
        "total_changed_lines": 3,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "98c6871fad0be42fbe045de2338d0a5bdbc5af1d",
        "author": "Ren\u00e9 Scharfe",
        "date": "2020-07-28T15:26:12-07:00",
        "message": "grep: avoid using oid_to_hex() with parse_object_or_die()\n\nparse_object_or_die() is passed an object ID and a name to show if the\nobject cannot be parsed.  If the name is NULL then it shows the\nhexadecimal object ID.  Use that feature instead of preparing and\npassing the hexadecimal representation to the function proactively.\nThat's shorter and a bit more efficient.\n\nSigned-off-by: Ren\u00e9 Scharfe <l.s.r@web.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/grep.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/98c6871fad0be42fbe045de2338d0a5bdbc5af1d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "grep_submodule"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "99a6a97b1bf866d7050e8afb137b4b29507f0caa",
        "author": "Johannes Schindelin",
        "date": "2008-01-02T02:28:54-08:00",
        "message": "Optimize prefixcmp()\n\nCertain codepaths (notably \"git log --pretty=format...\") use\nprefixcmp() extensively, with very short prefixes.  In those cases,\ncalling strlen() is a wasteful operation, so avoid it.\n\nInitial patch by Marco Costalba.\n\nSigned-off-by: Johannes Schindelin <johannes.schindelin@gmx.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "git-compat-util.h"
        ],
        "github_commit_url": "https://github.com/git/git/commit/99a6a97b1bf866d7050e8afb137b4b29507f0caa",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "prefixcmp"
        ],
        "added_lines": 5,
        "deleted_lines": 1,
        "total_changed_lines": 6,
        "net_line_change": 4,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "9a414486d9f0325c3663210471e4673ed0cd862c",
        "author": "Jeff King",
        "date": "2013-05-02T08:36:50-07:00",
        "message": "lookup_object: prioritize recently found objects\n\nThe lookup_object function is backed by a hash table of all\nobjects we have seen in the program. We manage collisions\nwith a linear walk over the colliding entries, checking each\nwith hashcmp(). The main cost of lookup is in these\nhashcmp() calls; finding our item in the first slot is\ncheaper than finding it in the second slot, which is cheaper\nthan the third, and so on.\n\nIf we assume that there is some locality to the object\nlookups (e.g., if X and Y collide, and we have just looked\nup X, the next lookup is more likely to be for X than for\nY), then we can improve our average lookup speed by checking\nX before Y.\n\nThis patch does so by swapping a found item to the front of\nthe collision chain. The p0001 perf test reveals that this\ndoes indeed exploit locality in the case of \"rev-list --all\n--objects\":\n\nTest                               origin          this tree\n-------------------------------------------------------------------------\n0001.1: rev-list --all             0.40(0.38+0.02) 0.40(0.36+0.03) +0.0%\n0001.2: rev-list --all --objects   2.24(2.17+0.05) 1.86(1.79+0.05) -17.0%\n\nThis is not surprising, as the full object traversal will\nhit the same tree entries over and over (e.g., for every\ncommit that doesn't change \"Documentation/\", we will have to\nlook up the same sha1 just to find out that we already\nprocessed it).\n\nThe reason why this technique works (and does not violate\nany properties of the hash table) is subtle and bears some\nexplanation. Let's imagine we get a lookup for sha1 `X`, and\nit hashes to bucket `i` in our table. That stretch of the\ntable may look like:\n\nindex       | i-1 |  i  | i+1 | i+2 |\n       -----------------------------------\nentry   ... |  A  |  B  |  C  |  X  | ...\n       -----------------------------------\n\nWe start our probe at i, see that B does not match, nor does\nC, and finally find X. There may be multiple C's in the\nmiddle, but we know that there are no empty slots (or else\nwe would not find X at all).\n\nWe do not know the original index of B; it may be `i`, or it\nmay be less than i (e.g., if it were `i-1`, it would collide\nwith A and spill over into the `i` bucket). So it is\nacceptable for us to move it to the right of a contiguous\nstretch of entries (because we will find it from a linear\nwalk starting anywhere at `i` or before), but never to the\nleft (if we moved it to `i-1`, we would miss it when\nstarting our walk at `i`).\n\nWe do know the original index of X; it is `i`, so it is safe\nto place it anywhere in the contiguous stretch between `i`\nand where we found it (`i+2` in the this case).\n\nThis patch does a pure swap; after finding X in the\nsituation above, we would end with:\n\nindex       | i-1 |  i  | i+1 | i+2 |\n       -----------------------------------\nentry   ... |  A  |  X  |  C  |  B  | ...\n       -----------------------------------\n\nWe could instead bump X into the `i` slot, and then shift\nthe whole contiguous chain down by one, resulting in:\n\nindex       | i-1 |  i  | i+1 | i+2 |\n       -----------------------------------\nentry   ... |  A  |  X  |  B  |  C  | ...\n       -----------------------------------\n\nThat puts our chain in true most-recently-used order.\nHowever, experiments show that it is not any faster (and in\nfact, is slightly slower due to the extra manipulation).\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "object.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/9a414486d9f0325c3663210471e4673ed0cd862c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "lookup_object"
        ],
        "added_lines": 12,
        "deleted_lines": 2,
        "total_changed_lines": 14,
        "net_line_change": 10,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "9d14ecf39dc70cd2d2cf639d873b8e2c7f039d11",
        "author": "Mike Hommey",
        "date": "2018-07-06T09:46:12-07:00",
        "message": "fast-import: do not call diff_delta() with empty buffer\n\nWe know diff_delta() returns NULL, saying \"no good delta exists for\nit\", when fed an empty data.  Check the length of the data in the\ncaller to avoid such a call.\n\nThis incidentally reduces the number of attempted deltification we\nsee in the final statistics.\n\nSigned-off-by: Mike Hommey <mh@glandium.org>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "fast-import.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/9d14ecf39dc70cd2d2cf639d873b8e2c7f039d11",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "store_object"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "9dad9d2e5b322835c87e1653268d892a95ee0f1f",
        "author": "Junio C Hamano",
        "date": "2006-10-30T18:58:03-08:00",
        "message": "revision traversal: --unpacked does not limit commit list anymore.\n\nThis is needed to gain smaller latency back.\n\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "revision.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/9dad9d2e5b322835c87e1653268d892a95ee0f1f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "setup_revisions"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "9e1313648d4c0ee1bab0ee3d7ed22553bd5bf87c",
        "author": "Ramkumar Ramachandra",
        "date": "2011-12-15T13:16:52-08:00",
        "message": "revert: simplify getting commit subject in format_todo()\n\nformat_todo() calls get_message(), but uses only the subject line of\nthe commit message.  As a minor optimization, save work and\nunnecessary memory allocations by using find_commit_subject() instead.\nAlso, remove the unnecessary check on cur->item->buffer: the\nlookup_commit_reference() call in parse_insn_line() has already made\nsure of this.\n\nSuggested-by: Jonathan Nieder <jrnieder@gmail.com>\nHelped-by: Junio C Hamano <gitster@pobox.com>\nSigned-off-by: Ramkumar Ramachandra <artagnon@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/revert.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/9e1313648d4c0ee1bab0ee3d7ed22553bd5bf87c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "format_todo"
        ],
        "added_lines": 5,
        "deleted_lines": 5,
        "total_changed_lines": 10,
        "net_line_change": 0,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "9e8e704f0bc14da325aa63f639c6dc782c81e26f",
        "author": "Jeff King",
        "date": "2012-05-22T13:31:03-07:00",
        "message": "fetch-pack: sort the list of incoming refs\n\nHaving the list sorted means we can avoid some quadratic\nalgorithms when comparing lists.\n\nThese should typically be sorted already, but they do come\nfrom the remote, so let's be extra careful. Our ref-sorting\nimplementation does a mergesort, so we do not have to care\nabout performance degrading in the common case that the list\nis already sorted.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/fetch-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/9e8e704f0bc14da325aa63f639c6dc782c81e26f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "do_fetch_pack"
        ],
        "added_lines": 2,
        "deleted_lines": 0,
        "total_changed_lines": 2,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "a1dab41af4c575bb72231c73df26ecb2af4814d6",
        "author": "Brian Downing",
        "date": "2007-07-12T14:32:34-07:00",
        "message": "Don't try to delta if target is much smaller than source\n\nAdd a new try_delta heuristic.  Don't bother trying to make a delta if\nthe target object size is much smaller (currently 1/32) than the source,\nas it's very likely not going to get a match.  Even if it does, you will\nhave to read at least 32x the size of the new file to reassemble it,\nwhich isn't such a good deal.  This leads to a considerable performance\nimprovement when deltifying a mix of small and large files with a very\nlarge window, because you don't have to wait for the large files to\npercolate out of the window before things start going fast again.\n\nSigned-off-by: Brian Downing <bdowning@lavos.net>\nAcked-by: Nicolas Pitre <nico@cam.org>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin-pack-objects.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/a1dab41af4c575bb72231c73df26ecb2af4814d6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "try_delta"
        ],
        "added_lines": 2,
        "deleted_lines": 0,
        "total_changed_lines": 2,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "a277d0a67f0324deb58abbeb0c5a2b3abbcde340",
        "author": "Ren\u00e9 Scharfe",
        "date": "2020-02-10T09:42:43-08:00",
        "message": "parse-options: use COPY_ARRAY in parse_options_concat()\n\nUse COPY_ARRAY to copy whole arrays instead of iterating through the\nelements.  That's shorter, simpler and bit more efficient.\n\nSigned-off-by: Ren\u00e9 Scharfe <l.s.r@web.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "parse-options-cb.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/a277d0a67f0324deb58abbeb0c5a2b3abbcde340",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "parse_options_concat"
        ],
        "added_lines": 2,
        "deleted_lines": 5,
        "total_changed_lines": 7,
        "net_line_change": -3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "a4b6d202caad83c6dc29abe9b17e53a1b3fb54a0",
        "author": "Derrick Stolee",
        "date": "2021-01-15T23:05:13-08:00",
        "message": "cache-tree: speed up consecutive path comparisons\n\nThe previous change reduced time spent in strlen() while comparing\nconsecutive paths in verify_cache(), but we can do better. The\nconditional checks the existence of a directory separator at the correct\nlocation, but only after doing a string comparison. Swap the order to be\nlogically equivalent but perform fewer string comparisons.\n\nTo test the effect on performance, I used a repository with over three\nmillion paths in the index. I then ran the following command on repeat:\n\n  git -c index.threads=1 commit --amend --allow-empty --no-edit\n\nHere are the measurements over 10 runs after a 5-run warmup:\n\n  Benchmark #1: v2.30.0\n    Time (mean \u00b1 \u03c3):     854.5 ms \u00b1  18.2 ms\n    Range (min \u2026 max):   825.0 ms \u2026 892.8 ms\n\n  Benchmark #2: Previous change\n    Time (mean \u00b1 \u03c3):     833.2 ms \u00b1  10.3 ms\n    Range (min \u2026 max):   815.8 ms \u2026 849.7 ms\n\n  Benchmark #3: This change\n    Time (mean \u00b1 \u03c3):     815.5 ms \u00b1  18.1 ms\n    Range (min \u2026 max):   795.4 ms \u2026 849.5 ms\n\nThis change is 2% faster than the previous change and 5% faster than\nv2.30.0.\n\nSigned-off-by: Derrick Stolee <dstolee@microsoft.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "cache-tree.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/a4b6d202caad83c6dc29abe9b17e53a1b3fb54a0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "verify_cache"
        ],
        "added_lines": 2,
        "deleted_lines": 2,
        "total_changed_lines": 4,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "a64dd34d8cce018742badb49b87c5c565be655ce",
        "author": "Junio C Hamano",
        "date": "2006-03-01T04:08:12-08:00",
        "message": "diffcore-break: micro-optimize by avoiding delta between identical files.\n\nWe did not check if we have the same file on both sides when\ncomputing break score.  This is usually not a problem, but if\nthe user said --find-copies-harde with -B, we ended up trying a\ndelta between the same data even when we know the SHA1 hash of\nboth sides match.\n\nSigned-off-by: Junio C Hamano <junkio@cox.net>\n(cherry picked from aeecd23ae2785a0462d42191974e9d9a8e439fbe commit)",
        "modified_files_count": 1,
        "modified_files": [
            "diffcore-break.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/a64dd34d8cce018742badb49b87c5c565be655ce",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "should_break"
        ],
        "added_lines": 4,
        "deleted_lines": 0,
        "total_changed_lines": 4,
        "net_line_change": 4,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "a6720955f19ea10bf9569d04480deed25b1bccf7",
        "author": "David Turner",
        "date": "2016-01-22T13:03:10-08:00",
        "message": "unpack-trees: fix accidentally quadratic behavior\n\nWhile unpacking trees (e.g. during git checkout), when we hit a cache\nentry that's past and outside our path, we cut off iteration.\n\nThis provides about a 45% speedup on git checkout between master and\nmaster^20000 on Twitter's monorepo.  Speedup in general will depend on\nrepostitory structure, number of changes, and packfile packing\ndecisions.\n\nSigned-off-by: David Turner <dturner@twopensource.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "unpack-trees.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/a6720955f19ea10bf9569d04480deed25b1bccf7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "find_cache_pos"
        ],
        "added_lines": 12,
        "deleted_lines": 1,
        "total_changed_lines": 13,
        "net_line_change": 11,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "a6eec1263883ce9787a354e1635b7b732e72c3c9",
        "author": "Jeff King",
        "date": "2013-03-16T22:16:45-07:00",
        "message": "upload-pack: drop lookup-before-parse optimization\n\nWhen we receive a \"have\" line from the client, we want to\nload the object pointed to by the sha1. However, we are\ncareful to do:\n\n  o = lookup_object(sha1);\n  if (!o || !o->parsed)\n\t  o = parse_object(sha1);\n\nto avoid loading the object from disk if we have already\nseen it.  However, since ccdc603 (parse_object: try internal\ncache before reading object db), parse_object already does\nthis optimization internally. We can just call parse_object\ndirectly.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "upload-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/a6eec1263883ce9787a354e1635b7b732e72c3c9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "got_sha1"
        ],
        "added_lines": 1,
        "deleted_lines": 3,
        "total_changed_lines": 4,
        "net_line_change": -2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "a7004abd0b17c2f2460f0fb318f49a75aab0785f",
        "author": "Patrick Steinhardt",
        "date": "2024-11-21T07:59:16+09:00",
        "message": "refs: don't normalize log messages with `REF_SKIP_CREATE_REFLOG`\n\nWhen the `REF_SKIP_CREATE_REFLOG` flag is set we skip the creation of\nthe reflog entry, but we still normalize the reflog message when we\nqueue the update. This is a waste of resources as the normalized message\nwill never get used in the first place.\n\nFix this issue by skipping the normalization in case the flag is set.\nThis leads to a surprisingly large speedup when migrating from the\n\"files\" to the \"reftable\" backend:\n\n    Benchmark 1: migrate files:reftable (refcount = 1000000, revision = HEAD~)\n      Time (mean \u00b1 \u03c3):     878.5 ms \u00b1  14.9 ms    [User: 726.5 ms, System: 139.2 ms]\n      Range (min \u2026 max):   858.4 ms \u2026 941.3 ms    50 runs\n\n    Benchmark 2: migrate files:reftable (refcount = 1000000, revision = HEAD)\n      Time (mean \u00b1 \u03c3):     831.1 ms \u00b1  10.5 ms    [User: 694.1 ms, System: 126.3 ms]\n      Range (min \u2026 max):   812.4 ms \u2026 851.4 ms    50 runs\n\n    Summary\n      migrate files:reftable (refcount = 1000000, revision = HEAD) ran\n        1.06 \u00b1 0.02 times faster than migrate files:reftable (refcount = 1000000, revision = HEAD~)\n\nAnd an ever larger speedup when migrating the other way round:\n\n    Benchmark 1: migrate reftable:files (refcount = 1000000, revision = HEAD~)\n      Time (mean \u00b1 \u03c3):     923.6 ms \u00b1  11.6 ms    [User: 705.5 ms, System: 208.1 ms]\n      Range (min \u2026 max):   905.3 ms \u2026 946.5 ms    50 runs\n\n    Benchmark 2: migrate reftable:files (refcount = 1000000, revision = HEAD)\n      Time (mean \u00b1 \u03c3):     818.5 ms \u00b1   9.0 ms    [User: 627.6 ms, System: 180.6 ms]\n      Range (min \u2026 max):   802.2 ms \u2026 842.9 ms    50 runs\n\n    Summary\n      migrate reftable:files (refcount = 1000000, revision = HEAD) ran\n        1.13 \u00b1 0.02 times faster than migrate reftable:files (refcount = 1000000, revision = HEAD~)\n\nSigned-off-by: Patrick Steinhardt <ps@pks.im>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "refs.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/a7004abd0b17c2f2460f0fb318f49a75aab0785f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ref_transaction_add_update"
        ],
        "added_lines": 2,
        "deleted_lines": 1,
        "total_changed_lines": 3,
        "net_line_change": 1,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "a7e9c34126ce7608bbc971b09b80540d0112091c",
        "author": "Dmitry Ivankov",
        "date": "2011-08-22T11:57:07-07:00",
        "message": "fast-import: treat cat-blob as a delta base hint for next blob\n\nDelta base for blobs is chosen as a previously saved blob. If we\ntreat cat-blob's blob as a delta base for the next blob, nothing\nis likely to become worse.\n\nFor fast-import stream producer like svn-fe cat-blob is used like\nfollowing:\n- svn-fe reads file delta in svn format\n- to apply it, svn-fe asks cat-blob 'svn delta base'\n- applies 'svn delta' to the response\n- produces a blob command to store the result\n\nCurrently there is no way for svn-fe to give fast-import a hint on\nobject delta base. While what's requested in cat-blob is most of\nthe time a best delta base possible. Of course, it could be not a\ngood delta base, but we don't know any better one anyway.\n\nSo do treat cat-blob's result as a delta base for next blob. The\nprofit is nice: 2x to 7x reduction in pack size AND 1.2x to 3x\ntime speedup due to diff_delta being faster on good deltas. git gc\n--aggressive can compress it even more, by 10% to 70%, utilizing\nmore cpu time, real time and 3 cpu cores.\n\nTested on 213M and 2.7G fast-import streams, resulting packs are 22M\nand 113M, import time is 7s and 60s, both streams are produced by\nsvn-fe, sniffed and then used as raw input for fast-import.\n\nFor git-fast-export produced streams there is no change as it doesn't\nuse cat-blob and doesn't try to reorder blobs in some smart way to\nmake successive deltas small.\n\nSigned-off-by: Dmitry Ivankov <divanorama@gmail.com>\nAcked-by: David Barr <davidbarr@google.com>\nAcked-by: Jonathan Nieder <jrnieder@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "fast-import.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/a7e9c34126ce7608bbc971b09b80540d0112091c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cat_blob"
        ],
        "added_lines": 6,
        "deleted_lines": 1,
        "total_changed_lines": 7,
        "net_line_change": 5,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "a9155c50bd52b7e27224e9588780ce5f972fa98d",
        "author": "Stefan Beller",
        "date": "2017-10-04T15:21:31+09:00",
        "message": "branch: reset instead of release a strbuf\n\nOur documentation advises to not re-use a strbuf, after strbuf_release\nhas been called on it. Use the proper reset instead.\n\nCurrently 'strbuf_release' releases and re-initializes the strbuf, so it\nis safe, but slow. 'strbuf_reset' only resets the internal length variable,\nsuch that this could also be accounted for as a micro-optimization.\n\nReviewed-by: Jonathan Nieder <jrnieder@gmail.com>\nSigned-off-by: Stefan Beller <sbeller@google.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/branch.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/a9155c50bd52b7e27224e9588780ce5f972fa98d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "delete_branches"
        ],
        "added_lines": 3,
        "deleted_lines": 2,
        "total_changed_lines": 5,
        "net_line_change": 1,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "ad14b450c0c70bfcf90de0aa19ffa5e44e402b69",
        "author": "Clemens Buchacher",
        "date": "2010-09-23T18:35:07-07:00",
        "message": "do not search functions for patch ID\n\nVisual aids, such as the function name in the hunk\nheader, are not necessary for the purposes of\ncomputing a patch ID.\n\nThis is a performance optimization.\n\nSigned-off-by: Clemens Buchacher <drizzd@aon.at>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "diff.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/ad14b450c0c70bfcf90de0aa19ffa5e44e402b69",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "diff_get_patch_id"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "aeecd23ae2785a0462d42191974e9d9a8e439fbe",
        "author": "Junio C Hamano",
        "date": "2006-02-28T20:19:47-08:00",
        "message": "diffcore-break: micro-optimize by avoiding delta between identical files.\n\nWe did not check if we have the same file on both sides when\ncomputing break score.  This is usually not a problem, but if\nthe user said --find-copies-harde with -B, we ended up trying a\ndelta between the same data even when we know the SHA1 hash of\nboth sides match.\n\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "diffcore-break.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/aeecd23ae2785a0462d42191974e9d9a8e439fbe",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "should_break"
        ],
        "added_lines": 4,
        "deleted_lines": 0,
        "total_changed_lines": 4,
        "net_line_change": 4,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "b180c681bb911714e2c9735038effe0251d6586e",
        "author": "Andrzej Hunt",
        "date": "2021-04-28T09:25:44+09:00",
        "message": "bloom: clear each bloom_key after use\n\nfill_bloom_key() allocates memory into bloom_key, we need to clean that\nup once the key is no longer needed.\n\nThis leak was found while running t0002-t0099. Although this leak is\nhappening in code being called from a test-helper, the same code is also\nused in various locations around git, and can therefore happen during\nnormal usage too. Gabor's analysis shows that peak-memory usage during\n'git commit-graph write' is reduced on the order of 10% for a selection\nof larger repos (along with an even larger reduction if we override\nmodified path bloom filter limits):\nhttps://lore.kernel.org/git/20210411072651.GF2947267@szeder.dev/\n\nLSAN output:\n\nDirect leak of 308 byte(s) in 11 object(s) allocated from:\n    #0 0x49a5e2 in calloc ../projects/compiler-rt/lib/asan/asan_malloc_linux.cpp:154:3\n    #1 0x6f4032 in xcalloc wrapper.c:140:8\n    #2 0x4f2905 in fill_bloom_key bloom.c:137:28\n    #3 0x4f34c1 in get_or_compute_bloom_filter bloom.c:284:4\n    #4 0x4cb484 in get_bloom_filter_for_commit t/helper/test-bloom.c:43:11\n    #5 0x4cb072 in cmd__bloom t/helper/test-bloom.c:97:3\n    #6 0x4ca7ef in cmd_main t/helper/test-tool.c:121:11\n    #7 0x4caace in main common-main.c:52:11\n    #8 0x7f798af95349 in __libc_start_main (/lib64/libc.so.6+0x24349)\n\nSUMMARY: AddressSanitizer: 308 byte(s) leaked in 11 allocation(s).\n\nSigned-off-by: Andrzej Hunt <ajrhunt@google.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "bloom.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/b180c681bb911714e2c9735038effe0251d6586e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_or_compute_bloom_filter"
        ],
        "added_lines": 1,
        "deleted_lines": 0,
        "total_changed_lines": 1,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "b495697b8228fdf7cde426ff99fc5ffe7e43d343",
        "author": "Jeff King",
        "date": "2013-01-26T19:37:30-08:00",
        "message": "fetch-pack: avoid repeatedly re-scanning pack directory\n\nWhen we look up a sha1 object for reading via parse_object() =>\nread_sha1_file() => read_object() callpath, we first check\npackfiles, and then loose objects. If we still haven't found it, we\nre-scan the list of packfiles in `objects/pack`. This final step\nensures that we can co-exist with a simultaneous repack process\nwhich creates a new pack and then prunes the old object.\n\nThis extra re-scan usually does not have a performance impact for\ntwo reasons:\n\n  1. If an object is missing, then typically the re-scan will find a\n     new pack, then no more misses will occur.  Or if it truly is\n     missing, then our next step is usually to die().\n\n  2. Re-scanning is cheap enough that we do not even notice.\n\nHowever, these do not always hold. The assumption in (1) is that the\ncaller is expecting to find the object. This is usually the case,\nbut the call to `parse_object` in `everything_local` does not follow\nthis pattern. It is looking to see whether we have objects that the\nremote side is advertising, not something we expect to\nhave. Therefore if we are fetching from a remote which has many refs\npointing to objects we do not have, we may end up re-scanning the\npack directory many times.\n\nEven with this extra re-scanning, the impact is often not noticeable\ndue to (2); we just readdir() the packs directory and skip any packs\nthat are already loaded. However, if there are a large number of\npacks, even enumerating the directory can be expensive, especially\nif we do it repeatedly.\n\nHaving this many packs is a good sign the user should run `git gc`,\nbut it would still be nice to avoid having to scan the directory at\nall.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/fetch-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/b495697b8228fdf7cde426ff99fc5ffe7e43d343",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "everything_local"
        ],
        "added_lines": 3,
        "deleted_lines": 0,
        "total_changed_lines": 3,
        "net_line_change": 3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "b4cf0f1784362fb4aa2383d8d5d829caa92ca3a0",
        "author": "Dylan Reid",
        "date": "2010-07-05T23:27:41-07:00",
        "message": "xdiff: optimise for no whitespace difference when ignoring whitespace.\n\nIn xdl_recmatch, do the memcmp to check if the two lines are equal before\nchecking if whitespace flags are set.  If the lines are identical, then\nthere is no need to check if they differ only in whitespace.\nThis makes the common case (there is no whitespace difference) faster.\nIt costs the case where lines are the same length and contain\nwhitespace differences, but the common case is more than 20% faster.\n\nSigned-off-by: Dylan Reid <dgreid@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "xdiff/xutils.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/b4cf0f1784362fb4aa2383d8d5d829caa92ca3a0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "xdl_recmatch"
        ],
        "added_lines": 3,
        "deleted_lines": 1,
        "total_changed_lines": 4,
        "net_line_change": 2,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "b500d5e11ea67d29dd7be622f65571d611d6e9a3",
        "author": "Nicolas Pitre",
        "date": "2010-02-17T11:08:44-08:00",
        "message": "fast-import: use the diff_delta() max_delta_size argument\n\nThis let diff_delta() abort early if it is going to bust the given\nsize limit.  Also, only objects larger than 20 bytes are considered\nas objects smaller than that are most certainly going to produce\nlarger deltas than the original object due to the additional headers.\n\nSigned-off-by: Nicolas Pitre <nico@fluxnic.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "fast-import.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/b500d5e11ea67d29dd7be622f65571d611d6e9a3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "store_object"
        ],
        "added_lines": 2,
        "deleted_lines": 6,
        "total_changed_lines": 8,
        "net_line_change": -4,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "b5f52f372e85c6e461b6123cd7eebd544b439020",
        "author": "Jeff King",
        "date": "2015-04-20T13:09:38-07:00",
        "message": "sha1_file: freshen pack objects before loose\n\nWhen writing out an object file, we first check whether it\nalready exists and if so optimize out the write. Prior to\n33d4221, we did this by calling has_sha1_file(), which will\ncheck for packed objects followed by loose. Since that\ncommit, we check loose objects first.\n\nFor the common case of a repository whose objects are mostly\npacked, this means we will make a lot of extra access()\nsystem calls checking for loose objects. We should follow\nthe same packed-then-loose order that all of our other\nlookups use.\n\nReported-by: Stefan Saasen <ssaasen@atlassian.com>\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "sha1_file.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/b5f52f372e85c6e461b6123cd7eebd544b439020",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "write_sha1_file"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "b6723e4671acdc6a06ef7672144106cfac4a234f",
        "author": "Derrick Stolee",
        "date": "2018-10-19T11:30:45+09:00",
        "message": "commit-reach: fix first-parent heuristic\n\nThe algorithm in can_all_from_reach_with_flags() performs a depth-\nfirst-search, terminated by generation number, intending to use\na hueristic that \"important\" commits are found in the first-parent\nhistory. This heuristic is valuable in scenarios like fetch\nnegotiation.\n\nHowever, there is a problem! After the search finds a target commit,\nit should pop all commits off the stack and mark them as \"can reach\".\nThis logic is incorrect, so the algorithm instead walks all reachable\ncommits above the generation-number cutoff.\n\nThe existing algorithm is still an improvement over the previous\nalgorithm, as the worst-case complexity went from quadratic to linear.\nThe performance measurement at the time was good, but not dramatic.\nBy fixing this heuristic, we reduce the number of walked commits.\n\nWe can also re-run the performance tests from commit 4fbcca4e\n\"commit-reach: make can_all_from_reach... linear\".\n\nPerformance was measured on the Linux repository using\n'test-tool reach can_all_from_reach'. The input included rows seeded by\ntag values. The \"small\" case included X-rows as v4.[0-9]* and Y-rows as\nv3.[0-9]*. This mimics a (very large) fetch that says \"I have all major\nv3 releases and want all major v4 releases.\" The \"large\" case included\nX-rows as \"v4.*\" and Y-rows as \"v3.*\". This adds all release-candidate\ntags to the set, which does not greatly increase the number of objects\nthat are considered, but does increase the number of 'from' commits,\ndemonstrating the quadratic nature of the previous code.\n\nSmall Case:\n\n4fbcca4e~1: 0.85 s\n  4fbcca4e: 0.26 s (num_walked: 1,011,035)\n      HEAD: 0.14 s (num_walked:     8,601)\n\nLarge Case:\n\n4fbcca4e~1: 24.0  s\n  4fbcca4e:  0.12 s (num_walked:  503,925)\n      HEAD:  0.06 s (num_walked:  217,243)\n\nSigned-off-by: Derrick Stolee <dstolee@microsoft.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "commit-reach.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/b6723e4671acdc6a06ef7672144106cfac4a234f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "can_all_from_reach_with_flag"
        ],
        "added_lines": 3,
        "deleted_lines": 1,
        "total_changed_lines": 4,
        "net_line_change": 2,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "b794ebeac9151af4a9136ef28a22a06c2afb17cc",
        "author": "Jeff King",
        "date": "2014-07-28T10:14:34-07:00",
        "message": "diff-tree: avoid lookup_unknown_object\n\nWe generally want to avoid lookup_unknown_object, because it\nresults in allocating more memory for the object than may be\nstrictly necessary.\n\nIn this case, it is used to check whether we have an\nalready-parsed object before calling parse_object, to save\nus from reading the object from disk. Using lookup_object\nwould be fine for that purpose, but we can take it a step\nfurther. Since this code was written, parse_object already\nlearned the \"check lookup_object\" optimization, so we can\nsimply call parse_object directly.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/diff-tree.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/b794ebeac9151af4a9136ef28a22a06c2afb17cc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "diff_tree_stdin"
        ],
        "added_lines": 1,
        "deleted_lines": 3,
        "total_changed_lines": 4,
        "net_line_change": -2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "b7c1ce4f14f37600a8a5bf8d81e0a723d42644b9",
        "author": "David Barr",
        "date": "2010-11-24T11:25:16-08:00",
        "message": "fast-import: insert new object entries at start of hash bucket\n\nMore often than not, find_object is called for recently inserted objects.\nOptimise for this case by inserting new entries at the start of the chain.\nThis doesn't affect the cost of new inserts but reduces the cost of find\nand insert for existing object entries.\n\nSigned-off-by: David Barr <david.barr@cordelta.com>\nSigned-off-by: Jonathan Nieder <jrnieder@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "fast-import.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/b7c1ce4f14f37600a8a5bf8d81e0a723d42644b9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "insert_object"
        ],
        "added_lines": 2,
        "deleted_lines": 7,
        "total_changed_lines": 9,
        "net_line_change": -5,
        "modified_code_blocks": 4,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "b8150bfee1f8d609e3d1f38eaa98cfb64a1c2ca5",
        "author": "Jeff King",
        "date": "2024-11-07T13:28:22+09:00",
        "message": "describe: stop traversing when we run out of names\n\nWhen trying to describe a commit, we'll traverse from the commit,\ncollecting candidate tags that point to its ancestors. But once we've\nseen all of the tags in the repo, there's no point in traversing\nfurther. There's nothing left to find!\n\nFor a default \"git describe\", this isn't usually a big problem. In a\nlarge repo you'll probably have multiple tags, so we'll eventually find\n10 candidates (the default for max_candidates) and stop there. And in a\nsmall repo, it's quick to traverse to the root.\n\nBut you can imagine a large repo with few tags. Or, as we saw in a real\nworld case, explicitly limiting the set of matches like this (on\nlinux.git):\n\n  git describe --match=v6.12-rc4 HEAD\n\nwhich goes all the way to the root before realizing that no, there are\nno other tags under consideration besides the one we fed via --match.\nIf we add in \"--candidates=1\" there, it's much faster (at least as of\nthe previous commit).\n\nBut we should be able to speed this up without the user asking for it.\nAfter expanding all matching tags, we know the total number of names. We\ncould just stop the traversal there, but as hinted at above we already\nhave a mechanism for doing that: the max_candidate limit. So we can just\nreduce that limit to match the number of possible candidates.\n\nOur p6100 test shows this off:\n\n  Test                                           HEAD^             HEAD\n  ---------------------------------------------------------------------------------------\n  6100.2: describe HEAD                          0.71(0.65+0.06)   0.72(0.68+0.04) +1.4%\n  6100.3: describe HEAD with one max candidate   0.01(0.00+0.00)   0.01(0.00+0.00) +0.0%\n  6100.4: describe HEAD with one tag             0.72(0.66+0.05)   0.01(0.00+0.00) -98.6%\n\nNow we are fast automatically, just as if --candidates=1 were supplied\nby the user.\n\nReported-by: Josh Poimboeuf <jpoimboe@kernel.org>\nHelped-by: Rasmus Villemoes <ravi@prevas.dk>\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/describe.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/b8150bfee1f8d609e3d1f38eaa98cfb64a1c2ca5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_describe"
        ],
        "added_lines": 2,
        "deleted_lines": 0,
        "total_changed_lines": 2,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "b9584c5858799d5603851af5f0dbad5e7af29b22",
        "author": "Jeff King",
        "date": "2023-07-17T14:16:05-07:00",
        "message": "ref-filter: avoid parsing tagged objects in match_points_at()\n\nWhen we peel tags to check if they match a --points-at oid, we\nrecursively parse the tagged object to see if it is also a tag. But\nsince the tag itself tells us the type of the object it points to (and\neven gives us the appropriate object struct via its \"tagged\" member), we\ncan use that directly.\n\nWe do still have to make sure to call parse_tag() before looking at each\ntag. This is redundant for the outermost tag (since we did call\nparse_object() to find its type), but that's OK; parse_tag() is smart\nenough to make this a noop when the tag has already been parsed.\n\nIn my clone of linux.git, with 782 tags (and only 3 non-tags), this\nyields a significant speedup (bringing us back where we were before the\ncommit before this one started recursively dereferencing tags):\n\n  Benchmark 1: ./git.old for-each-ref --points-at=HEAD --format=\"%(refname)\"\n    Time (mean \u00b1 \u03c3):      20.3 ms \u00b1   0.5 ms    [User: 11.1 ms, System: 9.1 ms]\n    Range (min \u2026 max):    19.6 ms \u2026  21.5 ms    141 runs\n\n  Benchmark 2: ./git.new for-each-ref --points-at=HEAD --format=\"%(refname)\"\n    Time (mean \u00b1 \u03c3):      11.4 ms \u00b1   0.2 ms    [User: 6.3 ms, System: 5.0 ms]\n    Range (min \u2026 max):    11.0 ms \u2026  12.2 ms    250 runs\n\n  Summary\n    './git.new for-each-ref --points-at=HEAD --format=\"%(refname)\"' ran\n      1.79 \u00b1 0.05 times faster than './git.old for-each-ref --points-at=HEAD --format=\"%(refname)\"'\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "ref-filter.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/b9584c5858799d5603851af5f0dbad5e7af29b22",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "match_points_at"
        ],
        "added_lines": 10,
        "deleted_lines": 2,
        "total_changed_lines": 12,
        "net_line_change": 8,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "bbfe5f2241f8baf6019c6cb7428aed9fb1353799",
        "author": "Junio C Hamano",
        "date": "2019-10-07T11:32:56+09:00",
        "message": "Merge branch 'jk/list-objects-optim-wo-trees'\n\nThe object traversal machinery has been optimized not to load tree\nobjects when we are only interested in commit history.\n\n* jk/list-objects-optim-wo-trees:\n  list-objects: don't queue root trees unless revs->tree_objects is set",
        "modified_files_count": 1,
        "modified_files": [
            "list-objects.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/bbfe5f2241f8baf6019c6cb7428aed9fb1353799",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "do_traverse"
        ],
        "added_lines": 3,
        "deleted_lines": 1,
        "total_changed_lines": 4,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "bc41bf422e15209860bfc6c898dbd3cd89d5da34",
        "author": "Martin von Zweigbergk",
        "date": "2013-01-15T09:38:08-08:00",
        "message": "reset [--mixed]: only write index file once\n\nWhen doing a mixed reset without paths, the index is locked, read,\nreset, and written back as part of the actual reset operation (in\nreset_index()). Then, when showing the list of worktree modifications,\nwe lock the index again, refresh it, and write it.\n\nChange this so we only write the index once, making \"git reset\" a\nlittle faster. It does mean that the index lock will be held a little\nlonger, but the difference is small compared to the time spent\nrefreshing the index.\n\nThere is one minor functional difference: We used to say \"Could not\nwrite new index file.\" if the first write failed, and \"Could not\nrefresh index\" if the second write failed. Now, we will only use the\nfirst message.\n\nThis speeds up \"git reset\" a little on the linux-2.6 repo (best of\nfive, warm cache):\n\n        Before      After\nreal    0m0.239s    0m0.214s\nuser    0m0.160s    0m0.130s\nsys     0m0.070s    0m0.080s\n\nSigned-off-by: Martin von Zweigbergk <martinvonz@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/reset.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/bc41bf422e15209860bfc6c898dbd3cd89d5da34",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_reset"
        ],
        "added_lines": 5,
        "deleted_lines": 9,
        "total_changed_lines": 14,
        "net_line_change": -4,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "bcb68bff80eab46f9d5f367555da803e61d3d7c8",
        "author": "Junio C Hamano",
        "date": "2020-09-22T12:36:28-07:00",
        "message": "Merge branch 'os/fetch-submodule-optim'\n\nOptimization around submodule handling.\n\n* os/fetch-submodule-optim:\n  fetch: do not look for submodule changes in unchanged refs",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/fetch.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/bcb68bff80eab46f9d5f367555da803e61d3d7c8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "store_updated_refs"
        ],
        "added_lines": 3,
        "deleted_lines": 1,
        "total_changed_lines": 4,
        "net_line_change": 2,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "be12681896fab9455eb65ea124df423b462e0072",
        "author": "Dan McGee",
        "date": "2011-10-18T00:16:31-07:00",
        "message": "pack-objects: mark add_to_write_order() as inline\n\nThis function is a whole 26 bytes when compiled on x86_64, but is\ncurrently invoked over 1.037 billion times when running pack-objects on\nthe Linux kernel git repository. This is hitting the point where\nmicro-optimizations do make a difference, and inlining it only increases\nthe object file size by 38 bytes.\n\nAs reported by perf, this dropped task-clock from 84183 to 83373 ms, and\ntotal cycles from 223.5 billion to 221.6 billion. Not astronomical, but\nworth getting for adding one word.\n\nSigned-off-by: Dan McGee <dpmcgee@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/pack-objects.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/be12681896fab9455eb65ea124df423b462e0072",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "add_to_write_order"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "be99ec97c8a1f94e723c6cc5331eff921ae49ed3",
        "author": "Jeremiah Mahler",
        "date": "2014-06-20T10:08:10-07:00",
        "message": "name-hash.c: replace cache_name_compare() with memcmp(3)\n\nThe same_name() private function wants a quick-and-exact check to\nsee if they two names are byte-for-byte identical first and then\nfall back to the slow path.  Use memcmp(3) for the former to make it\nclear that we do not want any \"name\" specific comparison.\n\nSigned-off-by: Jeremiah Mahler <jmmahler@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "name-hash.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/be99ec97c8a1f94e723c6cc5331eff921ae49ed3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "same_name"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "bec5ab8997c2391fa2241520f52f301397ebd538",
        "author": "Ren\u00e9 Scharfe",
        "date": "2017-02-08T13:38:41-08:00",
        "message": "dir: avoid allocation in fill_directory()\n\nPass the match member of the first pathspec item directly to\nread_directory() instead of using common_prefix() to duplicate it first,\nthus avoiding memory duplication, strlen(3) and free(3).\n\nSigned-off-by: Rene Scharfe <l.s.r@web.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "dir.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/bec5ab8997c2391fa2241520f52f301397ebd538",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "fill_directory"
        ],
        "added_lines": 3,
        "deleted_lines": 4,
        "total_changed_lines": 7,
        "net_line_change": -1,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "bf9c0cbddbcd730e4312ba5e19f8b8a2edd65bb3",
        "author": "Patrick Steinhardt",
        "date": "2021-08-09T09:51:12-07:00",
        "message": "revision: stop retrieving reference twice\n\nWhen queueing up references for the revision walk, `handle_one_ref()`\nwill resolve the reference's object ID via `get_reference()` and then\nqueue the ID as pending object via `add_pending_oid()`. But given that\n`add_pending_oid()` is only a thin wrapper around `add_pending_object()`\nwhich fist calls `get_reference()`, we effectively resolve the reference\ntwice and thus duplicate some of the work.\n\nFix the issue by instead calling `add_pending_object()` directly, which\ntakes the already-resolved object as input. In a repository with lots of\nrefs, this translates into a near 10% speedup:\n\n    Benchmark #1: HEAD~: rev-list --unsorted-input --objects --quiet --not --all --not $newrev\n      Time (mean \u00b1 \u03c3):      5.015 s \u00b1  0.038 s    [User: 4.698 s, System: 0.316 s]\n      Range (min \u2026 max):    4.970 s \u2026  5.089 s    10 runs\n\n    Benchmark #2: HEAD: rev-list --unsorted-input --objects --quiet --not --all --not $newrev\n      Time (mean \u00b1 \u03c3):      4.606 s \u00b1  0.029 s    [User: 4.260 s, System: 0.345 s]\n      Range (min \u2026 max):    4.565 s \u2026  4.657 s    10 runs\n\n    Summary\n      'HEAD: rev-list --unsorted-input --objects --quiet --not --all --not $newrev' ran\n        1.09 \u00b1 0.01 times faster than 'HEAD~: rev-list --unsorted-input --objects --quiet --not --all --not $newrev'\n\nSigned-off-by: Patrick Steinhardt <ps@pks.im>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "revision.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/bf9c0cbddbcd730e4312ba5e19f8b8a2edd65bb3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "handle_one_ref"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "c291293b2ecec8ca77dfd218fa820dd7a0137a2b",
        "author": "Jeff King",
        "date": "2017-11-21T11:30:41+09:00",
        "message": "everything_local: use \"quick\" object existence check\n\nIn b495697b82 (fetch-pack: avoid repeatedly re-scanning pack\ndirectory, 2013-01-26), we noticed that everything_local()\ncould waste time trying to find and parse objects which we\n_expect_ to be missing. The solution was to put\nhas_sha1_file() in front of parse_object() to skip the\nmore-expensive parse attempt.\n\nThat optimization was negated later when has_sha1_file()\nlearned to do the same re-scan in 45e8a74873 (has_sha1_file:\nre-check pack directory before giving up, 2013-08-30).\n\nWe can restore it by using the \"quick\" flag to tell\nhas_sha1_file (actually has_object_file these days) that we\nprefer speed to thoroughness for this call.  See also the\nfixes in 5827a0354 and 0eeb077be7 for prior art and\ndiscussion on using the \"quick\" flag for these cases.\n\nThe recently-added performance regression test in p5551\ndemonstrates the problem. You can see the original fix:\n\n  Test            b495697b82^       b495697b82\n  --------------------------------------------------------\n  5551.4: fetch   1.68(1.33+0.35)   0.87(0.69+0.18) -48.2%\n\nand then the regression:\n\n  Test            45e8a74873^       45e8a74873\n  ---------------------------------------------------------\n  5551.4: fetch   0.96(0.77+0.19)   2.55(2.04+0.50) +165.6%\n\nand now our fix:\n\n  Test            HEAD^             HEAD\n  --------------------------------------------------------\n  5551.4: fetch   7.21(6.58+0.63)   5.47(5.04+0.43) -24.1%\n\nYou can also see that other things have gotten a lot slower\nsince 2013. We'll deal with those in separate patches.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "fetch-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/c291293b2ecec8ca77dfd218fa820dd7a0137a2b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "everything_local"
        ],
        "added_lines": 2,
        "deleted_lines": 1,
        "total_changed_lines": 3,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "c3117b21666f2a68aebd5fce0bcdc4ab705c299a",
        "author": "Junio C Hamano",
        "date": "2012-03-16T08:23:53-07:00",
        "message": "Merge branch 'jc/maint-verify-objects-remove-pessimism'\n\nThe code to validate the history connectivity between old refs and new\nrefs used by fetch and receive-pack, introduced in 1.7.8, was grossly\ninefficient and unnecessarily tried to re-validate integrity of individual\nobjects. This essentially reverts that performance regression.\n\n* jc/maint-verify-objects-remove-pessimism:\n  fetch/receive: remove over-pessimistic connectivity check",
        "modified_files_count": 1,
        "modified_files": [
            "connected.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/c3117b21666f2a68aebd5fce0bcdc4ab705c299a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "check_everything_connected"
        ],
        "added_lines": 4,
        "deleted_lines": 4,
        "total_changed_lines": 8,
        "net_line_change": 0,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "c3b06a69ffc41b3ac3600628593dd0fdd3988607",
        "author": "Nicolas Pitre",
        "date": "2006-05-16T13:35:46-07:00",
        "message": "improve depth heuristic for maximum delta size\n\nThis provides a linear decrement on the penalty related to delta depth\ninstead of being an 1/x function.  With this another 5% reduction is\nobserved on packs for both the GIT repo and the Linux kernel repo, as\nwell as fixing a pack size regression in another sample repo I have.\n\nSigned-off-by: Nicolas Pitre <nico@cam.org>\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "pack-objects.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/c3b06a69ffc41b3ac3600628593dd0fdd3988607",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "try_delta"
        ],
        "added_lines": 5,
        "deleted_lines": 2,
        "total_changed_lines": 7,
        "net_line_change": 3,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "c4640fe8d9e25fd3e206a39233c71a6dbb68917e",
        "author": "Marco Costalba",
        "date": "2007-07-22T01:40:21-07:00",
        "message": "Avoid to duplicate commit message when is not encoded\n\nWhen a commit message doesn't have encoding information\nand encoding output is utf-8 (default) then an useless\nxstrdup() of commit message is done.\n\nIf we assume most of users live in an utf-8 world, this\nuseless copy is the common case.\n\nPerformance issue found with KCachegrind.\n\nSigned-off-by: Marco Costalba <mcostalba@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "commit.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/c4640fe8d9e25fd3e206a39233c71a6dbb68917e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "logmsg_reencode"
        ],
        "added_lines": 4,
        "deleted_lines": 1,
        "total_changed_lines": 5,
        "net_line_change": 3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "c61b2af7bd2c7225bcf576a39c245cebf9397ead",
        "author": "Nicolas Pitre",
        "date": "2016-07-06T14:09:32-07:00",
        "message": "sideband.c: small optimization of strbuf usage\n\nSigned-off-by: Nicolas Pitre <nico@fluxnic.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "sideband.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/c61b2af7bd2c7225bcf576a39c245cebf9397ead",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "recv_sideband"
        ],
        "added_lines": 3,
        "deleted_lines": 3,
        "total_changed_lines": 6,
        "net_line_change": 0,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "c673764dde8520e9d46f71882f0d026dfde8bdeb",
        "author": "Junio C Hamano",
        "date": "2010-03-02T12:44:07-08:00",
        "message": "Merge branch 'jc/maint-status-preload'\n\n* jc/maint-status-preload:\n  status: preload index to optimize lstat(2) calls",
        "modified_files_count": 1,
        "modified_files": [
            "builtin-commit.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/c673764dde8520e9d46f71882f0d026dfde8bdeb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_status"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "c835288be4cac722a20f9601a920879206a0ff61",
        "author": "Junio C Hamano",
        "date": "2010-12-16T12:49:16-08:00",
        "message": "Merge branch 'jn/maint-fast-import-object-reuse'\n\n* jn/maint-fast-import-object-reuse:\n  fast-import: insert new object entries at start of hash bucket",
        "modified_files_count": 1,
        "modified_files": [
            "fast-import.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/c835288be4cac722a20f9601a920879206a0ff61",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "insert_object"
        ],
        "added_lines": 2,
        "deleted_lines": 7,
        "total_changed_lines": 9,
        "net_line_change": -5,
        "modified_code_blocks": 4,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "c83f032e09e49e5bc60686663f7c78d36f72cef4",
        "author": "Nicolas Pitre",
        "date": "2007-07-12T14:18:14-07:00",
        "message": "apply delta depth bias to already deltified objects\n\nWe already apply a bias on the initial delta attempt with max_size being\na function of the base object depth.  This has the effect of favoring\nshallower deltas even if deeper deltas could be smaller, and therefore\ncreating a wider delta tree (see commits 4e8da195 and c3b06a69).\n\nThis principle should also be applied to all delta attempts for the same\nobject and not only the first attempt.  With this the criteria for the\nbest delta is not only its size but also its depth, so that a shallower\ndelta might be selected even if it is larger than a deeper one.  Even if\nsome deltas get larger, they allow for wider delta trees making the\ndepth limit less quickly reached and therefore better deltas can be\nsubsequently found, keeping the resulting pack size even smaller.\nRuntime access to the pack should also benefit from shallower deltas.\n\nTesting on different repositories showed slighter faster repacks,\nsmaller resulting packs, and a much nicer curve for delta depth\ndistribution with no more peak at the maximum depth level.\nImprovements are even more significant with smaller depth limits.\n\nSigned-off-by: Nicolas Pitre <nico@cam.org>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin-pack-objects.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/c83f032e09e49e5bc60686663f7c78d36f72cef4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "try_delta"
        ],
        "added_lines": 10,
        "deleted_lines": 4,
        "total_changed_lines": 14,
        "net_line_change": 6,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "c8c073c4201600b958f5d3bd9e8051b2060bd3f7",
        "author": "Alexey Mahotkin",
        "date": "2010-05-01T11:11:11-07:00",
        "message": "xdiff/xmerge.c: use memset() instead of explicit for-loop\n\nmemset() is heavily optimized, and resulting assembler code\nis about 150 lines less for that file.\n\nSigned-off-by: Alexey Mahotkin <squadette@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "xdiff/xmerge.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/c8c073c4201600b958f5d3bd9e8051b2060bd3f7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "fill_conflict_hunk"
        ],
        "added_lines": 8,
        "deleted_lines": 9,
        "total_changed_lines": 17,
        "net_line_change": -1,
        "modified_code_blocks": 5,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "c9052a8392878d9e38381db5d2172f7f8f7272a3",
        "author": "Alex Vandiver",
        "date": "2020-10-20T12:52:21-07:00",
        "message": "fsmonitor: use fsmonitor data in `git diff`\n\nWith fsmonitor enabled, the first call to match_stat_with_submodule\ncalls refresh_fsmonitor, incurring the overhead of reading the list of\nupdated files -- but run_diff_files does not respect the\nCE_FSMONITOR_VALID flag.\n\nMake use of the fsmonitor extension to skip lstat() calls on files\nthat fsmonitor judged as unmodified.\n\nNotably, this change improves performance of the git shell prompt when\nGIT_PS1_SHOWDIRTYSTATE is set.\n\nSigned-off-by: Alex Vandiver <alexmv@dropbox.com>\nSigned-off-by: Nipunn Koorapati <nipunn@dropbox.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "diff-lib.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/c9052a8392878d9e38381db5d2172f7f8f7272a3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "run_diff_files"
        ],
        "added_lines": 13,
        "deleted_lines": 2,
        "total_changed_lines": 15,
        "net_line_change": 11,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "ca598d5f2ab988935a5b882b44122cbfa5fd99f5",
        "author": "Ben Peart",
        "date": "2018-04-11T18:09:48+09:00",
        "message": "fsmonitor: force index write after full scan\n\nfsmonitor currently only flags the index as dirty if the extension is being\nadded or removed. This is a performance optimization that recognizes you can\nstat() a lot of files in less time than it takes to write out an updated index.\n\nThis patch makes a small enhancement and flags the index dirty if we end up\nhaving to stat() all files and scan the entire working directory.  The assumption\nbeing that must be expensive or you would not have turned on the feature.\n\nSigned-off-by: Ben Peart <benpeart@microsoft.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "fsmonitor.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/ca598d5f2ab988935a5b882b44122cbfa5fd99f5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "refresh_fsmonitor"
        ],
        "added_lines": 3,
        "deleted_lines": 0,
        "total_changed_lines": 3,
        "net_line_change": 3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "caf388caa101be90b7ec43d7f78ca4e935fc0150",
        "author": "Derrick Stolee",
        "date": "2020-04-09T11:04:35-07:00",
        "message": "bloom: ignore renames when computing changed paths\n\nThe changed-path Bloom filters record an entry in the filter for\nevery path that was changed. This includes every add and delete,\nregardless of whether a rename was detected. Detecting renames\ncauses significant performance issues, but also will trigger\ndownloading missing blobs in partial clone.\n\nThe simple fix is to disable rename detection when computing a\nchanged-path Bloom filter. This should already be disabled by\ndefault, but it is good to explicitly enforce the intended\nbehavior.\n\nSigned-off-by: Derrick Stolee <dstolee@microsoft.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "bloom.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/caf388caa101be90b7ec43d7f78ca4e935fc0150",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_bloom_filter"
        ],
        "added_lines": 1,
        "deleted_lines": 0,
        "total_changed_lines": 1,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "caff8b73402d4b5edb2c6c755506c5a90351b69a",
        "author": "Patrick Steinhardt",
        "date": "2021-09-01T12:43:56-07:00",
        "message": "fetch: avoid second connectivity check if we already have all objects\n\nWhen fetching refs, we are doing two connectivity checks:\n\n    - The first one is done such that we can skip fetching refs in the\n      case where we already have all objects referenced by the updated\n      set of refs.\n\n    - The second one verifies that we have all objects after we have\n      fetched objects.\n\nWe always execute both connectivity checks, but this is wasteful in case\nthe first connectivity check already notices that we have all objects\nlocally available.\n\nSkip the second connectivity check in case we already had all objects\navailable. This gives us a nice speedup when doing a mirror-fetch in a\nrepository with about 2.3M refs where the fetching repo already has all\nobjects:\n\n    Benchmark #1: HEAD~: git-fetch\n      Time (mean \u00b1 \u03c3):     30.025 s \u00b1  0.081 s    [User: 27.070 s, System: 4.933 s]\n      Range (min \u2026 max):   29.900 s \u2026 30.111 s    5 runs\n\n    Benchmark #2: HEAD: git-fetch\n      Time (mean \u00b1 \u03c3):     25.574 s \u00b1  0.177 s    [User: 22.855 s, System: 4.683 s]\n      Range (min \u2026 max):   25.399 s \u2026 25.765 s    5 runs\n\n    Summary\n      'HEAD: git-fetch' ran\n        1.17 \u00b1 0.01 times faster than 'HEAD~: git-fetch'\n\nSigned-off-by: Patrick Steinhardt <ps@pks.im>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/fetch.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/caff8b73402d4b5edb2c6c755506c5a90351b69a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "fetch_and_consume_refs"
        ],
        "added_lines": 3,
        "deleted_lines": 4,
        "total_changed_lines": 7,
        "net_line_change": -1,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "cc2a1f98ac1042c7cca0ecedd6d57819c6b8e02e",
        "author": "Taylor Blau",
        "date": "2023-07-10T14:48:56-07:00",
        "message": "builtin/receive-pack.c: avoid enumerating hidden references\n\nNow that `refs_for_each_fullref_in()` has the ability to avoid\nenumerating references matching certain pattern(s), use that to avoid\nvisiting hidden refs when constructing the ref advertisement via\nreceive-pack.\n\nNote that since this exclusion is best-effort, we still need\n`show_ref_cb()` to check whether or not each reference is hidden or not\nbefore including it in the advertisement.\n\nAs was the case when applying this same optimization to `upload-pack`,\n`receive-pack`'s reference advertisement phase can proceed much quicker\nby avoiding enumerating references that will not be part of the\nadvertisement.\n\n(Below, we're still using linux.git with one hidden refs/pull/N ref per\ncommit):\n\n    $ hyperfine -L v ,.compile 'git{v} -c transfer.hideRefs=refs/pull receive-pack --advertise-refs .git'\n    Benchmark 1: git -c transfer.hideRefs=refs/pull receive-pack --advertise-refs .git\n      Time (mean \u00b1 \u03c3):      89.1 ms \u00b1   1.7 ms    [User: 82.0 ms, System: 7.0 ms]\n      Range (min \u2026 max):    87.7 ms \u2026  95.5 ms    31 runs\n\n    Benchmark 2: git.compile -c transfer.hideRefs=refs/pull receive-pack --advertise-refs .git\n      Time (mean \u00b1 \u03c3):       4.5 ms \u00b1   0.2 ms    [User: 0.5 ms, System: 3.9 ms]\n      Range (min \u2026 max):     4.1 ms \u2026   5.6 ms    508 runs\n\n    Summary\n      'git.compile -c transfer.hideRefs=refs/pull receive-pack --advertise-refs .git' ran\n       20.00 \u00b1 1.05 times faster than 'git -c transfer.hideRefs=refs/pull receive-pack --advertise-refs .git'\n\nSigned-off-by: Taylor Blau <me@ttaylorr.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/receive-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/cc2a1f98ac1042c7cca0ecedd6d57819c6b8e02e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "write_head_info"
        ],
        "added_lines": 3,
        "deleted_lines": 1,
        "total_changed_lines": 4,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "cc5e1bf992470e0d514c743e75a0325c8b592f38",
        "author": "Johannes Schindelin",
        "date": "2018-04-24T11:12:31+09:00",
        "message": "gettext: avoid initialization if the locale dir is not present\n\nThe runtime of a simple `git.exe version` call on Windows is currently\ndominated by the gettext setup, adding a whopping ~150ms to the ~210ms\ntotal.\n\nGiven that this cost is added to each and every git.exe invocation goes\nthrough common-main's invocation of git_setup_gettext(), and given that\nscripts have to call git.exe dozens, if not hundreds, of times, this is\na substantial performance penalty.\n\nThis is particularly pointless when considering that Git for Windows\nships without localization (to keep the installer's size to a bearable\n~34MB): all that time setting up gettext is for naught.\n\nTo be clear, Git for Windows *needs* to be compiled with localization,\nfor the following reasons:\n\n- to allow users to copy add-on localization in case they want it, and\n\n- to fix the nasty error message\n\n\tBUG: your vsnprintf is broken (returned -1)\n\n  by using libgettext's override of vsnprintf() that does not share the\n  behavior of msvcrt.dll's version of vsnprintf().\n\nSo let's be smart about it and skip setting up gettext if the locale\ndirectory is not even present.\n\nSince localization might be missing for not-yet-supported locales, this\nwill not break anything.\n\nSigned-off-by: Johannes Schindelin <johannes.schindelin@gmx.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "gettext.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/cc5e1bf992470e0d514c743e75a0325c8b592f38",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "git_setup_gettext"
        ],
        "added_lines": 3,
        "deleted_lines": 0,
        "total_changed_lines": 3,
        "net_line_change": 3,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "ccdc6037fee8761db82ccb8751d9c9442f4a9cc7",
        "author": "Jeff King",
        "date": "2012-01-05T13:30:54-08:00",
        "message": "parse_object: try internal cache before reading object db\n\nWhen parse_object is called, we do the following:\n\n  1. read the object data into a buffer via read_sha1_file\n\n  2. call parse_object_buffer, which then:\n\n     a. calls the appropriate lookup_{commit,tree,blob,tag}\n\tto either create a new \"struct object\", or to find\n\tan existing one. We know the appropriate type from\n\tthe lookup in step 1.\n\n     b. calls the appropriate parse_{commit,tree,blob,tag}\n        to parse the buffer for the new (or existing) object\n\nIn step 2b, all of the called functions are no-ops for\nobject \"X\" if \"X->object.parsed\" is set. I.e., when we have\nalready parsed an object, we end up going to a lot of work\njust to find out at a low level that there is nothing left\nfor us to do (and we throw away the data from read_sha1_file\nunread).\n\nWe can optimize this by moving the check for \"do we have an\nin-memory object\" from 2a before the expensive call to\nread_sha1_file in step 1.\n\nThis might seem circular, since step 2a uses the type\ninformation determined in step 1 to call the appropriate\nlookup function. However, we can notice that all of the\nlookup_* functions are backed by lookup_object. In other\nwords, all of the objects are kept in a master hash table,\nand we don't actually need the type to do the \"do we have\nit\" part of the lookup, only to do the \"and create it if it\ndoesn't exist\" part.\n\nThis can save time whenever we call parse_object on the same\nsha1 twice in a single program. Some code paths already\nperform this optimization manually, with either:\n\n  if (!obj->parsed)\n\t  obj = parse_object(obj->sha1);\n\nif you already have a \"struct object\", or:\n\n  struct object *obj = lookup_unknown_object(sha1);\n  if (!obj || !obj->parsed)\n\t  obj = parse_object(sha1);\n\nif you don't.  This patch moves the optimization into\nparse_object itself.\n\nMost git operations won't notice any impact. Either they\ndon't parse a lot of duplicate sha1s, or the calling code\ntakes special care not to re-parse objects. I timed two\ncode paths that do benefit (there may be more, but these two\nwere immediately obvious and easy to time).\n\nThe first is fast-export, which calls parse_object on each\nobject it outputs, like this:\n\n  object = parse_object(sha1);\n  if (!object)\n\t  die(...);\n  if (object->flags & SHOWN)\n\t  return;\n\nwhich means that just to realize we have already shown an\nobject, we will read the whole object from disk!\n\nWith this patch, my best-of-five time for \"fast-export --all\" on\ngit.git dropped from 26.3s to 21.3s.\n\nThe second case is upload-pack, which will call parse_object\nfor each advertised ref (because it needs to peel tags to\nshow \"^{}\" entries). This doesn't matter for most\nrepositories, because they don't have a lot of refs pointing\nto the same objects. However, if you have a big alternates\nrepository with a shared object db for a number of child\nrepositories, then the alternates repository will have\nduplicated refs representing each of its children.\n\nFor example, GitHub's alternates repository for git.git has\n~120,000 refs, of which only ~3200 are unique. The time for\nupload-pack to print its list of advertised refs dropped\nfrom 3.4s to 0.76s.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "object.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/ccdc6037fee8761db82ccb8751d9c9442f4a9cc7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "parse_object"
        ],
        "added_lines": 7,
        "deleted_lines": 2,
        "total_changed_lines": 9,
        "net_line_change": 5,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "cd3799679533328dcf262549c9d6466b07628df1",
        "author": "Jeff King",
        "date": "2016-07-29T11:05:07-07:00",
        "message": "pack-objects: break out of want_object loop early\n\nWhen pack-objects collects the list of objects to pack\n(either from stdin, or via its internal rev-list), it\nfilters each one through want_object_in_pack().\n\nThis function loops through each existing packfile, looking\nfor the object. When we find it, we mark the pack/offset\ncombo for later use. However, we can't just return \"yes, we\nwant it\" at that point. If --honor-pack-keep is in effect,\nwe must keep looking to find it in _all_ packs, to make sure\nnone of them has a .keep. Likewise, if --local is in effect,\nwe must make sure it is not present in any non-local pack.\n\nAs a result, the sum effort of these calls is effectively\nO(nr_objects * nr_packs). In an ordinary repository, we have\nonly a handful of packs, and this doesn't make a big\ndifference. But in pathological cases, it can slow the\ncounting phase to a crawl.\n\nThis patch notices the case that we have neither \"--local\"\nnor \"--honor-pack-keep\" in effect and breaks out of the loop\nearly, after finding the first instance. Note that our worst\ncase is still \"objects * packs\" (i.e., we might find each\nobject in the last pack we look in), but in practice we will\noften break out early. On an \"average\" repo, my git.git with\n8 packs, this shows a modest 2% (a few dozen milliseconds)\nimprovement in the counting-objects phase of \"git\npack-objects --all <foo\" (hackily instrumented by sticking\nexit(0) right after list_objects).\n\nBut in a much more pathological case, it makes a bigger\ndifference. I ran the same command on a real-world example\nwith ~9 million objects across 1300 packs. The counting time\ndropped from 413s to 45s, an improvement of about 89%.\n\nNote that this patch won't do anything by itself for a\nnormal \"git gc\", as it uses both --honor-pack-keep and\n--local.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/pack-objects.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/cd3799679533328dcf262549c9d6466b07628df1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "want_object_in_pack"
        ],
        "added_lines": 16,
        "deleted_lines": 0,
        "total_changed_lines": 16,
        "net_line_change": 16,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "cd585e2a33841d725b821adbb9b48654fc7d0b61",
        "author": "Jonathan Tan",
        "date": "2017-06-26T10:28:58-07:00",
        "message": "sha1_file: do not access pack if unneeded\n\nCurrently, regardless of the contents of the \"struct object_info\" passed\nto sha1_object_info_extended(), that function always accesses the\npackfile whenever it returns information about a packed object, since it\nneeds to populate \"u.packed\".\n\nAdd the ability to pass NULL, and use NULL-ness of the argument to\nactivate an optimization in which sha1_object_info_extended() does not\nneedlessly access the packfile. A subsequent patch will make use of this\noptimization.\n\nA similar optimization is not made for the cached and loose cases as it\nwould not cause a significant performance improvement.\n\nSigned-off-by: Jonathan Tan <jonathantanmy@google.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "sha1_file.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/cd585e2a33841d725b821adbb9b48654fc7d0b61",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sha1_object_info_extended"
        ],
        "added_lines": 11,
        "deleted_lines": 0,
        "total_changed_lines": 11,
        "net_line_change": 11,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "ce163c793d2058056ccc57563c350fd6415397ca",
        "author": "Ren\u00e9 Scharfe",
        "date": "2009-03-02T18:28:03-08:00",
        "message": "diffcore-pickaxe: use memmem()\n\nUse memmem() instead of open-coding it.  The system libraries usually have a\nmuch faster version than the memcmp()-loop here.  Even our own fall-back in\ncompat/, which is used on Windows, is slightly faster.\n\nThe following commands were run in a Linux kernel repository and timed, the\nbest of five results is shown:\n\n  $ STRING='Ensure that the real time constraints are schedulable.'\n  $ git log -S\"$STRING\" HEAD -- kernel/sched.c >/dev/null\n\nOn Ubuntu 8.10 x64, before (v1.6.2-rc2):\n\n  8.09user 0.04system 0:08.14elapsed 99%CPU (0avgtext+0avgdata 0maxresident)k\n  0inputs+0outputs (0major+30952minor)pagefaults 0swaps\n\nAnd with the patch:\n\n  1.50user 0.04system 0:01.54elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k\n  0inputs+0outputs (0major+30645minor)pagefaults 0swaps\n\nOn Fedora 10 x64, before:\n\n  8.34user 0.05system 0:08.39elapsed 99%CPU (0avgtext+0avgdata 0maxresident)k\n  0inputs+0outputs (0major+29268minor)pagefaults 0swaps\n\nAnd with the patch:\n\n  1.15user 0.05system 0:01.20elapsed 99%CPU (0avgtext+0avgdata 0maxresident)k\n  0inputs+0outputs (0major+32253minor)pagefaults 0swaps\n\nOn Windows Vista x64, before:\n\n  real    0m9.204s\n  user    0m0.000s\n  sys     0m0.000s\n\nAnd with the patch:\n\n  real    0m8.470s\n  user    0m0.000s\n  sys     0m0.000s\n\nSigned-off-by: Rene Scharfe <rene.scharfe@lsrfire.ath.cx>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "diffcore-pickaxe.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/ce163c793d2058056ccc57563c350fd6415397ca",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "contains"
        ],
        "added_lines": 8,
        "deleted_lines": 10,
        "total_changed_lines": 18,
        "net_line_change": -2,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "ced9fff75dad2578d7583ba3085970b03c66c57b",
        "author": "Jeff King",
        "date": "2018-08-14T12:27:53-07:00",
        "message": "cat-file: use oidset check-and-insert\n\nWe don't need to check if the oidset has our object before\nwe insert it; that's done as part of the insertion. We can\njust rely on the return value from oidset_insert(), which\nsaves one hash lookup per object.\n\nThis measurable speedup is tiny and within the run-to-run\nnoise, but the result is simpler to read, too.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/cat-file.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/ced9fff75dad2578d7583ba3085970b03c66c57b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "batch_unordered_object"
        ],
        "added_lines": 1,
        "deleted_lines": 2,
        "total_changed_lines": 3,
        "net_line_change": -1,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "d1664e73ad96aa08735bf81d48ec0fb6d196cc3e",
        "author": "Ben Peart",
        "date": "2018-11-03T00:43:04+09:00",
        "message": "add: speed up cmd_add() by utilizing read_cache_preload()\n\nDuring an \"add\", a call is made to run_diff_files() which calls\ncheck_removed() for each index-entry.  The preload_index() code\ndistributes some of the costs across multiple threads.\n\nBecause the files checked are restricted to pathspec, adding\nindividual files makes no measurable impact but on a Windows repo\nwith ~200K files, 'git add .' drops from 6.3 seconds to 3.3 seconds\nfor a 47% savings.\n\nSigned-off-by: Ben Peart <benpeart@microsoft.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/add.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/d1664e73ad96aa08735bf81d48ec0fb6d196cc3e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_add"
        ],
        "added_lines": 4,
        "deleted_lines": 5,
        "total_changed_lines": 9,
        "net_line_change": -1,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "d21c463d558a1450c2560869193f279fc7ddba4a",
        "author": "Junio C Hamano",
        "date": "2012-03-15T15:23:17-07:00",
        "message": "fetch/receive: remove over-pessimistic connectivity check\n\nGit 1.7.8 introduced an object and history re-validation step after\n\"fetch\" or \"push\" causes new history to be added to a receiving\nrepository. This is to protect a malicious server or pushing client from\ncorrupting the repository by taking advantage of an existing corrupt\nobject that is unconnected to existing history.\n\nBut this check is way over-pessimistic.  During \"fetch\" or \"receive-pack\"\n(the server side of \"push\"), unpack-objects and index-pack already\nvalidate individual objects that are received, and the only thing we would\nwant to catch are corrupted objects that already happen to exist in our\nrepository but are not referenced from our refs.  Such objects must have\nbeen written by an earlier run of our codepaths that write out loose\nobjects or packfiles, and they must have done the validation of individual\nobjects when they did so.  The only thing left to worry about is the\nconnectivity integrity, which can be checked with \"rev-list --objects\",\nwhich is much cheaper.  We have been paying the 5x to 8x runtime overhead\nthe --verify-objects often adds for no real gain.\n\nRevert check_everything_connected() not to use this over-pessimistic\ncheck.\n\nCredit goes to Nguy\u1ec5n Th\u00e1i Ng\u1ecdc Duy, who originally identified the\nperformance regression and endured multiple rounds of reviews to fix it.\n\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "connected.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/d21c463d558a1450c2560869193f279fc7ddba4a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "check_everything_connected"
        ],
        "added_lines": 4,
        "deleted_lines": 4,
        "total_changed_lines": 8,
        "net_line_change": 0,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "d35825da6d5570524234e1bfe4ff0f57957b6db3",
        "author": "Nicolas Pitre",
        "date": "2008-08-29T21:51:28-07:00",
        "message": "fixup_pack_header_footer(): use nicely aligned buffer sizes\n\nIt should be more efficient to use nicely aligned buffer sizes, either\nfor filesystem operations or SHA1 checksums.  Also, using a relatively\nsmall nominal size might allow for the data to remain in L1 cache\nbetween both SHA1_Update() calls.\n\nSigned-off-by: Nicolas Pitre <nico@cam.org>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "pack-write.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/d35825da6d5570524234e1bfe4ff0f57957b6db3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "fixup_pack_header_footer"
        ],
        "added_lines": 8,
        "deleted_lines": 3,
        "total_changed_lines": 11,
        "net_line_change": 5,
        "modified_code_blocks": 4,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "d5120daba4f91c97fb9eb77e32f0f9e009bb515a",
        "author": "Junio C Hamano",
        "date": "2018-03-08T12:36:27-08:00",
        "message": "Merge branch 'ds/mark-parents-uninteresting-optim'\n\nMicro optimization in revision traversal code.\n\n* ds/mark-parents-uninteresting-optim:\n  revision.c: reduce object database queries",
        "modified_files_count": 1,
        "modified_files": [
            "revision.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/d5120daba4f91c97fb9eb77e32f0f9e009bb515a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mark_parents_uninteresting"
        ],
        "added_lines": 2,
        "deleted_lines": 1,
        "total_changed_lines": 3,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "d699676dda5fdf0996601006c3bac2a9c077a862",
        "author": "Linus Torvalds",
        "date": "2007-08-10T14:00:25-07:00",
        "message": "Optimize the two-way merge of git-read-tree too\n\nThis trivially optimizes the two-way merge case of git-read-tree too,\nwhich affects switching branches.\n\nWhen you have tons and tons of files in your repository, but there are\nonly small differences in the branches (maybe just a couple of files\nchanged), the biggest cost of the branch switching was actually just the\nindex calculations.\n\nThis fixes it (timings for switching between the \"testing\" and \"master\"\nbranches in the 100,000 file testing-repo-from-hell, where the branches\nonly differ in one small file).\n\nBefore:\n\t[torvalds@woody bummer]$ time git checkout master\n\treal    0m9.919s\n\tuser    0m8.461s\n\tsys     0m0.264s\n\nAfter:\n\t[torvalds@woody bummer]$ time git checkout testing\n\treal    0m0.576s\n\tuser    0m0.348s\n\tsys     0m0.228s\n\nso it's easily an order of magnitude different.\n\nThis concludes the series. I think we could/should do the three-way merge\ntoo (to speed up merges), but I'm lazy. Somebody else can do it.\n\nThe rule is very simple: you need to remove the old entry if:\n - you want to remove the file entirely\n - you replace it with a \"merge conflict\" entry (ie a non-stage-0 entry)\n\nand you can avoid removing it if you either\n\n - keep the old one\n - or resolve it to a new one.\n\nand these rules should all be valid for the three-way case too.\n\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "unpack-trees.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/d699676dda5fdf0996601006c3bac2a9c077a862",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "twoway_merge"
        ],
        "added_lines": 4,
        "deleted_lines": 3,
        "total_changed_lines": 7,
        "net_line_change": 1,
        "modified_code_blocks": 4,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "d7574c95bb74cd189950cc6e9cad762099382162",
        "author": "\u00c6var Arnfj\u00f6r\u00f0 Bjarmason",
        "date": "2019-01-22T11:32:56-08:00",
        "message": "commit-graph write: use pack order when finding commits\n\nSlightly optimize the \"commit-graph write\" step by using\nFOR_EACH_OBJECT_PACK_ORDER with for_each_object_in_pack(). See commit\n[1] and [2] for the facility and a similar optimization for \"cat-file\".\n\nOn Linux it is around 5% slower to run:\n\n    echo 1 >/proc/sys/vm/drop_caches &&\n    cat .git/objects/pack/* >/dev/null &&\n    git cat-file --batch-all-objects --batch-check --unordered\n\nThan the same thing with the \"cat\" omitted. This is as expected, since\nwe're iterating in pack order and the \"cat\" is extra work.\n\nBefore this change the opposite was true of \"commit-graph write\". We\nwere 6% faster if we first ran \"cat\" to efficiently populate the FS\ncache for our sole big pack on linux.git, than if we had populated it\nvia for_each_object_in_pack(). Now we're 3% faster without the \"cat\"\ninstead.\n\nMy tests were done on an unloaded Linux 3.10 system with 10 runs for\neach. Derrick Stolee did his own tests on Windows[3] showing a 2%\nimprovement with a high degree of accuracy.\n\n1. 736eb88fdc (\"for_each_packed_object: support iterating in\n   pack-order\", 2018-08-10)\n\n2. 0750bb5b51 (\"cat-file: support \"unordered\" output for\n   --batch-all-objects\", 2018-08-10)\n\n3. https://public-inbox.org/git/f71fa868-25e8-a9c9-46a6-611b987f1a8f@gmail.com/\n\nSigned-off-by: \u00c6var Arnfj\u00f6r\u00f0 Bjarmason <avarab@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "commit-graph.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/d7574c95bb74cd189950cc6e9cad762099382162",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "write_commit_graph"
        ],
        "added_lines": 4,
        "deleted_lines": 2,
        "total_changed_lines": 6,
        "net_line_change": 2,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "dbe4e8b3fdd11b96e3ae291ecd09ed6d763a44a1",
        "author": "Patrick Steinhardt",
        "date": "2024-02-12T09:18:04-08:00",
        "message": "reftable/pq: allocation-less comparison of entry keys\n\nThe priority queue is used by the merged iterator to iterate over\nreftable records from multiple tables in the correct order. The queue\nends up having one record for each table that is being iterated over,\nwith the record that is supposed to be shown next at the top. For\nexample, the key of a ref record is equal to its name so that we end up\nsorting the priority queue lexicographically by ref name.\n\nTo figure out the order we need to compare the reftable record keys with\neach other. This comparison is done by formatting them into a `struct\nstrbuf` and then doing `strbuf_strcmp()` on the result. We then discard\nthe buffers immediately after the comparison.\n\nThis ends up being very expensive. Because the priority queue usually\ncontains as many records as we have tables, we call the comparison\nfunction `O(log($tablecount))` many times for every record we insert.\nFurthermore, when iterating over many refs, we will insert at least one\nrecord for every ref we are iterating over. So ultimately, this ends up\nbeing called `O($refcount * log($tablecount))` many times.\n\nRefactor the code to use the new `refatble_record_cmp()` function that\nhas been implemented in a preceding commit. This function does not need\nto allocate memory and is thus significantly more efficient.\n\nThe following benchmark prints a single ref matching a specific pattern\nout of 1 million refs via git-show-ref(1), where the reftable stack\nconsists of three tables:\n\n  Benchmark 1: show-ref: single matching ref (revision = HEAD~)\n    Time (mean \u00b1 \u03c3):     224.4 ms \u00b1   6.5 ms    [User: 220.6 ms, System: 3.6 ms]\n    Range (min \u2026 max):   216.5 ms \u2026 261.1 ms    1000 runs\n\n  Benchmark 2: show-ref: single matching ref (revision = HEAD)\n    Time (mean \u00b1 \u03c3):     172.9 ms \u00b1   4.4 ms    [User: 169.2 ms, System: 3.6 ms]\n    Range (min \u2026 max):   166.5 ms \u2026 204.6 ms    1000 runs\n\n  Summary\n    show-ref: single matching ref (revision = HEAD) ran\n      1.30 \u00b1 0.05 times faster than show-ref: single matching ref (revision = HEAD~)\n\nSigned-off-by: Patrick Steinhardt <ps@pks.im>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "reftable/pq.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/dbe4e8b3fdd11b96e3ae291ecd09ed6d763a44a1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "pq_less"
        ],
        "added_lines": 1,
        "deleted_lines": 12,
        "total_changed_lines": 13,
        "net_line_change": -11,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "dd2e50a84ea431a6cec69f37251f29bf3cfcbb68",
        "author": "Jeff King",
        "date": "2019-09-09T10:56:50-07:00",
        "message": "commit-graph: turn off save_commit_buffer\n\nThe commit-graph tool may read a lot of commits, but it only cares about\nparsing their metadata (parents, trees, etc) and doesn't ever show the\nmessages to the user. And so it should not need save_commit_buffer,\nwhich is meant for holding onto the object data of parsed commits so\nthat we can show them later. In fact, it's quite harmful to do so.\nAccording to massif, the max heap of \"git commit-graph write\n--reachable\" in linux.git before/after this patch (removing the commit\ngraph file in between) goes from ~1.1GB to ~270MB.\n\nWhich isn't surprising, since the difference is about the sum of the\nuncompressed sizes of all commits in the repository, and this was\nequivalent to leaking them.\n\nThis obviously helps if you're under memory pressure, but even without\nit, things go faster. My before/after times for that command (without\nmassif) went from 12.521s to 11.874s, a speedup of ~5%.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/commit-graph.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/dd2e50a84ea431a6cec69f37251f29bf3cfcbb68",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_commit_graph"
        ],
        "added_lines": 2,
        "deleted_lines": 0,
        "total_changed_lines": 2,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "ddd63e64e4ac7e455dff3e807bf6a6977bb61456",
        "author": "Steven Grimm",
        "date": "2008-08-05T21:21:20-07:00",
        "message": "Optimize sha1_object_info for loose objects, not concurrent repacks\n\nWhen dealing with a repository with lots of loose objects, sha1_object_info\nwould rescan the packs directory every time an unpacked object was referenced\nbefore finally giving up and looking for the loose object. This caused a lot\nof extra unnecessary system calls during git pack-objects; the code was\nrereading the entire pack directory once for each loose object file.\n\nThis patch looks for a loose object before falling back to rescanning the\npack directory, rather than the other way around.\n\nSigned-off-by: Steven Grimm <koreth@midwinter.com>\nAcked-by: Shawn O. Pearce <spearce@spearce.org>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "sha1_file.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/ddd63e64e4ac7e455dff3e807bf6a6977bb61456",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sha1_object_info"
        ],
        "added_lines": 8,
        "deleted_lines": 1,
        "total_changed_lines": 9,
        "net_line_change": 7,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "df7000cd910a5f6991f73991b87d838a5d75e2fc",
        "author": "Johannes Schindelin",
        "date": "2021-11-03T11:22:26-07:00",
        "message": "test-tool genzeros: generate large amounts of data more efficiently\n\nIn this developer's tests, producing one gigabyte worth of NULs in a\nbusy loop that writes out individual bytes, unbuffered, took ~27sec.\nWriting chunked 256kB buffers instead only took ~0.6sec\n\nThis matters because we are about to introduce a pair of test cases that\nwant to be able to produce 5GB of NULs, and we cannot use `/dev/zero`\nbecause of the HP NonStop platform's lack of support for that device.\n\nSigned-off-by: Johannes Schindelin <johannes.schindelin@gmx.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "t/helper/test-genzeros.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/df7000cd910a5f6991f73991b87d838a5d75e2fc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd__genzeros"
        ],
        "added_lines": 15,
        "deleted_lines": 2,
        "total_changed_lines": 17,
        "net_line_change": 13,
        "modified_code_blocks": 4,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "df786f6efeaa302fa0bf1d39f46fe2528103e9bc",
        "author": "Junio C Hamano",
        "date": "2023-01-21T17:21:59-08:00",
        "message": "Merge branch 'sk/merge-filtering-strategies-micro-optim'\n\nMicro optimization.\n\n* sk/merge-filtering-strategies-micro-optim:\n  merge: break out of all_strategy loop when strategy is found",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/merge.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/df786f6efeaa302fa0bf1d39f46fe2528103e9bc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_strategy"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "df874fa82ef06c8c438b9a19c56c0b5eb089c012",
        "author": "Junio C Hamano",
        "date": "2013-01-10T12:33:09-08:00",
        "message": "log --use-mailmap: optimize for cases without --author/--committer search\n\nWhen we taught the commit_match() mechanism to pay attention to the\nnew --use-mailmap option, we started to unconditionally copy the\ncommit object to a temporary buffer, just in case we need the author\nand committer lines updated via the mailmap mechanism, and rewrite\nauthor and committer using the mailmap.\n\nIt turns out that this has a rather unpleasant performance\nimplications.  In the linux kernel repository, running\n\n  $ git log --author='Junio C Hamano' --pretty=short >/dev/null\n\nunder /usr/bin/time, with and without --use-mailmap (the .mailmap\nfile is 118 entries long, the particular author does not appear in\nit), cost (with warm cache):\n\n  [without --use-mailmap]\n  5.42user 0.26system 0:05.70elapsed 99%CPU (0avgtext+0avgdata 2005936maxresident)k\n  0inputs+0outputs (0major+137669minor)pagefaults 0swaps\n\n  [with --use-mailmap]\n  6.47user 0.30system 0:06.78elapsed 99%CPU (0avgtext+0avgdata 2006288maxresident)k\n  0inputs+0outputs (0major+137692minor)pagefaults 0swaps\n\nwhich incurs about 20% overhead.  The command is doing extra work,\nso the extra cost may be justified.\n\nBut it is inexcusable to pay the cost when we do not need\nauthor/committer match.  In the same repository,\n\n  $ git log --grep='fix menuconfig on debian lenny' --pretty=short >/dev/null\n\nshows very similar numbers as the above:\n\n  [without --use-mailmap]\n  5.32user 0.30system 0:05.63elapsed 99%CPU (0avgtext+0avgdata 2005984maxresident)k\n  0inputs+0outputs (0major+137672minor)pagefaults 0swaps\n\n  [with --use-mailmap]\n  6.64user 0.24system 0:06.89elapsed 99%CPU (0avgtext+0avgdata 2006320maxresident)k\n  0inputs+0outputs (0major+137694minor)pagefaults 0swaps\n\nThe latter case is an unnecessary performance regression.  We may\nwant to _show_ the result with mailmap applied, but we do not have\nto copy and rewrite the author/committer of all commits we try to\nmatch if we do not query for these fields.\n\nTrivially optimize this performace regression by limiting the\nrewrites for only when we are matching with author/committer fields.\n\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "revision.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/df874fa82ef06c8c438b9a19c56c0b5eb089c012",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "commit_match"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "e06c43c7959042e5612984b8193700f32f12b2be",
        "author": "Junio C Hamano",
        "date": "2008-04-12T19:42:17-07:00",
        "message": "write_index(): optimize ce_smudge_racily_clean_entry() calls with CE_UPTODATE\n\nWhen writing the index out, we need to check the work tree again to see if\nan entry whose timestamp indicates that it could be \"racily clean\", in\norder to smudge it if it is stat-clean but with modified contents.\n\nHowever, we can skip this step for entries marked with CE_UPTODATE,\nwhich are known to be the really clean (i.e. the one we already have\nchecked when we prepared the index).  This will reduce lstat(2) calls\nnecessary in git-status.\n\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "read-cache.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/e06c43c7959042e5612984b8193700f32f12b2be",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "write_index"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "e4c7292353dbef39feac1c6a60c5cde9140520a6",
        "author": "Kjetil Barvik",
        "date": "2009-02-09T20:59:26-08:00",
        "message": "write_entry(): use fstat() instead of lstat() when file is open\n\nCurrently inside write_entry() we do an lstat(path, &st) call on a\nfile which have just been opened inside the exact same function.  It\nshould be better to call fstat(fd, &st) on the file while it is open,\nand it should be at least as fast as the lstat() method.\n\nSigned-off-by: Kjetil Barvik <barvik@broadpark.no>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "entry.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/e4c7292353dbef39feac1c6a60c5cde9140520a6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "write_entry"
        ],
        "added_lines": 9,
        "deleted_lines": 3,
        "total_changed_lines": 12,
        "net_line_change": 6,
        "modified_code_blocks": 4,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "e5494631ed94017da862d55eb6393a0d01d8b91d",
        "author": "Jeff Hostetler",
        "date": "2017-04-19T20:33:01-07:00",
        "message": "read-cache: speed up add_index_entry during checkout\n\nTeach add_index_entry_with_check() to see if the path\nof the new item is greater than the last path in the\nindex array before attempting to search for it.\n\nDuring checkout, merge_working_tree() populates the new\nindex in sorted order, so this change will save a binary\nlookups per file.  This preserves the original behavior\nbut simply checks the last element before starting the\nsearch.\n\nThis helps performance on very large repositories.\n\nSigned-off-by: Jeff Hostetler <jeffhost@microsoft.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "read-cache.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/e5494631ed94017da862d55eb6393a0d01d8b91d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "add_index_entry_with_check"
        ],
        "added_lines": 10,
        "deleted_lines": 1,
        "total_changed_lines": 11,
        "net_line_change": 9,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "e596acc23a8c92784349da613502626d758215b2",
        "author": "Jeff Hostetler",
        "date": "2017-02-10T14:44:18-08:00",
        "message": "preload-index: avoid lstat for skip-worktree items\n\nTeach preload-index to avoid lstat() calls for index-entries\nwith skip-worktree bit set.  This is a performance optimization.\n\nDuring a sparse-checkout, the skip-worktree bit is set on items\nthat were not populated and therefore are not present in the\nworktree.  The per-thread preload-index loop performs a series\nof tests on each index-entry as it attempts to compare the\nworktree version with the index and mark them up-to-date.\nThis patch short-cuts that work.\n\nOn a Windows 10 system with a very large repo (450MB index)\nand various levels of sparseness, performance was improved\nin the {preloadindex=true, fscache=false} case by 80% and\nin the {preloadindex=true, fscache=true} case by 20% for various\ncommands.\n\nSigned-off-by: Jeff Hostetler <jeffhost@microsoft.com>\nSigned-off-by: Johannes Schindelin <johannes.schindelin@gmx.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "preload-index.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/e596acc23a8c92784349da613502626d758215b2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "preload_thread"
        ],
        "added_lines": 2,
        "deleted_lines": 0,
        "total_changed_lines": 2,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "e6812cfa9aba69a8c9d83b0710291b27bff0f7a3",
        "author": "Felipe Contreras",
        "date": "2013-05-07T07:03:01-07:00",
        "message": "fast-export: do not parse non-commit objects while reading marks file\n\nWe read from the marks file and keep only marked commits, but in\norder to find the type of object, we are parsing the whole thing,\nwhich is slow, specially in big repositories with lots of big files.\n\nThere's no need for that, we can query the object information with\nsha1_object_info().\n\nBefore this, loading the objects of a fresh emacs import, with 260598\nblobs took 14 minutes, after this patch, it takes 3 seconds.\n\nThis is the way fast-import does it. Also die if the object is not\nfound (like fast-import).\n\nSigned-off-by: Felipe Contreras <felipe.contreras@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/fast-export.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/e6812cfa9aba69a8c9d83b0710291b27bff0f7a3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "import_marks"
        ],
        "added_lines": 9,
        "deleted_lines": 6,
        "total_changed_lines": 15,
        "net_line_change": 3,
        "modified_code_blocks": 4,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "e6aac8177d02691bebedec56376ed17239793f9f",
        "author": "Johannes Schindelin",
        "date": "2019-03-04T13:31:03+09:00",
        "message": "built-in rebase: no need to check out `onto` twice\n\nIn the case that the rebase boils down to a fast-forward, the built-in\nrebase reset the working tree twice: once to start the rebase at `onto`,\nthen realizing that the original (pre-rebase) HEAD was an ancestor and\nwe basically already fast-forwarded to the post-rebase HEAD,\n`reset_head()` was called to update the original ref and to point HEAD\nback to it.\n\nThat second `reset_head()` call does not need to touch the working tree,\nthough, as it does not change the actual tip commit (and therefore the\nworking tree should stay unchanged anyway): only the ref needs to be\nupdated (because the rebase detached the HEAD, and we want to go back to\nthe branch on which the rebase was started).\n\nBut that second `reset_head()` was called without the flag to leave the\nworking tree alone (the reason: when that call was introduced, that flag\nwas not yet even thought of). Let's avoid that unnecessary work by\npassing that flag.\n\nSigned-off-by: Johannes Schindelin <johannes.schindelin@gmx.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/rebase.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/e6aac8177d02691bebedec56376ed17239793f9f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_rebase"
        ],
        "added_lines": 2,
        "deleted_lines": 2,
        "total_changed_lines": 4,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "e93ec6f9d8dd122557d54505129f7860b9301503",
        "author": "Junio C Hamano",
        "date": "2006-01-19T18:29:11-08:00",
        "message": "Revert \"check_packed_git_idx(): check integrity of the idx file itself.\"\n\nThis reverts c5ced64578a82b9d172aceb2f67c6fb9e639f6d9 commit.\nIt turns out that doing this check every time we map the idx file\nis quite expensive.  A corrupt idx file is caught by git-fsck-objects,\nso this check is not strictly necessary.\n\nIn one unscientific test, 0.99.9m spent 10 seconds usertime for\nthe same task 1.1.3 takes 37 seconds usertime.  Reverting this gives\nus the performance of 0.99.9 back.",
        "modified_files_count": 1,
        "modified_files": [
            "sha1_file.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/e93ec6f9d8dd122557d54505129f7860b9301503",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "check_packed_git_idx"
        ],
        "added_lines": 1,
        "deleted_lines": 15,
        "total_changed_lines": 16,
        "net_line_change": -14,
        "modified_code_blocks": 4,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "ebb722625805a0e98b5b8c062b79abd8eca1f639",
        "author": "Junio C Hamano",
        "date": "2013-04-05T10:31:09-07:00",
        "message": "diffcore-pickaxe: port optimization from has_changes() to diff_grep()\n\nThese two functions are called in the same codeflow to implement\n\"log -S<block>\" and \"log -G<pattern>\", respectively, but the latter\nlacked two obvious optimizations the former implemented, namely:\n\n - When a pickaxe limit is not given at all, they should return\n   without wasting any cycle;\n\n - When both sides of the filepair are the same, and the same\n   textconv conversion apply to them, return early, as there will be\n   no interesting differences between the two anyway.\n\nAlso release the filespec data once the processing is done (this is\nnot about leaking memory--it is about releasing data we finished\nlooking at as early as possible).\n\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "diffcore-pickaxe.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/ebb722625805a0e98b5b8c062b79abd8eca1f639",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "diff_grep"
        ],
        "added_lines": 6,
        "deleted_lines": 1,
        "total_changed_lines": 7,
        "net_line_change": 5,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "ebbed3ba04ce8e3cd9dff0e86717fb7e3d42db37",
        "author": "Derrick Stolee",
        "date": "2018-02-27T15:04:52-08:00",
        "message": "revision.c: reduce object database queries\n\nIn mark_parents_uninteresting(), we check for the existence of an\nobject file to see if we should treat a commit as parsed. The result\nis to set the \"parsed\" bit on the commit.\n\nModify the condition to only check has_object_file() if the result\nwould change the parsed bit.\n\nWhen a local branch is different from its upstream ref, \"git status\"\nwill compute ahead/behind counts. This uses paint_down_to_common()\nand hits mark_parents_uninteresting(). On a copy of the Linux repo\nwith a local instance of \"master\" behind the remote branch\n\"origin/master\" by ~60,000 commits, we find the performance of\n\"git status\" went from 1.42 seconds to 1.32 seconds, for a relative\ndifference of -7.0%.\n\nSigned-off-by: Derrick Stolee <dstolee@microsoft.com>\nReviewed-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "revision.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/ebbed3ba04ce8e3cd9dff0e86717fb7e3d42db37",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mark_parents_uninteresting"
        ],
        "added_lines": 2,
        "deleted_lines": 1,
        "total_changed_lines": 3,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "ec0c5798ee9376382d44163d38156fd47e8001c2",
        "author": "Jonathan Tan",
        "date": "2018-12-28T10:39:48-08:00",
        "message": "revision: use commit graph in get_reference()\n\nWhen fetching into a repository, a connectivity check is first made by\ncheck_exist_and_connected() in builtin/fetch.c that runs:\n\n  git rev-list --objects --stdin --not --all --quiet <(list of objects)\n\nIf the client repository has many refs, this command can be slow,\nregardless of the nature of the server repository or what is being\nfetched. A profiler reveals that most of the time is spent in\nsetup_revisions() (approx. 60/63), and of the time spent in\nsetup_revisions(), most of it is spent in parse_object() (approx.\n49/60). This is because setup_revisions() parses the target of every ref\n(from \"--all\"), and parse_object() reads the buffer of the object.\n\nReading the buffer is unnecessary if the repository has a commit graph\nand if the ref points to a commit (which is typically the case). This\npatch uses the commit graph wherever possible; on my computer, when I\nrun the above command with a list of 1 object on a many-ref repository,\nI get a speedup from 1.8s to 1.0s.\n\nAnother way to accomplish this effect would be to modify parse_object()\nto use the commit graph if possible; however, I did not want to change\nparse_object()'s current behavior of always checking the object\nsignature of the returned object.\n\nSigned-off-by: Jonathan Tan <jonathantanmy@google.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "revision.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/ec0c5798ee9376382d44163d38156fd47e8001c2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_reference"
        ],
        "added_lines": 14,
        "deleted_lines": 1,
        "total_changed_lines": 15,
        "net_line_change": 13,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "ecf4c2ec6ba6dc39e72c6b37f2a238e28fec2dc1",
        "author": "Junio C Hamano",
        "date": "2008-02-05T00:38:41-08:00",
        "message": "builtin-apply.c: optimize match_beginning/end processing a bit.\n\nWnen the caller knows the hunk needs to match at the beginning\nor at the end, there is no point starting from the line number\nthat is found in the patch and trying match with increasing\noffset.  The logic to find matching lines was made more line\noriented with the previous patch and this optimization is now\ntrivial.\n\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin-apply.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/ecf4c2ec6ba6dc39e72c6b37f2a238e28fec2dc1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "find_pos"
        ],
        "added_lines": 10,
        "deleted_lines": 0,
        "total_changed_lines": 10,
        "net_line_change": 10,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "ed016612e6956496d5028e41f6414be29c09be4e",
        "author": "Jeff King",
        "date": "2013-09-03T10:36:12-07:00",
        "message": "pager: turn on \"cat\" optimization for DEFAULT_PAGER\n\nIf the user specifies a pager of \"cat\" (or the empty\nstring), whether it is in the environment or from config, we\nautomagically optimize it out to mean \"no pager\" and avoid\nforking at all. We treat an empty pager variable similary.\n\nHowever, we did not apply this optimization when\nDEFAULT_PAGER was set to \"cat\" (or the empty string). There\nis no reason to treat DEFAULT_PAGER any differently. The\noptimization should not be user-visible (unless the user has\na bizarre \"cat\" in their PATH). And even if it is, we are\nbetter off behaving consistently between the compile-time\ndefault and the environment and config settings.\n\nThe stray \"else\" we are removing from this code was\nintroduced by 402461a (pager: do not fork a pager if PAGER\nis set to empty., 2006-04-16). At that time, the line\ndirectly above used:\n\n   if (!pager)\n\t   pager = \"less\";\n\nas a fallback, meaning that it could not possibly trigger\nthe optimization. Later, a3d023d (Provide a build time\ndefault-pager setting, 2009-10-30) turned that constant into\na build-time setting which could be anything, but didn't\nloosen the \"else\" to let DEFAULT_PAGER use the optimization.\n\nNoticed-by: Dale R. Worley <worley@alum.mit.edu>\nSuggested-by: Matthieu Moy <Matthieu.Moy@grenoble-inp.fr>\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "pager.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/ed016612e6956496d5028e41f6414be29c09be4e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "if"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "eede9f42b52b4001ffe844af061315b766682a69",
        "author": "Nicolas Pitre",
        "date": "2008-09-02T17:05:54-07:00",
        "message": "pack-objects: don't include missing preferred base objects\n\nThis improves commit 6d6f9cddbe a bit by simply not including missing\nbases in the list of objects to process at all.\n\nSigned-off-by: Nicolas Pitre <nico@cam.org>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin-pack-objects.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/eede9f42b52b4001ffe844af061315b766682a69",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "prepare_pack"
        ],
        "added_lines": 8,
        "deleted_lines": 0,
        "total_changed_lines": 8,
        "net_line_change": 8,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "f22ca7c50d79fcfd769ddcda988e0981fb883a16",
        "author": "robfitz@273k.net",
        "date": "2005-10-08T15:54:35-07:00",
        "message": "Reduce memory usage in git-update-server-info.\n\nModify parse_object_cheap() to also free all the entries from the tree\ndata structures.\n\nSigned-off-by: Robert Fitzsimons <robfitz@273k.net>\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "server-info.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/f22ca7c50d79fcfd769ddcda988e0981fb883a16",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "if"
        ],
        "added_lines": 10,
        "deleted_lines": 0,
        "total_changed_lines": 10,
        "net_line_change": 10,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "f26eef302fc315394d1016eb06360637ac86f62e",
        "author": "Jeff King",
        "date": "2016-07-20T12:09:31-07:00",
        "message": "check_everything_connected: always pass --quiet to rev-list\n\nThe check_everything_connected function takes a \"quiet\"\nparameter which does two things if non-zero:\n\n  1. redirect rev-list's stderr to /dev/null to avoid\n     showing errors to the user\n\n  2. pass \"--quiet\" to rev-list\n\nItem (1) is obviously useful. But item (2) is\nsurprisingly not. For rev-list, \"--quiet\" does not have\nanything to do with chattiness on stderr; it tells rev-list\nnot to bother writing the list of traversed objects to\nstdout, for efficiency.  And since we always redirect\nrev-list's stdout to /dev/null in this function, there is no\npoint in asking it to ever write anything to stdout.\n\nThe efficiency gains are modest; a best-of-five run of \"git\nrev-list --objects --all\" on linux.git dropped from 32.013s\nto 30.502s when adding \"--quiet\". That's only about 5%, but\ngiven how easy it is, it's worth doing.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "connected.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/f26eef302fc315394d1016eb06360637ac86f62e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "check_everything_connected_real"
        ],
        "added_lines": 1,
        "deleted_lines": 2,
        "total_changed_lines": 3,
        "net_line_change": -1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "f2cba9299be45f8e027f7b45c6e4a3cae55576c6",
        "author": "Shawn O. Pearce",
        "date": "2011-03-14T17:25:45-07:00",
        "message": "fetch-pack: Finish negotation if remote replies \"ACK %s ready\"\n\nIf multi_ack_detailed was selected in the protocol capabilities\n(both client and server are >= Git 1.6.6) the upload-pack side will\nsend \"ACK %s ready\" when it knows how to safely cut the graph and\nproduce a reasonable pack for the want list that was already sent\non the connection.\n\nUpon receiving \"ACK %s ready\" there is no point in looking at\nthe remaining commits inside of rev_list.  Sending additional\n\"have %s\" lines to the remote will not construct a smaller pack.\nIt is unlikely a commit older than the current cut point will have\na better delta base than the cut point itself has.\n\nThe original design of this code had fetch-pack empty rev_list by\nmarking a commit and its transitive ancestors COMMON whenever the\nremote side said \"ACK %s {continue,common}\" and skipping over any\nalready COMMON commits during get_rev().  This approach does not\nwork when most of rev_list is actually COMMON_REF, commits that\nare pointed to by a reference on the remote, which exist locally,\nand which have not yet been sent to the remote as a \"have %s\" line.\n\nMost of the common references are tags in the ref/tags namespace,\nusing points in the commit graph that are more than 1 commit apart.\nIn git.git itself, this is currently 340 tags, 339 of which point to\ncommits in the commit graph.  fetch-pack pushes all of these into\nrev_list, but is unable to mark them COMMON and discard during a\nremote's \"ACK %s {continue,common}\" because it does not parse through\nthe entire parent chain.  Not parsing the entire parent chain is\nan optimization to avoid walking back to the roots of the repository.\n\nAssuming the client is only following the remote (and does not make\nits own local commits), the client needs 11 rounds to spin through\nthe entire list of tags (32 commits per round, ceil(339/32) == 11).\nUnfortunately the server knows on the first \"have %s\" line that\nit can produce a good pack, and does not need to see the remaining\n320 tags in the other 10 rounds.\n\nOver git:// and ssh:// this isn't as bad as it sounds, the client is\nonly transmitting an extra 16,000 bytes that it doesn't need to send.\n\nOver smart HTTP, the client must do an additional 10 HTTP POST\nrequests, each of which incurs round-trip latency, and must upload\nthe entire state vector of all known common objects.  On the final\nPOST request, this is 16 KiB worth of data.\n\nFix all of this by clearing rev_list as soon as the remote side\nsays it can construct a pack.\n\nSigned-off-by: Shawn O. Pearce <spearce@spearce.org>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/fetch-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/f2cba9299be45f8e027f7b45c6e4a3cae55576c6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "find_common"
        ],
        "added_lines": 2,
        "deleted_lines": 0,
        "total_changed_lines": 2,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "f34242975fae1468dd94d31289d27f68853a28fb",
        "author": "Michael Haggerty",
        "date": "2018-01-24T12:55:26-08:00",
        "message": "packed_ref_iterator_begin(): make optimization more general\n\nWe can return an empty iterator not only if the `packed-refs` file is\nmissing, but also if it is empty or if there are no references whose\nnames succeed `prefix`. Optimize away those cases as well by moving\nthe call to `find_reference_location()` higher in the function and\nchecking whether the determined start position is the same as\n`snapshot->eof`. (This is possible now because the previous commit\nmade `find_reference_location()` robust against empty snapshots.)\n\nSigned-off-by: Michael Haggerty <mhagger@alum.mit.edu>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "refs/packed-backend.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/f34242975fae1468dd94d31289d27f68853a28fb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "packed_ref_iterator_begin"
        ],
        "added_lines": 6,
        "deleted_lines": 6,
        "total_changed_lines": 12,
        "net_line_change": 0,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "f35650dff6a4500e317803165b13cc087f48ee85",
        "author": "Jeff King",
        "date": "2017-07-09T10:00:48-07:00",
        "message": "log: do not free parents when walking reflog\n\nWhen we're doing a reflog walk (instead of walking the\nactual parent pointers), we may see commits multiple times.\nFor this reason, we hold on to the commit buffer for each\ncommit rather than freeing it after we've showed the commit.\n\nWe should do the same for the parent list. Right now this is\njust a minor optimization. But once we refactor how reflog\nwalks are performed, keeping the parents will avoid\nconfusing us the second time we see the commit.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/log.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/f35650dff6a4500e317803165b13cc087f48ee85",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_log_walk"
        ],
        "added_lines": 2,
        "deleted_lines": 2,
        "total_changed_lines": 4,
        "net_line_change": 0,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "f445644fd28d31a828731a618e9a9c79be89efd2",
        "author": "Jeff King",
        "date": "2010-01-05T23:41:50-08:00",
        "message": "run-command: optimize out useless shell calls\n\nIf there are no metacharacters in the program to be run, we\ncan just skip running the shell entirely and directly exec\nthe program.\n\nThe metacharacter test is pulled verbatim from\nlaunch_editor, which already implements this optimization.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "run-command.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/f445644fd28d31a828731a618e9a9c79be89efd2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "prepare_shell_cmd"
        ],
        "added_lines": 11,
        "deleted_lines": 9,
        "total_changed_lines": 20,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "f4f19fb63449e1beee02b0ec845319f7115fa9d0",
        "author": "Jeff King",
        "date": "2009-11-16T13:21:11-08:00",
        "message": "diffcore-break: free filespec data as we go\n\nAs we look at each changed file and consider breaking it, we\nload the blob data and make a decision about whether to\nbreak, which is independent of any other blobs that might\nhave changed. However, we keep the data in memory while we\nconsider breaking all of the other files. Which means that\nboth versions of every file you are diffing are in memory at\nthe same time.\n\nThis patch instead frees the blob data as we finish with\neach file pair, leading to much lower memory usage.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "diffcore-break.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/f4f19fb63449e1beee02b0ec845319f7115fa9d0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "diffcore_break"
        ],
        "added_lines": 4,
        "deleted_lines": 0,
        "total_changed_lines": 4,
        "net_line_change": 4,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "f7400da8005e8af979b61ab2f42bb2dacfa656c8",
        "author": "Orgad Shaneh",
        "date": "2022-05-16T10:58:01-07:00",
        "message": "fetch: limit shared symref check only for local branches\n\nThis check was introduced in 8ee5d73137f (Fix fetch/pull when run without\n--update-head-ok, 2008-10-13) in order to protect against replacing the ref\nof the active branch by mistake, for example by running git fetch origin\nmaster:master.\n\nIt was later extended in 8bc1f39f411 (fetch: protect branches checked out\nin all worktrees, 2021-12-01) to scan all worktrees.\n\nThis operation is very expensive (takes about 30s in my repository) when\nthere are many tags or branches, and it is executed on every fetch, even if\nno local heads are updated at all.\n\nLimit it to protect only refs/heads/* to improve fetch performance.\n\nSigned-off-by: Orgad Shaneh <orgads@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/fetch.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/f7400da8005e8af979b61ab2f42bb2dacfa656c8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "check_not_current_branch"
        ],
        "added_lines": 1,
        "deleted_lines": 0,
        "total_changed_lines": 1,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "f80c153bea4e0ea86f5b6d32e77df0b69501ee18",
        "author": "Jeff King",
        "date": "2015-04-16T08:15:05-07:00",
        "message": "strbuf_getwholeline: avoid calling strbuf_grow\n\nAs with the recent speedup to strbuf_addch, we can avoid\ncalling strbuf_grow() in a tight loop of single-character\nadds by instead checking strbuf_avail.\n\nNote that we would instead call strbuf_addch directly here,\nbut it does more work than necessary: it will NUL-terminate\nthe result for each character read. Instead, in this loop we\nread the characters one by one and then add the terminator\nmanually at the end.\n\nRunning \"git rev-parse refs/heads/does-not-exist\" on a repo\nwith an extremely large (1.6GB) packed-refs file went from\n(best-of-5):\n\n  real    0m10.948s\n  user    0m10.548s\n  sys     0m0.412s\n\nto:\n\n  real    0m8.601s\n  user    0m8.084s\n  sys     0m0.524s\n\nfor a wall-clock speedup of 21%.\n\nHelped-by: Eric Sunshine <sunshine@sunshineco.com>\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "strbuf.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/f80c153bea4e0ea86f5b6d32e77df0b69501ee18",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "strbuf_getwholeline"
        ],
        "added_lines": 2,
        "deleted_lines": 1,
        "total_changed_lines": 3,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "f8263c5339fd70ee00b60c37b715c7e46b30a3bf",
        "author": "Alexandre Julliard",
        "date": "2006-07-23T23:44:00-07:00",
        "message": "show-branch: Fix another performance problem.\n\nWhen naming commits, stop walking the parent chain as soon as we find\na commit that already has a name. The parent chain of that commit will\nbe walked later on in any case (or may even have been walked already).\nThis avoids O(n^2) behavior; on a tree where show-branch displays 6800\ncommits, the total run time drops from 77 seconds to 5 seconds.\n\nSigned-off-by: Alexandre Julliard <julliard@winehq.org>\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin-show-branch.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/f8263c5339fd70ee00b60c37b715c7e46b30a3bf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "name_first_parent_chain"
        ],
        "added_lines": 2,
        "deleted_lines": 0,
        "total_changed_lines": 2,
        "net_line_change": 2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "f89201494308524a92eff5995d122e8553c36508",
        "author": "David Kastrup",
        "date": "2019-04-03T16:45:26+09:00",
        "message": "blame.c: don't drop origin blobs as eagerly\n\nWhen a parent blob already has chunks queued up for blaming, dropping\nthe blob at the end of one blame step will cause it to get reloaded\nright away, doubling the amount of I/O and unpacking when processing a\nlinear history.\n\nKeeping such parent blobs in memory seems like a reasonable optimization\nthat should incur additional memory pressure mostly when processing the\nmerges from old branches.\n\nSigned-off-by: David Kastrup <dak@gnu.org>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "blame.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/f89201494308524a92eff5995d122e8553c36508",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "pass_blame"
        ],
        "added_lines": 2,
        "deleted_lines": 1,
        "total_changed_lines": 3,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "f9b8908b85247ef60001a683c281af0080e9ee77",
        "author": "Derrick Stolee",
        "date": "2018-05-22T12:36:34+09:00",
        "message": "commit: use generation numbers for in_merge_bases()\n\nThe containment algorithm for 'git branch --contains' is different\nfrom that for 'git tag --contains' in that it uses is_descendant_of()\ninstead of contains_tag_algo(). The expensive portion of the branch\nalgorithm is computing merge bases.\n\nWhen a commit-graph file exists with generation numbers computed,\nwe can avoid this merge-base calculation when the target commit has\na larger generation number than the initial commits.\n\nPerformance tests were run on a copy of the Linux repository where\nHEAD is contained in v4.13 but no earlier tag. Also, all tags were\ncopied to branches and 'git branch --contains' was tested:\n\nBefore: 60.0s\nAfter:   0.4s\nRel %: -99.3%\n\nReported-by: Jeff King <peff@peff.net>\nSigned-off-by: Derrick Stolee <dstolee@microsoft.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "commit.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/f9b8908b85247ef60001a683c281af0080e9ee77",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "in_merge_bases_many"
        ],
        "added_lines": 8,
        "deleted_lines": 1,
        "total_changed_lines": 9,
        "net_line_change": 7,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "fa6758e9afb7cbd211e38b6f81e9d21872d97338",
        "author": "Junio C Hamano",
        "date": "2018-07-24T14:50:46-07:00",
        "message": "Merge branch 'mh/fast-import-no-diff-delta-empty'\n\n\"git fast-import\" has been updated to avoid attempting to create\ndelta against a zero-byte-long string, which is pointless.\n\n* mh/fast-import-no-diff-delta-empty:\n  fast-import: do not call diff_delta() with empty buffer",
        "modified_files_count": 1,
        "modified_files": [
            "fast-import.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/fa6758e9afb7cbd211e38b6f81e9d21872d97338",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "store_object"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "fa96082617e07d988103854fb96c5e92b7587e72",
        "author": "Jeff King",
        "date": "2014-07-13T18:59:05-07:00",
        "message": "diff-tree: avoid lookup_unknown_object\n\nWe generally want to avoid lookup_unknown_object, because it\nresults in allocating more memory for the object than may be\nstrictly necessary.\n\nIn this case, it is used to check whether we have an\nalready-parsed object before calling parse_object, to save\nus from reading the object from disk. Using lookup_object\nwould be fine for that purpose, but we can take it a step\nfurther. Since this code was written, parse_object already\nlearned the \"check lookup_object\" optimization, so we can\nsimply call parse_object directly.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/diff-tree.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/fa96082617e07d988103854fb96c5e92b7587e72",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "diff_tree_stdin"
        ],
        "added_lines": 1,
        "deleted_lines": 3,
        "total_changed_lines": 4,
        "net_line_change": -2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "fb62eb7fab97cea880ea7fe4f341a4dfad14ab48",
        "author": "Ren\u00e9 Scharfe",
        "date": "2009-01-09T21:33:35-08:00",
        "message": "grep -w: forward to next possible position after rejected match\n\ngrep -w accepts matches between non-word characters, only.  If a match\nfrom regexec() doesn't meet this criteria, grep continues its search\nafter the first character of that match.\n\nWe can be a bit smarter here and skip all positions that follow a word\ncharacter first, as they can't match our criteria.  This way we can\nconsume characters quite cheaply and don't need to special-case the\nhandling of the beginning of a line.\n\nHere's a contrived example command on msysgit (best of five runs):\n\n\t$ time git grep -w ...... v1.6.1 >/dev/null\n\n\treal    0m1.611s\n\tuser    0m0.000s\n\tsys     0m0.015s\n\nWith the patch it's quite a bit faster:\n\n\t$ time git grep -w ...... v1.6.1 >/dev/null\n\n\treal    0m1.179s\n\tuser    0m0.000s\n\tsys     0m0.015s\n\nMore common search patterns will gain a lot less, but it's a nice clean\nup anyway.\n\nSigned-off-by: Rene Scharfe <rene.scharfe@lsrfire.ath.cx>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "grep.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/fb62eb7fab97cea880ea7fe4f341a4dfad14ab48",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "match_one_pattern"
        ],
        "added_lines": 7,
        "deleted_lines": 4,
        "total_changed_lines": 11,
        "net_line_change": 3,
        "modified_code_blocks": 4,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "fb79947487b628ec82bc0ad46a08629539a59091",
        "author": "Ren\u00e9 Scharfe",
        "date": "2014-06-02T13:51:22-07:00",
        "message": "pack-objects: use free()+xcalloc() instead of xrealloc()+memset()\n\nWhenever the hash table becomes too small then its size is increased,\nthe original part (and the added space) is zerod out using memset(),\nand the table is rebuilt from scratch.\n\nSimplify this proceess by returning the old memory using free() and\nallocating the new buffer using xcalloc(), which already clears the\nbuffer for us.  That way we avoid copying the old hash table contents\nneedlessly inside xrealloc().\n\nWhile at it, use the first array member with sizeof instead of a\nspecific type.  The old code used uint32_t and int, while index is\nactually an array of int32_t.  Their sizes are the same basically\neverywhere, so it's not actually a problem, but the new code is\ncleaner and doesn't have to be touched should the type be changed.\n\nSigned-off-by: Rene Scharfe <l.s.r@web.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "pack-objects.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/fb79947487b628ec82bc0ad46a08629539a59091",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "rehash_objects"
        ],
        "added_lines": 2,
        "deleted_lines": 2,
        "total_changed_lines": 4,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "fbab552a53a2558ec84a06034e6657fb95227266",
        "author": "Jeff King",
        "date": "2019-09-12T12:29:58-07:00",
        "message": "commit-graph: bump DIE_ON_LOAD check to actual load-time\n\nCommit 43d3561805 (commit-graph write: don't die if the existing graph\nis corrupt, 2019-03-25) added an environment variable we use only in the\ntest suite, $GIT_TEST_COMMIT_GRAPH_DIE_ON_LOAD. But it put the check for\nthis variable at the very top of prepare_commit_graph(), which is called\nevery time we want to use the commit graph. Most importantly, it comes\n_before_ we check the fast-path \"did we already try to load?\", meaning\nwe end up calling getenv() for every single use of the commit graph,\nrather than just when we load.\n\ngetenv() is allowed to have unexpected side effects, but that shouldn't\nbe a problem here; we're lazy-loading the graph so it's clear that at\nleast _one_ invocation of this function is going to call it.\n\nBut it is inefficient. getenv() typically has to do a linear search\nthrough the environment space.\n\nWe could memoize the call, but it's simpler still to just bump the check\ndown to the actual loading step. That's fine for our sole user in t5318,\nand produces this minor real-world speedup:\n\n  [before]\n  Benchmark #1: git -C linux rev-list HEAD >/dev/null\n    Time (mean \u00b1 \u03c3):      1.460 s \u00b1  0.017 s    [User: 1.174 s, System: 0.285 s]\n    Range (min \u2026 max):    1.440 s \u2026  1.491 s    10 runs\n\n  [after]\n  Benchmark #1: git -C linux rev-list HEAD >/dev/null\n    Time (mean \u00b1 \u03c3):      1.391 s \u00b1  0.005 s    [User: 1.118 s, System: 0.273 s]\n    Range (min \u2026 max):    1.385 s \u2026  1.399 s    10 runs\n\nOf course that actual speedup depends on how big your environment is. We\ncan game it like this:\n\n  for i in $(seq 10000); do\n    export dummy$i=$i\n  done\n\nin which case I get:\n\n  [before]\n  Benchmark #1: git -C linux rev-list HEAD >/dev/null\n    Time (mean \u00b1 \u03c3):      6.257 s \u00b1  0.061 s    [User: 6.005 s, System: 0.250 s]\n    Range (min \u2026 max):    6.174 s \u2026  6.337 s    10 runs\n\n  [after]\n  Benchmark #1: git -C linux rev-list HEAD >/dev/null\n  Time (mean \u00b1 \u03c3):      1.403 s \u00b1  0.005 s    [User: 1.146 s, System: 0.256 s]\n  Range (min \u2026 max):    1.396 s \u2026  1.412 s    10 runs\n\nSo this is really more about avoiding the pathological case than\nproviding a big real-world speedup.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "commit-graph.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/fbab552a53a2558ec84a06034e6657fb95227266",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "prepare_commit_graph"
        ],
        "added_lines": 4,
        "deleted_lines": 4,
        "total_changed_lines": 8,
        "net_line_change": 0,
        "modified_code_blocks": 2,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "fbac558a9bde48fa23b9c536357ab17c71b4bd22",
        "author": "Ren\u00e9 Scharfe",
        "date": "2018-01-16T13:21:51-08:00",
        "message": "describe: use strbuf_add_unique_abbrev() for adding short hashes\n\nCall strbuf_add_unique_abbrev() to add an abbreviated hash to a strbuf\ninstead of taking a detour through find_unique_abbrev() and its static\nbuffer.  This is shorter and a bit more efficient.\n\nPatch generated by Coccinelle (and contrib/coccinelle/strbuf.cocci).\n\nSigned-off-by: Rene Scharfe <l.s.r@web.de>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/describe.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/fbac558a9bde48fa23b9c536357ab17c71b4bd22",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "describe_commit"
        ],
        "added_lines": 1,
        "deleted_lines": 1,
        "total_changed_lines": 2,
        "net_line_change": 0,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "fbd4a7036dfa71ec89e7c441cef1ac9aaa59a315",
        "author": "Nguy\u1ec5n Th\u00e1i Ng\u1ecdc Duy",
        "date": "2013-08-28T11:54:18-07:00",
        "message": "list-objects: mark more commits as edges in mark_edges_uninteresting\n\nThe purpose of edge commits is to let pack-objects know what objects\nit can use as base, but does not need to include in the thin pack\nbecause the other side is supposed to already have them. So far we\nmark uninteresting parents of interesting commits as edges. But even\nan unrelated uninteresting commit (that the other side has) may\nbecome a good base for pack-objects and help produce more efficient\npacks.\n\nThis is especially true for shallow clone, when the client issues a\nfetch with a depth smaller or equal to the number of commits the\nserver is ahead of the client. For example, in this commit history\nthe client has up to \"A\" and the server has up to \"B\":\n\n    -------A---B\n     have--^   ^\n              /\n       want--+\n\nIf depth 1 is requested, the commit list to send to the client\nincludes only B. The way m_e_u is working, it checks if parent\ncommits of B are uninteresting, if so mark them as edges.  Due to\nshallow effect, commit B is grafted to have no parents and the\nrevision walker never sees A as the parent of B. In fact it marks no\nedges at all in this simple case and sends everything B has to the\nclient even if it could have excluded what A and also the client\nalready have.\n\nIn a slightly different case where A is not a direct parent of B\n(iow there are commits in between A and B), marking A as an edge can\nstill save some because B may still have stuff from the far ancestor\nA.\n\nThere is another case from the earlier patch, when we deepen a ref\nfrom C->E to A->E:\n\n    ---A---B   C---D---E\n     want--^   ^       ^\n       shallow-+      /\n          have-------+\n\nIn this case we need to send A and B to the client, and C (i.e. the\ncurrent shallow point that the client informs the server) is a very\ngood base because it's closet to A and B. Normal m_e_u won't recognize\nC as an edge because it only looks back to parents (i.e. A<-B) not the\nopposite way B->C even if C is already marked as uninteresting commit\nby the previous patch.\n\nThis patch includes all uninteresting commits from command line as\nedges and lets pack-objects decide what's best to do. The upside is we\nhave better chance of producing better packs in certain cases. The\ndownside is we may need to process some extra objects on the server\nside.\n\nFor the shallow case on git.git, when the client is 5 commits behind\nand does \"fetch --depth=3\", the result pack is 99.26 KiB instead of\n4.92 MiB.\n\nReported-and-analyzed-by: Matthijs Kooijman <matthijs@stdin.nl>\nSigned-off-by: Nguy\u1ec5n Th\u00e1i Ng\u1ecdc Duy <pclouds@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "list-objects.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/fbd4a7036dfa71ec89e7c441cef1ac9aaa59a315",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mark_edges_uninteresting"
        ],
        "added_lines": 17,
        "deleted_lines": 0,
        "total_changed_lines": 17,
        "net_line_change": 17,
        "modified_code_blocks": 3,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "fbe082a528861af785be15bb37d1c7d8f574daa4",
        "author": "Linus Torvalds",
        "date": "2005-05-26T17:41:28-07:00",
        "message": "git-diff-tree: don't use diffcore_pathspec()\n\ndiff-tree does the culling of uninteresting paths internally, and\nfundamentally has to do so for performance reasons. So there's no\npoint in calling the separate pathname culling logic here,\nespecially as it seems slightly broken.",
        "modified_files_count": 1,
        "modified_files": [
            "diff-tree.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/fbe082a528861af785be15bb37d1c7d8f574daa4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "call_diff_flush"
        ],
        "added_lines": 0,
        "deleted_lines": 2,
        "total_changed_lines": 2,
        "net_line_change": -2,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "fbff95b67f7e7bfc8799c2d6d16263cfeb61bc6f",
        "author": "Jeff King",
        "date": "2020-08-21T12:02:36-07:00",
        "message": "index-pack: adjust default threading cap\n\nCommit b8a2486f15 (index-pack: support multithreaded delta resolving,\n2012-05-06) describes an experiment that shows that setting the number\nof threads for index-pack higher than 3 does not help.\n\nI repeated that experiment using a more modern version of Git and a more\nmodern CPU and got different results.\n\nHere are timings for p5302 against linux.git run on my laptop, a Core\ni9-9880H with 8 cores plus hyperthreading (so online-cpus returns 16):\n\n  5302.3: index-pack 0 threads                   256.28(253.41+2.79)\n  5302.4: index-pack 1 threads                   257.03(254.03+2.91)\n  5302.5: index-pack 2 threads                   149.39(268.34+3.06)\n  5302.6: index-pack 4 threads                   94.96(294.10+3.23)\n  5302.7: index-pack 8 threads                   68.12(339.26+3.89)\n  5302.8: index-pack 16 threads                  70.90(655.03+7.21)\n  5302.9: index-pack default number of threads   116.91(290.05+3.21)\n\nYou can see that wall-clock times continue to improve dramatically up to\nthe number of cores, but bumping beyond that (into hyperthreading\nterritory) does not help (and in fact hurts a little).\n\nHere's the same experiment on a machine with dual Xeon 6230's, totaling\n40 cores (80 with hyperthreading):\n\n  5302.3: index-pack 0 threads                    310.04(302.73+6.90)\n  5302.4: index-pack 1 threads                    310.55(302.68+7.40)\n  5302.5: index-pack 2 threads                    178.17(304.89+8.20)\n  5302.6: index-pack 5 threads                    99.53(315.54+9.56)\n  5302.7: index-pack 10 threads                   72.80(327.37+12.79)\n  5302.8: index-pack 20 threads                   60.68(357.74+21.66)\n  5302.9: index-pack 40 threads                   58.07(454.44+67.96)\n  5302.10: index-pack 80 threads                  59.81(720.45+334.52)\n  5302.11: index-pack default number of threads   134.18(309.32+7.98)\n\nThe results are similar; things stop improving at 40 threads. Curiously,\ngoing from 20 to 40 really doesn't help much, either (and increases CPU\ntime considerably). So that may represent an actual barrier to\nparallelism, where we lose out due to context-switching and loss of\ncache locality, but don't reap the wall-clock benefits due to contention\nof our coarse-grained locks.\n\nSo what's a good default value? It's clear that the current cap of 3 is\ntoo low; our default values are 42% and 57% slower than the best times\non each machine. The results on the 40-core machine imply that 20\nthreads is an actual barrier regardless of the number of cores, so we'll\ntake that as a maximum. We get the best results on these machines at\nhalf of the online-cpus value. That's presumably a result of the\nhyperthreading. That's common on multi-core Intel processors, but not\nnecessarily elsewhere. But if we take it as an assumption, we can\nperform optimally on hyperthreaded machines and still do much better\nthan the status quo on other machines, as long as we never half below\nthe current value of 3.\n\nSo that's what this patch does.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin/index-pack.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/fbff95b67f7e7bfc8799c2d6d16263cfeb61bc6f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cmd_index_pack"
        ],
        "added_lines": 16,
        "deleted_lines": 3,
        "total_changed_lines": 19,
        "net_line_change": 13,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "fe5f51ce277df00cb01dfc984dba1e7128718e41",
        "author": "Linus Torvalds",
        "date": "2005-10-18T18:41:28-07:00",
        "message": "Optimize common case of git-rev-list\n\nI took a look at webgit, and it looks like at least for the \"projects\"\npage, the most common operation ends up being basically\n\n\tgit-rev-list --header --parents --max-count=1 HEAD\n\nNow, the thing is, the way \"git-rev-list\" works, it always keeps on\npopping the parents and parsing them in order to build the list of\nparents, and it turns out that even though we just want a single commit,\ngit-rev-list will invariably look up _three_ generations of commits.\n\nIt will parse:\n - the commit we want (it obviously needs this)\n - it's parent(s) as part of the \"pop_most_recent_commit()\" logic\n - it will then pop one of the parents before it notices that it doesn't\n   need any more\n - and as part of popping the parent, it will parse the grandparent (again\n   due to \"pop_most_recent_commit()\".\n\nNow, I've strace'd it, and it really is pretty efficient on the whole, but\nif things aren't nicely cached, and with long-latency IO, doing those two\nextra objects (at a minimum - if the parent is a merge it will be more) is\njust wasted time, and potentially a lot of it.\n\nSo here's a quick special-case for the trivial case of \"just one commit,\nand no date-limits or other special rules\".\n\nSigned-off-by: Linus Torvalds <torvalds@osdl.org>\nSigned-off-by: Junio C Hamano <junkio@cox.net>",
        "modified_files_count": 1,
        "modified_files": [
            "rev-list.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/fe5f51ce277df00cb01dfc984dba1e7128718e41",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "added_lines": 5,
        "deleted_lines": 0,
        "total_changed_lines": 5,
        "net_line_change": 5,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    },
    {
        "repository_name": "git",
        "hash": "fec501dae8bf6c8fdcd4124c94f37c4cbc26ba29",
        "author": "Jeff King",
        "date": "2015-04-16T08:15:05-07:00",
        "message": "strbuf_addch: avoid calling strbuf_grow\n\nWe mark strbuf_addch as inline, because we expect it may be\ncalled from a tight loop. However, the first thing it does\nis call the non-inline strbuf_grow(), which can handle\narbitrary-sized growth. Since we know that we only need a\nsingle character, we can use the inline strbuf_avail() to\nquickly check whether we need to grow at all.\n\nOur check is redundant when we do call strbuf_grow(), but\nthat's OK. The common case is that we avoid calling it at\nall, and we have made that case faster.\n\nOn a silly pathological case:\n\n  perl -le '\n    print \"[core]\";\n    print \"key$_ = value$_\" for (1..1000000)\n  ' >input\n  git config -f input core.key1\n\nthis dropped the time to run git-config from:\n\n  real    0m0.159s\n  user    0m0.152s\n  sys     0m0.004s\n\nto:\n\n  real    0m0.140s\n  user    0m0.136s\n  sys     0m0.004s\n\nfor a savings of 12%.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "strbuf.h"
        ],
        "github_commit_url": "https://github.com/git/git/commit/fec501dae8bf6c8fdcd4124c94f37c4cbc26ba29",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "strbuf_addch"
        ],
        "added_lines": 2,
        "deleted_lines": 1,
        "total_changed_lines": 3,
        "net_line_change": 1,
        "modified_code_blocks": 1,
        "is_opt_ds_simple": "true"
    }
]